machine_learning	a high degree of uncertainty associated with the emission inventory for china tends to degrade the performance of chemical transport models in predicting pm2.5 concentrations especially on a daily basis. in this study a novel machine learning algorithm, geographically -weighted gradient boosting machine (gw-gbm), was developed by improving gbm through building spatial smoothing kernels to weigh the loss function. this modification addressed the spatial nonstationarity of the relationships between pm2.5 concentrations and predictor variables such as aerosol optical depth (aod) and meteorological conditions. gw-gbm also overcame the estimation bias of pm2.5 concentrations due to missing aod retrievals, and thus potentially improved subsequent exposure analyses. gw-gbm showed good performance in predicting daily pm2.5 concentrations (r-2 = 0.76, rmse = 23.0 g/m(3)) even with partially missing aod data, which was better than the original gbm model (r-2 = 0.71, rmse = 25.3 g/m(3)). on the basis of the continuous spatiotemporal prediction of pm2.5 concentrations, it was predicted that 95% of the population lived in areas where the estimated annual mean pm2.5 concentration was higher than 35 g/m(3), and 45% of the population was exposed to pm2.5 >75 g/m(3) for over 100 days in 2014. gw-gbm accurately predicted continuous daily pm2.5 concentrations in china for assessing acute human health effects. (c) 2017 elsevier ltd. all rights reserved.
data_structures	this paper presents an unsupervised approach to feature binary coding for efficient semantic image retrieval. although the majority of the existing methods aim to preserve neighborhood structures of the feature space, semantically similar images are not always in such neighbors but are rather distributed in non-linear low-dimensional manifolds. moreover, images are rarely alone on the internet and are often surrounded by text data such as tags, attributes, and captions, which tend to carry rich semantic information about the images. on the basis of these observations, the approach presented in this paper aims at learning binary codes for semantic image retrieval using multimodal information sources while preserving the essential low-dimensional structures of the data distributions in the hamming space. specifically, after finding the low-dimensional structures of the data by using an unsupervised sparse coding technique, our approach learns a set of linear projections for binary coding by solving an optimization problem which is designed to jointly preserve the extracted data structures and multimodal data correlations between images and texts in the hamming space as much as possible. we show that the joint optimization problem can readily be transformed into a generalized eigenproblem that can be efficiently solved. extensive experiments demonstrate that our method yields significant performance gains over several existing methods.
state_space_representation	this article presents and analyzes the implementation of risk-sensitive particle filtering algorithm for volatility estimation of continuously compounded returns of financial assets. the proposed approach uses a stochastic state-space representation for the evolution of the dynamic system -the unobserved generalized autoregressive conditional heteroskedasticity (ugarch)model- and an inverse gamma distribution as risk functional (and importance density distribution) to ensure the allocation of particles in regions of the state-space that are associated to sudden changes in the volatility of the system. a set of ad-hoc performance and entropy-based measures is used to compare the performance of this scheme with respect to a classic implementation of sequential monte carlo methods, both in terms of accuracy and precision of the resulting volatility estimates; considering for this purpose data sets generated in a blind-test format with garch structures and time-varying parameters.
machine_learning	the detection of negative emotions through daily activities such as writing and drawing is useful for promoting wellbeing. the spread of human-machine interfaces such as tablets makes the collection of handwriting and drawing samples easier. in this context, we present a first publicly available database which relates emotional states to handwriting and drawing, that we call emothaw (emotion recognition from handwriting and drawing). this database includes samples of 129 participants whose emotional states, namely anxiety, depression, and stress, are assessed by the depression-anxiety-stress scales (dass) questionnaire. seven tasks are recorded through a digitizing tablet: pentagons and house drawing, words copied in handprint, circles and clock drawing, and one sentence copied in cursive writing. records consist in pen positions, on-paper and in-air, time stamp, pressure, pen azimuth, and altitude. we report our analysis on this database. from collected data, we first compute measurements related to timing and ductus. we compute separate measurements according to the position of the writing device: on paper or inair. we analyze and classify this set of measurements (referred to as features) using a random forest approach. this latter is a machine learning method [1], based on an ensemble of decision trees, which includes a feature ranking process. we use this ranking process to identify the features which best reveal a targeted emotional state. we then build random forest classifiers associated with each emotional state. we provide accuracy, sensitivity, and specificity evaluation measures obtained from cross-validation experiments. our results showthat anxiety and stress recognition perform better than depression recognition.
electricity	rural electrification rates in india lag behind government goals, in part due to the inability of distribution companies (discoms) to fund central grid expansion. in the absence of central grid electrification, mini-grids offer significant potential for an immediate pathway toward rural electrification and the attendant gains in economic growth and productivity. yet private investment in mini-grids has been virtually absent in india. using a comprehensive life-cycle cost analysis, we find that mini-grids based on solar pv power and storage are more economical than incumbent energy services available to households without central grid connection. under current law, a prospective entrepreneur in india does not require a license or certification in order to build a mini-grid and subsequently provide electricity services in the area covered by said installation. conversely, there is no legal or regulatory framework that specifies what is to happen if the central grid were to be extended to an area that is already covered by a mini-grid. we report detailed survey evidence from interviews with entrepreneurs, analysts and policymakers whose assessments converge on the same point: mini-grid investments would be jeopardized in the event of central grid extension, precisely because discoms would, by regulatory order, provide electricity services at highly subsidized rates, well below their full economic cost. our fieldwork suggests that the threat of central grid extension is a gateway barrier preventing mini-grid development in india. the issues associated with the gateway barrier have common elements with the so-called holdup problem as identified in the economics of organizations. there have been two recent federal policy guidelines and one actual state-level policy addressing the regulatory status of mini-grids. we examine the effectiveness of these policies/proposals in terms of an entrepreneur 's willingness to develop mini-grids in the future. (c) 2016 elsevier ltd. all rights reserved.
electrical_circuits	silicon photonics which is compatible with mature complementary metal oxide semiconductor (cmos) fabrication process has been extensively demonstrated for monolithic integration of photonic and electrical circuits. we show that an integrated silicon mach-zehnder modulator (mzm) may be used for advanced modulation formats despite the nonlinear dependence of refractive index change with applied voltage in the free-carrier depletion modulator. we experimentally demonstrated the use of a silicon mzm for direct detection optical orthogonal frequency division multiplexing (ddo-ofdm) modulation with advanced data formats of quadrature phase-shift keying (qpsk), 8 phase-shift keying (8psk) and 16-quadrature amplitude modulation (16-qam). the measured bit error rate performance of the back-to-back and 50 km single mode fiber transmission of each format is well below the forward error correction limit.
pid_controller	the imbalance between the generated power and the load demand is the major factor that is usually responsible for frequency instability in power systems, most especially islanded microgrids. to determine the size of the loads that should be shed and their appropriate locations in the power system, to maintain the system frequency within the permissible limits, this paper presents an effective adaptive control scheme. in the proposed controller, a stepwise load-shedding approach is designed in the islanded mgs to regulate the grid frequency while providing the amount of power shortage. to this achieve, it locally measures the system parameters most especially voltage and frequency signals. thereafter, a stepwise load-shedding will take place in locations where the highest voltage drop and frequency variation are experienced. the load-shedding step changes according to certain factors such as shedding speed, location and value, and the rate of frequency change. the proposed approach eliminates the adjustable loads to return the frequency back to the desired value. simulation results of the proposed method under different practical scenarios, when compared with the conventional pid controller, provide considerable enhancement in the power system frequency stability. (c) 2016 elsevier b.v. all rights reserved.
cryptography	a seamless and secure handover is always one of the important design goals of the cellular networks. the handover scheme of 4g long term evolution (lte) wireless networks is complex due to the presence of two possible different types of base stations. in lte communication systems, a normal base station is referred to as an enodeb (enb). what increases the level of complexity of the system is the fact that the other kind of base stations, namely, home enodeb (henb), cannot directly communicate with enb. in the lte networks, the handover scenarios involving a henb could result in a complicated handover procedure. besides, since key chains have been used in the handover processes, it is found to be lack of backward security. therefore, in order to handle the handover involving a henb efficiently with security provisioning, in this paper, a proxy signature based handover scheme is proposed. the proposed scheme works based on the elliptic curve cryptography (ecc) algorithm, which makes the computational cost of the handover process smaller compared to other handover schemes.
microcontroller	this research investigated a method to optimize the start-up performance of a dimmable light-emitting diode (led) driver based on half-bridge class d series-parallel lcc topology. this led driver is designed for outdoor or high bay applications with 347-480 v-ac input voltage. the total maximum output power is 100 w with a wide tunable output current range (from 50 to 800 ma). the wide load range makes it difficult to achieve a startup time of less than 1 s under each load condition as well as limit the output overshoot level to below 150% by implementing only one set of ki values in the feedback loop. moreover, in this design, a fluorescent control ic is used due to the cost efficiency of repurposing existing fluorescent ballast manufacturing systems. the start-up sequence of the fluorescent control ic introduces an additional challenge to the start-up design. in order to comply with energy star, which requires the output current to reach 75% of its nominal value and also limit the overshoot level, a self-adjusted-duty-cycle control algorithm is designed. this duty-cycle signal generated by measuring the load condition through a secondary side microcontroller is used to determine the switching frequency of the lcc tank. with this method, the start-up performance is greatly improved and meets all requirements.
analog_signal_processing	this paper presents precision full-wave rectifier for low-level signal with operational conveyor and current mirrors. operational conveyor circuit topology, based on current-steering output stage, is also described and analyzed. the current-mode full-wave rectifier is realized with four unity-gain current mirrors and three dc current sources. pspice program was used to verify the proposed design of the operational conveyor and precision full-wave rectifier. the results of the simulation are presented and compared with simulation results of the realization that was published.
cryptography	we present new connections between quantum information and the field of classical cryptography. in particular, we provide examples where simon 's algorithm can be used to show insecurity of commonly used cryptographic symmetric-key primitives. specifically, these examples consist of a quantum distinguisher for the 3-round feistel network and a forgery attack on cbc-mac which forges a tag for a chosen-prefix message querying only other messages (of the same length). we assume that an adversary has quantum-oracle access to the respective classical primitives. similar results have been achieved recently in independent work by kaplan et al. [kllnp16]. our findings shed new light on the post-quantum security of cryptographic schemes and underline that classical security proofs of cryptographic constructions need to be revisited in light of quantum attackers.
algorithm_design	with the development of the communication technology and the intelligent terminal, the artificial attendance based on the intelligent terminal technology and mobile communication technology is replaced by the attendance and replacement. based on this, on the basis of existing research on the aloha anti-collision strategy, and improved it for mobile positioning attendance. firstly, the algorithm design, and then gives terminal specific operation, and finally carried out experiments and comparative analysis of simulation results show that the improved aloha algorithm outperforms traditional anti-collision algorithm, ensuring the system has a shorter at the same time delay, can effectively improve the throughput performance.
digital_control	this work presents a novel mixed-signal control scheme for a boost power factor correction (pfc) rectifier. the digital controller modulates the inductor peak current to produce a low-distortion ac line current in discontinuous conduction mode (dcm) and continuous conduction mode (ccm), without the need for average current sensing. a lookup table (lut) optimizes efficiency at low input currents, by allowing operation at 125-500-khz dcm based on calculated thresholds. at high input currents, the converter operates at 1-mhz ccm for reduced inductor footprint. an analog off-time generator with a digital frequency locked loop facilitates ccm operation, eliminating the need for slope compensation in the current loop and reduces frequency variations. the lut is programmed with an adaptive output voltage of 250/450 v for low/highmains line voltage (85-265vrms) to optimize efficiency over a broad range of conditions. the 150-w pfc prototype operates up to 1 mhz with a peak efficiency of 95% and a total harmonic distortion of 5%.
distributed_computing	one of the major challenges in digital forensics today is data encryption. due to the leaked information about unlawful sniffing, many users decided to protect their data by encryption. in case of criminal activities, forensic experts are challenged how to decipher suspects' data that are subject to investigation. a common method how to overcome password-based protection is a brute force password recovery using gpu-accelerated hardware. this approach seems to be expensive. this paper presents an alternative approach using task distribution based on boinc platform. the cost, time, and energy efficiency of this approach is discussed and compared to the gpu-based solution.
microcontroller	we validate a hol4 model of the arm cortex-m0 microcontroller core by testing the model 's behaviour on randomly chosen instructions against real chips from several manufacturers. the model and our intended application involve precise timing information about instruction execution, but the implementations are pipelined, so checking the behaviour of single instructions would not give us sufficient confidence in the model. thus we test the model using sequences of randomly chosen instructions. the main challenge is to meet the constraints on the initial and intermediate execution states: we must ensure that memory accesses are in range and that we respect restrictions on the instructions. by careful transformation of these constraints an off-the-shelf smt solver can be used to find suitable states for executing test sequences. we also use additional constraints to test our hypotheses about the timing anomalies encountered. (c) 2015 elsevier b.v. all rights reserved.
symbolic_computation	factorization of polynomials is one of the foundations of symbolic computation. its applications arise in numerous branches of mathematics and other sciences. however, the present advanced programming languages such as c++ and j++, do not support symbolic computation directly. hence, it leads to difficulties in applying factorization in engineering fields. in this paper, the authors present an algorithm which use numerical method to obtain exact factors of a bivariate polynomial with rational coefficients. the proposed method can be directly implemented in efficient programming language such c++ together with the gnu multiple-precision library. in addition, the numerical computation part often only requires double precision and is easily parallelizable.
parallel_computing	for a decision table, it is firstly proved that the effective pair is equivalent to improved discernibility matrix to guarantee that the attribute reduction based on discernibility matrix can be calculated by effective pair. to get the attribute reduction more quickly, a parallel radix sort model is proposed. then a simple decision table and effective pair are obtained. taking the length of distinguishable or indistinguishable elements string among the effective pair as heuristic information, an attribute reduction algorithm based on parallel logical or is proposed. finally, the examples and experiments are shown to verify the effectiveness and feasibility of the proposed algorithm.
operating_systems	modern discrete gpus have been the processors of choice for accelerating compute-intensive applications, but using them in large-scale data processing is extremely challenging. unfortunately, they do not provide important i/o abstractions long established in the cpu context, such as memory mapped files, which shield programmers from the complexity of buffer and i/o device management. however, implementing these abstractions on gpus poses a problem: the limited gpu virtual memory system provides no address space management and page fault handling mechanisms to gpu developers, and does not allow modifications to memory mappings for running gpu programs. we implement activepointers, a software address translation layer and paging system that introduces native support for page faults and virtual address space management to gpu programs, and enables the implementation of fully functional memory mapped files on commodity gpus. files mapped into gpu memory are accessed using active pointers, which behave like regular pointers but access the gpu page cache under the hood, and trigger page faults which are handled on the gpu. we design and evaluate a number of novel mechanisms, including a translation cache in hardware registers and translation aggregation for deadlock-free page fault handling of threads in a single warp. we extensively evaluate activepointers on commodity nvidia gpus using microbenchmarks, and also implement a complex image processing application that constructs a photo collage from a subset of 10 million images stored in a 40gb file. the gpu implementation maps the entire file into gpu memory and accesses it via active pointers. the use of active pointers adds only up to 1% to the application 's runtime, while enabling speedups of up to 3.9x over a combined cpu+gpu implementation and 2.6x over a 12-core cpu-only implementation which uses avx vector instructions.
electrical_circuits	conducting polymers have been used for many years as coating materials against corrosion. however, the coated materials absorb water over time resulting in reduction of resistivity and anticorrosion properties. in this study, poly(n-ethylpyrrole) (p(n-mpy)) and p(n-mpy)/titanium dioxide ((tio2) nanocomposite films were synthesized in 0.5 m oxalic acid solution on al 1050 electrode by chronoamperometric method. the modified electrodes were characterized by scanning electron microscopy-energy dispersive x-ray analysis, fourier transform infrared-attenuated transmission reflectance, electrochemical impedance spectroscopy (eis), and tafel extrapolation techniques. the corrosion tests results were obtained in 3.5% sodium chloride (nacl) solution by tafel plots. in addition, the equivalent electrical circuit model of p(n-mpy) and p(n-mpy)/tio2 nanocomposite films were investigated in 3.5% nacl solution at different time periods. the eis study of the polymer and nanocomposite were analyzed by matlab program and for the first time tina, the equivalent electrical circuits program, was used.
relational_databases	protein secondary structure describe protein construction in terms of regular spatial shapes, including alpha-helices, beta-strands, and loops, which protein amino acid chain can adopt in some of its regions. this information is supportive for protein classification, functional annotation, and 3d structure prediction. the relevance of this information and the scope of its practical applications cause the requirement for its effective storage and processing. relational databases, widely-used in commercial systems in recent years, are one of the serious alternatives honed by years of experience, enriched with developed technologies, equipped with the declarative sql query language, and accepted by the large community of programmers. unfortunately, relational database management systems are not designed for efficient storage and processing of biological data, such as protein secondary structures. in this paper, we present a new search method implemented in the search engine of the pss-sql language. the pss-sql allows formulation of queries against a relational database in order to find proteins having secondary structures similar to the structural pattern specified by a user. in the paper, we will show how the search process can be accelerated by multiple scanning of the segment index and parallel implementation of the alignment procedure using multiple threads working on multiple-core cpus.
computer_programming	this paper presents a substantially simplified axiomatization of map theory and proves the consistency of this axiomatization (called mt) in zfc under the assumption that there exists an inaccessible ordinal. map theory axiomatizes lambda calculus plus hilbert 's epsilon operator. all theorems of zfc set theory including the axiom of foundation are provable in map theory, and if one omits hilbert 's epsilon operator from map theory then one is left with a computer programming language. map theory fulfills church 's original aim of lambda calculus. map theory is suited for reasoning about classical mathematics as well as computer programs. furthermore, map theory is suited for eliminating the barrier between classical mathematics and computer science rather than just supporting the two fields side by side. map theory axiomatizes a universe of ""maps"", some of which are ""wellfounded"". the class of wellfounded maps in map theory corresponds to the universe of sets in zfc. the first axiomatization mt0 of map theory had axioms which populated the class of wellfounded maps, much like the power set axiom along with others populate the universe of zfc. the new axiomatization mt of map theory is ""synthetic"" in the sense that the class of wellfounded maps is defined inside map theory rather than being introduced through axioms. in the paper we define the notions of canonical and non-canonical kappa- and kappa sigma-expansions and prove that if a is the smallest strongly inaccessible ordinal then canonical kappa sigma-expansions are models of mt (which proves the consistency). furthermore, in appendix a, we prove that canonical w-expansions are fully abstract models of the computational part of map theory. (c) 2015 elsevier b.v. all rights reserved.
computer_vision	low-cost, high-performance vision sensors in conjunction with aerial sensing platforms are providing new possibilities for achieving autonomous visual inspection in civil engineering structures. a large volume of images of a given structure can readily be collected for use in visual inspection, overcoming spatial and temporal limitations associated with human-based inspection. although researchers have explored several algorithms and techniques for visionbased inspection in recent decades, a major challenge in past implementations lies in dealing with a high volume of images while only a small fraction of them are important for actual inspection. because processing irrelevant images can generate a significant number of falsepositives, automated visual inspection techniques should be used in coordination with methods to localize relevant regions on the images. when combined, automated visual inspection will be able to meet the objectives and quality of human visual inspection. to enable this technology, we develop and validate a novel automated image localization technique to extract regions of interest (rois) on each of the images before utilizing vision-based damage detection techniques. rois are the portions of an image that contain the physical region of the structure that is targeted for visual interrogation, denoted as the targeted region of interest (tri). rois are computed based on the geometric relationship between the collected images and the tris. analysis of such highly relevant and localized images would enable efficient and reliable visual inspection. we successfully demonstrate the capability of the technique to extract the rois using a full-scale highway sign structure in the case where weld connections serve as the tris.
algorithm_design	designed with the goal of mimicking key features of real hpc workloads, mini-apps have become an important tool for co-design. an investigation of mini-app behavior can provide system designers with insight into the impact of architectures, programming models, and tools on application performance. mini-apps can also serve as a platform for fast algorithm design space exploration, allowing the application developers to evaluate their design choices before significantly redesigning the application codes. consequently, it is prudent to develop a mini-app alongside the full blown application it is intended to represent. in this paper, we present cmt-bone a mini-app for the compressible multiphase turbulence (cmt) application, cmt-nek, being developed to extend the physics of the cesar nek5000 application code. cmt-bone consists of the most computationally intensive kernels of cmt-nek and the communication operations involved in nearest-neighbor updates and vector reductions. the mini-app represents cmt-nek in its most mature state and going forward it will be developed in parallel with the cmt-nek application to keep pace with key new performance impacting changes. we describe these kernels and discuss the role that cmt-bone has played in enabling interdisciplinary collaboration by allowing application developers to work with computer scientists on performance optimization on current architectures and performance analysis on notional future systems.
microcontroller	in this paper, an inkjet-printed paper-based capacitive touchpad is proposed. this touchpad detects finger contact by sensing the change in effective capacitance caused by the skin electrical impedance. a low-cost flexible disposable touchpad with nine capacitive buttons is fabricated, using paper as a substrate. the use of home inkjet printing technology with silver nanoparticle ink makes the fabrication process simple, fast, cheap, and environmentally friendly. the performance of the proposed touchpad is measured with a microcontroller, and tests are conducted for both the cases of finger and touch pen operation. the measured capacitance of the non-touched state is 228-236 pf, whereas themeasured capacitance of the touched state is 340-564 pf. the differences in the capacitance of each state are sufficiently large to indicate that a finger has made contact with the touchpad. the sensitivity of the proposed sensor is evaluated, and the parameters of the proposed sensor are compared with those of other paper-based touch pads.
electrical_circuits	this paper provides an analysis of rc and rl electrical circuits described by a fractional difierential equation of caputo type. the order considered is 0 < gamma <= 1. the laplace transform of the fractional derivative is used. to keep the dimensionality of the physical quantities, r, c, l, and an auxiliary parameter sigma are introduced, characterizing the existence of fractional components in the system. the relationship between gamma and sigma is reported. the response obtained from the fractional rc and rl circuits exhibits the characteristic behaviors of a cap-resistor, memcapacitor, and memristor, as well as charge-voltage for memcapacitive systems and current-voltage for memristive systems. the relationship between ohm 's law and faraday 's laws for the charge stored in a capacitor and induction is reported. illustrative examples are presented.
image_processing	the image thresholding techniques are considered as a must for objects segmentation, compression and target recognition, and they have been widely studied for the last few decades; for example, the multilevel thresholding methods, and as such ( they) render more great challenges for image segmentation techniques that remain computationally more expensive, when their choices of threshold numbers were increased. therefore, our aim was to propose an algorithm based on bayesian theorem and the so-called honeybee- mating algorithm (hbma), called a bayesian honey bee mating algorithm bhbma. it can notonly reduce the computational time and curse of dimensionality, but also can run more reliably and more stably. this enhanced capability was technically accomplished by embedding a new population initialization strategy based on the characteristics of multi-level thresholding technique in pixel-basedintensity images arranged from lower grey levels to higher ones. extensive experiments have shown that our proposed method outperformed other state-of-the-art algorithms empirically in terms of their effectiveness and efficiency, when applying to complex image processing scenario such as automatic target recognition. (c) 2016 elsevier b.v. all rights reserved.
control_engineering	this paper proposes a novel radiometric compensation technique for cooperative projection system based-on distributed optimization. to achieve high scalability and robustness, we assume cooperative projection environments such that 1. each projector does not have information about other projectors as well as target images, 2. the camera does not have information about the projectors either, while having the target images, and 3. only a broadcast communication from the camera to the projectors is allowed to suppress the data transfer bandwidth. to this end, we first investigate a distributed optimization based feedback mechanism that is suitable for the required decentralized information processing environment. next, we show that this mechanism works well for still image projection, however not necessary for moving images due to the lack of dynamic responsiveness. to overcome this issue, we propose to implement an additional feedforward mechanism. such a 2 degree of freedom (2-dof) control structure is well-known in control engineering community as a typical method to enhance not only disturbance rejection but also reference tracking capability, simultaneously. we theoretically guarantee and experimentally demonstrate that this 2-dof structure yields the moving image projection accuracy that is overwhelming the best achievable performance only by the distributed optimization mechanisms.
digital_control	the current controller with fast transient response and satisfactory steady state characteristics is required in pmsm servo system. in this paper, the application of active disturbance rejection control (adrc) for current loop is proposed and the design proceeding of a first-order adrc controller in the current loop is elaborated. then, by taking use of the adrc controller and the analysis of the digital control delay effect, an improved method focusing on delay effects is presented. by taking these measures, the current regulation can achieve high performance. simulation and experimental results verify the correctness and feasibility of the proposed method.
computer_vision	full human body shape scans provide valuable data for a variety of applications including anthropometric surveying, clothing design, human-factors engineering, health, and entertainment. however, the high price, large volume, and difficulty of operating professional 3-d scanners preclude their use in home entertainment. recently, portable low-cost red green blue-depth cameras such as the kinect have become popular for computer vision tasks. however, the infrared mechanism of this type of camera leads to noisy and incomplete depth images. we construct a stereo full-body scanning environment composed of multiple depth cameras and propose a novel registration algorithm. our algorithm determines a segment constrained correspondence for two neighboring views, integrating them using rigid transformation. furthermore, it aligns all of the views based on uniform error distribution. the generated 3-d mesh model is typically sparse, noisy, and even with holes, which makes it lose surface details. to address this, we introduce a geometric and topological fitting prior in the form of a professionally designed high-resolution template model. we formulate a template deformation optimization problem to fit the high-resolution model to the low-quality scan. its solution overcomes the obstacles posed by different poses, varying body details, and surface noise. the entire process is free of body and template markers, fully automatic, and achieves satisfactory reconstruction results.
electrical_circuits	this work investigates the influence of the electrical circuits on tmf (total thermoelectromotive force) response signals captured from the rotating workpiece generated by the tool-workpiece thermocouple system in turning process considering four different thermoelectrical circuits - ec namely: c-1 - bronze pin, c-2 - aluminum pin, c-3 - graphite brush and c-4 - liquid mercury contact. the tests were carried out under different cutting conditions. a multifactorial analysis of variance was performed using the 2(k) factorial design, always considering the c-4 as the lower level. in addition, a single factor analysis of variance was performed, keeping the cutting speed, vc, the feed rate, f, the depth of cut, doc, and the lubri-coolant system, lub, constants while varying the ec in order to validate the results found with the factorial design. the results indicated that there was no statistical significant difference in the tmf responses of the tool-workpiece thermocouples c-1 and c-4 as well as c-2 and c-4. however, when comparing the tmf generated by c-3 and c-4 a significant difference was detected, indicating that graphite brushes is not recommended for such application, while the bronze and aluminum pins can be thought as an advantageous substitute for the laborious liquid mercury system. (c) 2013 elsevier ltd. all rights reserved.
operational_amplifier	this study describes the analysis and design of an improved recycling folded cascode using a new input path and positive feedback which simultaneously increases transconductance considerably. the proposed amplifier with bias circuits and cmfb circuit was simulated with the tsmc 90 nm and hspice circuit simulator @ 1.2 v. according to the simulation results, the proposed circuit shows 75 db, 357 mhz and 359 a mu w as dc gain, gbw and power dissipation respectively. this demonstrates 22 db gain enhancement and 207 mhz gbw improvement, in comparison to recycling the folded cascode (for same capacitor load and power dissipation). finally, corners and monte-carlo simulations were performed to verify the robustness of the proposed circuit versus process, temperature, supply voltage and device dimension mismatch variations.
computer_graphics	shape correspondence is a fundamental problem in computer graphics and vision, with applications in various problems including animation, texture mapping, robotic vision, medical imaging, archaeology and many more. in settings where the shapes are allowed to undergo non-rigid deformations and only partial views are available, the problem becomes very challenging. to this end, we present a non-rigid multi-part shape matching algorithm. we assume to be given a reference shape and its multiple parts undergoing a non-rigid deformation. each of these query parts can be additionally contaminated by clutter, may overlap with other parts, and there might be missing parts or redundant ones. our method simultaneously solves for the segmentation of the reference model, and for a dense correspondence to (subsets of) the parts. experimental results on synthetic as well as real scans demonstrate the effectiveness of our method in dealing with this challenging matching scenario.
bioinformatics	background: viral hepatitis c is an important global health problem that affects about 2.2% of humans. strategies on the control of this hepatotropic virus focused on chemotherapy and surveillance of emerging hcv drug resistant mutants, respectively. hcv genotype 1 response to therapy is one of major interests. the aim of this research was to study the prevalence of resistant associated variants (ravs) in the naive hcv patient candidate for direct acting antiviral (daa) therapy. methods: a total of 70 hcv confirmed patients which referred to hospitals affiliated to iran university of medial sciences, tehran, iran from may 2014 to march 2015 were enrolled in this cross sectional study. after rna extraction, rflp-rt-nested-pcr was performed for hcv genotyping, then some genotypes 1 and 3 strains were used for further amplification of ns5b gene s282t mutation site and purified products were sequenced. bioinformatics software was used for analysis of sequences. results: from a total of 70 hcv patients, 54 were male (mean age (y)+/- sd 35.1 +/- 8.2) and 16 were female (mean age (y)+/- sd 43.4 +/- 10.1); 26 isolates from 1 a, lb and 3a showed that there were no s282t resistant mutants. moreover, 2 (4.8%) had a synonymous point mutation (c to t). statistical analysis did n't found any significant correlation between age, sex and genotype variables. conclusion: finally, it can be concluded that there were no resistant mutants in our hcv genotypes 1 and 3 infected patients and broader scale of studies are required in this area using larger specimens, genotype groups and stages of treatment. (c) 2017 published by elsevier ltd.
operating_systems	hybridcheck is a software package to visualize the recombination signal in large dna sequence data set, and it can be used to analyse recombination, genetic introgression, hybridization and horizontal gene transfer. it can scan large (multiple kb) contigs and whole-genome sequences of three or more individuals. hybridcheck is written in the r software for os x, linux and windows operating systems, and it has a simple graphical user interface. in addition, the r code can be readily incorporated in scripts and analysis pipelines. hybridcheck implements several abba-baba tests and visualizes the effects of hybridization and the resulting mosaic-like genome structure in high-density graphics. the package also reports the following: (i) the breakpoint positions, (ii) the number of mutations in each introgressed block, (iii) the probability that the identified region is not caused by recombination and (iv) the estimated age of each recombination event. the divergence times between the donor and recombinant sequence are calculated using a jc, k80, f81, hky or gtr correction, and the dating algorithm is exceedingly fast. by estimating the coalescence time of introgressed blocks, it is possible to distinguish between hybridization and incomplete lineage sorting. hybridcheck is libre software and it and its manual are free to download from .
electric_motor	in a yet another effort to produce better permanent magnet (pm)-less rotor-winding-less brushless electric motor drives, this paper reports work related to multiphase (m = 6) high saliency rotor dual-flat-top alternative current control brushless dc (bldc) reluctance machine drives. the aim is to produce high torque density, low loss/torque in a pm-less rotor-windingless machine by full usage of machine windings and core and of inverter kva. a new derivation of the principle of operation, essential rotary and linear machine topologies, and a 2-d finite-element method (fem) analysis for torque density and torque pulsations on an already built (6 phase, 6 poles, 35 n.m) lab prototype are made available and show promising results. experimental flux decay test results are presented, which, together with standstill torque measurements, validate the finite-element model. advanced iron loss computation by finite-element analysis indicates moderate core loss, although high air-gap magnetic flux density and current harmonics occur as a natural behavior of a bldc machine. electrical and mechanical parameter identification is followed by the development of a circuit model based on fem imported data for parameters and by a four-quadrant control strategy proposal. running experiments (motoring and generating) with speed-reversal and field-weakening modes using a dspace platform, which drives three three-phase inverters that power a star-connected six-phase bldc multiphase reluctance machine are presented, thus showing operation with a reduced number of switches in the inverter.
computer_programming	currently, educational games are being developed to teach children the basics of computer programming. research and design of such games is usually based on general learning theories. yet, computer programming poses specific types of difficulties to novice programmers. taking into account these particular characteristics and problems of computer programming as a learning content in the design of programming games could allow for producing games that are more suitable to the needs of novice programmers. this paper first reports on a novice programmer problems analysis, to gain insight into learners' specific difficulties. then, a review of existing programming games is presented to investigate how and to which extent these games deal with specific programming problems. the results of these studies aim to contribute to the requirements and ideation phases of a programming game design process, thereby informing a learning content-driven design perspective.
computer_vision	this paper presents a new linear velocity estimator based on the unscented kalman filter and making use of image information aided with inertial measurements. the proposed technique is independent of the scale factor in case of planar observed scene and does not require a priori knowledge of the scene. image moments of virtual objects, i.e. sets of classical image features such as corners collected online, are employed as the sole correcting information to be fed back to the estimator. experimental results performed with a quadrotor equipped with a fisheye camera highlight the potential of the proposed approach.
image_processing	although the importance of cellular forces to a wide range of embryogenesis and disease processes is widely recognized, measuring these forces is challenging, especially in three dimensions. here, we introduce cellfit-3d, a force inference technique that allows tension maps for three-dimensional cellular systems to be estimated from image stacks. like its predecessors, video force microscopy and cellfit, this cell mechanics technique assumes boundary-specific interfacial tensions to be the primary drivers, and it constructs force-balance equations based on triple junction (tj) dihedral angles. the technique involves image processing, segmenting of cells, grouping of cell outlines, calculation of dihedral planes, averaging along three-dimensional tjs, and matrix equation assembly and solution. the equations tend to be strongly overdetermined, allowing indistinct tjs to be ignored and solution error estimates to be determined. application to clean and noisy synthetic data generated using surface evolver gave tension errors of 1.6-7%, and analyses of eight-cell murine embryos gave estimated errors smaller than the 10% uncertainty of companion aspiration experiments. other possible areas of application include morphogenesis, cancer metastasis and tissue engineering. this article is part of the themed issue 'systems morphodynamics: understanding the development of tissue hardware'.
parallel_computing	this paper describes a fully coupled finite element/finite volume approach for simulating field-scale hydraulically driven fractures in three dimensions, using massively parallel computing platforms. the proposed method is capable of capturing realistic representations of local heterogeneities, layering and natural fracture networks in a reservoir. a detailed description of the numerical implementation is provided, along with numerical studies comparing the model with both analytical solutions and experimental results. the results demonstrate the effectiveness of the proposed method for modeling large-scale problems involving hydraulically driven fractures in three dimensions. (c) 2016 the authors. international journal for numerical and analytical methods in geomechanics published by john wiley & sons ltd.
computer_programming	amid growing calls for greater collaboration between journalism and computer programming, this article examines a salient case study that reveals processes of communication, exchange, and work production at the intersection of these social and occupational worlds. we focus on a key stage of the knight-mozilla news technology partnership - namely, an online 'learning lab' through which 60 individuals sought to coordinate around a shared interest in the innovation of journalism through open-source software. drawing on the science and technology studies concepts of trading zones and boundary objects, we explore how distinct understandings about news and technology converged, diverged, and ultimately blended around three thematic ambitions: making news more process-oriented, participatory, and socially curated. this window onto boundary negotiations in journalism provides a glimpse into the future development of news and its norms and values, as programmers and their ethics assume a greater role in the journalistic field - in the very heart of some of its leading institutions.
digital_control	recently, we have reported on a compact microcontroller-based unit developed to accurately synchronize excimer laser pulses (mingesz et al. 2012 fluct. noise lett. 11, 1240007 (doi:10.1142/s021947751240007x)). we have shown that dithering based on random jitter noise plus pseudorandom numbers can be used in the digital control system to radically reduce the long-term drift of the laser pulse from the trigger and to improve the accuracy of the synchronization. in this update paper, we present our new experimental results obtained by the use of the delay-controller unit to tune the timing of a krf excimer laser as an addition to our previous numerical simulation results. the hardware was interfaced to the laser using optical signal paths in order to reduce sensitivity to electromagnetic interference and the control algorithm tested by simulations was applied in the experiments. we have found that the system is able to reduce the delay uncertainty very close to the theoretical limit and performs well in real applications. the simple, compact and flexible system is universal enough to also be used in various multidisciplinary applications.
analog_signal_processing	in this work the investigation and design of a direct drive wave energy conversion system for the seaquest concept is presented. it involves all the steps of the project, from the marine environment analysis to the problems linked to the connection to the grid, passing through the sizing procedure of an innovative arc-shaped electrical generator, in which the flux-switching principle has been applied, then through its analysis, optimization and performance verification by fea, and then the study of the most suitable control strategies. particular attention has been given to all the specificities this new particular generator presents: non-constant rotational speed, reciprocating motion, border effects. this arch-shaped generator has then been compared to a traditional rotating machine directly coupled with the shaft and moved by the pendulum (c) 2012 published by elsevier ltd. selection and/or peer-review under responsibility of the centre for renewable energy.
digital_control	in this paper, a nonlinear current-output digital to analog converter (dac) employing a pseudo-exponential transconductance amplifier is presented. the proposed transconductance amplifier makes use of the code-dependent body-biasing to realize the exponential relationship of the output current to the input digital signal in the cmos technology. a digital control unit is designed to provide a linearly code-dependent voltage to feed into the transconductance amplifier by charging a capacitor for a period determined by a counter which is loaded by the input digital code. the proposed dac is simulated in a 180 nm standard cmos technology. the accuracy of the exponential input-output characteristic is verified by the curve fitting of the simulation results where r-squared value of the fitted functions is greater than 0.999 in all process and temperature corners. the presented dac consumed 79 mu w in the worst-case.
pid_controller	in this paper, the autonomous hybrid power system consisting of wind-turbine generator (wtg), dieselengine generator (deg), fuel-cell (fc) and aqua-electrolyzer (ae) is studied. deg acts as slack generator, whose output power is controlled to have real power balance in the system to keep the frequency deviation within the limit. this paper proposes a new control scheme incorporating pid and pd controllers, to control the output power of deg to keep real power-frequency balance in the system. pid controller is introduced to make the frequency deviation zero under steady-state, after any disturbance. pd controller is incorporated to damp out the oscillations in system frequency, after disturbance. detail analysis of the effect of pid and pd controllers on system mode is presented using participation factor. the sensitivity of system modes to the variation of controller parameters is investigated. simulated responses under isolated operation are presented to show that the proposed control strategy is capable of maintaining power-frequency balance in the system, following any disturbance. the mathematical model of the interconnected system is developed. one feedback loop is added to the existing pid controller in each area to reduce the tie-line power loss. grid-connected and distribution system connected operation of the hybrid power system are also investigated. (c) 2016 elsevier ltd. all rights reserved.
algorithm_design	it is well known that laser scanner has better accuracy than stereo vision in detecting the distance and velocity of the obstacles, whereas stereo vision can distinguish the objects better than the laser scanner. these advantages of each sensor can be maximized by sensor fusion approach so that the obstacles in front can be detected accurately. in this paper, high-level sensor fusion for the laser scanner and stereo vision is developed for object matching between the sensors. time synchronization, object age, and reordering algorithms are designed for robust tracking of the objects. a time-delay update algorithm is also developed to determine the process time delay of the laser scanner. the expanded laser scanner data at every 1 ms is predicted by kalman filter and is matched with the stereo vision data at every 66 ms. a cost function is formulated to describe the object matching similarity between the sensors, and the best matching candidate is selected for theminimumcost function. the proposedmatching algorithms are verified experimentally in field tests of various maneuvering cases.
cryptography	security features such as privacy and device authentication are required in wireless sensor networks, electronic ids, radio frequency identification tags, and many other applications. these features are provided using cryptography. symmetric key cryptography, where the key is distributed between the communication parties prior to communication, does not provide adequate solution for large scalable systems such as sensor networks. in these cases, public-key cryptography should be used. however, public-key algorithms are typically more computationally intensive than their symmetric key counterparts, which creates difficulties in meeting the strict area, power, and energy requirements. elliptic curve cryptography, because of relatively small operand sizes, can be used to answer the imposed challenges. in this paper, we present a processor for elliptic curve cryptography over gf(2(163)). this processor can perform elliptic curve point multiplication as well as general modular operations. the processor is flexible enough to support multiple cryptographic protocols. the chip is fabricated using umc .13 m 1p8m process, resulting in a core area of 0.54 mm(2). the energy consumption to perform one elliptic curve point multiplication is 5.1j. the design features lightweight countermeasures against side-channel attacks. a security evaluation shows the effectiveness of such countermeasures. copyright (c) 2016 john wiley & sons, ltd.
electricity	until the banking reform in 1936, banks and industrial companies in italy were strongly intertwined (both in terms of ownership and interlocking directorates). using imita.db-a large dataset containing data on over 300,000 directors of italian joint-stock companies-this paper analyzes what would have happened to the italian corporate network in the years 1913, 1921, 1927 and 1936 if the german-type universal banks and their directors would have not been there. our test shows that new centers of the system would have emerged (financial, electricity, and phone companies), confirming the interconnected nature of the italian capitalism. we also analyze two industries (textiles and iron and steel) characterized by different labor-to-capital intensities to check for sectoral differences. contrary to conventional wisdom, we find that local banks were important in funding both industries.
relational_databases	the rapid growth of digital data storage of medical or health, social media, education and many more in the world has amplified the demand for big data storage, which requires trillion of files having exabytes of data. this growth in data has put up the key question of how we can effectively manage and find the data in the emergent ocean of information. the upcoming demand for data storage in petabytes and exabytes of data has also resulted in putting pressure in organizing the file structure in such a way that retrieval results of searching a keyword should match with the growing pace of data storage. as a result, there is an increase in demand for keyword indexing and searching of file systems. directly implementing searching methodology in file system has resulted in inefficient and inconsistent results. general purpose indexes may not be suitable for file system searching as it relies on relational databases and may limit the scalability and performance. this proposed bilingual framework for english and hindi addresses these problems through a novel approach for indexing and searching queries in large scale file system.
electrical_network	ever increasing nonlinear loads and supplies are changing dynamics of the electrical network. the levels of harmonics are on the rise and polluting more and more of the electrical network, posing new challenges before the designers and operators. to maintain the present power quality levels and to improve the performance of the electrical network, many control schemes and devices like active power filter 's have been proposed, but still an improvement is required. this paper proposes a five-level diode clamped multilevel inverter based distribution statcom (mli-dstatcom) with synchronous reference frame based control for harmonic mitigation. a three-phase four wire system with nonlinear, balanced/unbalanced load is designed and simulated in matlab/simulink for performance analysis of proposed mli-dstatcom. the results provide the evidence of restricting harmonic currents at load end and prevent from entering into source effectively. the performance of five-level, three-level and two-level dstatcom 's are compared under nonlinear, balanced/unbalanced load. simulation result analysis show superior performance of five-level diode clamped mli-dstatcom controlled using srf.
electricity	utilization of wind turbines to produce energy has been increasing in recent years, due to technology advancement, cost stability and environmental issues. in this paper, the wind resource and economic feasibility have been studied to avoid investment risk in cites of zabol, zahak, zahedan and mirjaveh in sistan and balouchestan province of iran. the weibull distribution function has been applied to estimate the wind power and energy density, using meteorological data. determination of coefficient, root mean square error, mean bias error and mean bias absolute error are also calculated to ensure the accuracy of the statistical analysis of fitted distribution. windographer software has been employed to investigate the prevailing wind direction. the estimated annual energy densities are 2495.36, 2355.69, 126524 and 1214.01 kwh/m(2)/year, and the annual mean power densities are 284.97, 269.02, 144.49 and 138.64 w/m(2). it is found that zabol and zahedan are suitable for large scale power generation. the results indicate that using dw61-900 kw wind turbines are highly beneficial for zabol and zahak, while for zahedan, dw52/54-250 kw wind turbine is more appropriate for generating electricity. however, mirjaveh is suitable for off-grid applications. it should be noted that in this analysis, monetary units are presented in 2016 u.s. dollar. (c) 2017 elsevier ltd. all rights reserved.
electric_motor	the present paper deals with the defect detection and diagnosis of induction motor, based on motor current signature analysis in a quality control scenario. in order to develop a monitoring system and improve the reliability of induction motors, clarke-concordia transformation and kernel density estimation are employed to estimate the probability density function of data related to healthy and faulty motors. kullback-leibler divergence identifies the dissimilarity between two probability distributions and it is used as an index for the automatic defects identification. kernel density estimation is improved by fast gaussian transform. since these techniques achieve a remarkable computational cost reduction respect the standard kernel density estimation, the developed monitoring procedure became applicable on line, as a quality control method for the end of production line test. several simulations and experimentations are carried out in order to verify the proposed methodology effectiveness: broken rotor bars and connectors are simulated, while experimentations are carried out on real motors at the end of production line. results show that the proposed data-driven diagnosis procedure is able to detect and diagnose different induction motor faults and defects, improving the reliability of induction machines in quality control scenario. (c) 2015 elsevier ltd. all rights reserved.
symbolic_computation	in this paper, hirota 's bilinear method is extended to a new kdv hierarchy with variable coefficients. as a result, one-soliton solution, two-soliton solution and three-soliton solutions are obtained, from which the uniform formula of n-soliton solution is derived. thanks to the arbitrariness of the included functions, these obtained solutions possess rich local structural features like the ridge soliton and the concave column soliton. it is shown that the hirota 's bilinear method can be used for constructing multi-soliton solutions of some other hierarchies of nonlinear partial differential equations with variable coefficients.
digital_control	this paper presents the simulation results of a linear, fully integrated, two-stage digitally programmable 130 nm cmos power amplifier (pa) operating at 2.4 ghz. its power stage is composed of a set of amplifying cells which can be enabled or disabled independently by a digital control circuit. all seven operational modes are univocal in terms of 1 db output compression point (ocp1db), saturated output power (p-sat) and power gain at 2.4 ghz. the lowest power mode achieves an 8.1 dbm p-sat, a 13.5 db power gain and consumes 171 mw dc power (p-dc) at an ocp1db of 6 dbm, whereas the highest power mode reaches an 18.9 dbm p-sat and a 21.1 db power gain and consumes 415 mw p-dc at an ocp1db of 18.2 dbm.
bioinformatics	germline mutations in pole and pold1 have been shown to cause predisposition to colorectal multiple polyposis and a wide range of neoplasms, early-onset colorectal cancer being the most prevalent. in order to find additional mutations affecting the proofreading activity of these polymerases, we sequenced its exonuclease domain in 155 patients with multiple polyps or an early-onset colorectal cancer phenotype without alterations in the known hereditary colorectal cancer genes. interestingly, none of the previously reported mutations in pole and pold1 were found. on the other hand, among the genetic variants detected, only two of them stood out as putative pathogenic in the pole gene, c. 1359 + 46del71 and c. 1420g >a (p.val474ile). the first variant, detected in two families, was not proven to alter correct rna splicing. contrarily, c. 1420g >a (p. val474ile) was detected in one early-onset colorectal cancer patient and located right next to the exonuclease domain. the pathogenicity of this change was suggested by its rarity and bioinformatics predictions, and it was further indicated by functional assays in schizosaccharomyces pombe. this is the first study to functionally analyze a pole genetic variant outside the exonuclease domain and widens the spectrum of genetic changes in this dna polymerase that could lead to colorectal cancer predisposition.
symbolic_computation	with the help of symbolic computation, the benjamin-bona-mahony (bbm) equation with variable coefficients is presented, which was proposed for the first time by benjamin as the regularized long-wave equation and originally derived as approximation for surface water waves in a uniform channel. by employing the improved (g'/g)-expansion method, the truncated painleve expansion method, we derive new auto-backlund transformation, hyperbolic solutions, a variety of traveling wave solutions, soliton-type solutions and two solitary wave solutions of the bbm equation. these obtained solutions possess abundant structures. the figures corresponding to these solutions are illustrated to show the particular localized excitations and the interactions between two solitary waves.
system_identification	this paper approaches the problem of output power prediction for an off-shore wind park. to this end, a so called wind deficiency factor for each turbine and for each wind direction sector is identified using past data. this identification is done by using the effective wind speed concept that can establish a link between output power of each wind turbine and meteorological mast measures in terms of wind speed and direction. based on forecast wind speed and direction, a wind park simulator that uses the previously identified deficiency factors, computes future output power time evolutions. nunierical simulations show the feasibility of the proposed approach. (c) 2016 elsevier ltd. all rights reserved.
cryptography	to evaluate the visual quality in visual secret sharing schemes, most of the existing metrics fail to generate fair and uniform quality scores for tested reconstructed images. we propose a new approach to measure the visual quality of the reconstructed image for visual secret sharing schemes. we developed an object detection method in the context of secret sharing, detecting outstanding local features and global object contour. the quality metric is constructed based on the object detection-weight map. the effectiveness of the proposed quality metric is demonstrated by a series of experiments. the experimental results show that our quality metric based on secret object detection outperforms existing metrics. furthermore, it is straightforward to implement and can be applied to various applications such as performing the security test of the visual secret sharing process.
data_structures	with the increasing complexity of both data structures and computer architectures, the performance of applications needs fine tuning in order to achieve the expected runtime execution time. performance tuning is traditionally based on the analysis of performance data. the analysis results may not be accurate, depending on the quality of the data and the applied analysis approaches. therefore, application developers may ask: can we trust the analysis results? this paper introduces our research work in performance optimization of the memory system, with a focus on the cache locality of a shared memory and the memory locality of a distributed shared memory. the quality of the data analysis is guaranteed by using both real performance data acquired at the runtime while the application is running and well-established data analysis algorithms in the field of bioinformatics and data mining. we verified the quality of the proposed approaches by optimizing a set of benchmark applications. the experimental results show a significant performance gain.
computer_graphics	graphic clipping algorithm is a hotspot all the time in computer graphics. based upon non-intersect polygon boundary, a clipping algorithm on vector graphics is proposed in this paper. the proposed algorithm can be divided into three steps. first, eliminating the boundary which has no intersection with vector graphics and calculating effective intersections; second, dividing graphics into several parts; finally, determining whether each part within boundaries and achieving graphic clipping. besides, it can be demonstrated by experiments that compared with traditional algorithm, the proposed algorithm is clear, simple, effective and can be applied widely. furthermore, the proposed algorithm only consumes about 7 seconds in millions of data and the memory consumption nearly unchanged.
image_processing	the behaviors of the keyhole and the weld pool are dynamically-coupled in controlled-pulse plasma arc welding and can be used to indicate weld quality. the vision system was improved to detect the geometries of both the keyhole and weld pool at the backside simultaneously during a whole controlled-pulse keyholing period by one single ccd camera without auxiliary illumination. with the assistance of an appropriate optical filter system, the unchanged aperture and exposure time of the camera was also adopted and can be used under a different current period. an image processing method was then proposed to extract the keyhole boundary in open keyhole status and weld pool boundary for the whole welding process. the influences of current waveform parameters on the welding process are studied and discussed. it was found that dimensions of the weld pool at the backside are determined by the heat input of the plasma arc and keyhole duration. the keyhole moves forward during the welding process while the weld pool maximum width at the backside is located behind the keyhole center.
digital_control	the voltage source converters (vsc) are the key power interfaces between the individual ac grids and dc grids in the hybrid power system. when the ac grid is unbalanced, the grid currents are distorted and the harmonic is induced. meanwhile, the oscillations in the active and reactive power are also increased, which may damage these interfaces. in order to ensure the safety of the converters and the grid facility, a flexible control strategy is proposed for the ac/dc hybrid grid in this paper. at first, the current harmonic for the vsc is theoretically analyzed under unbalanced conditions. furthermore, the methods to separate the positive- and negative-sequence components of the ac grid voltages are summed up and analyzed. based on the theoretical analysis, different protected control methods are compared. a new control method, which can flexibly control oscillations of the active and reactive power by introducing a parameter k, has been proposed. the estimation of maximum current in each phase is discussed; meanwhile, the relationship between the voltage ripple on dc link and the parameter k is given. finally, the validity and advantages of the proposed method are verified by the simulating and experimental results.
signal-flow_graph	the validity of proposed sfg model was verified by comparing our theoretical results of s-21, s-11 to originally obtained values. we also introduced weighted averaging method to improve parameters estimation accuracy.
microcontroller	this paper presents the design of a sliding mode control (smc) for trajectory tracking of an unmanned aerial vehicle (uav), quadrotor. a simplified model of the quadrotor is used for the controller design. the robustness of the controller is verified through simulations, and also through data analysis from the experiments in the 3dr arducopter platform. the smc algorithms are implemented in a microcontroller that communicates with a human machine interface (hmi), which monitors the behavior and stability of the state variables. the results show effectiveness of the control technique for maintaining stability in the quadrotor under different operating scenarios.
microcontroller	in this paper, a stand-alone photovoltaic (sapv) power supply system for microner sprayer is identified and proposed. the designed system was composed of three main parts: sprayer, solar power supply and control system. initially, the control board and data acquisition system were designed and simulated by the proteus software and then implemented using an avr microcontroller and tested via labview in the laboratory. next, a prototype system was fabricated for evaluation purposes. a pv panel size of 88.5 cm(2), positioned horizontally above operator 's head that generates 26.4 wh/day was used as a solar energy source. a small 2 ah (12 v) battery is installed in the system as a stabiliser. this sprayer can work seven to nine hours daily. it is calculated that the average loss of collected energy due to non-application of maximum power point tracker was approximately 25%.
machine_learning	k nearest neighbor (knn) is one of the basic processes behind various machine learning methods in knn, the relation of a query to a neighboring sample is basically measured by a similarity metric, such as euclidean distance. this process starts with mapping the training dataset onto a one-dimensional distance space based on the calculated similarities, and then labeling the query in accordance with the most dominant or mean of the labels of the k nearest neighbors, in classification or regression issues, respectively. the number of nearest neighbors (k) is chosen according to the desired limit of success. nonetheless, two distinct samples may have equal distances to query but, with different angles in the feature space. the similarity of the query to these two samples needs to be weighted in accordance with the angle going between the query and each of the samples to differentiate between the two distances in reference to angular information. this opinion can be analyzed in the context of dependency and can be utilized to increase the precision of classifier. with this point of view, instead of knn, the query is labeled according to its nearest dependent neighbors that are determined by a joint function, which is built on the similarity and the dependency. this method, therefore, may be called dependent nn (d-nn). to demonstrate d-nn, it is applied to synthetic datasets, which have different statistical distributions, and 4 benchmark datasets, which are pima indian, hepatitis, approximate sinc and casp datasets. results showed the superiority of d-nn in terms of accuracy and computation cost as compared to other employed popular machine learning methods. (c) 2017 elsevier b.v. all rights reserved.
computer_vision	during the last decades photogrammetric computer vision systems have been well established in scientific and commercial applications. recent developments in image-based 3d reconstruction systems have resulted in an easy way of creating realistic, visually appealing and accurate 3d models. we present a fully automated processing pipeline for metric and geo-accurate 3d reconstructions of complex geometries supported by an online feedback method for user guidance during image acquisition. our approach is suited for seamlessly matching and integrating images with different scales, from different view points (aerial and terrestrial), and with different cameras into one single reconstruction. we evaluate our approach based on different datasets for applications in mining, archaeology and urban environments and thus demonstrate the flexibility and high accuracy of our approach. our evaluation includes accuracy related analyses investigating camera self-calibration, georegistration and camera network configuration. (c) 2016 elsevier inc. all rights reserved.
analog_signal_processing	we derive a model for a wind turbine tower in the plane of the turbine blades, which comprises an euler-bernoulli beam coupled with a nacelle (rigid body) and a two-mass drive-train model (with gearbox). this model has two possible control inputs: the torque created by the electrical generator and the force created by an electrically driven mass located in the nacelle. first, we consider the case of only torque control and a possibly non-uniform tower. using the theory of coupled linear systems (one infinite dimensional and one finite dimensional) developed by us recently, we show that this wind turbine tower model is well-posed and regular on either the energy state space x-c or the domain of its generator on x-c, denoted by x-1(c). we also show that generically, this model is exactly controllable on x-1(c) in arbitrarily short time. more precisely, for every t >0, we show that if we vary a certain parameter in the model, then exact controllability in time t holds for all except three values of the parameter. in the case of using both force and torque control, we derive similar well-posedness, regularity and generic exact controllability results on a state space that is larger than x-1(c) but smaller than x-c. in this second case, we assume that the tower is uniform.
computer_vision	the design of computer-assisted decision (cad) systems for different biomedical imaging scenarios is a challenging task in computer vision. sometimes, this challenge can be attributed to the image acquisition mechanisms since the lack of control on the cameras can create different visualizations of the same imaging site under different rotation, scaling, and illumination parameters, with a requirement to get a consistent diagnosis by the cad systems. moreover, the images acquired from different sites have specific colors, making the use of standard color spaces highly redundant. in this paper, we propose to tackle these issues by introducing novel region-based texture, and color descriptors. the proposed texture features are based on the usage of analytic gabor filters (for compensation of illumination variations) followed by the calculation of first-and second-order statistics of the filter responses and making them invariant using some trivial mathematical operators. the proposed color features are obtained by compensating for the illumination variations in the images using homomorphic filtering followed by a bag-of-words approach to obtain the most typical colors in the images. the proposed features are used for the identification of cancer in images from two distinct imaging modalities, i.e., gastroenterology and dermoscopy. experiments demonstrate that the proposed descriptors compares favorably to several other state-of-the-art methods, elucidating on the effectiveness of adapted features for image characterization.
state_space_representation	resonant converters used as coil drivers in inductive links generally operate efficiently at optimum switching conditions for constant load values and ranges. changes in load and range can shift the operation of the coil driver to a nonoptimum switching state which results in higher switching losses and reduced output power levels. this paper presents a method to adapt to variations in range for a class e inverter used as a coil driver in a wireless power transfer (wpt) system based on inductive coupling. it is shown that by controlling the duty cycle of the inverter 's switch and the value of its dc-feed inductance, the class e inverter can be tuned to operate at optimum switching conditions as the distance between the coils of the wpt system changes. mathematical analysis is presented based on a linear piecewise state-space representation of the inverter and the inductive link. extensive experimental results are presented to verify the performed analysis and validity of the proposed tuning procedure.
computer_programming	with the flood of publicly available data, it allows scientists to explore and discover new findings. gene expression is one type of biological data which captures the activity inside the cell. studying gene expression data may expose the mechanisms of disease development. however, with the limitation of computing resources or knowledge in computer programming, many research groups are unable to effectively utilize the data. for about a decade now, various web-based data analysis tools have been developed to analyze gene expression data. different tools were implemented by different analytical approaches, often resulting in different outcomes. this study conducts a comparative study of three existing web-based gene expression analysis tools, namely gene-set activity toolbox (gat), networkanalyst and geo2r using six publicly available cancer data sets. results of our case study show that networkanalyst has the best performance followed by gat and geo2r, respectively.
algorithm_design	converting geographic features (e.g., place names) in map images into a vector format is the first step for incorporating cartographic information into a geographic information system (gis). with the advancement in computational power and algorithm design, map processing systems have been considerably improved over the last decade. however, the fundamental map processing techniques such as color image segmentation, (map) layer separation, and object recognition are sensitive to minor variations in graphical properties of the input image (e.g., scanning resolution). as a result, most map processing results would not meet user expectations if the user does not ""properly"" scan the map of interest, preprocess the map image (e.g., using compression or not), and train the processing system, accordingly. these issues could slow down the further advancement of map processing techniques as such unsuccessful attempts create a discouraged user community, and less sophisticated tools would be perceived as more viable solutions. thus, it is important to understand what kinds of maps are suitable for automatic map processing and what types of results and process-related errors can be expected. in this paper, we shed light on these questions by using a typical map processing task, text recognition, to discuss a number of map instances that vary in suitability for automatic processing. we also present an extensive experiment on a diverse set of scanned historical maps to provide measures of baseline performance of a standard text recognition tool under varying map conditions (graphical quality) and text representations (that can vary even within the same map sheet). our experimental results help the user understand what to expect when a fully or semi-automatic map processing system is used to process a scanned map with certain (varying) graphical properties and complexities in map content. (c) 2016 elsevier ltd. all rights reserved.
operating_systems	recent years have witnessed a processor development trend that integrates central processing unit (cpu) and graphic processing unit (gpu) into a single chip. the integration helps to save some host-device data copying that a discrete gpu usually requires, but also introduces deep resource sharing and possible interference between cpu and gpu. this work investigates the performance implications of independently co-running cpu and gpu programs on these platforms. first, we perform a comprehensive measurement that covers a wide variety of factors, including processor architectures, operating systems, benchmarks, timing mechanisms, inputs, and power management schemes. these measurements reveal a number of surprising observations.we analyze these observations and produce a list of novel insights, including the important roles of operating system (os) context switching and power management in determining the program performance, and the subtle effect of cpu-gpu data copying. finally, we confirm those insights through case studies, and point out some promising directions to mitigate anomalous performance degradation on integrated heterogeneous processors.
relational_databases	this article focuses on testing a path-oriented querying approach to hierarchical data in relational databases. the authors execute a user study to compare the path-oriented approach and traditional sql from two perspectives: correctness of queries and time spent in querying. they also analyze what kinds of errors are typical in path-oriented sql. path-oriented query languages are popular in the context of object-orientation and xml. however, relational databases are the most common paradigm for storing data and sql is most common for manipulating data. when querying hierarchical data in sql, the user must specify join conditions explicitly between hierarchy levels. path-oriented sql is a new alternative for expressing hierarchical queries in relational databases. in the authors' study, the users spent significantly less time in writing path-oriented sql queries and made fewer errors in query formulation.
control_engineering	this paper presents an educational software tool, called wtcontrolgui, whose main purpose is to show the applicability and performance of different decoupling control strategies in wind turbines. nowadays, wind turbines are a very important field in control engineering. therefore, from an educational point of view, the tool also aims to improve the learning of multivariable control concepts applied on this field. in addition, wtcontrolgui allows for testing and controlling of a lab-scale system which emulates the dynamic response of a large-scale wind turbine. the designed graphical user interface essentially allows simulation and experimental testing of decoupling networks and other multivariable methodologies, such as robust or decentralized control strategies. the tool is available for master degree students in control engineering. a survey was performed to evaluate the effectiveness of the proposed tool when it is used in educational related tasks. (c) 2016 wiley periodicals, inc.
microcontroller	this paper aims to develop a new method for identification of power quality (pq) events based on discrete gabor transform (dgt) with a finite impulse response window (fir-dgt) and type-2 fuzzy kernel-based support vector machine (t2fk-svm). the fir-dgt extracted features from the input signals and the t2fk-svm classified them. using proper window function for dgt is essential. iterated sine window was used as window function to extract the events' features. the iterated sine window 's function is four times faster than the default window function of dgt. kernel design is a main part of many kernel-based methods such as svm, so by using t2fk, the total accuracy of classification is enhanced. in the present work, use of this hybrid approach decreased the extracted features size, so the execution time and total required memory were optimized for the classification section. the simulation results revealed accurate classification and execution in the detection and classification of nine types of pq events. the overall accuracy of the proposed method was comparable to other methods and the accuracy evaluated under noisy conditions. hardware platform was developed for evaluating the proposed method based on arm lpc 1768 microcontroller to assess accuracy of the method in real conditions.
software_engineering	context: software defect prediction (sdp) is an important task in software engineering. along with estimating the number of defects remaining in software systems and discovering defect associations, classifying the defect-proneness of software modules plays an important role in software defect prediction. several machine-learning methods have been applied to handle the defect-proneness of software modules as a classification problem. this type of yes or no decision is an important drawback in the decision-making process and if not precise may lead to misclassifications. to the best of our knowledge, existing approaches rely on fully automated module classification and do not provide a way to incorporate extra knowledge during the classification process. this knowledge can be helpful in avoiding misclassifications in cases where system modules cannot be classified in a reliable way. objective:we seek to develop a sdp method that (i) incorporates a reject option in the classifier to improve the reliability in the decision-making process; and (ii) makes it possible postpone the final decision related to rejected modules for an expert analysis or even for another classifier using extra domain knowledge. method: we develop a sdp method called rejoelm and its variant, irejoelm. both methods were built upon the weighted extreme learning machine (elm) with reject option that makes it possible postpone the final decision of non-classified modules, the rejected ones, to another moment. while rejoelm aims to maximize the accuracy for a rejection rate, irejoelm maximizes the f-measure. hence, irejoelm becomes an alternative for classification with reject option for imbalanced datasets. results: rejoem and irejoelm are tested on five datasets of source code metrics extracted from real world open-source software projects. results indicate that rejoelm has an accuracy for several rejection rates that is comparable to some state-of-the-art classifiers with reject option. although irejoelm shows lower accuracies for several rejection rates, it clearly outperforms all other methods when the f-measure is used as a performance metric. conclusion: it is concluded that rejoelm is a valid alternative for classification with reject option problems when classes are nearly equally represented. on the other hand, irejoelm is shown to be the best alternative for classification with reject option on imbalanced datasets. since sdp problems are usually characterized as imbalanced learning problems, the use of irejoelm is recommended. (c) 2016 elsevier b.v. all rights reserved.
computer_graphics	planar shape interpolation is a classic problem in computer graphics. we present a novel shape interpolation method that blends c-infinity planar harmonic mappings represented in closed-form. the intermediate mappings in the blending are guaranteed to be locally injective c-infinity harmonic mappings, with conformal and isometric distortion bounded by that of the input mappings. the key to the success of our method is the fact that the blended differentials of our interpolated mapping have a simple closed-form expression, so they can be evaluated with unprecedented efficiency and accuracy. moreover, in contrast to previous approaches, these differentials are integrable, and result in an actual mapping without further modification. our algorithm is embarrassingly parallel and is orders of magnitude faster than state-of-the-art methods due to its simplicity, yet it still produces mappings that are superior to those of existing techniques due to its guaranteed bounds on geometric distortion.
analog_signal_processing	slow light systems are particularly attractive for analog signal processing, since their inherent limitation to a delay-bandwidth product of 1 is less critical for analog systems such as those used in microwave photonics. we present here the implementation of two basic functions - phase shifting and true time delaying - fully optically controlled using stimulated brillouin scattering in optical fibers. the combination of these two functions makes possible the implementation of true time delays without limitation on the microwave carrier frequency using the separate carrier tuning technique. this is illustrated by the implementation of the delaying system for the realization of a microwave tunable notch filter.
system_identification	a methodology is proposed to update mechanics-based nonlinear finite element (fe) models of civil structures subjected to unknown input excitation. the approach allows to jointly estimate unknown time-invariant model parameters of a nonlinear fe model of the structure and the unknown time histories of input excitations using spatially-sparse output response measurements recorded during an earthquake event. the unscented. kalman filter, which circumvents the computation of fe response sensitivities with respect to the unknown model parameters and unknown input excitations by using a deterministic sampling approach, is employed as the estimation tool. the use of measurement data obtained from arrays of heterogeneous sensors, including accelerometers, displacement sensors, and strain gauges is investigated. based on the estimated fe model parameters and input excitations, the updated nonlinear fe model can be interrogated to detect, localize, classify, and assess damage in the structure. numerically simulated response data of a three-dimensional 4-story 2-by-1 bay steel frame structure with six unknown model parameters subjected to unknown bi-directional horizontal seismic excitation, and a three-dimensional 5-story 2-by-1 bay reinforced concrete frame structure with nine unknown model parameters subjected to unknown bi-directional horizontal seismic excitation are used to illustrate and validate the proposed methodology. the results of the validation studies show the excellent performance and robustness of the proposed algorithm to jointly estimate unknown fe model parameters and unknown input excitations. (c) 2017 elsevier ltd. all rights reserved.
analog_signal_processing	this paper describes a new class of the versatile network elements for analog signal processing; two-ports with frequency dependent phase shift which starts with arbitrary value and tends towards different but still arbitrary value. speaking in terms of the complex frequency response plotted in polar coordinates the characteristics can connect any two lines in any segment. the idea behind this concept is in utilization of coupled two-terminal devices which are able to keep constant phase shift between driving force and response signal from dc up to infinite frequency; the so-called constant phase elements. the passive realizations of these constant phase elements as well as the proposed network structures based on positive second generation current conveyors are verified by orcad pspice circuit simulator as well as experimental measurement.
electricity	this paper presents a power management system of a household photovoltaic-battery hybrid power system within demand side management under time of use electricity tariff. this system is easy to implement by employing cheap electrical switches, off-the-shelf chargers and inverters. control system models combining both power dispatching level and home appliance scheduling level are proposed to minimize the residents` energy cost and energy consumption from the grid with the practical constraints strictly satisfied. in addition, the resident comfort inconvenience level is considered in the control system models. the trade-off among operating cost, energy consumption and inconvenience is considered and a multi-objective optimization problem is formulated. the optimal control strategies are derived by solving a mixed-integer nonlinear programming problem. simulation results show that the energy cost and energy consumption from the grid can be largely reduced with the proposed strategies. these results are important for customers to dispel their major uncertainty in determining whether to newly install or update to such photovoltaic-battery hybrid power systems. (c) 2017 elsevier ltd. all rights reserved.
software_engineering	most of the research effort in the area of software analysis is focused on the perspective of the developer (as in ""software developing company"") and the ways how the software development process could be improved. however, that is not the only type of software assessment common in the industry. there are also assessments that are commissioned by other parties, such as the primary recipients of the software solutions or courts dealing with legal cases that are related to software products or services. this work presents one such case-study that was performed for a public administration in italy. the paper describes the assessment itself and also points out the need for more focused research by providing a comparison between developer-oriented and customer-oriented assessment types. (c) 2015 elsevier inc. all rights reserved.
network_security	a network traffic detection model based on swarm intelligent optimization neural network algorithm is proposed in this paper. qapso algorithm is used to optimize the basis function center and base function width of rbf neural network, and the connection weights of the output layer and the hidden layer as well. this paper analyzes the detection model studied in this paper by an example, and use the collected data to train the network traffic identification system and test its performance. the comparison between the proposed method and the conventional pso algorithm based on the hpso algorithm shows that the proposed method has faster recognition speed and better recognition accuracy, and avoids the problem of falling into the local optimal solution. situation.
computer_graphics	within education, concepts such as distance learning, and open universities, are now becoming more widely used for teaching and learning. however, due to the nature of the subject domain, the teaching of science, technology, and engineering are still relatively behind when using new technological approaches (particularly for online distance learning). the reason for this discrepancy lies in the fact that these fields often require laboratory exercises to provide effective skill acquisition and hands-on experience. often it is difficult to make these laboratories accessible for online access. either the real lab needs to be enabled for remote access or it needs to be replicated as a fully software-based virtual lab. we argue for the latter concept since it offers some advantages over remotely controlled real labs, which will be elaborated further in this paper. we are now seeing new emerging technologies that can overcome some of the potential difficulties in this area. these include: computer graphics, augmented reality, computational dynamics, and virtual worlds. this paper summarizes the state of the art in virtual laboratories and virtual worlds in the fields of science, technology, and engineering. the main research activity in these fields is discussed but special emphasis is put on the field of robotics due to the maturity of this area within the virtual-education community. this is not a coincidence; starting from its widely multidisciplinary character, robotics is a perfect example where all the other fields of engineering and physics can contribute. thus, the use of virtual labs for other scientific and non-robotic engineering uses can be seen to share many of the same learning processes. this can include supporting the introduction of new concepts as part of learning about science and technology, and introducing more general engineering knowledge, through to supporting more constructive (and collaborative) education and training activities in a more complex engineering topic such as robotics. the objective of this paper is to outline this problem space in more detail and to create a valuable source of information that can help to define the starting position for future research. (c) 2016 elsevier ltd. all rights reserved.
relational_databases	the concept of homogeneous integrity constraints in database systems is introduced. the metric space for the state of database schemes with homogeneous integrity constraints is established. it is shown that many common integrity constraints that are used in practice satisfy the condition of homogeneity of integrity constraints. such constraints include key, referential, joint, and many-to-many integrity constraints, etc. the proposed constructs allow one to design metric spaces for the state of database schemes and enable the study of integrity constraints of databases based on the methods and concepts of ""continuous mathematics.
electrical_network	optimal microgrid design is a challenging problem, especially for multi-energy microgrids with electricity, heating, and cooling loads as well as sources, and multiple energy carriers. to address this problem, this paper presents an optimization model formulated as a mixed-integer linear program, which determines the optimal technology portfolio, the optimal technology placement, and the associated optimal dispatch, in a microgrid with multiple energy types. the developed model uses a multi-node modeling approach (as opposed to an aggregate single-node approach) that includes electrical power flow and heat flow equations, and hence, offers the ability to perform optimal siting considering physical and operational constraints of electrical and heating/cooling networks. the new model is founded on the existing optimization model der-cam, a state-of-the-art decision support tool for microgrid planning and design. the results of a case study that compares single-node vs. multi-node optimal design for an example microgrid show the importance of multi-node modeling. it has been shown that single-node approaches are not only incapable of optimal der placement, but may also result in sub-optimal der portfolio, as well as underestimation of investment costs. published by elsevier ltd.
distributed_computing	multiscale, multi-physics applications are central to solve the increasing number of important scientific challenges. computationally speaking, the difficulty is to combine high performance computing with the need to couple various codes or solvers, each representing a different scale or a different physical process. in this paper, we present muscle-hpc a new hpc implementation of muscle-2, a previously developed multiscale coupling library and environment. we present its design and implementation and we demonstrate its advantages compared to muscle-2. we conduct a performance comparison through a tightly coupled mpi application use-case. our results indicate that using muscle-hpc to couple submodels within the same hpc cluster can lead to better computing performance comparable to a native mpi execution and can, thus, reduce the coupling overhead. (c) 2016 elsevier b.v. all rights reserved.
state_space_representation	the aim of the paper is to present a design procedure of the optimal controller minimizing the h-2-type norm of discrete-time stochastic linear systems with periodic coefficients simultaneously affected by a nonhomogeneous but periodic markov chain and state and control multiplicative white noise perturbations. firstly, two h-2-type norms for the linear stochastic systems under consideration were introduced. these h-2-type norms may be viewed as measures of the effect of the additive white noise perturbations on the regulated output of the considered system. before deriving of the state space representation of the optimal controller, some useful formulae of the two h-2-type norms were obtained. these formulae are expressed in terms of periodic solutions of some suitable linear equations and are derived in the absence of some additional assumptions regarding the markov chain other than the periodicity of the sequence of the transition probability matrices. further, it is shown that the optimal h-2 controller depends on the stabilizing solutions of some specific systems of coupled riccati equations, which generalize the well-known control and filtering equations from linear time invariant case. for the readers convenience, the paper presents iterative numerical algorithms for the computations of the stabilizing solutions of these riccati type systems. the theoretical developments are illustrated by numerical examples. copyright (c) 2014 john wiley & sons, ltd.
system_identification	in this paper, a novel approach was proposed to increase the confidence of active slip system identification in polycrystalline metals. the approach takes advantage of microscale deformation tracking via digital image correlation (dic) combined with scanning electron microscopy (sem). the experimentally-obtained high-resolution deformation fields were mapped to an undeformed configuration, which gives slip traces suitable for comparison with undeformed crystal orientation data. a metric, named herein as the 'relative displacement ratio' (rdr), is calculated from the displacement fields near slip traces to characterize the localized deformation due to slip. in validation cases, the experimentally-measured rdrs matched well with rdrs theoretically-calculated from active slip systems. in test cases, active slip system identification by incorporating rdr as an additional constraint was demonstrated to be preferable to using schmid factor alone as a constraint. the proposed approach supplements existing techniques for slip system identification with increased confidence.
state_space_representation	in this paper, a new identification method for large heterogeneous spatially interconnected systems is presented. a string of different systems in state-space representation is considered. the proposed algorithm optimizes the output-error of the global system by using the steepest-descent and the gauss-newton methods. the main contribution of this work is that both the jacobian and the hessian matrix can be entirely captured by using sequentially semi-separable (sss) matrices. therefore, all the computations in the optimization routine can be performed with complexity that is linear in the number of subsystems. this fact permits to obtain models for large interconnected systems at low computational cost. finally, a numerical example is presented in order to show the effectiveness of the proposed algorithm.
system_identification	this paper describes the development, implementation and experimental investigation of a hybrid model predictive control (hmpc) strategy to control solar-assisted heating, ventilation and air-conditioning (hvac) systems with on-site thermal energy generation and storage. a comprehensive approach to the thermal energy management of a residential building is presented to optimise the scheduling of the available thermal energy resources to meet a comfort objective. the system has a hybrid nature with both continuous variables and discrete, logic-driven operating modes. the proposed control strategy is organized in two hierarchical levels. at the high-level, an hmpc controller with a 24-h prediction horizon and a 1-h control step is used to select the operating mode of the hvac system. at the low-level, each operating mode is optimised using a 1-h rolling prediction horizon with a 5-min control step. the proposed control strategy has been practically implemented on the building management and control system (bmcs) of a net zero-energy solar decathlon house. this house features a sophisticated hvac system comprising of an air-based photovoltaic thermal (pvt) collector and a phase change material (pcm) thermal storage integrated with the air-handling unit (ahu) of a ducted reverse-cycle heat pump system. the simulation and experimental results demonstrated the high performance achievable using an hmpc approach to optimising complex multimode hvac systems in residential buildings, illustrating efficient selection of the appropriate operating modes to optimally manage thermal energy of the house. (c) 2016 elsevier ltd. all rights reserved.
data_structures	background: data capture for clinical registries or pilot studies is often performed in spreadsheet-based applications like microsoft excel or ibm spss. usually, data is transferred into statistic software, such as sas, r or ibm spss statistics, for analyses afterwards. spreadsheet-based solutions suffer from several drawbacks: it is generally not possible to ensure a sufficient right and role management; it is not traced who has changed data when and why. therefore, such systems are not able to comply with regulatory requirements for electronic data capture in clinical trials. in contrast, electronic data capture (edc) software enables a reliable, secure and auditable collection of data. in this regard, most edc vendors support the cdisc odm standard to define, communicate and archive clinical trial meta-and patient data. advantages of edc systems are support for multi-user and multicenter clinical trials as well as auditable data. migration from spreadsheet based data collection to edc systems is labor-intensive and time-consuming at present. hence, the objectives of this research work are to develop a mapping model and implement a converter between the ibm spss and cdisc odm standard and to evaluate this approach regarding syntactic and semantic correctness. results: a mapping model between ibm spss and cdisc odm data structures was developed. spss variables and patient values can be mapped and converted into odm. statistical and display attributes from spss are not corresponding to any odm elements; study related odm elements are not available in spss. the s2o converting tool was implemented as command-line-tool using the spss internal java plugin. syntactic and semantic correctness was validated with different odm tools and reverse transformation from odm into spss format. clinical data values were also successfully transformed into the odm structure. conclusion: transformation between the spreadsheet format ibm spss and the odm standard for definition and exchange of trial data is feasible. s2o facilitates migration from excel-or spss-based data collections towards reliable edc systems. thereby, advantages of edc systems like reliable software architecture for secure and traceable data collection and particularly compliance with regulatory requirements are achievable.
computer_vision	rgb-d human action recognition is a very active research topic in computer vision and robotics. in this paper, an action recognition method that combines gradient information and sparse coding is proposed. first of all, we leverage depth gradient information and distance of skeleton joints to extract coarse depth-skeleton (ds) feature. then, the sparse coding and max pooling are combined to refine the coarse ds feature. finally, the random decision forests (rdf) is utilized to perform action recognition. experimental results on three public datasets show the superior performance of our method.
distributed_computing	extreme hydrometeorological events such as flash floods have caused considerable loss of life and damage to infrastructure over recent years. flood events in the mediterranean region between 1990 and 2006 caused over 4,500 fatalities and cost over (sic)29 billion in damage, with italy one of the worst affected countries. the distributed computing infrastructure for hydro-meteorology (drihm) project is a european initiative aiming at providing an open, fully integrated escience environment for predicting, managing, and mitigating the risks related to such extreme weather phenomena. incorporating both modeled and observational data sources, it enables seamless access to a set of computing resources with the objective of providing a collection of services for performing experiments with numerical models in meteorology, hydrology, and hydraulics. the purpose of this article is to demonstrate how this flexible modeling architecture has been constructed using a set of standards including the netcdf and waterml2 file formats, in-memory coupling with openmi, controlled vocabularies such as cf standard names, iso19139 metadata, and a model map (metadata, adaptors, portability) gateway concept for preparing numerical models for standardized use. hydraulic results, including the impact to buildings and hazards to people, are given for the use cases of the severe and fatal flash floods, which occurred in genoa, italy in november 2011 and october 2014.
machine_learning	in the literature, a number of approaches have been proposed for learning grapheme-to-phoneme (g2p) relationship and inferring pronunciations. in this letter, we present a novel multistream framework for g2p conversion, where various machine learning techniques providing different estimates of probability of phonemes given graphemes can be effectively combined during pronunciation inference. more precisely, analogous to multistream automatic speech recognition, the framework involves obtaining different streams of estimates of probability of phonemes given graphemes, combining them based on probability combination rules, and inferring pronunciations by decoding the probabilities resulting after combination. we demonstrate the potential of the proposed approach by combining probabilities estimated by the state-of-the-art conditional random field-based g2p conversion approach and acoustic data-driven g2p conversion approach in the kullback-leibler-divergence-based hidden markov model framework on the phonebook 600-word task.
symbolic_computation	in this paper, the (3+1)-dimensional jimbo-miwa equation is solved by fan sub-equation method with improved algorithms. as a result, many new and more general travelling wave solutions are obtained including kink-shaped soliton solutions, rational solutions, triangular periodic solutions, jacobi and weierstrass doubly periodic wave solutions. at a certain limit condition, the obtained jacobi elliptic periodic wave solutions can degenerate into soliton solutions. it is shown that the improved algorithms of fan sub-equation method can lead to such solutions with external linear functions possessing two remarkable evolutionary properties: (i) the wave propagation is skew; (ii) the amplitude enlarges along with the increasing time.
cryptography	conditional differential cryptanalysis on nfsr-based cryptosystems was first proposed by knellwolf et al. in asiacrypt 2010 and has been successfully used to attack reduced variants of grain v1. in this paper, we greatly improve conditional differential attacks on grain v1 in the following four aspects. first, a new differential engine is derived to correctly track the differential trails of grain v1. second, we propose a new difference-searching strategy which serves to find suitable differences for the conditional differential attack on a given reduced variant of grain v1. third, a highly iv-saving condition-imposing strategy is presented. last, we propose a further bias-increasing strategy. in particular, the improvements on the difference-searching strategy and the condition-imposing strategy are crucial to mount conditional differential attacks on the variants of grain v1 with more than 106 rounds. it is shown that the improved conditional differential attacks could retrieve 31 distinct secret key expressions for 107-round grain v1 and could retrieve 15 distinct secret key expressions for 110-round grain v1. both the attacks succeed with constant probabilities. thus far, our results are the best known for the reduced variants of grain v1 as far as the number of rounds attacked is concerned.
computer_programming	unlike conventional taught learning, video games are very successful at keeping players constantly motivated and engaged on a set of tasks for many hours without apparent loss of focus. additionally, when playing, gamers solve complex problems without experiencing the fatigue or frustration, which would normally accompany a comparable learning task. any methods able to deliver deep learner engagement are naturally of interest to the academic community, thus resulting in an increasing interest in adopting gamification - the integration of gaming elements, mechanics, and frameworks into non-game situations and scenarios - as a means to drive student engagement and improve information retention. however, its application to education has been a challenging task, as attempts have generally been restricted to a one-dimensional approach, such as transposing a trivial reward system onto existing teaching material. the empirical evidence presented in this paper suggests that a gamified, multi-dimensional, problem-based learning approach may yield improved outcomes even when applied to a very complex and traditionally dry task like the teaching of computer programming. this quasi-experimental study employed a real time sequence of scored quizzes, instructor feedback, and live coding to deliver a fully interactive learning experience. by using a combination of the classroom version of the tv game show ""who wants to be a millionaire?"", the ""kahoot!"" classroom response system (crs), and codecademy 's online interactive platform on a python programming course, students were allowed to experience multiple interlocking methods similar to what would be found in a top quality game experience. empirical data on learning outcomes from the gamified group were compared with a control group that followed a traditional learning path, which had been used during previous cohorts. whilst this was a relatively small study, the results were quite interesting in a number of key metrics, including attendance, downloading of course material, and final grades.
algorithm_design	if we apply the developed local polar edge detection method, or lped method, to a binary image (with each pixel being either black or white), we can obtain the boundary points of all objects embedded in the more randomly distributed noise background in sub-milli-second time. then we can apply our newly developed grouping or clustering algorithm to separate the boundary points for all objects into individual-object, boundary-point groups. then we can apply our fast identification-and-tracking technique to automatically identify each object by its unique geometry shape and track its movement simultaneously for n objects like we did before for two objects. this paper will concentrate at the algorithm design of this superfast grouping technique. it is not like the classical combinatorial clustering algorithm in which the computation time increases exponentially with the number of points to be clustered. it is a linear time grouping method in which the grouping time increases only linearly with the number of the total points to be grouped. the total time for automatic grouping of 100-200 boundary points into separated object boundary groups is about 10 to 50 milli-seconds live computer experiments will be demonstrated in the presentation.
network_security	the cloud computing environment has expanded considerably with the rapid advancement of related technologies. although cloud computing is convenient for users, detecting and preventing possible security breaches remains an unsolved problem. security logs are critical data that indicate events in an operating system or other software, and these data are stored through heterogeneous machines such as network security devices, server systems, and database management systems (dbms). however, existing methods can create problems for efficient analysis because of large-scale heterogeneous security logs in the cloud-computing environment. therefore, because cloud computing provides various services to users, an efficient integration method of security logs must be developed. this study proposes a nosql-based method to collect and integrate security logs using mapreduce. our study shows that log data were reduced by more than 87% when integrating duplicate large-scale security logs. this proposed method provides faster data storage than conventional dbms and is more effective.
parallel_computing	in this paper, we present a bio-inspired parallel implementation of a solution of the problem of looking for the representative geometrical objects of the homology groups in a binary 2d image (extended-hgb2i problem), which is an extended version of a well-known problem in homology theory. in particular, given a binary 2d image, all black connected components and the representative curves of the holes of these components are obtained and labelled. to this aim, a new technique for labelling the connected components of a binary image is presented. in order to compute the solution, the formal framework uses techniques from membrane computing and the implementation has been done in a hardware architecture called compute unified device architecture (cuda). the computational complexity of the proposed solution is o(m) with respect to the input (image) size m similar to n(2). finally, some examples and applications are also presented.
electricity	vibration energy harvesting converts mechanical energy from ambient sources to electricity to power remote sensors. compared to linear resonators that have poor performance away from their natural frequency, nonlinear vibration energy harvesters perform better because they use vibration energy over a broader spectrum. we present a hybrid nonlinear energy harvester that combines bi-stability with internal resonance to increase the frequency bandwidth. a two-fold increase in the frequency bandwidth can be obtained compared to a bi-stable system with fixed magnets. the harvester consists of a piezoelectric cantilever beam carrying a movable magnet facing a fixed magnet. a spring allows the magnet to move along the beam and it provides an extra stored energy to further increase the amplitude of vibration acting as a mechanical amplifier. an electromechanically coupled mathematical model of the system is presented to obtain the dynamic response of the cantilever beam, the movable magnet and the output voltage. the perturbation method of multiple scales is applied to solve these equations and obtain approximate analytical solutions. the effects of various system parameters on the frequency responses are investigated. the numerical approaches of the long time integration (runge-kutta method) and the shooting technique are used to verify the analytical results. the results of this study can be used to improve efficiency in converting wasted mechanical vibration to useful electrical energy by broadening the frequency bandwidth. (c) 2016 elsevier ltd. all rights reserved.
data_structures	the way data structures organize data is often a function of the sequence of past operations. the organization of data is referred to as the data structure 's state, and the sequence of past operations constitutes the data structure 's history. a data structure state can, therefore, be used as an oracle to derive information about its history. for history-sensitive applications, such as privacy in e-voting, it is imperative to conceal historical information contained within data structure states. data structure history can be hidden by making data structures history independent. in this paper, we explore how to achieve history independence (hi). we observe that the current hi notions are significantly limited in number and scope. there are two existing notions of hi: 1) weak hi (whi) and 2) strong hi (shi). whi does not protect against insider adversaries, and shi mandates canonical representations, resulting in inefficiency. we postulate the need for a broad, encompassing notion of hi, which can capture whi, shi, and a broad spectrum of new hi notions. to this end, we introduce delta hi, a generic game-based framework that is malleable enough to accommodate the existing and new hi notions. as an essential step toward formalizing delta hi, we explore the concepts of abstract data types, data structures, machine models, memory representations, and hi. finally, to bridge the gap between theory and practice, we outline a general recipe for building end-to-end, history-independent systems and demonstrate the use of the recipe in designing two history-independent file systems.
operational_amplifier	the objective of this work is to minimize testing cost of analog and rf circuits for which complete specification tests are available. we use an integer linear program (ilp) to eliminate as many tests as possible without exceeding the required defect level. the method leverages correlation among specifications, thereby avoiding the tests for specifications that are sufficiently covered by tests for other specifications. first, monte carlo simulation determines probabilities for each test covering all other specifications it was not originally intended for. these probabilities and the given defect level then define an ilp model for eliminating unnecessary tests. an hypothetical example illustration of ten specifications demonstrates that depending on the defect level requirement up to half of the tests may be eliminated. monte carlo simulation using spice for probabilistic characterization of tests versus specifications followed by ilp optimization for two commercially available integrated circuits, an operational amplifier and a radio frequency power controller (rfpc), are presented as evidence of effectiveness of the technique.
operational_amplifier	circuit parameters and configuration are very important when studying the synergistic effects total dose/set. we explore a method combining dynamic parameter measurement and spectrum analysis which lead to a better understanding of this complex phenomenon. in this paper symbolic circuit analysis is used to obtain the relationship between input, output and noise injection due to photocurrent generation in the form of a rational function using symbolic variables in the complex frequency domain. this simulation technique was able to predict the impact of (i) total dose level, (ii) circuit parameters, and (iii) the injected energy on the aset shapes. basic mechanisms as field collapse and collection efficiency were also predicted and assessed.
bioinformatics	transposable elements (tes) constitute the most dynamic and the largest component of large plant genomes: for example, 80% to 90% of the maize genome and the wheat genome may be tes. de novo te annotation is therefore a computational challenge, and we investigated, using current tools in the repet package, new strategies to overcome the difficulties. we tested our methodological developments on the sequence of the chromosome 3b of the hexaploid wheat; this chromosome is similar to 1 gb, one of the ""fattest"" genomes ever sequenced. we successfully established various strategies for annotating tes in such a complex dataset. our analyses show that all of our strategies can overcome the current limitations for de novo te discovery in large plant genomes. relative to annotation based on a library of known tes, our de novo approaches improved genome coverage (from 84% to 90%), and the number of full length annotated copies from 14 830 to 15905. we also developed two new metrics for qualifying te annotation: nte50 involves measuring the number, and lte50 the smallest sizes of annotations that cover 50% of the genome. nte50 decreased the number of annotations from 124868 to 93633 and lte50 increased it from 1839 to 2659. this work shows how to obtain comprehensive and high-quality automatic te annotation for a number of economically and agronomically important species.
image_processing	a mathematica application providing the user with a graphical interface (gui) is presented and published, which can be used to interactively explore image filtering and segmentation methods to analyse variously shaped particles in a microscopic image. the application functionality is designed around mathematica 's in-built image processing capability with custom designed functions specialized at segmenting greyscale microscope images. the main contribution is a specially designed gui which allows the characterization of segmented particles based on their morphological properties, with focus given to differentiation of the shapes of the segmented particles. the application provides a convenient way of navigating through the myriad of ways to analyse particles in micrographs. (c) 2016 elsevier b.v. all rights reserved.
electrical_circuits	electrical circuits are difficult to understand. novices tend to have inadequate understandings of what happens at the level of atoms and electrons, leading to difficulty predicting the outcomes of electrical circuits at the level of wires, resistors, and light bulbs. in this paper, we argue that integrating micro and macro representations of an electrical circuit can provide students with a better understanding of fundamental concepts of electricity. we then introduce spark, an interactive multi-level simulation environment that enables learners to interact with representations of electrical circuit at both levels. the primary goal of our design is to familiarize students with electrical current, resistance, and potential difference in a circuit. we conducted a study with 17 university students that shows the ability of our design to improve novice understanding of electrical circuits. our study offers evidence that learners are able to develop better understandings of fundamental concepts of electricity drawing on both micro-level and macro-level representations of an electrical circuit.
parallel_computing	this paper presents a new hybrid modeling technique for the efficient simulation of guided wave generation, propagation, and interaction with damage in complex composite structures. a local finite element model is deployed to capture the piezoelectric effects and actuation dynamics of the transmitter, while the global domain wave propagation and interaction with structural complexity (structure features and damage) are solved utilizing a local interaction simulation approach (lisa). this hybrid approach allows the accurate modeling of the local dynamics of the transducers and keeping the lisa formulation in an explicit format, which facilitates its readiness for parallel computing. the global lisa framework was extended through the 3d kelvin-voigt viscoelasticity theory to include anisotropic damping effects for composite structures, as an improvement over the existing lisa formulation. the global lisa framework was implemented using the compute unified device architecture running on graphic processing units. a commercial preprocessor is integrated seamlessly with the computational framework for grid generation and material property allocation to handle complex structures. the excitability and damping effects are successfully captured by this hybrid model, with experimental validation using the scanning laser doppler vibrometry. to demonstrate the capability of our hybrid approach for complex structures, guided wave propagation and interaction with a delamination in a composite panel with stiffeners is presented.
state_space_representation	this work presents a novel variable speed generator system, i.e. double-generator system for the hydropower plants. it consists of two synchronous machines, a superposition gearbox and an inverter. one of the synchronous machines is coupled directly to the grid and the other is connected to the inverter. the stabilization of the system and the regulation of the turbine desired speed are achieved by the control of the latter synchronous machine. due to its specific construction the investment of hydropower plants can be reduced. the dynamic behavior e.g. the step responses characterizes the system properties. firstly, the equations, which describe the total system, are presented. then these equations are linearized at an operating point, so that the controller can be designed. finally, the stability of the system and the control behavior are examined with the method of state space representation.
software_engineering	the mobile app market continues to grow at a tremendous rate. the market provides a convenient and efficient distribution mechanism for updating apps. app developers continuously leverage such mechanism to update their apps at a rapid pace. the mechanism is ideal for publishing emergency updates (i.e., updates that are published soon after the previous update). in this paper, we study such emergency updates in the google play store. examining more than 44,000 updates of over 10,000 mobile apps in the google play store, we identify 1,000 emergency updates. by studying the characteristics of such emergency updates, we find that the emergency updates often have a long lifetime (i.e., they are rarely followed by another emergency update). updates preceding emergency updates often receive a higher ratio of negative reviews than the emergency updates. however, the release notes of emergency updates rarely indicate the rationale for such updates. hence, we manually investigate the binary changes of several of these emergency updates. we find eight patterns of emergency updates. we categorize these eight patterns along two categories ""updates due to deployment issues"" and ""updates due to source code changes"". we find that these identified patterns of emergency updates are often associated with simple mistakes, such as using a wrong resource folder (e.g., images or sounds) for an app. we manually examine each pattern and document its causes and impact on the user experience. app developers should carefully avoid these patterns in order to improve the user experience.
machine_learning	this work develops a method for calibrating a crystal plasticity model to the results of discrete dislocation (dd) simulations. the crystal model explicitly represents junction formation and annihilation mechanisms and applies these mechanisms to describe hardening in hexagonal close packed metals. the model treats these dislocation mechanisms separately from elastic interactions among populations of dislocations, which the model represents through a conventional strength-interaction matrix. this split between elastic interactions and junction formation mechanisms more accurately reproduces the dd data and results in a multi-scale model that better represents the lower scale physics. the fitting procedure employs concepts of machine learning-feature selection by regularized regression and crossvalidation- to develop a robust, physically accurate crystal model. the work also presents a method for ensuring the final, calibrated crystal model respects the physical symmetries of the crystal system. calibrating the crystal model requires fitting two linear operators: one describing elastic dislocation interactions and another describing junction formation and annihilation dislocation reactions. the structure of these operators in the final, calibrated model reflect the crystal symmetry and slip system geometry of the dd simulations.
electricity	green energy has gained significant research attention across the globe due to its ability to reduce environmental damage. however, for complete acceptance of green energy, only government regulations are not enough; the willingness to use green energy and contribute to the wellbeing of the environment should spring from within consumers. such willingness may be developed by enhancing consumers' perceived value of green energy. however, in order to do so, it is necessary to assess existing levels of consumers' perceived value towards green energy. the present study develops a multidimensional green perceived value scale to measure existing levels of consumers' perceived value. the scale considers green perceived value as a multidimensional second order construct comprising functional value, social value, conditional value and emotional value dimensions. such an attempt has not been made before which highlights the originality value of the present study. the scale can be used to assess consumers' perception towards green energy. such information would help in formulating strategies that encourage consumers to voluntarily adopt green energy. the study also reveals that it is not only the financial aspects that lead consumers to decide on adoption of green energy; consumers are also driven by emotional and social considerations. thus, policy makers could formulate pro-green energy programmes and mass messages that appeal to consumers' sense of responsibility to voluntarily adopt green energy without having to rely on financial incentives. researchers could examine the considered dimensions of the scale further with respect to other constructs related to consumer behaviour. (c) 2017 elsevier ltd. all rights reserved.
relational_databases	provision of an uniform query interface facade to access the health-care data present in multiple data-stores being used autonomously by various departments of an hospital, will empower the health-care community to make better decisions and conclusions. one naive approach for implementation of such system is to use any one popular database to store and process all the data pertaining to all the departments of an hospital. nonetheless, any single data-model cannot efficiently store and process multitude of data generated by healthcare institutions. for example, not all data fit well into row-column format of traditional relational databases. however, modern nosql data-stores allow data to be stored in a form closer to their actual representation and usage. storage and retrieval of data from disparate data-stores has its challenges and issues like dealing with multiple querying languages, understanding different data modeling techniques and, creation and maintenance of knowledge base of data (kbod). we have developed an intelligent information integration solution named polyglot-persistent healthcare information system-polyglothis which makes use of cooperating agents enabling health-care professionals to retrieve data from heterogeneous data-stores. polyglothis uses multiple data-stores for storage and processing of the his data. the rationale is to select the most appropriate data storage technology that meets the specific requirements of each module of the his. architecture of polyglothis consists primarily of multiple cooperative agents. capabilities and contents of data-stores are stored and inferred using datalog, a declarative logic programming language used to store set of facts and rules. design and working principle of polyglothis is illustrated with the help of a running example. performance analysis of the implemented system showcase that very less latency has been induced by the system.
parallel_computing	to accurately construct the topographic information of a six-legged walking robot in real time, this study proposes a stereo matching algorithm that can conduct disparity estimation on each pixel by using the bayesian posterior probability model based on gpu-accelerated parallel processing. in the proposed algorithm, supporting points construct a disparity space to obtain the prior distribution probability density of each pixel and then substitute it into the bayesian posterior probability model to establish the energy function of the disparity. the estimated disparity value of the unknown pixel can be obtained by minimizing the energy function. by performing a consistency check on the left and right sides of an image, the mismatching pixel can be eliminated. according to the disparity value of the supporting point, the disparity filling of the mismatching area can be achieved by applying the adaptive weight method on the basis of cross extending to obtain the accurate density of the disparity map. parallel computing in each stage of the proposed algorithm is performed by using the compute unified device architecture to reduce the running time. experimental results show that the proposed algorithm has good robustness for different illuminations and texture curved surface reconstruction. the algorithm can also adapt to the fast matching of images in different sizes and reconstruct the disparity map of scenes in real time under the resolution ratio of 640 x 480. the stereoscopic vision test board is employed to construct the disparity map of real scenes and verify the practical application effect of the algorithm. good experiment effect is achieved. (c) 2015 elsevier b.v. all rights reserved.
electrical_network	the electrical network measurements are usually sent to the control centers using specific communication protocols. however, these measurements contain uncertainties due to the meters and communication errors (noise), incomplete metering or unavailability of some of these measurements. the aim of state estimation is to estimate the state variables of the power system by minimizing all measurement errors available at the control center. in the past, many traditional algorithms, based on gradient approach, have been used for this purpose. this paper discusses the application of an artificial intelligence (ai) algorithm, the particle swarm optimization (pso), to solve the state estimation problem within a power system. two objective functions are formulated: the weighted least square (wls) and weighted least absolute value (wlav). the effectiveness of pso over another ai optimization algorithm, genetic algorithm (ga), is shown by comparing both two solutions to the true state variable values obtained using newton-raphson (nr) algorithm. (c) 2014 elsevier b.v. all rights reserved.
control_engineering	the objective of this paper is to present an example in which matrix functions are used to solve a modern control exercise. specifically, the solution for the equation of state, which is a matrix differential equation is calculated. to resolve this, two different methods are presented, first using the properties of the matrix functions and by other side, using the classical method of laplace transform.
computer_vision	video object tracking represents a very important computer vision domain. in this paper, a perceptual hashing based template-matching method for object tracking is proposed to efficiently track objects in challenging video sequences. in the tracking process, we first apply three existing basic perceptual hashing techniques to visual tracking, namely average hash (ahash), perceptive hash (phash) and difference hash (dhash). compared with previous tracking methods such as mean-shift or compressive tracking (ct), perceptual hashing-based tracking outperforms in terms of efficiency and accuracy. in order to further improve the accuracy of object localization and the robustness of tracking, we propose laplace-based hash (lhash) and laplace-based difference hash (ldhash). by qualitative and quantitative comparison with some representative tracking algorithms, experimental results show that our improved perceptual hashing-based tracking algorithms perform favorably against the state-of-the-art algorithms under various challenging environments in terms of time cost, accuracy and robustness. since our improved perceptual hashing can be a compact and efficient representation of objects, it can be further applied to fusing with depth information for more robust rgb-d video tracking.
image_processing	visible light positioning (vlp) is widely believed to be a cost-effective answer to the growing demand for real-time indoor positioning. however, due to the high computational cost of image processing, most existing vlc-based systems fail to deliver satisfactory performance in terms of positioning speed and accuracy, both of which are crucial for the performance of indoor navigation. this paper proposes a novel vlp solution that provides accurate and high-speed indoor navigation via the designs of an elaborate flicker-free line coding scheme and a lightweight image processing algorithm. in addition, this solution has the advantage of supporting flicker mitigation and dimming, which are important for illumination. an android-based system prototype has been developed for field tests on an off-the-shelf smartphone. experimental results show that it supports indoor positioning for users moving at a speed of up to 18 km/h. in addition, it can achieve a high accuracy of 7.5 cm, and the computational time is reduced to 22.7 ms for single-luminaire and to 35.7 ms for dual-luminaries, respectively.
state_space_representation	this study introduces power quality (pq) state space representation to describe continuous pq disturbances. a tolerance boundary is designed to represent the integrated disturbance tolerance of all equipment connected to electric power network, and the uncertainty of integrated disturbance tolerance is described with the cloud model. electromagnetic compatibility and incompatibility degree indices are proposed to reflect the severity of pq disturbances affecting the equipment. the influence degree index is defined to quantify the severity and impact scope of pq disturbances. the uncertainty of equipment fault state is expressed by a fuzzy membership function. subsequently, pq performance is assessed according to equipment compatibility/incompatibility degree to pq disturbances. case studies on a 14-bus distribution system are performed and analysed. results reveal the effectiveness and reasonableness of the proposed indices in assessing equipment compatibility/incompatibility degree to pq disturbances, influence of pq disturbances on the equipment, and pq performance.
image_processing	a new vision-based system is designed for the identification of chatter vibration. chatter vibration is a major obstacle in cnc machining as it causes bad surface finishes and increases tooling damage and costs. this research proposes the use of machine vision for the detection of chatter vibration frequencies during high-speed milling operations. the vision system utilizes digital image processing and texture analysis to determine the frequencies of the chatter marks on the surface of a machined workpiece. the developed system provides a solution to machinists at ease without any expensive measuring equipment. the vision system was verified and compared with other chatter detection methods by identifying and creating tests based on the dynamics of a machine tool.
digital_control	the main tendency of rolling mills drives modernization is outdated analog control systems replacement with new digital ones. at the same time, a power section of the drive remains the same. this gives an opportunity to develop and implement adaptive digital control system for such plants in order to take into consideration their high nonlinearity. having considered different types of such systems, the ones which does not change the well-accepted pid control algorithm, but tune its parameters kp, ki, kd are believed to have the highest chances to be applied into industry. the main aim of this research is to develop and apply a neural tuner to adjust armature current pi-controller parameters of a two-high reversing rolling mill drive online. the neural tuner consists of 1) a neural network calculating kp and ki values and trained online with the help of backpropagation method and 2) a rule base, which conditions is used to estimate transient quality, whereas consequences are values of a learning rate of the network output layer neurons. modeling experiments are conducted with a model of the plant under consideration. they are used to check the ability of the tuner to: 1) adjust the pi-controller parameters back to optimal values; 2) cope with an armature winding parameters drift. such experiments are conducted both for the systems with the neural tuner and a conventional pi-controller. as far as the second type of experiments is concerned, the system with the neural tuner is able to achieve 2% energy consumption decrease comparing to a conventional pi-controller based control system.
electrical_circuits	a new concept of an electrical shunt with different materials (aluminum and copper) has been developed to be used as an alternative current measurement device. the device provides better current measurement characteristics compared with the conventional current measurement devices such as a shunt resistor with an ammeter or the multiple shunts consisting of molybdenum having a low temperature coefficient and a rogowski coil with an integrated circuit. the currents in several electrical circuits have been measured using the developed current-voltage transferring device (cvtd) as voltages between the aluminum and copper elements. the measured voltages (v-m) are proportional to measuring currents (i-m), which is shown as the following the experimental equation v-m [mv] =ki(m) [a], in which k is a coefficient depending on the configuration of the cvtd. (c) 2015 institute of electrical engineers of japan. published by john wiley & sons, inc.
microcontroller	this paper describes the implementation of two neuron emulator circuits. the first circuit provides the electrical properties of a neuron as seen from a single patch-clamp electrode with a defined action potential (ap) charge output and the second circuit offers multi-channel output with an adjustable phase delay that provides responses typically seen by a longitudinal electrode (e.g., peripheral nerve cuff or intraneural electrode) using a 3 x 4 cm(2) prototype board. the emulators are intended for testing electrophysiological equipment such as patch-clamp amplifiers and multi-channel devices. aps are generated with a voltage-dependent frequency controlled by a microcontroller. the reported measured results confirm the capability of performing voltage-clamp and rate-responsive current-clamp techniques and generating phase-delayed ap outputs, respectively.
operational_amplifier	a model of the operational amplifier based on vhdl-ams is proposed. according to needs of simulating the total ionizing dose (ted) radiation effect, parameters of operational amplifier are taken into account when the performance is specified. the operational amplifier model used for the tid radiation effect simulation is completed after verifying each modeled parameter. and a parameter for describing the external environment is introduced to make the model combined with tid. finally, an example is used to illustrate the tid effect on the operational amplifier of mc14573, proving the validity of the model.
cryptography	the session initiation protocol (sip) is a signaling protocol widely applied in the world of multimedia communication. numerous sip authenticated key agreement schemes have been proposed with the purpose of ensuring security communication. farash recently put forward an enhancement employing smart cards counted on zhang et al. 's scheme. in this study, we observe that the enhanced scheme presented by farash has also some security pitfalls, such as disclosure of user identity, lack of a pre-authentication in the smart card and vulnerability to key-compromise masquerading attack which results in an off-line guessing attack. we then propose an anonymous modified scheme with elliptic curve cryptography to eliminate the security leakages of the scheme proposed by farash. we demonstrate that our scheme is immune to different kinds of attacks including attacks involved in farash 's scheme. we mention burrows-abadi-needham logic for completeness of the proposed scheme. also, we compare the performance of our scheme with its predecessor schemes and the comparative results shows that it perfectly satisfies the needs of sip.
computer_programming	lateral diffusion and compartmentalization of plasma membrane proteins are tightly regulated in cells and thus, studying these processes will reveal new insights to plasma membrane protein function and regulation. recently, k-space image correlation spectroscopy (kics)(1) was developed to enable routine measurements of diffusion coefficients directly from images of fluorescently tagged plasma membrane proteins, that avoided systematic biases introduced by probe photophysics. although the theoretical basis for the analysis is complex, the method can be implemented by nonexperts using a freely available code to measure diffusion coefficients of proteins. kics calculates a time correlation function from a fluorescence microscopy image stack after fourier transformation of each image to reciprocal (k-) space. subsequently, circular averaging, natural logarithm transform and linear fits to the correlation function yields the diffusion coefficient. this paper provides a step-by-step guide to the image analysis and measurement of diffusion coefficients via kics. first, a high frame rate image sequence of a fluorescently labeled plasma membrane protein is acquired using a fluorescence microscope. then, a region of interest (roi) avoiding intracellular organelles, moving vesicles or protruding membrane regions is selected. the roi stack is imported into a freely available code and several defined parameters (see method section) are set for kics analysis. the program then generates a ""slope of slopes"" plot from the k-space time correlation functions, and the diffusion coefficient is calculated from the slope of the plot. below is a step-by-step kics procedure to measure the diffusion coefficient of a membrane protein using the renal water channel aquaporin-3 tagged with egfp as a canonical example.
control_engineering	material forming industry urgently needs high-quality engineering and technical skill talents with practical operation ability and using all kinds of digital tools for the independent die & mould design and manufacture. the paper analyzes the material forming industry situation, development trend and current situation of shanghai mould talents demand and training, the results showed that people possessing more than one post, fusing multidisciplinary knowledge, mastering multi-capacity, realizing the future development demand exceeds supply. all of these provide the support for the breakthrough cultivationin of the professional positioning and the talent cultivation aim determining.
software_engineering	fuzzy systems have been used widely thanks to their ability to successfully solve a wide range of problems in different application fields. however, their replication and application require a high level of knowledge and experience. furthermore, few researchers publish the software and/or source code associated with their proposals, which is a major obstacle to scientific progress in other disciplines and in industry. in recent years, most fuzzy system software has been developed in order to facilitate the use of fuzzy systems. some software is commercially distributed, but most software is available as free and open-source software, reducing such obstacles and providing many advantages: quicker detection of errors, innovative applications, faster adoption of fuzzy systems, etc. in this paper, we present an overview of freely available and open-source fuzzy systems software in order to provide a well-established framework that helps researchers to find existing proposals easily and to develop well-founded future work. to accomplish this, we propose a two-level taxonomy, and we describe the main contributions related to each field. moreover, we provide a snapshot of the status of the publications in this field according to the isi web of knowledge. finally, some considerations regarding recent trends and potential research directions are presented.
pid_controller	force sensing and control are of paramount importance in robotic micromanipulation. a contact force regulator capable of accurately applying mechanical stimuli to a live drosophila larva could greatly facilitate mechanobiology research on drosophila and may eventually lead to novel discoveries in mechanotransduction mechanisms of neuronal circuitries. in this paper, we present a novel contact force control scheme implemented in an automated drosophila larvae micromanipulation system, featuring a switched fuzzy to proportional-differential (pd) controller and a noise-insensitive extended high gain observer (ehgo). the switched fuzzy-pd control law inherits the fast convergence of fuzzy control and overcomes its drawbacks such as large overshoot and steady-state oscillation. the noise-insensitive ehgo can reliably estimate system modeling errors and is robust to force measurement noises, which is advantageous over conventional high gain observers (sensitive to signal noises). force control experiments show that, compared to a proportional-integral-differential (pid) controller, this new force control scheme significantly enhances the system dynamic performance in terms of rising time, overshoot, and oscillation. the developed robotic system and the force control scheme will be applied to mechanical stimulation and fluorescence imaging of drosophila larvae for identifying new mechanotransduction mechanisms.
distributed_computing	while cloud computing led the path towards a revolutionary change in the modern day computing aspects, further developments gave way to the internet of things and its own range of highly interactive applications. while such a paradigm is more distributed in reach, it also brings forth its own set of challenges in the form of latency sensitive applications, where a quick response highly contributes to efficient usage and qos (quality of service). fog computing, which is the answer to all such challenges, is rapidly changing the distributed computing landscape by extending the cloud computing paradigm to include widespread resources located at the network edge. while the fog paradigm makes use of edge-ward devices capable of computing, networking and storage, one of the key impending challenges is to determine where to place the data analytic operators for maximum efficiency and least costs for the network and its traffic, the efficient algorithmic solution to which we seek to propose by way of this work underway.
electrical_network	the reduction of emissions in harbours is of particular importance due to the proximity to human habitation. vessels normally run onboard generators, typically using diesel fuel, to provide the service loads while berthed. new and upcoming regulations aim to decrease emissions from shipping, and coupled with increased environmental consciousness of ship owners and harbour operators, shore supply is becoming a more popular and feasible option. cold ironing provides an alternative locally emission-free solution by having berthed ships plug in to the shore electrical network, such that the onboard electrical energy demand is supplied from land. electrically, a number of different shore network topologies are possible, providing different infrastructural options of supplying power to multiple berths. this paper examines the electrical characteristics of one such installation and the impact on the shoreside electrical network for an existing port using actual visiting ship power profiles. the paper examines how the cold ironing system influences important electrical network characteristics such as bus voltages and power quality, as well as the potential impact on the rest of the utility distribution system. (c) 2015 elsevier ltd. all rights reserved.
system_identification	this paper concerns the problem of dynamic modelling and parameter estimation for a seven degree of freedom hydraulic manipulator. the laboratory example is a dual-manipulator mobile robotic platform used for research into nuclear decommissioning. in contrast to earlier control model-orientated research using the same machine, the paper develops a nonlinear, mechanistic simulation model that can subsequently be used to investigate physically meaningful disturbances. the second contribution is to optimise the parameters of the new model, i.e. to determine reliable estimates of the physical parameters of a complex robotic arm which are not known in advance. to address the nonlinear and non-convex nature of the problem, the research relies on the multi-objectivisation of an output error single-performance index. the developed algorithm utilises a multi-objective genetic algorithm (ga) in order to find a proper solution. the performance of the model and the ga is evaluated using both simulated (i.e. with a known set of 'true' parameters) and experimental data. both simulation and experimental results show that multi-objectivisation has improved convergence of the estimated parameters compared to the single-objective output error problem formulation. this is achieved by integrating the validation phase inside the algorithm implicitly and exploiting the inherent structure of the multi-objective ga for this specific system identification problem.
software_engineering	software product lines (spl) aim at reducing time-to-market and increasing software quality through extensive, planned reuse of artifacts. an essential activity in spl is variability management, i. e., defining and managing commonality and variability among member products. due to the large scale and complexity of today 's software-intensive systems, variability management has become increasingly complex to conduct. accordingly, tool support for variability management has been gathering increasing momentum over the last few years and can be considered a key success factor for developing and maintaining spls. while several studies have already been conducted on variability management, none of these analyzed the available tool support in detail. in this work, we report on a survey in which we analyzed 37 existing variability management tools identified using a systematic literature review to understand the tools' characteristics, maturity, and the challenges in the field. we conclude that while most studies on variability management tools provide a good motivation and description of the research context and challenges, they often lack empirical data to support their claims and findings. it was also found that quality attributes important for the practical use of tools such as usability, integration, scalability, and performance were out of scope for most studies.
software_engineering	this paper provides an overview of the state of the art technologies for software development in cloud environments. the surveyed systems cover the whole spectrum of cloud-based development including integrated programming environments, code repositories, software modeling, composition and documentation tools, and application management and orchestration. in this work we evaluate the existing cloud development ecosystem based on a wide number of characteristics like applicability (e.g. programming and database technologies supported), productivity enhancement (e.g. editor capabilities, debugging tools), support for collaboration (e.g. repository functionality, version control) and post-development application hosting and we compare the surveyed systems. the conducted survey proves that software engineering in the cloud era has made its initial steps showing potential to provide concrete implementation and execution environments for cloud-based applications. however, a number of important challenges need to be addressed for this approach to be viable. these challenges are discussed in the article, while a conclusion is drawn that although several steps have been made, a compact and reliable solution does not yet exist.
computer_graphics	many recent applications of computer graphics and human computer interaction have adopted both colour cameras and depth cameras as input devices. therefore, an effective calibration of both types of hardware taking different colour and depth inputs is required. our approach removes the numerical difficulties of using non-linear optimization in previous methods which explicitly resolve camera intrinsics as well as the transformation between depth and colour cameras. a matrix of hybrid parameters is introduced to linearize our optimization. the hybrid parameters offer a transformation from a depth parametric space (depth camera image) to a colour parametric space (colour camera image) by combining the intrinsic parameters of depth camera and a rotation transformation from depth camera to colour camera. both the rotation transformation and intrinsic parameters can be explicitly calculated from our hybrid parameters with the help of a standard qr factorisation. we test our algorithm with both synthesized data and real-world data where ground-truth depth information is captured by microsoft kinect. the experiments show that our approach can provide comparable accuracy of calibration with the state-of-the-art algorithms while taking much less computation time (1/50 of herrera 's method and 1/10 of raposo 's method) due to the advantage of using hybrid parameters.
image_processing	background and objectivebreast cancer is one of the most common cancers, and recognized as the third leading cause of mortality in women. optical coherence tomography (oct) enables three dimensional visualization of biological tissue with micrometer level resolution at high speed, and can play an important role in early diagnosis and treatment guidance of breast cancer. in particular, ultra-high resolution (uhr) oct provides images with better histological correlation. this paper compared uhr oct performance with standard oct in breast cancer imaging qualitatively and quantitatively. automatic tissue classification algorithms were used to automatically detect invasive ductal carcinoma in ex vivo human breast tissue. study design/materials and methodshuman breast tissues, including non-neoplastic/normal tissues from breast reduction and tumor samples from mastectomy specimens, were excised from patients at columbia university medical center. the tissue specimens were imaged by two spectral domain oct systems at different wavelengths: a home-built ultra-high resolution (uhr) oct system at 800nm (measured as 2.72m axial and 5.52m lateral) and a commercial oct system at 1,300nm with standard resolution (measured as 6.5m axial and 15m lateral), and their imaging performances were analyzed qualitatively. using regional features derived from oct images produced by the two systems, we developed an automated classification algorithm based on relevance vector machine (rvm) to differentiate hollow-structured adipose tissue against solid tissue. we further developed b-scan based features for rvm to classify invasive ductal carcinoma (idc) against normal fibrous stroma tissue among oct datasets produced by the two systems. for adipose classification, 32 uhr oct b-scans from 9 normal specimens, and 28 standard oct b-scans from 6 normal and 4 idc specimens were employed. for idc classification, 152 uhr oct b-scans from 6 normal and 13 idc specimens, and 104 standard oct b-scans from 5 normal and 8 idc specimens were employed. resultswe have demonstrated that uhr oct images can produce images with better feature delineation compared with images produced by 1,300nm oct system. uhr oct images of a variety of tissue types found in human breast tissue were presented. with a limited number of datasets, we showed that both oct systems can achieve a good accuracy in identifying adipose tissue. classification in uhr oct images achieved higher sensitivity (94%) and specificity (93%) of adipose tissue than the sensitivity (91%) and specificity (76%) in 1,300nm oct images. in idc classification, similarly, we achieved better results with uhr oct images, featured an overall accuracy of 84%, sensitivity of 89% and specificity of 71% in this preliminary study. conclusionin this study, we provided uhr oct images of different normal and malignant breast tissue types, and qualitatively and quantitatively studied the texture and optical features from oct images of human breast tissue at different resolutions. we developed an automated approach to differentiate adipose tissue, fibrous stroma, and idc within human breast tissues. our work may open the door toward automatic intraoperative oct evaluation of early-stage breast cancer. (c) 2017 wiley periodicals, inc.
operational_amplifier	a signal- and transient-current boosting (stcb) circuit is proposed and applied to a single-stage amplifier driving large capacitive loads. the proposed stcb circuit provides gain-bandwidth product (gbw) extension, slew-rate (sr) improvement and gain enhancement to the amplifier, with only slight alterations to the frequency response and transient response of the single-stage amplifier driving large capacitive loads. no on-chip capacitor or resistor is required. the stcb amplifier is fabricated in a commercial 0.18-mu m cmos technology. the active chip area is 0.00705 mm(2). the supply is 1.8 v, and the current consumption is 20.3 mu a. the capacitive load (c-o) ranges from about 4.4 nf to 19 nf. the measured results with a similar to 19-nf load show the small-signal figure-of-merit (foms = gbw . c-o/power) and the large-signal large-figure-of-merit (foml = sr . c-o/power) are 150345 mhz . pf/mw and 31213 v/mu s . pf/mw, respectively, which correspond to improvements of 1.52 times and 1.36 times, respectively, to the prior art. the achieved phase margin and gain margin are 80.8 degrees and 36.3 db, respectively.
network_security	optimization of power system restoration path is a key issue to the system restoration following a significant disruption, such as the northeast blackout of 2003 in the united states and canada. the restoration path optimization problem (rpop) is to calculate the shortest restoration path between specified nodes, while subject to network security constraints. the rpop is normally modeled as a large-scale mixed integer nonlinear programming, including both routing components and the nonlinear steady-state power flow equations. intelligent algorithm is widely used to solve this complicated problem due to its excellent optimization capability, but existing research concern about the generate method of initial population. in this paper, an orthogonal genetic algorithm is adopted to achieve the optimal solutions. the orthogonal array method is used to generate an initial population of genetic algorithm. this method has been proven to be optimal to select representative samples from all the possible combinations, due to the selected samples scatter uniformly over the feasible solution space. finally, the ieee standard test systems are used to examine the applicability of proposed method. simulation results demonstrate that the proposed method is more efficient than traditional method.
parallel_computing	parallel computing is widely utilized to speed up automatic test pattern generation (atpg); however, most of today 's parallel atpgs are non-deterministic, which often leads to non-reproducible test pattern sets. this paper presents a fault-parallel test pattern generator: cpp-atpg; it generates the same test pattern set regardless of the thread count and timing. besides, it exhibits good speedup scalability as the thread count increases. these are achieved by the circular pipeline processing (cpp) principle, which guides the proposed parallel atpg to preserve the task processing orders that are necessary to ensure atpg determinism but with low inter-thread synchronization overhead. furthermore, a multi-round test generation and compaction strategy is proposed to avoid possible test pattern inflation. experimental results show that cpp-atpg exhibits close-to-linear speedup for at least up to 12 threads.
data_structures	in many applications, top-k query is an important operation to return a set of interesting points in a potentially huge data space. the existing algorithms, either maintaining too many candidates, or requiring assistant structures built on the specific attribute subset, or returning results with probabilistic guarantee, cannot process top-k query on massive data efficiently. this paper proposes a sorted-list-based tkap algorithm, which utilizes some data structures of low space overhead, to efficiently compute top-k results on massive data. in round-robin retrieval on sorted lists, tkap performs adaptive pruning operation and maintains the required candidates until the stop condition is satisfied. the adaptive pruning operation can be adjusted by the information obtained in round-robin retrieval to achieve a better pruning effect. the adaptive pruning rule is developed in this paper, along with its theoretical analysis. the extensive experimental results, conducted on synthetic and real-life data sets, show the significant advantage of tkap over the existing algorithms.
algorithm_design	there exist two key problems about data aggregation that should be thoroughly explored - algorithm design in networking layer, and algorithm design in application layer. those two problems should be subtlety tackled in termers of high efficiency and robustness. therefore, the former one requires the survivability and highly reliable design at networking layer, the latter one usually asks for high efficiency and robustness at application layer. moreover, the optimization of algorithms is also considered for further enhancement. the integrity check is a key requirement for optimization. the context-aware and cross-layer design is applied in the optimization. a dynamic fragment odd-even parity checking code is proposed, and a context-aware aggregative integrity check code is proposed.
image_processing	objectiveto evaluate whether and to which extent skin redness (erythema) affects investigator blinding in transcranial direct current stimulation (tdcs) trials. material and methodstwenty-six volunteers received sham and active tdcs, which was applied with saline-soaked sponges of different thicknesses. high-resolution skin images, taken before and 5, 15, and 30 min after stimulation, were randomized and presented to experienced raters who evaluated erythema intensity and judged on the likelihood of stimulation condition (sham vs. active). in addition, semi-automated image processing generated probability heatmaps and surface area coverage of erythema. adverse events were also collected. resultserythema was present, but less intense in sham compared to active groups. erythema intensity was inversely and directly associated to correct sham and active stimulation group allocation, respectively. our image analyses found that erythema also occurs after sham and its distribution is homogenous below electrodes. tingling frequency was higher using thin compared to thick sponges, whereas erythema was more intense under thick sponges. conclusionsoptimal investigator blinding is achieved when erythema after tdcs is mild. erythema distribution under the electrode is patchy, occurs after sham tdcs and varies according to sponge thickness. we discuss methods to address skin erythema-related tdcs unblinding.
computer_programming	bayesianism is fast becoming the dominant paradigm in archaeological chronology construction. this paradigm shift has been brought about in large part by widespread access to tailored computer software which provides users with powerful tools for complex statistical inference with little need to learn about statistical modelling or computer programming. as a result, we run the risk that such software will be reduced to the status of black boxes. this would be a dangerous position for our community since good, principled use of bayesian methods requires mindfulness when selecting the initial model, defining prior information, checking the reliability and sensitivity of the software runs and interpreting the results obtained. in this article, we provide users with a brief review of the nature of the care required and offer some comments and suggestions to help ensure that our community continues to be respected for its philosophically rigorous scientific approach.
algorithm_design	mapreduce comes from its simplicity to preparing the input data, the programmer needs only to implement the mapper, the reducer, and optionally, the combiner and the partitioner. all other aspects of execution are handled transparently by the execution framework on clusters ranging from a single node to a few thousand nodes, over datasets ranging from gigabytes to petabytes. however, this also means that any conceivable algorithm that a programmer wishes to develop must be expressed in terms of a small number of rigidly defined components that must fit together in very specific ways. it may not appear obvious how a multitude of algorithms can be recast into this programming model. the purpose of this paper is to provide, a guide to mapreduce algorithm design. this paper presents the notion of design pattern of mapreduce, which instantiate arrangements of components and specific techniques designed to handle frequently encountered situations across a variety of domains.
software_engineering	we present a multi-level formation model for complex software systems. the previous works extract the software systems to software networks for further studies, but usually investigate the software networks at the class level. in contrast to these works, our treatment of software systems as multi-level networks is more realistic. in particular, the software networks are organized by three levels of granularity, which represents the modularity and hierarchy in the formation process of real-world software systems. more importantly, simulations based on this model have generated more realistic structural properties of software networks, such as power-law, clustering and modularization. on the basis of this model, how the structure of software systems effects software design principles is then explored, and it could be helpful for understanding software evolution and software engineering practices.
pid_controller	this paper deals with design of pid controller with the use of methods of global optimization implemented in matlab environment and optimization toolbox. it is based on minimization of a chosen integral criterion with respect to additional requirements on control quality such as overshoot, phase margin and limits for manipulated value. the objective function also respects user-defined weigh coefficients for its particular terms for a different penalization of individual requirements that often clash each other such as for example overshoot and phase margin. the described solution is designated for continuous linear time-invariant static systems up to 4th order and thus efficient for the most of real control processes in practice.
system_identification	sparse signal reconstruction (ssr) problems based on compressive sensing (cs) arise in a broad range of application fields. among these are the so-called ""block-structured"" or ""block sparse"" signals with nonzero atoms occurring in clusters that occur frequently in natural signals. to make block-structured sparsity use more explicit, many block-structure-based ssr algorithms, such as convex optimization and greedy pursuit, have been developed. convex optimization algorithms usually pose a heavy computational burden, while greedy pursuit algorithms are overly sensitive to ambient interferences, so these two types of block-structure-based ssr algorithms may not be suited for solving large-scale problems in strong interference scenarios. sparse adaptive filtering algorithms have recently been shown to solve large-scale cs problems effectively for conventional vector sparse signals. encouraged by these facts, we propose two novel block-structure-based sparse adaptive filtering algorithms, i.e., the ""block zero attracting least mean square"" (bza-lms) algorithm and the ""block l(0)-norm lms"" (bl0-lms) algorithm, to exploit their potential performance gain. experimental results presented demonstrate the validity and applicability of these proposed algorithms.
system_identification	this study focuses on a discrete-time hammerstein system to investigate the identification with quantised inputs and quantised output observations. after the discussion of the system identifiability and by parameterising the static non-linear function, a three-step algorithm is proposed to estimate the unknown parameters for the identifiable system. the strong convergence and the mean-square convergence rate of the algorithm are established. it is shown that the asymptotic efficiency can be achieved in terms of the cramer-rao lower bound by selecting a suitable transformation matrix. a numerical simulation is given to demonstrate the effectiveness of the algorithm.
electrical_circuits	in this letter we report patterning of colloidal nanocrystal films that combines direct e-beam (electron beam) writing with cation exchange. the e-beam irradiation causes cross-linking of the ligand molecules present at the nanocrystal surface, and the cross-linked molecules act as a mask for further processing. consequently, in the following step of cation exchange, which is performed by directly dipping the substrate in a solution containing the new cations, the regions that have not been exposed to the electron beam are chemically transformed, while the exposed ones remain unchanged. this selective protection allows the design of patterns that are formed by chemically different nanocrystals, yet in a homogeneous nanocrystal film. spatially resolved compositional analysis by energy-dispersive x-ray spectroscopy (eds) corroborates that the selective exchange occurs only in the nonirradiated regions. we demonstrate the utility of this lithography approach by fabricating conductive wires and luminescent patterns in cdse/cds nanocrystal films by converting nonirradiated regions to cu2-xse/cu2-xs. furthermore, we show that x-ray irradiation too can lead to protection from cation exchange.
digital_control	efficiency in a light load dc-dc converter is improved by reducing the switching frequency with the load current. further, a bifrequency operation (bfo) using pulse train (pt) control can achieve spread spectrum. using discrete-time models, this paper shows that a stable periodic bfo is generally not achievable in existing pt control methods. thereafter, a unified multimode digital control technique is proposed, in which a voltage-mode digital pulse-width-modulator (dpwm) is used to control a predefined periodic bfo. beside the fixed-frequency dpwm, an extra multiplexer is considered for real-time configuration to: 1) bifrequency pulse frequency modulation; 2) pt control; or 3) pulse regulation control; or 4) pulse skipping control with smooth transition. analysis and design methods are discussed to ensure periodic bfo and to customize the power spectrum with predictable ripple parameters. a buck converter prototype is made, and the proposed control is implemented using an fpga device.
pid_controller	to meet the more stringent environmental requirements of automobile exhaust gas emissions, diesel engines have recently received increased attention due to their high heat efficiency. to lower fuel consumption and reduce exhaust gas simultaneously, fuel combustion must be more precisely controlled. for example, the oxygen concentration, which affects emissions, is controlled by exhaust gas recirculation (egr) and variable nozzle turbo (vnt). however, realizing a controlled design is difficult due to system non-linearity and strong interference between egr and vnt. recently, various design methods have employed the so-called model-based control design, but this design approach is difficult to use when the controlled object is complex. currently, mass production uses gain scheduling of map-based on proportional-integral-derivative (pid) control, in which each gain is tuned at various operational points. however, map calibration has many drawbacks, including time-consuming tuning, difficulty tuning during transient operations and problems adapting to the individual variations in the engine characteristics. this study proposes a construction method for a model-free adaptive pid controller using the simultaneous perturbation stochastic approximation (spsa) and its performance is confirmed in an engine bench test.
electricity	currently, the algerian energy system relies almost exclusively on fossil resources, but a new paradigm is emerging in the country. the algeria program on renewable energy and energy efficiency established the ambitious goal of deriving 40% of electricity production from renewable energy sources (res) by 2030. this study addresses the sustainability objectives of this program using a methodology, which combines an analytic hierarchy process (ahp) and experts' feedback to evaluate different renewable energy options. the performance of different res options was assessed against 13 sub-criteria reflecting social, environmental, economic and technical concerns. the results highlighted the importance of social and environmental criteria as the main drivers for the obtained final ranking, with three of these sub-criteria weighting 35% in the decision process. solar power was shown to be particularly well suited for algeria, outperforming most of the other renewable options in a large set of highly weighted criteria. wind power ranked second, followed by biomass, geothermal and lastly by hydropower. wind and solar power together achieved a total score of more than 0.5 out of 1. from the results, policy implications were drawn and directions for future research were suggested. (c) 2017 elsevier ltd. all rights reserved.
digital_control	a design of a new hybrid-type digital pulsewidth modulator (dpwm) with a wide frequency range of 1000 : 1, from 10 khz to 10 mhz, is presented. the proposed dpwm has the maximum duty-cycle resolution of 11 bits and consumes the power of 17.5 mu w at 10 khz and 2.36 mw at 10 mhz, respectively. the proposed dpwm realizes the upper 5-bit resolution using a programmable digital counter and the lower 6-bit resolution using a current-integrating-type phase interpolator, employing an m2m-ladder current-steering digital-to-analog converter for low power consumption. the operating clock is generated in on-chip using a relaxation oscillator. the prototype integrated circuit fabricated in a 0.25-mu m high-voltage complementary metal-oxide-semiconductor demonstrates that the proposed dpwm maintains a good linearity across the entire operating range.
data_structures	it is well known that there are linear-space data structures for 2-d orthogonal range counting with worst-case optimal query time o(log n/ loglog n). we give an o(n log log n)-space adaptive data structure that improves the query time to o(log log n + log k/ log log n), where k is the output count. when k = o(1), our bounds match the state of the art for the 2-d orthogonal range emptiness problem [chan et al., 2011]. we give an o(n log log n)-space data structure for approximate 2-d orthogonal range counting that can compute a (1 + delta)-factor approximation to the count in o(log log n) time for any fixed constant delta >0. again, our bounds match the state of the art for the 2-d orthogonal range emptiness problem. last, we consider the 1-d range selection problem, where a query in an array involves finding the kth least element in a given subarray. this problem is closely related to 2-d 3-sided orthogonal range counting. recently, jorgensen and larsen [2011] presented a linear-space adaptive data structure with query time o(log log n + log k/ log log n). we give a new linear-space structure that improves the query time to o(1 + log k/log log n), exactly matching the lower bound proved by jorgensen and larsen.
computer_programming	by means of miedema formation enthalpy model with toop model, the excess free-energy, enthalpies of formation, excess entropies and activity values of all components of mg-al-y ternary alloy were calculated with computer programming. the experimental results show that enthalpies of formation, excess free-energy and excess entropies of the ternary alloy are negative in the whole content range, the minimum values at 1 123 k are all obtained at x (al)=55%, x (y)=45%, x (mg)=0%, which are -37.969, -30.961 kj/mol and -6.24 j/(mol center dot k) respectively. activity curves show that the activity values of al and y in mg-al-y ternary alloy rapidly decrease with the decrease of molar fraction, the values of which are very small when the molar fraction decreases to 0.4. it means that there is a strong interaction between al and y and stable compounds can be form in the mg-al-y ternary alloy system.
microcontroller	usage of inercial sensors is widespread in many areas, especially in aueronautics. another field of use for such sensors is capturing and recognizing gestures from sensors placed on human body parts, for example hand or shoulder. this article is dealing with a proposal of weareable sensors, capable of detecting simple gestures such as rotation, elevation, movement etc.. system will be based on stm32 platform, which will guarantee low energy consumption and sufficient performance to evaluate the captured motions. multilayer neural network capable of recognizing the elementary gestures was designed to detect movements such as hand rotations, hand vertical and horizontal movements
distributed_computing	in recent years, the technological advancements have led to a deluge of data from distinctive domains and the need for development of solutions based on parallel and distributed computing has still long way to go. that is why, the research and development of massive computing frameworks is continuously growing. at this particular stage, highlighting a potential research area along with key insights could be an asset for researchers in the field. therefore, this paper explores one of the emerging distributed computing frameworks, apache hama. it is a top level project under the apache software foundation, based on bulk synchronous parallel model. we present an unbiased and critical interrogation session about apache hama and conclude research directions in order to assist interested researchers.
operational_amplifier	current sources with howland topology made with operational amplifier are often used for sensors that requires constant current polarization, for bioimpedance measuring, actuators driving systems and so on. theoretical determination of overall performances for this circuits is generally known. this paper presents a practical method for real output impedance determining of such current sources based on performing two simple measurements. the results is according with the measurements on the practical circuit. using the tl084 circuit the frequency cut-off was 250 khz but using one other circuit as ths3201 the cut-off frequency was 20mhz.
parallel_computing	this paper considers the problem of many-to-many disjoint paths in the hypercube q(n) with f faulty vertices and obtains the following result. for any integer k with 1 <= k= 2), if f <= 2n - 2k - 2 and each fault-free vertex has at least two fault-free neighbors, then there exist k fully disjoint fault-free paths linking s and t which contain at least 2(n) - 2f vertices. a linear algorithm for finding such disjoint paths is also given. this result improves some known results in a sense. (c) 2016 elsevier b.v. all rights reserved.
cryptography	we consider a new type of attack on a coherent quantum key distribution protocol [coherent one-way (cow) protocol]. the main idea of the attack consists in measuring individually the intercepted states and sending the rest of them unchanged. we have calculated the optimum values of the attack parameters for an arbitrary length of a communication channel and compared this novel attack with a standard beam-splitting attack.
network_security	a smart grid is delay sensitive and requires the techniques that can identify and react on the abnormal changes (i.e., system fault, attacker, shortcut, etc.) in a timely manner. in this paper, we propose a real-time detection scheme against false data injection attack in smart grid networks. unlike the classical detection test, the proposed algorithm is able to tackle the unknown parameters with low complexity and process multiple measurements at once, leading to a shorter decision time and a better detection accuracy. the objective is to detect the adversary as quickly as possible while satisfying certain detection error constraints. a markov-chain-based analytical model is constructed to systematically analyze the proposed scheme. with the analytical model, we are able to configure the system parameters for guaranteed performance in terms of false alarm rate, average detection delay, and missed detection ratio under a detection delay constraint. the simulations are conducted with matpower 4.0 package for different ieee test systems.
signal-flow_graph	this paper presents a new method: zbus algorithm combined with the forward and backward algorithm to deal with power flow calculation of the distribution network with ring-net. the topological structure of the network can be analyzed by decomposing the branch network into radial parts and ring-net parts through the forward path which is the concept of the signal flow graph, using forward and backward algorithm on radial parts, calculation speed can be greatly improved by adopting parallel calculation; zbus algorithm is used on ring-net parts, then the voltage and power of the boundary nodes will be corrected with the two parts calculation result to keep the whole network calculation in consistency. finally, a practical example analysis shows that the method can not only processes the ring network problems very well, but also improves the calculation speed.
distributed_computing	data processing complexity, partitionability, locality and provenance play a crucial role in the effectiveness of distributed data processing. dynamics in data processing necessitates effective modeling which allows the understanding and reasoning of the fluidity of data processing. through virtualization, resources have become scattered, heterogeneous, and dynamic in performance and networking. in this paper, we propose a new distributed data processing model based on automata where data processing is modeled as state transformations. this approach falls within a category of declarative concurrent paradigms which are fundamentally different than imperative approaches in that communication and function order are not explicitly modeled. this allows an abstraction of concurrency and thus suited for distributed systems. automata give us a way to formally describe data processing independent from underlying processes while also providing routing information to route data based on its current state in a p2p fashion around networks of distributed processing nodes. through an implementation, named pumpkin, of the model we capture the automata schema and routing table into a data processing protocol and show how globally distributed resources can be brought together in a collaborative way to form a processing plane where data objects are self-routable on the plane. (c) 2015 elsevier b.v. all rights reserved.
digital_control	in many digital control systems, it is required to perform computation in a strictly periodic fashion to provide high control performance. system designers need to assign time slots that are infinitely repeated given a strict period for each task such that the time slots of different tasks do not overlap. while previous work has studied how to decide if a system is schedulable with a certain time slot assignment, it is still an unexplored area of how to select time slots for strictly periodic tasks to make them schedulable. in this paper, we propose an efficient method to solve the above problem. our method explores the relations among task periods to improve the possibility of finding feasible start time configurations. finally, we conduct experiments with randomly generated workload to evaluate the performance of the proposed method. (c) 2016 elsevier b.v. all rights reserved.
state_space_representation	in this paper, the tip tracking control problem of a timoshenko micro-cantilever beam is investigated. the beam is actuated by a piezoelectric layer laminated on one side of the beam. dynamic equations of the beam and piezoelectric layer are found using the hamilton principle. by employing the galerkin projection method, state space representation of the system is derived. then, a cascade control loop is used for tracking control of the beam 's tip. the cascade control structure consists of an inner loop stabilizer and an outer loop proportional-integral-derivative controller. the stabilizer has a linear feedback form whose states are obtained through a linear observer which is based on the beam tip displacement measurement. stability analysis of the inner loop stabilizer is performed to study the effects of higher un-controlled modes on performance of the controlled system. simulation results show the effectiveness of the proposed control method.
parallel_computing	in this paper, a corrected parallel smoothed particle hydrodynamics (c-sph) method is proposed to simulate the 3d generalized newtonian free surface flows with low reynolds number, especially the 3d viscous jets buckling problems are investigated. the proposed c-sph method is achieved by coupling an improved sph method based on the incompressible condition with the traditional sph (tsph), that is, the improved sph with diffusive term and first-order kernel gradient correction scheme is used in the interior of the fluid domain, and the tsph is used near the free surface. thus the c-sph method possesses the advantages of two methods. meanwhile, an effective and convenient boundary treatment is presented to deal with 3d multiple-boundary problem, and the mpi parallelization technique with a dynamic cells neighbor particle searching method is considered to improve the computational efficiency. the validity and the merits of the c-sph are first verified by solving several benchmarks and compared with other results. then the viscous jet folding/coiling based on the cross model is simulated by the c-sph method and compared with other experimental or numerical results. specially, the influences of macroscopic parameters on the flow are discussed. all the numerical results agree well with available data, and show that the c-sph method has higher accuracy and better stability for solving 3d moving free surface flows over other particle methods. (c) 2016 elsevier b.v. all rights reserved.
machine_learning	multilevel spin toque transfer ram (stt-ram) is a suitable storage device for energy-efficient neural network accelerators (nnas), which relies on large-capacity on-chip memory to support brain-inspired large-scale learning models from conventional artificial neural networks to current popular deep convolutional neural networks. in this paper, we investigate the application of multilevel stt-ram to general-purpose nnas. first, the error-resilience feature of neural networks is leveraged to tolerate the read/write reliability issue in multilevel cell stt-ram using approximate computing. the induced read/write failures at the expense of higher storage density can be effectively masked by a wide spectrum of nn applications with intrinsic forgiveness. second, we present a precision-tunable stt-ram buffer for the popular general-purpose nna. the targeted stt-ram memory design is able to transform between multiple working modes and adaptable to meet the varying quality constraint of approximate applications. lastly, the reconfigurable stt-ram buffer not only enables precision scaling in nna but also provides adaptiveness to the demand for different learning models with distinct working-set sizes. particularly, we demonstrate the concept of capacity/precision-tunable stt-ram memory with the emerging reconfigurable deep nna and elaborate on the data mapping and storage mode switching policy in stt-ram memory to achieve the best energy efficiency of approximate computing.
operating_systems	the complex span paradigm is one of the most influential and widely used instruments for measuring working memory capacity (wmc). we report the results of four experiments designed to explore the feasibility of obtaining valid estimates of wmc online. we explored the relationships between the complex span tasks and fluid intelligence (gf) in the lab and on the web using a new platform called the online working memory lab (the owl). the owl is universally accessible across all computer operating systems and functions in both local and remote contexts, allowing researchers to sample more diverse subjects from practically anywhere. experiments 1 and 2 showed that the complex span failed to predict gf when the to-be-remembered stimuli were letters and the tests were taken online. we increased the predictive validity of the test battery in experiments 3 and 4 by replacing the letters with memory stimuli that were more difficult to write down in an unproctored setting. this work describes our most recent attempts to measure working memory capacity in the wild.
electricity	solar energy for building applications may significantly reduce the conventional energy consumption and the related carbon dioxide emissions. the comprehensive utilization of integrated solar thermal and photovoltaic systems is undoubtedly a subject of interest. in the present paper, an optimization model was proposed for integrated solar energy systems, aiming to figure out the optimal utilization and economical efficiency of solar energy resources for buildings in cold plateau areas. a case study in lhasa city was further carried out in order to evaluate the energy and economic performance of the developed model. the results indicated that solar photovoltaic systems are preferred than solar thermal systems for typical office buildings in cold plateau areas with rich solar energy resources. in addition, a sensitivity analysis was performed to investigate the influences of financial subsidies and commercial electricity prices on the system economical performance. furthermore, life cycle assessment was conducted to compare and analyze the performances of an optimization system and a conventional system. (c) 2016 elsevier ltd. all rights reserved.
algorithm_design	a spatiotemporal mining framework is a novel tool for the analysis of marine association patterns using multiple remote sensing images. from data pretreatment, to algorithm design, to association rule mining and pattern visualization, this paper outlines a spatiotemporal mining framework for abnormal association patterns in marine environments, including pixel-based and object-based mining models. within this framework, some key issues are also addressed. in the data pretreatment phase, we propose an algorithm for extracting abnormal objects or pixels over marine surfaces, and construct a mining transaction table with object-based and pixel-based strategies. in the mining algorithm phase, a recursion method to construct a direct association pattern tree is addressed with an asymmetric mutual information table, and a recursive mining algorithm to find frequent items. in the knowledge visualization phase, a ""dimension-attributes"" visualization framework is used to display spatiotemporal association patterns. finally, spatiotemporal association patterns for marine environmental parameters in the pacific ocean are identified, and the results prove the effectiveness and the efficiency of the proposed mining framework. (c) 2014 elsevier b.v. all rights reserved.
cryptography	the smart-grid concept takes the communications from the enclosed and protected environment of a substation to the wider city or nationwide area. in this environment, cyber security takes a key role in order to secure the communications. the challenge is to be able to secure the grid without impacting the latency while, at the same time, maintaining compatibility with older devices and non secure services. at the lower level, added security must not interfere with the redundancy and the latency required for the real-time substation automation communications. this paper studies how to integrate ieee mac security standard (macsec) in the substation environment, especially when used in substation system communications that have stringent response time requirements and zero recovery time as defined in iec 62439-3.
operating_systems	robot software combines the challenges of general purpose and real-time software, requiring complex logic and bounded resource use. physical safety, particularly for dynamic systems such as humanoid robots, depends on correct software. general purpose computation has converged on unix-like operating systems standardized as posix, the portable operating system interface for devices from cellular phones to supercomputers. the modular, multi-process design typical of posix applications is effective for building complex and reliable software. absent from posix, however, is an interproccess communication mechanism that prioritizes newer data as typically desired for control of physical systems. we address this need in the ach communication library which provides suitable semantics and performance for real-time robot control. although initially designed for humanoid robots, ach has broader applicability to complex mechatronic devices humanoid and otherwise that require real-time coupling of sensors, control, planning, and actuation. the initial user space implementation of ach was limited in the ability to receive data from multiple sources. we remove this limitation by implementing ach as a linux kernel module, enabling ach 's high performance and latest-message-favored semantics within conventional posix communication pipelines. we discuss how these posix interfaces and design principles apply to robot software, and we present a case study using the ach kernel module for communication on the baxter robot.
relational_databases	insertion propagation problem is a class of view update problem in relational databases [1]. given a source database d, a monotone relational algebraic query q, and the view v generated by the query q(d), insertion propagation problem is to find a set delta d of tuples whose insertion into d will add the given tuples delta v into the view v via q without producing side-effect on view. in this paper, we consider the fd-restricted version insertion propagation problem 'fd-vsef-ip', in which we aim to find the delta d not only view side-effect free but also without introducing inconsistency with respect to the predefined functional dependencies. we study both data and combined complexity of fd-vsef-ip under both single and group insertion. interestingly, the problem ranges from ptime to sigma(p)(2)-complete, for queries in different classes in either complexity aspect. we show that the fd-restricted version will be harder to get the optimal solution, contrary to its counterpart under deletion. our study of this fd-restricted version insertion propagation problem generalize the computational issues involved in data lineage - the process by which databases updated through view insertion under fd.
computer_graphics	as location-aware applications and location-based services continue to increase in popularity, data sources describing a range of dynamic processes occurring in near real-time over multiple spatial and temporal scales are becoming the norm. at the same time, existing frameworks useful for understanding these dynamic spatio-temporal data, such as time geography, are unable to scale to the high volume, velocity, and variety of these emerging data sources. in this paper, we introduce a computational framework that turns time geography into a scalable analysis tool that can handle large and rapidly changing datasets. the hierarchical prism tree (hpt) is a dynamic data structure for fast queries on spatio-temporal objects based on time geographic principles and theories, which takes advantage of recent advances in moving object databases and computer graphics. we demonstrate the utility of our proposed hpt using two common time geography tasks (finding similar trajectories and mapping potential space-time interactions), taking advantage of open data on space-time vehicle emissions from the envirocar platform.
electric_motor	rapid changes in cross-polarization discrimination (xpd) of ka-band satellite radio wave signals caused by thunderstorm events are presented. their yearly statistics and yearly variations are discussed using the co-polar and cross-polar signals received for the past 17 years from 1990 to 2006. the number of thunderstorm events and rapid changes in xpd shows large yearly variations in a time scale of about five or six years. these long-term yearly variations may be related to periodic cycles of the equatorial climate, such as el nino and la nina, which tend to bring weak and strong convective activities, respectively, to the summertime weather in japan.
electrical_circuits	background: a laboratory-scale two-chamber microbial fuel cell employing an aerated cathode with no catalyst was inoculated with mixed inoculum and acetate as the carbon source. electrochemical impedance spectroscopy (eis) was used to study the behavior of the mfc during initial biofilm (week 1) and maximum power density (week 20). eis were performed on the anode chamber, biofilm (without anolyte) and anolyte (without biofilm). nyquist plots of the eis data were fitted with two equivalent electrical circuits to estimate the contributions of intrinsic resistances to the overall internal mfc impedance at weeks 1 and 20, respectively. results: the results showed that the system tended to increase power density from 15 +/- 3 (week 1) to 100 +/- 15 mw/m(2) (week 20) and current density 211 +/- 7 (week 1) to 347 +/- 29 ma/m(2) (week 20). the samples were identified by pyrosequencing of the 16s rrna gene and showed that initial inoculum (week 1) was constituted by proteobacteria (40%), bacteroidetes (22%) and firmicutes (18%). at week 20, proteobacterial species were predominant (60%) for electricity generation in the anode biofilm, being 51% rhodopseudomonas palustris. meanwhile on anolyte, firmicutes phylum was predominant with bacillus sp. this study proved that under the experimental conditions used there is an important contribution from the interaction of the biofilm and the anolyte on cell performance. table 1 presents a summary of the specific influence of each element of the system under study. conclusions: the results showed certain members of the bacterial electrode community increased in relative abundance from the initial inoculum. for example, proteobacterial species are important for electricity generation in the anode biofilms and firmicutes phylum was predominant on anolyte to transfer electron. r1 is the same in the three systems and no variation is observed over time. the biofilm makes a significant contribution to the charge transfer processes at the electrode (r2 and cdl) and, consequently, on the performance of the anode chamber. the biofilm can act as a barrier which reduces diffusion of the anolyte towards the electrode, all the while behaving like a porous material. the anolyte and its interaction with the biofilm exert a considerable influence on diffusion processes, given that it presents the highest values for rd which increased at week 20.
cryptography	multimedia contents are inherently sensitive signals that must be protected whenever they are outsourced to an untrusted environment. this problem becomes a challenge when the untrusted environment must perform some processing on the sensitive signals; a paradigmatic example is cloud-based signal processing services. approaches based on secure signal processing (ssp) address this challenge by proposing novel mechanisms for signal processing in the encrypted domain and interactive secure protocols to achieve the goal of protecting signals without disclosing the sensitive information they convey. this paper presents a novel and comprehensive set of approaches and primitives to efficiently process signals in an encrypted form, by using number theoretic transforms (ntts) in innovative ways. this usage of ntts paired with appropriate signal pre- and post-coding enables a whole range of easily composable signal processing operations comprising, among others, filtering, generalized convolutions, matrix-based processing or error correcting codes. our main focus is on unattended processing, in which no interaction from the client is needed; for implementation purposes, efficient lattice-based somewhat homomorphic cryptosystems are used. we exemplify these approaches and evaluate their performance and accuracy, proving that the proposed framework opens up a wide variety of new applications for secured outsourced-processing of multimedia contents.
relational_databases	analysis of data stored in a graph enables the discovery of certain information that could be hard to see if the data were stored using some other model (e.g. relational). however, the vast majority of data in information systems today is stored in relational databases, which dominate the data management field over the last decades. in spite of the rise of nosql technologies, the development of new information systems is still mostly based on relational databases. given the increasing awareness about the benefits of data analysis as well as current research interest in graph mining techniques, we aim to enable the usage of those techniques on relational data. in that regard, we propose a universal relational-to-graph data conversion algorithm which can be used in preparation of data to perform a graph mining analysis. our approach leverages the property graph model which is mainly used by the graph databases, while maintaining the level of relational data clarity.
operational_amplifier	this paper presents an optimization-based design methodology for fully differential amplifiers (fdas) including the effects of real common-mode feedback (cmfb) circuits as constraints in the design flow. the sizing procedure is performed separately for the main amplifier and for the cmfb circuit, reducing the number of free variables and exploring the design space in a more efficient way. also, this methodology can be employed to design single and two-stages fdas whereas a second pole compensation scheme is necessary. in order to validate the proposed methodology, a two-stage fully differential amplifier with a no capacitor feed-forward (ncff) compensation technique was designed in 0.13 mu m cmos technology with a 1.2 v power supply. the presented results also include a pole-zero pair mismatch analysis and proposes a solution in order to compensate the generated pole-zero doublet that might affect the performance of the amplifier. we can show that this approach reduces the overall static power consumption while satisfying the design specifications.
electrical_circuits	the paper deals with a method for the simulation of stochastic responses at multiconductor transmission lines (mtl) with fluctuating parameters via theory of stochastic differential equations (sde). the mtl responses are formed by the sets of stochastic trajectories completed by corresponding sample means and confidence intervals. the mtl model is based on a cascade connection of generalized rlcg networks and a state-variable method is used to formulate basic mtl 's model equations. the boundary conditions are folded in via a modified nodal analysis (mna) enabling to consider an mtl as a part of arbitrarily complex lumped-parameter circuits. finally, a vector stochastic differential-algebraic equation (sdae) is formulated, and the implicit euler numerical scheme consistent with the ito stochastic calculus used. to partly verify the results deterministic responses were stated via other methods and compared with mean values of stochastic ones. all simulations were performed in matlab (r).
control_engineering	the central china power grid (ccpg) and north china power grid (ncpg) are connected together by a single ac ultra-high-voltage (uhv) transmission link. when suffering power disturbances, power oscillation with high magnitude and long period would happen on the uhv tie-line, which may affect the synchronous and stable operation of the interconnected two power grids. this study proposes a novel emergency control scheme for high-voltage direct current (hvdc) in ccpg to suppress the high peak value of the power oscillation. based on a two-machine equivalent model, the maximum rising slope of power oscillat`ion is used to predict the peak value of power oscillation and power disturbance which is used as the reference of emergency power modulation. simulation verification is carried out based on the full model of the ccpg and ncpg, using power system analysis software package. moreover, field test has also been carried out in ccpg. both simulation results and recorded wave curve show that the proposed hvdc emergency control scheme can effectively suppress the peak value under different power disturbances. this significantly improves the transient performance of the interconnected power system and the power transfer capacity of the uhv tie-line.
state_space_representation	in this paper,we propose an output observer design methodology for linear single output systems. it is shown that, among other potential applications, the proposed observer can be used for filtering and fault detection purposes. unlike traditional observers that are based on the the state-space representation of the system, the proposed observer design is based on the input-output representation of the system. the main advantage of the proposed observer is its simplicity of design and it has a lower order than the original system.
image_processing	human target characteristic parameter extraction is an important approach of behavior monitoring. the extraction of the characteristic can be applied in various backgrounds, such as sanatorium and hospital. therefore, this technology is widely studied. towards extracting physiological characteristic parameters and motion characteristic features of human target, a novel human parameter extraction algorithm is proposed in this paper which has high detection accuracy. the high accuracy detection is achieved by combining the time-frequency analysis and image processing algorithm. besides that, the utilization of short wavelength and evident micro-motion features inherent with terahertz radar also contributes the improvement of detection accuracy. simulations test the effectiveness of proposed the algorithm, and illustrate its performance of high extraction precision and insensitivity to noise. for comparison, the simulations are also performed in x-band radar. via the thorough simulations, we can clearly find the advantage of our proposed algorithm in human target characteristic parameter extraction. (c) 2016 elsevier b.v. all rights reserved.
data_structures	the concept of uncertain pattern mining was recently proposed to fulfill the demand for processing databases with uncertain data, and various relevant methods have been devised. however, previous approaches have the following limitations. state-of-the-art methods based on tree structure can cause fatal problems in terms of runtime and memory usage according to the characteristics of uncertain databases and threshold settings because their own tree data structures can become excessively large and complicated in their mining processes. various approximation approaches have been suggested in order to overcome such problems; however, they are methods that increase their own mining performance at the cost of accuracy of the mining results. in order to solve the problems, we propose an exact, efficient algorithm for mining uncertain frequent patterns based on novel data structures and mining techniques, which can also guarantee the correctness of the mining results without any false positives. the newly proposed list-based data structures and pruning techniques allow a complete set of uncertain frequent patterns to be mined more efficiently without pattern losses. we also demonstrate that the proposed algorithm outperforms previous state-of-the art approaches in both theoretical and empirical aspects. especially, we provide analytical results of performance evaluation for various types of datasets to show efficiency of runtime, memory usage, and scalability in our method. (c) 2016 elsevier b.v. all rights reserved.
network_security	network big data is an important driving force for the upgrading of information technology, and network data has brought great opportunities to the economic survey. the openness and freedom of the network also produced the possibility of private information and data to be destroyed or violated, and the security of the internet is becoming more and more important. in this paper, the author analyzes the impact of fiscal expenditure on the new urbanization and income gap by using data mining technology. the result shows that the public expenditure increase 1% will lead urbanization rate increase 0.0462%; also, the effect of public finance expenditure on urbanization has a certain time lag, and the effect will be more obvious in the long term. at the same time, public expenditure will help to narrow the income gap in the long term, public expenditure at lag 2 increase 1% will lead income gap decrease 0.758%. so that, increasing public expenditure is an important way to promote the equalization of basic public services between urban and rural areas.
distributed_computing	we discuss the future of massively parallel computing from a fundamental architecture standpoint. our central thesis is that various versions of moore 's laws will all unavoidably break down over the next two to three decades, due to fundamental limitations imposed by the laws of physics (especially quantum mechanics). therefore, the end to scaling-up von neumann-based architectures by adding more cores and other incremental technology advancements is within sight. how are these challenges to be overcome, in order to continue making computation faster, cheaper, more energy efficient and more reliable? one possible answer lies in connectionist massively parallel models, based on (artificial) neural networks and other paradigms from biology, neuroscience and statistical physics. we discuss what would such massively parallel connectionist computers be like if they were to be based on ""implementing neural networks in the hardware"", and undertake several thought experiments comparing and contrasting the hypothetical connectionist parallel machines with the ""classical"" multicore supercomputers and large-scale distributed computing systems.
computer_programming	grinding employs an abrasive product, usually a rotating wheel, which is brought into controlled contact with a workpiece surface. the grinding patterning process can be simulated using computer programming with specific user-defined parameters. to predict the surface pattern that will result from grinding with the grooved wheel, calculating the cam parameters is very important. the intention of this research is to formulate cam parameters for the generation of a surface pattern on a flat nominal surface by grinding with a wheel that has been prepared in a special way. a diamond dresser having a rounded tip is applied to prepare helical grooves on the conventional wheel 's surface. with the intention of extracting cam parameters, a mathematical model is developed for a grinding patterning process, starting from the unit pattern geometry of the workpiece plate. the models are characterized by the process parameters of grinding patterning such as unit pattern geometry, dressing parameters, wheel geometry and grinding conditions, as well as work surface geometry. a computer program with a user interface is developed using matlab according to the proposed mathematical model to predict surface pattern. in addition, several examples of simulation results of the 3d wheel geometry model and corresponding patterned surfaces have been displayed using the proposed cam parameters as input. formulated cam parameters can be used to control the actual grinding process or predict the ground surface pattern.
parallel_computing	this paper presents the use of a computer cluster with heterogeneous computing components to provide concurrency and multi-level parallelism at coarse grain and massive fine-grain for multiview video coding (mvc) applications. mvc involves coding of multiple video sequences that are taken from the same scene but different perspective. in addition to motion estimation (me) used in conventional video coding for single view video for exploiting inter-frame temporal similarities, mvc adopts disparity estimation (de) to further increase compression. to overcome the huge computational cost associated with me and by extension with de, attention has been mainly focused on developing fast me/de algorithms. although fast me/de algorithms bring substantial speedup, to achieve realtime mvc encoding, it requires further acceleration of the coding process at higher levels. towards this end, this paper proposes a multiple-view-parallel, multiple-interleaved group of pictures (multiple-igop) scheduling scheme for mvc. when evaluated over eight views, with no loss in rate distortion (rd) performance, the proposed scheme outperforms view-sequential coding by a factor of up to 12.4 and 12.3, respectively, for two popular prediction structures, ibp and ipp.
control_engineering	this paper presents several mechatronics equipments of low cost and small scale; employing components and technology applied to model building. all systems were developed and built by students with different levels of knowledge in pontifical catholic university of rio de janeiro to aid the teaching. learning and research in engineering, particularly on the control and automation. mechanical and mechatronics fields. (c) 2016, ifac (international federation of automatic control) hosting by elservier ltd. all rights reserved.
state_space_representation	we propose a deterministic fluid model for the operation of two tandem sip proxies in overload conditions. using our model, we categorize overload scenarios into several classes, gaining better understanding of sip overload. we then use the theory of lyapunov for system stability and characterize stabilizing sip overload control schemes over the state-space representation of a sip server. a simple lyapunov function is then utilized to build a proportional-integral-derivative (pid) controller for performing overload control in a tandem system of sip servers. the proposed pid overload control algorithm is then evaluated using experiments showing it can successfully restore throughput close to maximum system capacity during overload. furthermore, we study the effect of overload detection lag on system stability showing that even a small delay in reacting to overload can postpone system stabilization by multiple minutes. (c) 2017 elsevier b.v. all rights reserved.
computer_vision	compared with vertical photogrammtry, oblique photogrammetry is radically different for images acquired from sensor with big yaw, pitch, and roll angles. image matching is a vital step and core problem of oblique low-altitude photogrammetric process. among the most popular oblique images matching methods are currently sift/asift and many affine invariant feature-based approaches, which are mainly used in computer vision, while these methods are unsuitable for requiring evenly distributed corresponding points and high efficiency simultaneously in oblique photogrammetry. in this paper, we present an oblique low-altitude images matching approach using robust perspective invariant features. firstly, the homography matrix is estimated by a few corresponding points obtained from top pyramid images matching in several projective simulation. then images matching are implemented by sub-pixel harris corners and descriptors after shape perspective transforming on the basis of homography matrix. finally, the error or gross error matched points are excluded by epipolar geometry, ransac algorithm and back projection constraint. experimental results show that the proposed approach can achieve more excellent performances in oblique low-altitude images matching than the common methods, including sift and surf. and the proposed approach can significantly improve the computational efficiency compared with asift and affine-surf.
system_identification	identification of nonlinear structural system is an important but challenging task for structural health monitoring. due to the complexities of structural nonlinearities, it is hard to establish proper mathematical models for some structural nonlinear behaviors. moreover, only partial structural responses can be measured in practice; it is essential to conduct identification of nonlinear structural systems using only partial measurements of structural responses. to cope with these issues, an algorithm is proposed in this article for the identification of some model-free structural nonlinear restoring forces using only partial measurements of structural responses. first, an equivalent linear structural system is introduced for the identification of the locations of structural nonlinearities. then, a model-free structural nonlinear restoring force is approximated by a power series polynomial. the unknown coefficients of the power series polynomials together with other structural parameters are identified by the extended kalman filter so that the characteristics of the behaviors of the model-free of nonlinear restoring forces can be identified. some numerical examples including the identification of two nonlinear multi-story shear frames and a planar nonlinear truss with different structural nonlinear restoring forces are used to validate the proposed algorithm.
software_engineering	reuse of software components, either closed or open source, is considered to be one of the most important best practices in software engineering, since it reduces development cost and improves software quality. however, since reused components are (by definition) generic, they need to be customized and integrated into a specific system before they can be useful. since this integration is system-specific, the integration effort is non-negligible and increases maintenance costs, especially if more than one component needs to be integrated. this paper performs an empirical study of multi-component integration in the context of three successful open source distributions (debian, ubuntu and freebsd). such distributions integrate thousands of open source components with an operating system kernel to deliver a coherent software product to millions of users worldwide. we empirically identified seven major integration activities performed by the maintainers of these distributions, documented how these activities are being performed by the maintainers, then evaluated and refined the identified activities with input from six maintainers of the three studied distributions. the documented activities provide a common vocabulary for component integration in open source distributions and outline a roadmap for future research on software integration.
algorithm_design	we demonstrate circuits that generate set and integer partitions on a set s of n objects at a rate of one per clock. partitions are ways to group elements of a set together and have been extensively studied by researchers in algorithm design and theory. we offer two versions of a hardware set partition generator. in the first, partitions are produced in lexicographical order in response to successive clock pulses. in the second, an index input determines the set partition produced. such circuits are useful in the hardware implementation of the optimum distribution of tasks to processors. we show circuits for integer partitions as well. our circuits are combinational. for large n, they can have a large delay. however, one can easily pipeline them to produce one partition per clock period. we show (1) analytical and (2) experimental time/complexity results that quantify the efficiency of our designs. for example, our results show that a hardware set partition generator running on a 100mhz fpga produces partitions at a rate that is approximately 10 times the rate of a software implementation on a processor running at 2.26ghz.
operational_amplifier	in this paper a high gain low noise op-amp has been designed. in designing of a high gain op-amp, for large values of coupling capacitor, gain will decrease. since our requirement was to increase the gain, so we have designed a three stage op-amp. our designed circuit provides gain of 78.4 db, which is very much larger than two stage op-amp. there is a trade-off between various parameters like phase margin, gain, slew rate etc. for example, to achieve larger values of gbw, pm will decrease. we have compared the results for two values of input common mode range. improvement in the designed circuit is done to achieve the desired gbw by recalculating the transistor 's w/l ratios and then simulating the results. gain bandwidth product of 176.9 mhz and phase margin greater than 60 degrees is achieved but at the cost of power dissipation and area. the op-amp is designed in gpdk 180 nm cmos technology.
image_processing	the circle hough transform (cht) is one of the popular circle detection algorithm in image processing and machine vision application, favored for its tolerance to noise. nevertheless, it involves huge computation and excessive memory requirements. because of its drawbacks, various modifications have been suggested to increase its performances. in this paper, we present a new modification of the cht method developed for an automatic biometric iris recognition system. the novelty of this method resides on the use of the incremental property in order to reduce the resources requirement and the parallel property for decreasing the computation time. the incremental property is obtained using the approximation of the used trigonometric functions, while the parallel property is achieved by calculating, at the same time, several point coordinates of the circle. the software implementation and the validation have been done in c++ and matlab on real images. the errors analysis and the performances of the proposed method against the basic cht method are presented in this paper. (c) 2016 elsevier gmbh. all rights reserved.
algorithm_design	the problem of data representation is fundamental to the efficiency of search algorithms for the traveling salesman problem (tsp). the computational effort required to perform such tour operations as traversal and subpath reversal considerably influence algorithm design and performance. we propose a new data structure-the k-level satellite tree-for representing a tsp tour with a discussion of properties in the framework of general tour operations. the k-level satellite tree representation is shown to be significantly more efficient than its predecessors for large-scale instances.
system_identification	in this paper, the infinite-horizon robust optimal control problem for a class of continuous-time uncertain non-linear systems is investigated by using data-based adaptive critic designs. the neural network identification scheme is combined with the traditional adaptive critic technique, in order to design the nonlinear robust optimal control under uncertain environment. first, the robust optimal controller of the original uncertain system with a specified cost function is established by adding a feedback gain to the optimal controller of the nominal system. then, a neural network identifier is employed to reconstruct the unknown dynamics of the nominal system with stability analysis. hence, the data-based adaptive critic designs can be developed to solve the hamilton-jacobi-bellman equation corresponding to the transformed optimal control problem. the uniform ultimate boundedness of the closed-loop system is also proved by using the lyapunov approach. finally, two simulation examples are presented to illustrate the effectiveness of the developed control strategy.
data_structures	the ability to timely process significant amounts of continuously updated spatial data is mandatory for an increasing number of applications. parallelism enables such applications to face this data-intensive challenge and allows the devised systems to feature low latency and high scalability. in this paper, we focus on a specific data-intensive problem concerning the repeated processing of huge amounts of range queries over massive sets of moving objects, where the spatial extent of queries and objects is continuously modified over time. to tackle this problem and significantly accelerate query processing, we devise a hybrid cpu/gpu pipeline that compresses data output and saves query processing work. the devised system relies on an ad-hoc spatial index leading to a problem decomposition that results in a set of independent data-parallel tasks. the index is based on a point-region quadtree space decomposition and allows to tackle effectively a broad range of spatial object distributions, even those very skewed. also, to deal with the architectural peculiarities and limitations of the gpus, we adopt non-trivial gpu data structures that avoid the need of locked memory accesses while favouring coalesced memory accesses, thus enhancing the overall memory throughput. to the best of our knowledge, this is the first work that exploits gpus to efficiently solve repeated range queries over massive sets of continuously moving objects, possibly characterized by highly skewed spatial distributions. in comparison with state-of-the-art cpu-based implementations, our method highlights significant speedups in the order of 10 - 20x, depending on the dataset. copyright (c) 2016 john wiley & sons, ltd.
electric_motor	we present a method of comparing data on habitat use and availability that allows availability to differ among observations. this method is applicable when habitats change over time and when animals are unable to move throughout a predetermined study area between observations. we used maximum-likelihood techniques to derive an index that estimates the probability that each habitat type would be used if all were equally available. we also demonstrate how these indices can be used to compare relative use of available habitats, assign them ranks, and assess statistical differences between pairs of indices. the set of these indices for all habitats can be compared between groups of animals that represent different seasons, sex or age classes, or experimental treatments. this method allows quantitative comparisons among types and is not affected by arbitrary decisions about which habitats to include in the study. we provide an example by comparing the availability of four categories of sea ice concentration to their use by adult female polar bears (ursus maritimus), whose movements were monitored by satellite radio tracking in the bering and chukchi seas during 1990. use of ice categories by bears was nonrandom, and the pattern of use differed between spring and late summer seasons.
computer_graphics	the army 's combat training is very important now, and the simulation of the real battlefield environment is of great significance. two-dimensional information has been unable to meet the demand at present. with the development of virtual reality technology, three-dimensional (3d) simulation of the battlefield environment is possible. in the simulation of 3d battlefield environment, in addition to the terrain, combat personnel and the combat tool, the simulation of explosions, fire, smoke and other effects is also very important, since these effects can enhance senses of realism and immersion of the 3d scene. however, these special effects are irregular objects, which make it difficult to simulate with the general geometry. therefore, the simulation of irregular objects is always a hot and difficult research topic in computer graphics. here, the particle system algorithm is used for simulating irregular objects. we design the simulation of the explosion, fire, smoke based on the particle system and applied it to the battlefield 3d scene. besides, the battlefield 3d scene simulation with the glasses-free 3d display is carried out with an algorithm based on gpu 4k super-multiview 3d video real-time transformation method. at the same time, with the human-computer interaction function, we ultimately realized glasses-free 3d display of the simulated more realistic and immersed 3d battlefield environment.
operational_amplifier	this paper discusses the use of a low gain amplifier and a passive switched-capacitor (sc) network to enable the sc integrator function. the method is applied to a delta-sigma modulator to achieve high resolution as proved by the 65-nm cmos technology test vehicle. compared with the conventional operational amplifier (op-amp)-based sc integrator, this solution utilizes a low-gain open-loop amplifier to drive a passive sc integrator with positive feedback. since the open-loop amplifier requires a low dc gain and implements an embedded current adder, the power consumption is very low. power reduction for single bit is obtained by using passive feed-forward with built-in adder to assist the first amplifier. the low swing obtained at the output of the active blocks relaxes the slew rate requirement and enhances the linearity. implemented in 65-nm digital cmos technology with an active area of 0.1 mm(2), the test chip achieves a dynamic range of 91 db, peak signal-to-noise ratio of 88.4 db, peak signal-to-noise-plus-distortion ratio of 88.2 db, and a spurious free dynamic range of 106 db while consuming 73.6 mu w in a 25-khz signal bandwidth at 1 v supply, yielding a fom(walden) of 70 fj/conv-step and fom(schreier) of 176 db.
distributed_computing	phylogenetic analysis has achieved extraordinary results in domains like species delimitation and evolutionary biology. an essential element behind this success has been the introduction of high performance computing techniques in the step of estimating the phylogenetic likelihoods. this paper describes the design and implementation of a distributed and cpu-gpu based heterogeneous computing system on parallelizing the analysis. the parallelization has been implemented in the state-of-the-art version of mrbayes, a widespread phylogeny reconstruction program. we benchmarked the method and another two gpu-based methods by using 8 distributed computing nodes on tianhe-1a. the experimental results indicate that the proposed method outstrips beagle and the nmc(3) method by speedup factors of up to 1.98x and 1.68x, respectively. in comparison to the serially implemented mrbayes, a peak speedup of 188x is finally achieved by using 8 tesla m 2050 gpus. the proposed method is publicly available to facilitate further research on phylogenetic analysis.
computer_programming	timing is critical when trying to engage students in various engineering career paths. while many ""national engineers week"" programs exist for primary and middle school students, there is a lack of hands on activities for students in the 9th-12th grades. it is often difficult to devise experiments for this age group that are interesting and not juvenile. yet, it is during these crucial years that most students are lost to science, math and engineering. engaging students and presenting opportunities for invention and excitement is important in the teen years, when peer pressure and the distractions of friends, social events, and activities are particularly high.(1). there are a number of open source programming and affordable hardware platforms that can be used to implement low cost and interactive programs to promote innovation with various age groups. in this paper we share our work, as well as our learnings on how to make the workshops more effective. we have created various arduino projects that can be customized to grade levels ranging from grades 7-12, and even college undergraduate students. the various projects we describe in this paper have been used to interact with students of different grade levels to engage in basic elements of engineering and computer programming. the classes should be set up to work in groups to promote shared innovation, teamwork and collaboration with peers. the open source and hardware experimenting exposed the students to various career paths ranging from software engineer, to electronic engineers and basic elements of various other engineering paths. this paper is designed to demonstrate the promotion of the engineering profession in schools through the use of arduino uno, raspberry pi gemma kits, and flora kits. the programs are also designed to accommodate classroom setting, workshops, or as an in-class field trip.
image_processing	luminescence imaging is a versatile characterisation technique used for a broad range of research and industrial applications, particularly for the field of photovoltaics where photoluminescence and electroluminescence imaging is routinely carried out for materials analysis and quality control. luminescence imaging can reveal a wealth of material information, as detailed in extensive literature, yet these techniques are often only used qualitatively instead of being utilised to their full potential. part of the reason for this is the time and effort required for image processing and analysis in order to convert image data to more meaningful results. in this work, a custom built, matlab based software suite is presented which aims to dramatically simplify luminescence image processing and analysis. the suite includes four individual programs which can be used in isolation or in conjunction to achieve a broad array of functionality, including but not limited to, point spread function determination and deconvolution, automated sample extraction, image alignment and comparison, minority carrier lifetime calibration and iron impurity concentration mapping. program summary program title: lumitools program files doi: http://dx.dolorg/10.17632/7nd34fbwfg.1 licensing provisions: creative commons by 4.0 (cc by 4.0) programming language: matlab nature of problem: data acquired using the technique of luminescence imaging require unique corrections and processing in order to convert the qualitative image into more meaningful, quantitative results. such processing is often non-trivial and can present a barrier to research. solution method: the lumitools package provides a broad array of common functionality required for the processing and analysis of luminescence images. several tools are available to allow processing for various applications and each tool has been developed with a simple to use graphical user interface. (c) 2017 elsevier b.v. all rights reserved.
computer_vision	this paper mainly studies the image contour detection algorithm which can distinguish edges of different strengths. based on the study of probability-of-boundary operator, we find that defects such as response suppression and offset exist in the algorithm during the detection of corners and curved edges, thus an improved algorithm is proposed. this algorithm retains the advantage in probability-of-boundary algorithm which can effectively distinguish the edge strength, while improves the above-mentioned defects. and an improved algorithm is proposed to characterize the strength of boundary reasonably, making the test results in line with human subjective recognition results.
cryptography	due to an increase in the number of internet users, electronic commerce has grown significantly during the last decade. electronic auction (e-auction) is one of the famous e-commerce applications. even so, security and robustness of e-auction schemes still remain a challenge. requirements like anonymity and privacy of the bid value are under threat from the attackers. any auction protocol must not leak the anonymity and the privacy of the bid value of an honest bidder. keeping these requirements in mind, we have firstly proposed a controlled traceable blind signature scheme (ctbss) because e-auction schemes should be able to trace the bidders. using ctbss, a blind sealed-bid electronic auction scheme is proposed (bsea). we have incorporated the notion of blind signature to e-auction schemes. moreover, both the schemes are based upon elliptic curve cryptography (ecc), which provides a similar level of security with a comparatively smaller key size than the discrete logarithm problem (dlp) based e-auction protocols. the analysis shows that bsea fulfills all the requirements of e-auction protocol, and the total computation overhead is lower than the existing schemes.
operating_systems	this paper presents a real-time operating system ( rtos) implementation. this rtos is based on the osek-os 2.2.3 standard, which will be extended to support an asymmetric multiprocessor system ( amp). the term asymmetric means that the microprocessors included in the system have heterogeneous architectures ( a subgroup of identical processors may exist but not the whole amount of them are identical) and each processor executes an instance of the rtos specifically designed and optimised. also, a description of the development process that took place to communicate each rtos instance, taking advantage of hardware features in order to exchange information between processors, is provided. finally, a functional test application is presented: processors monitor each other using rtos resources as keep-alive events while sharing information about gpio activity and reporting changes and system status using serial communication. in addition, an energy consumption analysis is performed for this test case. the hardware platform used in this development is the argentine open industrial computer ( computadora industrial abierta argentina, ciaa) based on the lpc4337 dual-core amp microcontroller, which includes an arm cortex-m4 ( armv7e-m architecture) acting as the master microprocessor and an arm cortex-m0 ( armv6-m architecture), as the slave coprocessor.
data_structures	given a matrix of size n, two dimensional range minimum queries (2d-rmqs) ask for the position of the minimum element in a rectangular range within the matrix. we study trade-offs between the query time and the additional space used by indexing data structures that support 2d-rmq5. using a novel technique-the discrepancy properties of fibonacci lattices we give an indexing data structure for 2d-rmqs that uses o (n/c) bits additional space with o (c logc(log log c)(2)) query time, for any parameter c, 4 <= c <= n. also, when the entries of the input matrix are from 10,11, we show that the query time can be improved to o (c logc) with the same space usage. (c) 2016 published by elsevier b.v.
algorithm_design	in this paper, needs of trusted iot application are identified and a methodology is proposed to create a framework ""iotee"" for rapid prototyping of secure, trusted and commercial iot applications in absence of hardware. this has been done by analysis of requirements of a sample trusted iot application heartbeat sensor (hbs), classification of bhs services and their decomposition into trusted and non-trusted components. furthermore, the methodology includes algorithm design for services like registration, authentication, authorization and secure communication in the proposed framework. detailed operation sequence of the algorithms is also depicted to understand the overall switching scenario between trusted and non-trusted components of application. finally, a dynamic deployment structure is created to enable and disable the trusted components in the framework.
signal-flow_graph	the signal flow graph (sfg) nonlinear modeling approach is well known for modeling dc-dc converters and it is a powerful analysis tool for higher order converter systems. modeling, of several specific fourth-order dc-dc converter circuits have been reported using conventional state-space averaging. particular emphasis has been given, so far, only to arrive at any of the large, small-signal (ss) and steady-state models but not a generalized one. this paper gives the generalized sfg model of the fourth-order dc-dc converter topology that is useful for generating different types of fourth-order dc-dc converter circuits unified models. further, it is shown that the deduction of large, ss and steady-state models from these unified sfgs is easy and straightforward. all possible fourth-order dc-dc converter circuits from its generalized topology have been identified and an analysis of a few converter circuits is given here for illustration of the proposed modeling method. large-signal (ls) models are developed for different topology configurations and are programmed in simulink simulator. ls responses against supply and load disturbances are obtained. experimental observations are provided to validate the proposed modeling method.
cryptography	in this paper, we propose a three-party and a multi-party quantum key agreement protocols with single photons in both polarization and spatial-mode degrees of freedom. based on the defined collective unitary operations, the participants can agree on a secure shared key through encoding their sub-secret keys on the particles. moreover, the security of our protocols is discussed comprehensively. it is showed that the presented protocols can defend both the outside attacks and participant attacks. the efficiency analysis also shows that our two protocols can achieve high qubit efficiency. besides, our protocols are feasible since the preparation and themeasurement of singlephoton state in both polarization and spatial-mode degrees of freedom are available with current quantum techniques.
operational_amplifier	new voltage-mode electronically tunable notch, bandpass, highpass and lowpass shadow filters are presented. the filters are built around the current-feedback operational-amplifier. in each case one or more of the parameters of the filter can be electronically controlled by adjusting the gain of an external amplifier built around the current-feedback operational-amplifier. contrary to the current-mode shadow filters where a summing junction must be used, no summing amplifiers are used in these voltage-mode realizations. experimental results obtained using the ad844 current-feedback operational-amplifier are presented. the results obtained confirm the functionality of the proposed circuits.
network_security	it is essential to design a protocol to allow sensor nodes to attest to their trustworthiness for mission-critical applications based on wireless sensor networks (wsns). however, it is a challenge to evaluate the trustworthiness without appropriate hardware support. hence, we present a hardware-based remote attestation protocol to tackle the problem within wsns. in our design, each sensor node is equipped with a trusted platform module (tpm) which plays the role of a trusted anchor. we start with the formulation of remote attestation and its security. the complete protocol for both single-hop and multi-hop attestations is then demonstrated. results show the new protocol is effective, efficient, and secure.
network_security	aims: protocol security which is important concern in the network security, which ensures the security and integrity of data transmission over the internet. secure network data from any illegimate attempt to extract content of the data and cloud computing is the advance computing technology for the internet users. materials and methods: we can enhance our system without modify or changing our resources by the internet over cloud technology. so, all the resources we can get through cloud system. our data should be transmit in secure channel. results: this paper focus on protocol security in private cloud system deployment and security against poodle (discovered by google team at oct 2014).
computer_vision	the main objective of this study was to configure the acquisition and analysis of low-field magnetic resonance imaging (mri) to predict physico-chemical characteristics of iberian loin, evaluating the use of different mri sequences (spin echo, se; gradient echo, ge; turbo 3d, t3d), computational texture feature methods (glcm, ngldm, glrlm, glcm + ngldm + glrlm), and data mining techniques (multiple linear regression, mlr; isotonic regression, ir). moderate to very good correlation coefficients and low mean absolute error were found when applying mlr or ir on any method of computational texture features from mri acquired with se or ge. for t3d sequence, accurate results are only obtained by applying ir on glcm or glcm + ngldm + glrlm methods. considering not only the accuracy of the methodology but also consumed time and required resources, the use of se sequences for mri acquisition, glcm method for mri texture analysis, and mlr could be indicated for prediction physico-chemical characteristics of loin.
electricity	in the transition to renewable energy systems, fluctuating renewable energy, such as wind and solar power, plays a large and important role. this creates a challenge in terms of meeting demands, as the energy production fluctuates based on weather patterns. to utilise high amounts of fluctuating renewable energy, the energy system has to be more flexible in terms of decoupling demand and production. this paper investigates two potential ways to increase flexibility. the first is the interconnection between energy systems, for instance between two countries, labelled as cross-border interconnection, and the second is cross-sector interconnection, i.e., the integration between different parts of an energy system, for instance heat and electricity. this paper seeks to compare the types of interconnectivity and discuss to which extent they are mutually beneficial. to do this, the study investigates two energy systems that represent northern and southern europe. both systems go through three developmental steps that increase the cross-sector interconnectivity. at each developmental step an increasing level of transmission capacities is examined to identify the benefits of cross-border interconnectivity. the results show that while both measures increase the system utilisation of renewable energy and the system efficiency, the cross-sector interconnection gives the best system performance. to analyse the possible interaction between cross-sector and cross-border interconnectivity, two main aspects have to be clarified. the first part defines the approach and the second is the construction of the two archetypes. (c) 2017 elsevier ltd. all rights reserved.
microcontroller	the volume measurement system based on the unmanned aerial vehicle (uav) platform designed in this paper is to solve the problems of long measuring period, low accuracy and high cost in the process of material volume measurement. the system mainly consists of an unmanned aerial vehicle (uav), a laser scanner, an inertial measurement unit, a differential positioning system, a wireless transmission equipment and a microcontroller. the uav performs measurement tasks in a specified measurement area with the planned routes, the measured data will be returned to the ground station system to calculate the 3d coordinates of each measured point and build the stack model based on triangular or grid modeling method. finally, the ground station system calculates the volume and produce three-dimensional map of the measured stock. the characteristics of the system are strong adaptability to environment, short measurement period and high accuracy.
data_structures	understanding beliefs, values, and preferences of patients is a tenet of contemporary health sciences. this application was motivated by the analysis of multiple partially ordered set (poset) responses from an inventory on layman beliefs about diabetes. the partially ordered set arises because of two features in the data-first, the response options contain a do n't know (dk) option, and second, there were two consecutive occasions of measurement. as predicted by the common sense model of illness, beliefs about diabetes were not necessarily stable across the two measurement occasions. instead of analyzing the two occasions separately, we studied the joint responses across the occasions as a poset response. few analytic methods exist for data structures other than ordered or nominal categories. poset responses are routinely collapsed and then analyzed as either rank ordered or nominal data, leading to the loss of nuanced information that might be present within poset categories. in this paper we developed a general class of item response models for analyzing the poset data collected from the common sense model of diabetes inventory. the inferential object of interest is the latent trait that indicates congruence of belief with the biomedical model. to apply an item response model to the poset diabetes inventory, we proved that a simple coding algorithm circumvents the requirement of writing new codes such that standard irt software could be directly used for the purpose of item estimation and individual scoring. simulation experiments were used to examine parameter recovery for the proposed poset model.
computer_programming	providing students opportunities to appreciate interdisciplinary systems remains a challenge for educators at all levels. sensing and data-logging in the environment and in engineered systems offer a unique opportunity for students to explore the connections between engineering processes, analog signals, and digital outputs. here, we present the design of a device that uses an infrared sensor and microcontroller to measure and record low liquid flow rates. we designed this device using the open-source arduino t microcontroller platform, which can stand alone or interface with a pc to display data in real time. in order to demonstrate the usefulness of this device in the undergraduate learning laboratory, we have incorporated it into a membrane distillation system. building and experimenting with such devices helps students practice and learn creativity, troubleshooting, and programming fundamentals, allowing them to understand the importance of electrical engineering and computer programming in the context of chemical and environmental engineering.
digital_control	this work describes an electrical interferometer for contactless permittivity measurements working at 120 ghz. it was fabricated in a 130 nm sige process featuring an ft and fmax of 240 and 330 ghz. the on-chip system contains a 120 ghz vco with a tuning range of 7 ghz featuring a divide-by- 64 circuit to enable external pll operation. the subsequent buffer provides 7 dbm of output power at 120 ghz. additionally, the ic contains high-precision and high-resolution phase shifters based on a slow-wave transmission line approach with digital control for direct readout ability. a 120 ghz lna with 17 db gain and a power detector to provide dc output signals were realized on chip. it enables sample emulation capability by phase shift inducement in the measurement as well as a reference transmission line. in terms of phase detection, the system shows a sensitivity of 907.36 mhz/degrees.
computer_vision	deep convolutional neural networks (cnns) have been widely used to obtain high-level representation in various computer vision tasks. however, in the field of remote sensing, there are not sufficient images to train a useful deep cnn. instead, we tend to transfer successful pre-trained deep cnns to remote sensing tasks. in the transferring process, generalization power of features in pre-trained deep cnns plays the key role. in this paper, we propose two promising architectures to extract general features from pre-trained deep cnns for remote scene classification. these two architectures suggest two directions for improvement. first, before the pre-trained deep cnns, we design a linear pca network (lpcanet) to synthesize spatial information of remote sensing images in each spectral channel. this design shortens the spatial distance of target and source datasets for pre-trained deep cnns. second, we introduce quaternion algebra to lpcanet, which further shortens the spectral distance between remote sensing images and images used to pre-train deep cnns. with five well-known pre-trained deep cnns, experimental results on three independent remote sensing datasets demonstrate that our proposed framework obtains state-of-the-art results without fine-tuning and feature fusing. this paper also provides baseline for transferring fresh pre-trained deep cnns to other remote sensing tasks.
algorithm_design	this paper investigates the development of a mild hybrid powertrain system through the integration of a conventional manual transmission equipped powertrain and a secondary power source in the form of an electric motor driving the transmission output shaft. the primary goal of this paper is to study the performance of partial power-on gear shifts through the implementation of torque hole filling by the electric motor during gear changes. to achieve this goal, mathematical models of both conventional and mild hybrid powertrain are developed and used to compare the system dynamic performance of the two systems. this mathematical modelling is used to run different simulations for gearshift control algorithm design during system development, allowing us to evaluate the achievable performance and its dependency on system properties. the impact of motor power on the degree of torque hole compensation is also investigated, keeping in mind the practical limits to motor specification. this investigation uses both the output torque, vehicle speed as well as vibration dose value to evaluate the quality of gearshifts at different motor sizes. results demonstrate that the torque hole may be eliminated using a motor power of 50 kw. however, the minimum vibration dose value during gear change is achieved using a peak power of 16-20 kw. (c) 2017 elsevier ltd. all rights reserved.
symbolic_computation	a modeling language for hybrid systems hydla and its implementation hylagi are described. hydla is a constraint-based language that can handle uncertainties of models smoothly. hylagi calculates trajectories by symbolic formula manipulation to exclude errors resulting from floating-point arithmetic. hylagi features a nondeterministic simulation algorithm so it can calculate all possible qualitative different trajectories of models with uncertainties.
bioinformatics	objectives. the purpose of this study was to determine the level of heterogeneity in high grade serous ovarian cancer (hgsoc) by analyzing rna expression in single epithelial and cancer associated stromal cells. in addition, we explored the possibility of identifying subgroups based on pathway activation and pre-defined signatures from cancer stem cells and chemo-resistant cells. methods. a fresh, hgsoc tumor specimen derived from ovary was enzymatically digested and depleted of immune infiltrating cells. rna sequencing was performed on 92 single cells and 66 of these single cell datasets passed quality control checks. sequences were analyzed using multiple bioinformatics tools, including clustering, principle components analysis, and geneset enrichment analysis to identify subgroups and activated pathways. immunohistochemistry for ovarian cancer, stem cell and stromal markers was performed on adjacent tumor sections. results. analysis of the gene expression patterns identified two major subsets of cells characterized by epithelial and stromal gene expression patterns. the epithelial group was characterized by proliferative genes including genes associated with oxidative phosphorylation and myc activity, while the stromal group was characterized by increased expression of extracellular matrix (ecm) genes and genes associated with epithelial-to-mesenchymal transition (emt). neither group expressed a signature correlating with published chemo-resistant gene signatures, but many cells, predominantly in the stromal subgroup, expressed markers associated with cancer stem cells. conclusions. single cell sequencing provides a means of identifying subpopulations of cancer cells within a single patient. single cell sequence analysis may prove to be critical for understanding the etiology, progression and drug resistance in ovarian cancer. (c) 2017 elsevier inc. all rights reserved.
image_processing	at nano/micro-scales, the resistance of a particle to rolling is a critical factor in many applications and biological phenomena as it affects particle adhesion, motion and flow as well as particle manipulation (e.g. picking and placing of microparticles). in present work, a non-contact non-invasive experimental method is detailed and applied to determine the pre-rolling critical leaning angle (cla) of single microparticles. transient rayleigh surface acoustic waves (saw) are utilized as the excitation mechanism and interferometry and image processing as detection/monitoring and analysis techniques for capturing the micro/nano-scale dynamics of the microparticles. the cla values for a set of 30 psl (polystyrene latex) microparticles with a diameter of 14.9 +/- 0.6 pm on a soda-lime glass substrate are reported. the cia of the studied particles are determined to be between 0.9 and 7.8 degrees. it is also observed that during a saw field burst cycle, microparticles could change their drifting (rolling and/or sliding) directions, speeds and accelerations. the trajectory of a particle is often found to be non-linear. this nonlinear behavior is attributed to the inhomogeneity of the surface properties of the particles and the substrate as well as possible electric charge density, chemistry variations and potential contamination on surfaces. moreover, the effect of electric charge (developed due to the triboelectric effect) on the particle drifting motion is investigated. it is found that the percentage of drifting particles is not only a function of the amplitude of the excitation field but also a function of possible electrostatic charges developed on the particles due to the drifting motion on the substrate. in addition to their potential uses in particle manipulation, removal and adhesion characterization, the reported results could be utilized in numerical simulations of microparticle motion and deposition. (c) 2017 elsevier b.v. all rights reserved.
computer_vision	a stereovision based methodology to estimate the position, speed and heading of a moving marine vehicle from a pursuing unmanned surface vehicle (usv) is considered, in support of enabling a usv to follow a target vehicle in motion. the methodology involves stereovision ranging, object detection and tracking, and minimization of tracking error due to image quantization limitations and pixel miscorrespondences in the stereo pixel-matching process. the method consists of combining a simple stereovision-matching algorithm, together with a predictive-corrective approach based on an extended kalman filter (ekf), and use of suitable choices of probabilistic models representing the motion of the target vehicle and the stereovision measurements. simple matching algorithms perform faster at the expense of potential errors in depth measurement. the approach considered aims to minimize the tracking errors related to such errors in stereovision measurements, thereby improving the accuracy of the state estimation of the vehicle. results from simulations and a real-time implementation reveal the effectiveness of the system to compute accurate estimates of the state of the target vehicle over non-compliant trajectories subjected to a variety of motion conditions.
control_engineering	elms and sawteeth, located in different parts of the plasma, are similar from a control engineering point of view. both manifest themselves through quiescent periods interrupted by periodic collapses. for both, large collapses, following long quiescent periods, have detrimental effects while short periods are associated with decreased confinement. following the installation of the all metal 'iter like wall' on jet, sawteeth and elms also play an important role by expelling tungsten from the core and edge of the plasma respectively. control of tungsten has therefore been added to divertor heat load reduction, ntm avoidance and helium ash removal as reasons for requiring elm and sawtooth control. it is therefore of interest to implement control systems to maintain the sawtooth and elm frequencies in the desired ranges. on jet, elm frequency control uses radial field 'kicks' and pellet and gas injection as actuators, while sawtooth control uses ion cyclotron resonance heating (icrh). jet experiments have, for the first time, established feedback control of the elm frequency, via real time variation of the injected gas flow [1]. using this controller in conjunction with pellet injection allows the elm frequency to be kept as required despite variations in pellet elm triggering efficiency. jet sawtooth control experiments have, for the first time, demonstrated that low field side icrh, as foreseen for iter, can shorten sawteeth lengthened by central fast ions [2]. the development of elm and sawtooth control could be key to achieve stable high performance jet discharges with minimal tungsten content. integrating such schemes into an overall control strategy will be required in future tokamaks and gaining experience on current tokamaks is essential.
digital_control	we have proposed the sensorless model control based on the static model equation of the dc-dc converter that is able to change the bias value corresponding to changes of the load current, the input voltage and output voltage. the sensorless model control can regulate the output voltage. on the other hand, the transient response of output voltage is not improved. therefore, an improvement of the transient response is carried out by adding the transient improvement function which changes a bias value drastically for a short time at the start of the transient state. the purpose of this paper is to indicate the parameter setting of the transient improvement function that improves the transient response by the simulation analysis under changing the circuit condition.
digital_control	this paper presents a fully digital-control soft start mechanism with coefficients ki optimization for dc-dc power converters. during the soft start phase, a ladder reference voltage steps up gradually to make inductor current ramp up smoothly and overshoot voltage is minimized with the proposed coefficients ki distribution. simulation results show that massive inductor current can be well avoided during the soft start process with the proposed soft start mechanism, which only occupies a chip area of 300umx120um.
software_engineering	the selection of which requirements should be implemented in the next software release is an important and complex task in the software development process, considering the presence of budget constraints and other conflicting aspects. in this context, search based software engineering, has the main objective of applying automatic search methods to solve complex software engineering problems. however, most of these methods do not consider human expertise during the search, especially due to the difficulty in mathematically modeling the user 's preferences. consequently, the user can present some resistance or place little confidence in the final results, given that his/her knowledge and domain expertise was not properly considered in the solution construction. this paper aims at proposing an interactive model for the next release problem using ant colony optimization, where the user can define which requirements he/she would like to include or not in the next release. employing humans and a simulator, an empirical study was performed that considers real-world and artificial instances. the achieved results demonstrate that the loss of score was, on average, 12% when it was compared with a solution with no human intervention. on the other hand, the algorithm generates solutions that have more than 80% of the met preferences, as defined by the users. furthermore, the results showed that aco can be an interesting choice as an interactive search engine, given the low quantity of interactions that are required to reach good solutions. (c) 2016 elsevier b.v. all rights reserved.
software_engineering	double absorption heat transformer (daht) is a promising device in reducing the use of fossil fuels since it can utilize renewable sources or waste heat to provide high temperature energy. the absorber evaporator is an important component in the daht system, and there exists an optimum absorber evaporator temperature (oaet) at which the maximum coefficient of performance (cop) and exergy efficiency (ecop) can be obtained simultaneously. in this paper, an optimization study is carried out by means of a parametric analysis, using a mathematical model developed in the software engineering equation solver. the effects of the operating parameters such as the absorber, condenser, evaporator and generator temperatures and design parameters including the first and second economizer efficiencies on the oaet and corresponding maximum cop and ecop have been analyzed in detail. besides, some suggestions derived from the results are also given. (c) 2016 elsevier ltd. all rights reserved.
microcontroller	this paper deals with the design and real-time implementation of an model predictive control (mpc)-based reference governor on an industrial-like microcontroller. the task of the governor is to provide optimal setpoints for an inner proportional-summation-difference (psd) controller. the mpc-based governor is synthesized off-line as a piecewise affine (pwa) function that maps measurements onto optimal references. to achieve a fast and memory-efficient implementation, the pwa function is encoded as a binary search tree. this allows the reference governor to run on a sub-millisecond scale even on a very simple hardware. the proposed concept is experimentally verified on a laboratory device involving a magnetic levitation system. here, the psd controller is responsible for controlling the vertical position of the ball in the magnetic field. by using the reference governor, control performance can be significantly improved and input/output constraints enforced in a systematic manner.
microcontroller	in this brief, a practical power optimization method that calculates the optimal power supply and body bias voltages, for a given target operational frequency and a temperature, is proposed and evaluated. the proposed optimization method is based upon a simple power model in which several coefficients for leakage power, switching power, temperature, and operational frequency are obtained from accurate real chip measurements. the calculated optimal-voltage settings by the proposed model can achieve minimum accuracies of 93.8%, 91.6%, and 79.5% for room-temperature, 50 degrees c, and 65 degrees c, respectively. since the proposed methodology is based on well-known power formulas, it can be applied to the latest fd-soi technologies.
operational_amplifier	this paper presents a chopper amplifier for precision current sensing, capable of handling common mode input voltages outside the supply rails. for high common mode rejection ratio (cmrr) and dc gain, the amplifier employs a three-stage topology with nested-miller frequency compensation. by using the chopping technique, a referred to input offset voltage of +/-90 mu v is obtained. to reduce the output ripples caused by the chopping technique the amplifier employs a notch filter. a cmrr of 123db has been obtained, considering a supply voltage of 5v, for a common mode input voltage range from 4v to 80v. the stability of the operational amplifier (oa) is ensured for a minimum closed loop gain of 20v/v.
analog_signal_processing	instrumentation amplifiers (ia) used in wearable biomedical monitoring systems have to satisfy several performance requirements, such as low-voltage supply and low-power consumption, enabling increased portability. in the same time, a very important feature is wide range parameter programmability. this paper proposes a solution to implement electronic gain programming into an ia. the proposed solution is developed around the current balancing concept. an electronically tunable transconductance amplifier is used for adjusting the ia voltage gain as a function of the transconductor bias currents. additionally, the proposed ia outputs a differential signal, useful for latter differential analog signal processing. simulation results validate the proposed ia.
state_space_representation	nowadays, as more systems are regarded to be complex, the processes to develop them are becoming more complex too. this increasing trend makes more effective analysis methods inevitable necessities. meanwhile, matriarchal tools are becoming the most prominent, this paper has tried to study a work transformation matrix (wtm) at the level of coupled blocks of activities (cbas). the neighboring matrices of such a wtm act as its information flow interfaces with other activities. it is shown how these are equivalent to some state-space representation matrices. the equivalency helps us to improve the analysis method for a set of cbas constituting the whole wtm. additionally, the concepts of powers of adjacency matrices and elementary dynamic properties of process as a system in modern control theory are brought together to analyze the behavior of activities in coupled blocks. by analyzing these properties in a case study, five heuristic are derived and proposed for improving the process through better preference and ordering of activities. effectiveness of these heuristics is tested by a simple discrete-time simulation for which results show 17% of time reduction for the case study.
system_identification	refrigeration systems exist in different branches of industry and are characterized as great energy consumers with considerable nonlinear behavior. several studies have promoted energy costs reduction and minimization of nonlinearities effects in such systems. model predictive control has been successfully used to stabilize processes in the presence of such nonlinearities; therefore, its application in refrigeration systems is considered promising. in the present study, takagi-sugeno models were developed and validated in order to predict the evaporating and secondary fluid temperatures (te and tp) based on the anfis technique (adaptive network-based fuzzy inference systems) for a vapor-compressor chiller equipment. the prediction performance of resulting models was analyzed and accessed based on the variance accounted for criteria. these models were then used as the basis for prediction models in several generalized predictive controllers (gpc) denoted here as gpc-anfis controllers. different predictive controllers were designed for different local rules (fuzzy rules) and the global control action was assumed as the weighted sum of local controllers. experimental tests considered two distinct controllers, namely the gpc-anfis(te) (evaporating temperature control by means of compressor speed variation) and gpc-anfis(tp) (propylene glycol temperature control by means of compressor speed variation), were performed. the experimental tests for setpoint tracking (+/- 1 degrees c) considering 3000w of constant heat load showed satisfactory results with setpoint deviation around +/- 0.3 degrees c. therefore, the anfis technique demonstrated to be able to provide reliable predictive models to be used in generalized predictive control algorithms.
computer_programming	computer programming subject is a core ingredient for most of the engineering disciplines. however for the first year engineering, teaching and learning fundamentals of programming language like c has been considered as a great challenge to both teachers and novice learners. the challenges in learning the programming languages are: the learners are not able to analyze the flow of program, cannot fix errors or not able to debug the program, usually dependent on others for problem solving, bug fixing. programming skills and documentation are the most important aspects of software development. the structure of c program with proper indentation; comments & proper named variables can reduce most of the general compiler errors. the study proposes a novice way of teaching c language programming with effective program writing skills for the beginners. the experiment is conducted for the first year civil engineering students and the course is computer programming based on c language. a training session on effective program writing skills is conducted, to improve the ability of program writing skills with minimized compiler errors for novice learners. the effect of the experiment is verified with pretest & posttest before and after the training session. it is observed that the program written with proper indentation, comments and proper named variable can reduce the number of compiler errors and more than 60% of the student have written & executed the given c programs successfully in a stipulated time.
network_security	scheduling for generation units in modern power markets is one of the most important tasks of independent system operators (iso). to ensure secure and economical operation of power systems, isos solve the security constrained unit commitment (scuc) problem. scuc is a very complex and large-scale optimization problem. in addition, uncertainties imposed by wind generators and variable loads add to this complexity. stochastic scuc, one of the most important problems for scheduling generation units, considers different power system uncertainties. a considerable amount of previous works demonstrates the efficacy of decomposition techniques, such as benders' decomposition for stochastic scuc. solving this problem, even with decomposition techniques, for large-scale systems with multiple uncertainties is very time-consuming. a major part of stochastic scuc constraints belongs to network security. this paper presents a method in which cumulants are used to detect and eliminate inactive network constraints during the solving process. as a result, the method reduces the number of network security constraints and decreases the simulation time considerably. implementing the proposed method on a six -bus test system and a modified ieee 118-bus system demonstrates its efficiency and accuracy.
signal-flow_graph	a new framework on the representation of signal processing that considers multi-domain information flow of the signal is proposed. elementary information processing and their diagrams are identified to analyze the components of an algorithm, which is to be translated to the diagram. intra- and extra-domain relationships are represented as graphs that connect the corresponding domains by suitable mappings or transforms and corresponding emissions or absorption of information. various examples: convolution, wavelet filtering, projection imaging and coding in noisy channel; are presented to show the ubiquity and to illustrate the usability of the proposed framework.
pid_controller	the present work approaches a relatively new optimization scheme called ""quasi-oppositional symbiotic organism search (qosos) algorithm"", for the first time, to find an optimal and effective solution for load frequency control (lfc) problem of the power system. the symbiotic organism search (sos) algorithm works on the effect of symbiotic interaction strategies adopted by an organism to survive and propagate in the ecosystem. to avoid the suboptimal solution and to accelerate the convergence speed, the theory of quasi-oppositional based learning (q-obl) is integrated with original sos and used to solve the lfc problem. to demonstrate the effectiveness of qosos algorithm, two-area interconnected power system with nonlinearity effect of governor dead band and generation rate constraint is considered at the first instant, followed by the four-area power system showing the consequence of load perturbation. the structural simplicity, robust performance and acceptability of well-popular proportional-integral-derivative (pid) controller enforce to implement it as a secondary controller for the present analysis. the success of qosos algorithm is established by comparing the dynamic performances of concerned power system with those obtained by some recently published algorithms available in the literature. furthermore, the robustness and sensitivity are analyzed for the concerned power system to judge the efficacy of the proposed qosos approach.
algorithm_design	network control strategies for energy-efficient operation of hetnets need to match the dynamics of spatial and temporal traffic loads and to stabilize the network. in this paper, we develop a stochastic optimization framework, which formulates spatially inhomogeneous traffic distributions and time-varyingly random traffic arrivals and guarantees network stability, to investigate the energy conservation problem in hetnets. in particular, we jointly optimize base station (bs) operation, user association, subcarrier assignment, and power allocation to minimize the average energy consumption. we devise an algorithm without requiring any prior-knowledge of traffic distributions, referred to as the steerable energy expenditure algorithm (seed), to solve the problem. to deal with a highly coupled and mixed combinational subproblem in the seed, we separate optimization variables for suboptimal but cost-efficient and easy-to-implement algorithm design. by this, we develop closed-form solutions for both user association and subcarrier assignment, a fast and tuning-free algorithm that provably achieves at least local optimality for power allocation, and a greedy-style heuristic algorithm for bs operation with polynomial complexity. simulation results exhibit that the seed usually converges fast, can flexibly tune the power-delay tradeoff, and can significantly reduce energy consumption against other existing schemes.
distributed_computing	traditionally, the allocation and dynamic adaptation of federated cyberinfrastructure resources residing across multiple domains for data-intensive application workflows have been performance or quality of service-centric (i.e., qspecs); often compromising the end-to-end security requirements of scientific workflows. lack of standardized formalization methods of the workflows' end-to-end security requirements, and diverse/heterogenous domain resource and security policies make inter-conflict characterization between application 's security and performance requirements non-trivial, and leads to sub-optimal resource allocation. in this paper, we present a joint security and performance-driven federated resource allocation and adaptation scheme to define and characterize a data-intensive scientific application 's security specifications (i.e., sspecs). in order to aid security-driven resource brokering among domains with diverse security postures, we describe an alignment technique inspired by portunes algebra to combine domain-specific resource policies (i.e., rspecs) along the application workflow life cycle. we use standardized guidelines that help in compute/storage resource domain/location selection as well as network path selection based on both application qspecs and sspecs. we implement our security formalization and alignment methods as a framework, viz., ""ontimeurb"" and apply it on an exemplar distributed computing workflow to show the benefits of joint qspecs-sspecs-driven, rspecs-compliant federated workflow management.
pid_controller	we present a prototype of 6-dof magnetically levitated stage based on single axis lorentz force actuator is capable of positioning down to micron in several millimeter travel range with a simple and compact structure. the implementation of the lorentz force actuators, instrument modeling, and motion controller of the maglev system are described. with the force-gap relationship of the actuator solved by gaussian quadrature, 2-demsional (2d) lookup table is employed to store the result for the designing of control system. based on the force-gap relationship, we choose the suitable stroke of each actuator to develop the stability of the maglev stage. complete decoupling matrix is analyzed here to establish a decoupled dynamics between resulting six axis motion and eight outputs to the actuators. the design travel volume of the stage is 2mmx2mmx2mm in translation and 80mradx 80mradx40mrad in rotation. with a constant gain and critical damping pid controller, the resolution of the translation is 2.8um and 4um root mean square in horizontal and vertical direction respectively. experimental results are presented to illustrate the positioning fluctuations, step responds and multi axis motion. some comparative tests are taken to highlight the advantage resulted from the accurate force-gap relationship, suitable stroke, and complete decoupling matrix.
electrical_network	the paper considers the study of the electromagnetic field of a synchronous generator based on the three-phase induction machine. the stand includes: a frequency converter, an induction motor, a synchronous generator, a three-phase rectifier, an active load resistance, power protection and inclusion industrial electrical network. the study provides an analytical solution to one of the main objectives within theoretical foundations of electrical engineering, formulated so to reflect the decision making while designing new types of synchronous generators with permanent magnets. the necessity for such generators is determined, above all, by development of the area of small-scale energy sector due to the emergence on the consumer market of affordable and accessible strong magnets of neodymium alloy ndfeb. the purpose of this paper is to obtain an analytical solution for the determination of the induced electromotive force (emf) in the loop placed in a magnetic field of the permanent magnet of rectangular cross-sectional shape while in relative motion. the pictures magnetic field of the generator in an idling mode, the transverse and the longitudinal armature reaction at the nominal current in the stator winding are presented in the paper.
operating_systems	today, wireless sensor networks (wsns) with open source operating systems still need many efforts to guarantee that the protocol stack succeeds in delivering its expected performance. this is due to subtle implementation problems and unexpected interactions between protocol layers. the subtleties are often related to the judicious choice of parameters, in particular those related to timing issues. as these issues are often not visible in simulation studies, this paper proposes a low-cost versatile measurement testbed and demonstrates its usefulness in measuring the performance of rdc protocols. we demonstrate how the testbed helped to identify bugs in the implementation of an rdc protocol.
digital_control	this paper addresses the self-interference (si) cancellation in a full-duplex radio transceiver. in particular, we focus on shared-antenna based full-duplex transceivers where the self-interference coupling channel is always frequency-selective and can also be strongly time-varying depending on the antenna matching characteristics and reflections from the surroundings. a novel digitally-controlled rf self-interference canceller structure is described, being able to process the signals in a frequency-selective manner as well as track adaptively the time-varying si features, stemming from the fast digital control loop. a complete demonstrator board is developed, reported and measured, incorporating both the rf processing and the digital control processing. comprehensive rf measurements are then also carried out and reported at 2.4ghz ism band, evidencing more than 40dbs of active rf cancellation gain up to 80mhz instantaneous waveform bandwidths. furthermore, real-time self-adaptive tracking features are successfully demonstrated.
symbolic_computation	evolution equation is among one of the important nonlinear partial differential equations and its exact solutions are of great interest for the researchers around the globe. in this article, a new analytical technique is used to search for exact solutions of nonlinear evolution equation with the aid of symbolic computation. to check the validity of the method developed, we choose the srlw equation and many new and more general exact solutions have been obtained for the equation, which are of great importance. the efficiency of the developed scheme is confirmed since it provides more exact solutions than other techniques used now a day.
lorentz_force_law	consensus on a single electrodynamic theory has yet to be reached. discord was seeded over a century ago when abraham and minkowski proposed different forms of electromagnetic momentum density and has since expanded in scope with the gradual introduction of other forms of momentum and force densities. although degenerate sets of electrodynamic postulates can be fashioned to comply with global energy and momentum conservation, hope remains to isolate a single theory based on detailed comparison between force density predictions and radiation pressure experiments. this comparison is two-fold challenging because there are just a handful of quantitative radiation pressure measurements over the past century and the solutions developed from different postulates, which consist of approximate expressions and inferential deductions, are scattered throughout the literature. for these reasons, it is appropriate to conduct a consolidated and comprehensive re-analysis of past experiments under the assumption that the momentum and energy of light in matter are degenerate. we create a combined electrodynamic/fluid dynamic simulation testbed that uses five historically significant sets of electrodynamic postulates, including those by abraham and minkowski, to model radiation pressure under diverse configurations with minimal assumptions. this leads to new interpretations of landmark investigations of light momentum, including the balazs thought experiment, the jones-richards and jones-leslie measurements of radiation pressure on submerged mirrors, observations of laser-deformed fluid surfaces, and experiments on optical trapping and tractor beaming of dielectric particles. we discuss the merits and demerits of each set of postulates when compared to available experimental evidence and fundamental conservation laws. of the five sets of postulates, the abraham and einstein-laub postulates provide the greatest consistency with observations and the most physically plausible descriptions of electrodynamic interactions. force density predictions made by these two postulates are unique under many conditions and their experimental isolation is potentially within reach.
operating_systems	internet of things (iot) is an environment in which everywhere and every device became smart in a smart world. internet of things is growing vastly, it is implemented using smart devices which involve with embedded systems (ess). real time operating systems (rtos) are used in ess development due to rtos added important features as rtos simplifies development and makes systems more reliable. many researches directed to the internet of things, rtos became a part of iot development. in this paper, a generic vision and architecture of rtos for iot and the way it could be implemented in different applications are presented. implementation and testing methods of the rtos for iot are discussed. finally, research directions in using rtos for iot are discussed.
distributed_computing	in this paper, a multi-objective framework is proposed for the daily operation of a smart grid (sg) with high penetration of sensitive loads. the virtual power player (vpp) manages the day-ahead energy resource scheduling in the smart grid, considering the intensive use of distributed generation (dg) and vehicle-to-grid (v2g), while maintaining a highly reliable power for the sensitive loads. this work considers high penetration of sensitive loads, i.e. loads such as some industrial processes that require high power quality, high reliability and few interruptions. the weighted-sum approach is used with the distributed and parallel computing techniques to efficiently solve the multi-objective problem. a two-stage optimization method is proposed using a particle swarm optimization (pso) and a deterministic technique based on mixed-integer linear programming (milp). a realistic mathematical formulation considering the electric network constraints for the day-ahead scheduling model is described. the execution time of the large-scale problem can be reduced by using a parallel and distributed computing platform. a pareto front algorithm is applied to determine the set of non-dominated solutions. the maximization of the minimum available reserve is incorporated in the mathematical formulation in addition to the cost minimization, to take into account the reliability requirements of sensitive and vulnerable loads. a case study with a 180-bus distribution network and a fleet of 1000 gridable electric vehicles (evs) is used to illustrate the performance of the proposed method. the execution time to solve the optimization problem is reduced by using distributed computing. (c) 2015 elsevier ltd. all rights reserved.
operational_amplifier	in communication and computing devices, the growing demand for high performance, battery-operated portable equipments have transferred the concentration from staid constraints (such as area, performance and reliability) to power consumption. in the present scenario there is a cardinal requirement to diminish power consumption for non-portable systems where power dissipation and leakage current are censorious concerns. in vlsi circuits and systems, power dissipation is still censorious because the leakage occurs when device is in inactive mode. to reduce the leakage power and leakage current in finfet based operational amplifier, a new circuit technique called low power state technique is adduced in this paper. this approach reduces significant amount of power during active mode and also has an endowment of conserving the state in state retention mode 1. the op-amp electrical characteristics are obtained by employing cadence virtuoso tool for circuit simulation at 0.7 v input supply voltage. the simulated dc gain thus obtained is 65.4 db in the active mode. the proposed finfet based operational amplifier performance traits are studied and compared with the existing cmos technology at 45 nm scale. here, the effect of temperature variation on electrical characteristics of op-amp at 45 nm technology regime has been reconnoitered. furthermore, by employing low power approach, the enhancement in slew rate has been significantly attained. the simulation results are given and concluded.
cryptography	utilizing complex dynamics of chaotic maps and systems in encryption was studied comprehensively in the pas two and a half decades. in 1989, fridrich 's chaotic image encryption scheme was designed by iterating chaotic position permutation and value substitution some rounds, which received intensive attention in the field of chaos-based cryptography. in 2010, solak et al. proposed a chosen-ciphertext attack on the fridrich 's scheme utilizing influence network between cipher-pixels and the corresponding plain-pixels. based on their creative work, this paper scrutinized some properties of fridrich 's scheme with concise mathematical language. then, some minor defects of the real performance of solak 's attack method were given. the work provides some base. for further optimizing attack on the fridrich 's, scheme and its variants.
software_engineering	this paper presents a documentation and development method to facilitate the certification of scientific computing software used in the safety analysis of nuclear facilities. to study the problems faced during quality assurance and certification activities, a case study was performed on legacy software used for thermal analysis of a fuelpin in a nuclear reactor. although no errors were uncovered in the code, 27 issues of incompleteness and inconsistency were found with the documentation. this work proposes that software documentation follow a rational process, which includes a software requirements specification following a template that is reusable, maintainable, and understandable. to develop the design and implementation, this paper suggests literate programming as an alternative to traditional structured programming. literate programming allows for documenting of numerical algorithms and code together in what is termed the literate programmer 's manual. this manual is developed with explicit traceability to the software requirements specification. the traceability between the theory, numerical algorithms, and implementation facilitates achieving completeness and consistency, as well as simplifies the process of verification and the associated certification. copyright (c) 2015, published by elsevier korea llc on behalf of korean nuclear society.
cryptography	this paper proposes a new cryptosystem system that combines dna cryptography and algebraic curves defined over different galois fields. the security of the proposed cryptosystem is based on the combination of dna encoding, a compression process using a hyperelliptic curve over a galois field , and coding via an algebraic geometric code built using a hermitian curve on a galois field , where . the proposed cryptosystem resists the newest attacks found in the literature because there is no linear relationship between the original data and the information encoded with the hermitian code. further, the work factor for such attacks increases proportionally to the number of possible choices for the generator matrix of the hermitian code. simulations in terms of ber and signal-to-noise ratio (snr) are included, which evaluate the gain of the transmitted data in an awgn channel. the performance of the dna/ag cryptosystem scheme is compared with un-coded qpsk, and the mceliece code in terms of ber. further, the proposed dna/ag system outperforms the security level of the mceliece algorithm.
operational_amplifier	monte carlo (mc) techniques are widely applied to check a design on its robustness and for estimating the production yield of integrated circuits. using standard random mc and the sample yield for estimation, a very large number of samples is required for accurate verification, especially if a high yield is desired. this can make mc extremely time consuming, but if the data follows a normal gaussian distribution a much faster yield prediction is possible by using the well-known c-pk method. we extended this specification-distance-based scheme for the far more difficult general non-normal case by three different means, ending up in a new generalized process capability index named c-gpk. first, we apply parametric modeling only to the specification-sided distribution part. this way any difficulties in distribution parts that actually have little yield impact do not degrade the model fit anymore. second, to improve the parametric model we introduce a new tail parameter t. third, to allow modeling of difficult asymmetrical, multimodal or flat distributions we also introduce a new reference location parameter instead of using the mean. an advantage of improving mc this way is that-in opposite to many other mc enhancements (like importance sampling)-the performance of the c-gpk is not negatively impacted by design complexity. we described the formulation of the c-gpk and derived confidence intervals using an advanced bootstrap scheme. we verified the performance against the sample yield and c-pk for a representative set of distributions, including real production data and mc data from the design of a cmos operational amplifier and other circuits.
control_engineering	a non-isothermal jacketed continuous stirred tank reactor (cstr) is extensively used in chemical as well as in other process industries to manufacture different products. the dynamics of non-isothermal cstr are highly nonlinear and open-loop unstable in nature. moreover, it may have parametric uncertainties, disturbances and un-modeled side reactions which may cause the reactor temperature to deviate from the reference value. this deviation may degrade quality of the product because the chemical reaction inside the cstr depends on reactor temperature. for such a nonlinear, unstable and uncertain process, designing a control scheme with the ability to reject the effects of disturbances along with a good reference tracking capability is a challenging control engineering problem. in this work, a novel robust sliding mode control technique named as improved integral sliding mode control (iismc) has been presented for uncertain non-isothermal jacketed cstr process. moreover, a variety of recently developed sliding mode control techniques such as classical integral sliding mode control (cismc) and super twisted algorithm based sliding mode control (sta-smc) have also been devised and compared with the proposed approach in order to investigate the effectiveness of the proposed scheme. a lyapunov based analysis has also been provided to assure the robust stability of the closed loop process. furthermore, in order to extend the state feedback approach to the output feedback scheme, two robust observers; high gain observer (hgo) and extended high gain observer (ehgo), are also designed for the very process. they have also been compared with each other and have been investigated for robust stability using lyapunov based approach. finally, an output feedback control scheme using iismc and ehgo has been presented and its performance has been examined and compared with the iismc based state feedback approach. the simulation results show that the proposed control scheme effectively rejects the uncertainties and disturbances without leading the process to instability and offers good reference tracking capabilities. (c) 2016 elsevier ltd. all rights reserved.
signal-flow_graph	in this paper, we propose a theoretical framework to analyze the performance of ultra wideband acquisition (uwb) system based on energy detection (ed) over ieee 802.15.3a channel. the proposed framework enables to calculate probability density function (pdf) of square-sum of multipath components (mpcs) gain collected by receiver, and the averaged criteria. in particular, the expectation and variance of the sum variant characterized approximately by log-normal distribution are expressed in a closed form based on cluster point process. moreover, the calculating methods of averaged criteria, through markov chain model and signal flow graph, are clearly demonstrated for different applicable scenarios. the proposed framework is well consistent with simulation results with respect to each calculation method.
state_space_representation	leader-follower formation control of unmanned vehicles in the presence of limited sensing and communication is studied. it is assumed that the follower is equipped with an onboard tracker to measure relative kinematic parameters with respect to the leader. considering practical measurements obtained from the onboard tracker, a state-space representation for the leader-follower system is obtained, and by employing a state feedback controller, the relative angle and the relative range are regulated to desired values. then, by modeling of the tracker mechanism, the effect of the tracker dynamics and sensor measurement noise on the formation keeping are studied. simulation results verify the effectiveness of the proposed leader-follower formation control structure.
machine_learning	background: phenotyping is a critical component of plant research. accurate and precise trait collection, when integrated with genetic tools, can greatly accelerate the rate of genetic gain in crop improvement. however, efficient and automatic phenotyping of traits across large populations is a challenge; which is further exacerbated by the necessity of sampling multiple environments and growing replicated trials. a promising approach is to leverage current advances in imaging technology, data analytics and machine learning to enable automated and fast phenotyping and subsequent decision support. in this context, the workflow for phenotyping (image capture. data storage and curation ->trait extraction ->machine learning/classification ->models/apps for decision support) has to be carefully designed and efficiently executed to minimize resource usage and maximize utility. we illustrate such an end- to- end phenotyping workflow for the case of plant stress severity phenotyping in soybean, with a specific focus on the rapid and automatic assessment of iron deficiency chlorosis (idc) severity on thousands of field plots. we showcase this analytics framework by extracting idc features from a set of similar to 4500 unique canopies representing a diverse germplasm base that have different levels of idc, and subsequently training a variety of classification models to predict plant stress severity. the best classifier is then deployed as a smartphone app for rapid and real time severity rating in the field. results: we investigated 10 different classification approaches, with the best classifier being a hierarchical classifier with a mean per-class accuracy of similar to 96%. we construct a phenotypically meaningful ' population canopy graph', connecting the automatically extracted canopy trait features with plant stress severity rating. we incorporated this image capture ->image processing ->classification workflow into a smartphone app that enables automated real-time evaluation of idc scores using digital images of the canopy. conclusion: we expect this high-throughput framework to help increase the rate of genetic gain by providing a robust extendable framework for other abiotic and biotic stresses. we further envision this workflow embedded onto a high throughput phenotyping ground vehicle and unmanned aerial system that will allow real-time, automated stress trait detection and quantification for plant research, breeding and stress scouting applications.
network_security	network and computer systems administrators are facing a serious problem of the big network traffic data analysis. it became difficult work of administrators to extract and analysis the abnormal and normal patterns from large amounts of the network traffic data. currently, traditional relational database management systems (rdbms) are unsuitable to store a large amount of data because they are designed for storing and processing the structured data. hive is a data warehouse tool built on top of hadoop for storing, processing, querying, and analysis the large amount of data. hive stores the data in a table similar the relational database management system. in this paper, we propose a hadoop-based traffic querying and analyzing system that handles the tcp, icmp, and udp analysis of the big network traffic data. the system consists of six modules: data collection module, transferring and storing information module, convertor module, data mining process module, dm2sc module, and report module. we also performed complex search queries and compared the query response times of mysql against hive in hadoop environment. as the result, in some scenario, mysql outperform a cluster of four hive nodes on querying the icmp protocol information, nevertheless, mysql database that stored more than the network traffic data about 45 million records cannot be query the tcp protocol information. moreover, we observed that the average query response times of hive in hadoop cluster that reduce continuously be scale up node into the cluster.
algorithm_design	this paper presents the design and experimental validation of a new model-free data-driven iterative reference input tuning (irit) algorithm that solves a reference trajectory tracking problem as an optimization problem with control signal saturation constraints and control signal rate constraints. the irit algorithm design employs an experiment-based stochastic search algorithm to use the advantages of iterative learning control. the experimental results validate the irit algorithm applied to a non-linear aerodynamic position control system. the results prove that the irit algorithm offers the significant control system performance improvement by few iterations and experiments conducted on the real-world process and model-free parameter tuning.
network_security	cloud computing is a paradigm that provides scalable it resources as a service over the internet. vulnerabilities in the cloud infrastructure have been readily exploited by the adversary class. therefore, providing the desired level of assurance to all stakeholders through safeguarding data (sensitive or otherwise) which is stored in the cloud, is of utmost importance. in addition, protecting the cloud from adversarial attacks of diverse types and intents, cannot be understated. economic denial of sustainability (edos) attack is considered as one of the concerns that has stalled many organizations from migrating their operations and/or data to the cloud. this is because an edos attack targets the financial component of the service provider. in this work, we propose a novel and reactive approach based on a rate limit technique, with low overhead, to detect and mitigate edos attacks against cloud-based services. through this reactive scheme, a limited access permission for cloud services is granted to each user. experiments were conducted in a laboratory cloud setup, to evaluate the performance of the proposed mitigation technique. results obtained show that the proposed approach is able to detect and prevent such an attack with low cost and overhead. (c) 2016 elsevier b.v. all rights reserved.
electric_motor	the hts superconducting coils that are components of the rotating electrical machines made in icpe-ca, work at the liquid nitrogen temperature (77k). they are made of ceramic material, ybco type, which has a critical current of 130a (superpower) and 100a respectively (amsc). there are analyzed two different types of coil for two prototypes of electrical machines: an electric motor (p = 4 kw) and an electric generator (p = 4.5 kw). they were made from hts tape, in the form of simple and double racetrack pancake. within the paper the design parameters of these hts coils are examined. also, the generated magnetic field, the field numerical simulation and the optimal functioning conditions are analyzed.
operating_systems	the popularity of smartphones usage especially android mobile platform has increased to 80% of share in global smartphone operating systems market, as a result of which it is on the top in the attacker 's target list. the fact of having more private data and low security assurance letting the attacker to write several malware programs in different ways for smartphone, and the possibility of obfuscating the malware detection applications through different coding techniques is giving more energy to attacker. several approaches have been proposed to detect malwares through code analysis which are now severely facing the problem of code obfuscation and high computation requirement. we propose a machine learning based method to detect android malware by analyzing the visual representation of binary formatted apk file into grayscale, rgb, cmyk and hsl. gist feature from malware and benign image dataset were extracted and used to train machine learning algorithms. initial experimental results are encouraging and computationally effective. among machine learning algorithms random forest have achieved highest accuracy of 91% for grayscale image, which can be further improved by tuning the various parameters.
computer_programming	the computer technology has advanced profoundly that the application seems to have no limit. equipped with programming, our research team has created programs that could be used practically in the field of chemistry. the purpose of this paper is not on the making useful tools for science, but on using analytic tools based on computer programming to find additional evidence that supports a theory. the suport vector machine (also known as its acronym, svm) is used frequently in genetic analysis to find certain patterns in dna sequence. this paper deals with pattern similarity between rrna of mitochondria and that of alphaproteobacteria, which is believed to be the ancestor of the mitochondria. this theory, also known as ""endosymbiotic theory"" has a variety of evidences and has accepted as authentic. the pattern similarity between the two organisms' dna sequence, which is the result of the paper would consolidate the evolutionary endosymbiosis.
parallel_computing	natural source electromagnetic methods have the potential to recover rock property distributions from the surface to great depths. unfortunately, results in complex 3d geo-electrical settings can be disappointing, especially where significant near-surface conductivity variations exist. in such settings, unconstrained inversion of magnetotelluric data is inexorably non-unique. we believe that: (1) correctly introduced information from seismic reflection can substantially improve mt inversion, (2) a cooperative inversion approach can be automated, and (3) massively parallel computing can make such a process viable. nine inversion strategies including baseline unconstrained inversion and new automated/semiautomated cooperative inversion approaches are applied to industry-scale co-located 3d seismic and magnetotelluric data sets. these data sets were acquired in one of the carlin gold deposit districts in north-central nevada, usa. in our approach, seismic information feeds directly into the creation of sets of prior conductivity model and covariance coefficient distributions. we demonstrate how statistical analysis of the distribution of selected seismic attributes can be used to automatically extract subvolumes that form the framework for prior model 3d conductivity distribution. our cooperative inversion strategies result in detailed subsurface conductivity distributions that are consistent with seismic, electrical logs and geochemical analysis of cores. such 3d conductivity distributions would be expected to provide clues to 3d velocity structures that could feed back into full seismic inversion for an iterative practical and truly cooperative inversion process. we anticipate that, with the aid of parallel computing, cooperative inversion of seismic and magnetotelluric data can be fully automated, and we hold confidence that significant and practical advances in this direction have been accomplished.
computer_graphics	due to formal protection and commercial development, cultural ecology and cultural forms of vernacular architecture landscape that have local characteristics have been threatened seriously. however, at present the records of vernacular architecture landscape protection lack support of new and high technology. three-dimensional panoramic hybrid technology can blend the virtual objects accurately into real environment through computer graphics and computer vision technology. this technique provides an effective way to express a stereoscopic three-dimensional real scene. in this research, three-dimensional panoramic hybrid technology is reasonably applied to implementation strategy and process of vernacular architecture landscape protection, which can make up the inadequacy of application field of vernacular architecture heritage protection, and can extend application of information technology based on 3-dimensional digitalization in architecture heritage protection at the same time.
symbolic_computation	under investigation in this paper is a nonisospectral and variable-coefficient fifth order korteweg-de vries equation in fluids. by virtue of the bell polynomials and symbolic computation, the bilinear form, backlund transformation and lax pair are obtained. based on its bilinear form, n-soliton solutions are constructed. furthermore, periodic wave and breather wave solutions are obtained by virtue of the riemann theta function and homoclinic test approach, respectively. in addition, the characteristic-line method is applied to discuss the features of the solitons for the nonisospectral problem, such as the amplitude, velocity and width of the solitary wave. (c) 2016 elsevier ltd. all rights reserved.
bioinformatics	amifostine, 2-(3-aminopropyl) aminoethyl phosphorothioate, is a broad-spectrum cytoprotective agent used to treat nuclear radiation and chemical weapon injuries. recently, amifostine has been shown to have a profound biological influence on tumor cells. to examine the effects and mechanisms underlying the effects of amifostine on human acute megakaryocytic leukemia, we evaluated the efficacy of amifostine against dami cells and observed a cell cycle arrest in g(2)/m phase. amifostine treatment also induced cell apoptosis of dami cells which corresponds to formal studies. through whole-genome microarray and bioinformatics analyses, we found that amifostine affected the gene expression of ccnd1,bcl2, and casp3 which revealed the mechanism amifostine acted on dami cells. thus, ccnd1-bcl2 gene network is predicted to be a direct target of amifostine treating human acute megakaryocytic leukemia, which may provide a novel potential target for the therapy of several subtypes of human aml.
network_security	network intrusion attempts have been on the rise recently. researchers have shown an increased interest in assessing the security situation for entire network instead of single asset. a considerable amount of assessment models have been designed. however, there is a lack of solid and standard guidelines to define the importance of network asset. in addition, based on our knowledge, no research has been found that adequately covered the cost factor in the assessment model. thus, the purpose of this paper is to propose a cost-sensitive entropy-based network security situation assessment model. with the aid of analytic hierarchy process (ahp), the model can quantitatively determine the importance of assets in the network by considering the tangible and intangible criteria. to verify the performance of proposed model, a simulation of national advanced ipv6 centre (nav6) 's network environment has been setup. the simulation results regarding security situation in particular time-interval are promising. hence, the proposed model is able to provide network administrator a more reliable reference before any further decision making for the organization 's network.
computer_programming	dzhafarov and kujala (2015) have introduced a contextual probability theory called contextuality-by-default (c-b-d) which is based on three principles. the first of these principles states that each random variable should be automatically labelled by all conditions under which it is recorded. the aim of this article is to relate this principle to block structured computer programming languages where variables are declared local to a construct called a ""scope"". scopes are syntactic constructs which correspond to the notion of condition used by c-b-d. in this way a variable declared in two scopes can be safely overloaded meaning that they can have the same label but preserve two distinct identities without the need to label each variable in each condition as advocated by c-b-d. by means of examples, the notion of a probabilistic-program, or p-program, is introduced which is based on scopes. the semantics of p-programs will be illustrated using the well known relational database language sql which provides an efficient and understandable operational semantics. a core issue addressed is how to construct a single probabilistic model from the various interim probability distributions returned by each syntactic scope. for this purpose, a probabilistic variant of the natural join operator of relational algebra is used to ""glue"" together interim distributions into a single distribution. more generally, this article attempts to connect contextuality with probabilistic programming by means of relational database theory. (c) 2016 published by elsevier inc.
electrical_network	an alternative hybrid time/frequency domain approach to compute the periodic steady-state of an electrical network is presented. the network under analysis can include a variety of linear and nonlinear components, e.g., pv-buses, nonlinear reactors, and electronic devices. in the proposed approach, the linear part of the network is modeled in the frequency-domain (fd) via an equivalent input-admittance and all nonlinear components but pv-buses are resolved in the time-domain (td). the fd equivalent is interfaced to the nonlinear components via discrete fourier transform (oft) operations, accounting for harmonic and interharmonic frequencies. the interfacing voltage/current variables are solved through a global gauss-seidel procedure; pv-buses are solved via a local newton-type iterative procedure. it is shown that the proposed approach achieves faster computations than traditional hybrid methods due to (i) the compact fd equivalent representation of the linear part of the network and (ii) the gauss-seidel iterative scheme that avoids calculation and inversions of jacobians. a sample network is used to compare the proposed method with a newton-type solution scheme; the resulting waveforms are also compared with those given by the pscad (tm)/emtdc (tm) simulation software. (c) 2015 elsevier b.v. all rights reserved.
computer_graphics	changes in the human pigmentary system can lead to imbalances in the distribution of melanin in the skin resulting in artefacts known as pigmented lesions. our work takes as departing point biological data regarding human skin, the pigmentary system and the melanocytes life cycle and presents a reaction-diffusion model for the simulation of the shape features of human-pigmented lesions. the simulation of such disorders has many applications in dermatology, for instance, to assist dermatologists in diagnosis and training related to pigmentation disorders. our study focuses, however, on applications related to computer graphics. thus, we also present a method to seamless blend the results of our simulation model in images of healthy human skin. in this context, our model contributes to the generation of more realistic skin textures and therefore more realistic human models. in order to assess the quality of our results, we measured and compared the characteristics of the shape of real and synthesized pigmented lesions. we show that synthesized and real lesions have no statistically significant differences in their shape features. visually, our results also compare favourably with images of real lesions, being virtually indistinguishable from real images.
operational_amplifier	vlsi technology is being adopted widely nowadays for biomedical applications to improve healthcare diagnosis, monitoring and cure. analog devices such as a/d converters for biomedical applications can be of modest precision but need to be very energy efficient in order to operate for decades. cntfet can be the future alternative to be used in various high performance, low power devices. in this paper we have presented a low power cntfet based two stage op-amp for biomedical a/d converters. a sample and hold circuit is also implemented using cntfet based op-amp to be used in biomedical adcs. simulation results of cntet based circuits are compared with mosfet circuits. results indicate improvement of power consumption up to 80%. the proposed circuit simulations are carried out in hspice. it is concluded that cntfet based circuits can be prime choice for low power applications.
system_identification	this paper proposes a novel observer/controller identification method for identifying the minimally realised equivalent (reduced-order) mathematical models in the block observer/controller-canonical forms of the unknown (i) open-loop system, (ii) existing feedback/feedforward controllers and/or (iii) observer, based on available measurements of the operating closed-loop system. by skipping the singular value decomposition procedure and without involving the model conversion of the identified model from the general coordinate into the block observer/controller-canonical forms during the identification process, the proposed method is able to directly realise the identified parameters in the minimally realised block observer/controller-canonical forms. this simplifies the system identification process. the new procedures enable us to enhance the computational aspects of designing self-tuning controllers for online adaptive control of (a class of) multivariable systems and to improve the tracking performance considerably. as a result, the newly proposed compensation improvement approach is able to compensate the undesirable operating controller.
machine_learning	background and objective: according to the world health organization (who) epilepsy affects approximately 45-50 million people. electroencephalogram (eeg) records the neurological activity in the brain and it is used to identify epilepsy. visual inspection of eeg signals is a time-consuming process and it may lead to human error. feature extraction and classification are two main steps that are required to build an automated epilepsy detection framework. feature extraction reduces the dimensions of the input signal by retaining informative features and the classifier assigns a proper class label to the extracted feature vector. our aim is to present effective feature extraction techniques for automated epileptic eeg signal classification. methods: in this study, two effective feature extraction techniques (local. neighbor descriptive pattern [lndp] and one-dimensional local gradient pattern [1d-lgp]) have been introduced to classify epileptic eeg signals. the classification between epileptic seizure and non -seizure signals is performed using different machine learning classifiers. the benchmark epilepsy eeg dataset provided by the university of bonn is used in this research. the classification performance is evaluated using 10 -fold cross validation. the classifiers used are the nearest neighbor (nn), support vector machine (svm), decision tree (dt) and artificial neural network (ann). the experiments have been repeated for 50 times. results: lndp and 1d-lgp feature extraction techniques with ann classifier achieved the average classification accuracy of 99.82% and 99.80%, respectively, for the classification between normal and epileptic eeg signals. eight different experimental cases were tested. the classification results were better than those of some existing methods. conclusions: this study suggests that lndp and 1d-lgp could be effective feature extraction techniques for the classification of epileptic eeg signals. (c) 2017 elsevier ltd. all rights reserved.
system_identification	the system identification and generalized predictive control of a class of multiple input multiple output models are studied. the generalized predictive control problem with unknown parameters is first addressed by finding a control sequence for control performance as a goal. then, the unknown parameters of the models are estimated by a new stochastic gradient algorithm providing high estimation accuracy. third, the generalized predictive control problem is formulated to a quadratic programming problem with linear inequality constraints. finally, the constrained quadratic programming problem is solved through a generalized projection neural network with simple structure and small number of neurons, while previous projection neural networks have complex structure and require more neurons. numerical simulations are provided to reinforce our theoretical results.
system_identification	this paper discusses the measurement of frequency response functions for various dc-dc converters. the frequency domain identification procedure is applied to the measured frequency responses. the identified transfer functions are primarily used in developing behavioral models for dc-dc converters. distributed power systems are based upon such converters in cascade, parallel and several other configurations. the system level analysis of a complete system becomes complex when the identified transfer functions are of high order. therefore, a certain technique needs to be applied for order reduction of the identified transfer functions. during the process of order reduction, it has to be ensured that the system retains the dynamics of the full order system. the technique used here is based on the hankel singular values of a system. a systematic procedure is given to retain the maximum energy states for the reduced order model. a dynamic analysis is performed for behavioral models based on full and reduced order frequency responses. the close agreement of results validates the effectiveness of the model order reduction. stability is the key design objective for any system designer. therefore, the measured frequency responses at the interface of the source and load are also used to predict stability of the system.
electric_motor	this paper proposes an estimating method of both the operating temperature and flux density of the magnet, for permanent magnet synchronous motor (pmsm) under the load condition. the method is based on the combination of motor differential equations, thermal equivalent circuit and magnetic equivalent circuit. in this paper, the effectiveness of the proposed method is verified by comparing calculated result with the finite element analysis (fea). also, the effectiveness is confirmed by experimental result.
electrical_circuits	this paper discusses the effective contribution of a learning object (lo) to teach circuit theory based on research conducted with students of higher education, and their interaction with a teacher of electronics. from the results of such research, it is pointed out which features one wants in the lo so that it successfully promotes learning. it is in this perspective that this work was conceived having as goal the development of lo, admitting that this may be a possible alternative to represent models of interactions, which occur within the area, thereby improving understanding of physical concepts, in particular those involved with the subject of electrical circuits. it has also as objective to characterize the learning process through a series of situations that are replicated leading to a set of behaviors from the students. it is assumed that the use of this tool can lead to acquiring a specific set of skills, a better practice and meaningful learning.
algorithm_design	greedy algorithms is an important class of algorithms. teaching greedy algorithms is a complex task. ensuring that students can design greedy algorithms for new problems is also complex. we have built a guided discovery based greedy algorithm tutor (gatutor), to teach the process of designing greedy algorithms. gatutor guides the student to discover the greedy algorithm for a few well-known problems, by asking two important questions - i) what is the satisfying condition at each step? and ii) what is the selection criterion for the next item? as a result, the students not only learn the algorithms for the given problems, but also the process of designing greedy algorithms for new problems. we conducted a study to compare the greedy algorithm design abilities of the students who were trained with gatutor versus those who worked with traditional algorithm visualizations. the results indicate that students who worked with gatutor performed better in designing a greedy algorithm for a new problem. the students also said that their confidence in greedy algorithm design increased because of gatutor.
cryptography	super-simple designs can be used to provide samples with maximum intersection as small as possible in statistical planning of experiments and can be also applied to cryptography and codes. in this paper, super-simple pairwise balanced designs with block sizes 3 and 4 are investigated and it is proved that the necessary conditions for the existence of a super-simple (nu,{3, 4}, lambda)-pbd for 2 <= lambda <= 6 are sufficient with three possible exceptions. (c) 2016 elsevier b.v. all rights reserved.
microcontroller	recording evoked potentials in un-anesthetized animals and people is a powerful technique to non-invasively measure the function of neurons. as such, the primary output neurons of the eye can be assessed by the pattern electroretinogram (perg). currently, electro-physiologic setups to perform perg or related recordings are costly, complicated, and non-portable. here, we design a simple steady-state perg system, based off an arduino board. the amplifier is built on a shield that fits over a microcontroller board, an arduino, which digitizes the signal and sends it to a computer that presents stimuli then records and analyzes the evoked potentials. we used the device to record perg accurately with a sensitivity as low as half a microvolt. the device has also been designed to implement other evoked potential recordings. this simple device can be quickly constructed and used for experiments in moving systems. additionally, this device can be used to expose students in underserved areas to research technology that they would otherwise not have access to.
state_space_representation	this paper aims at designing a nonasymptotic and robust pseudo-state estimator for a class of fractional order linear systems which can be transformed into the brunovsky 's observable canonical form of pseudo-state space representation with unknown initial conditions. first, this form is expressed by a fractional order linear differential equation involving the initial values of the fractional sequential derivatives of the output, based on which the modulating functions method is applied. then, the former initial values and the fractional derivatives of the output are exactly given by algebraic integral formulae using a recursive way, which are used to nonasymptotically estimate the pseudo-state of the system in noisy environment. second, the pseudo-state estimator is studied in discrete noisy case, which contains the numerical error due to a used numerical integration method, and the noise error contribution due to a class of stochastic processes. then, the noise error contribution is analyzed, where an error bound useful for the selection of design parameter is provided. finally, numerical examples illustrate the efficiency of the proposed pseudo-state estimator, where some comparisons with the fractional order luenberger- like observer and a new fractional order h-infinity-like observer are given.
cryptography	in the classical secret-key generation model, common randomness is generated by two terminals based on the observation of correlated components of a common source, while keeping it secret from a non-legitimate observer. it is assumed that the statistics of the source are known to all participants. in this paper, the secret-key generation based on a compound source is studied where the realization of the source statistic is unknown. the protocol should guarantee the security and reliability of the generated secret-key, simultaneously for all possible realizations of the compound source. a single-letter lower-bound of the secret-key capacity for a finite compound source is derived as a function of the public communication rate constraint. a multi-letter capacity formula is further computed for a finite compound source for the case in which the public communication is unconstrained. finally, a single-letter capacity formula is derived for a degraded compound source with an arbitrary (possibly infinite) set of source states and a finite set of marginal states.
software_engineering	adaptive educational hypermedia systems (aehs) have provided new perspectives for access to information and enhance learning. however aehs have advantages and positive impact on learning, there are still defies to their design and production. in this paper, we propose an agile learning design method to support the design and production of aehs. it is based on agile practices from software engineering and on practices of learning design. we illustrate our approach with an experiment that validates the proposed method through its application in the design of an aehs called (ald-aehs) and creation of one of the most important component of aehs: the user model.
electricity	active demand side response (dsr) will provide a significant opportunity to enhance the power system flexibility in the great britain (gb). although electricity peak shaving has a clear reduction on required investments in the power system, the benefits on the gas supply network have not been examined. using a combined gas and electricity networks expansion model (cgen+), the impact of dsr on the electricity and gas supply systems in gb was investigated for the time horizon from 2010 to 2050s. the results showed a significant reduction in the capacity of new gas-fired power plants, caused by electricity peak shaving. the reduction of gas-fired power plants achieved through dsr consequently reduced the requirements for gas import capacity up to 90 million cubic meter per day by 2050. the cost savings resulted from the deployment of dsr over a 50-year time horizon from 2010 was estimated to be around 60 billion for the gb power system. although, the cost saving achieved in the gas network was not significant, it was shown that the dsr will have a crucial role to play in the improvement of security of gas supply. (c) 2016 the authors. published by elsevier ltd.
network_security	honeypots, i.e. networked computer systems specially designed and crafted to mimic the normal operations of other systems while capturing and storing information about the interactions with the world outside, are a crucial technology into the study of cyber threats and attacks that propagate and occur through networks. among them, high-interaction honeypots are considered the most efficient because the attacker (whether automated or not) perceives realistic interactions with the target machine. in the case of automated attacks, propagated by malware, currently available honeypots alone are not specialized enough to allow the analysis of their behaviors and effects on the target system. the research presented in this paper shows how high-interaction honeypots can be enhanced by powering them with specific features that improve the reverse engineering activities needed to effectively analyze captured malicious entities.
computer_vision	when designing and developing scale selection mechanisms for generating hypotheses about characteristic scales in signals, it is essential that the selected scale levels reflect the extent of the underlying structures in the signal. this paper presents a theory and in-depth theoretical analysis about the scale selection properties of methods for automatically selecting local temporal scales in time-dependent signals based on local extrema over temporal scales of scale-normalized temporal derivative responses. specifically, this paper develops a novel theoretical framework for performing such temporal scale selection over a time-causal and time-recursive temporal domain as is necessary when processing continuous video or audio streams in real time or when modelling biological perception. for a recently developed time-causal and time-recursive scale-space concept defined by convolution with a scale-invariant limit kernel, we show that it is possible to transfer a large number of the desirable scale selection properties that hold for the gaussian scale-space concept over a non-causal temporal domain to this temporal scale-space concept over a truly time-causal domain. specifically, we show that for this temporal scale-space concept, it is possible to achieve true temporal scale invariance although the temporal scale levels have to be discrete, which is a novel theoretical construction. the analysis starts from a detailed comparison of different temporal scale-space concepts and their relative advantages and disadvantages, leading the focus to a class of recently extended time-causal and time-recursive temporal scale-space concepts based on first-order integrators or equivalently truncated exponential kernels coupled in cascade. specifically, by the discrete nature of the temporal scale levels in this class of time-causal scale-space concepts, we study two special cases of distributing the intermediate temporal scale levels, by using either a uniform distribution in terms of the variance of the composed temporal scale-space kernel or a logarithmic distribution. in the case of a uniform distribution of the temporal scale levels, we show that scale selection based on local extrema of scale-normalized derivatives over temporal scales makes it possible to estimate the temporal duration of sparse local features defined in terms of temporal extrema of first- or second-order temporal derivative responses. for dense features modelled as a sine wave, the lack of temporal scale invariance does, however, constitute a major limitation for handling dense temporal structures of different temporal duration in a uniform manner. in the case of a logarithmic distribution of the temporal scale levels, specifically taken to the limit of a time-causal limit kernel with an infinitely dense distribution of the temporal scale levels towards zero temporal scale, we show that it is possible to achieve true temporal scale invariance to handle dense features modelled as a sine wave in a uniform manner over different temporal durations of the temporal structures as well to achieve more general temporal scale invariance for any signal over any temporal scaling transformation with a scaling factor that is an integer power of the distribution parameter of the time-causal limit kernel. it is shown how these temporal scale selection properties developed for a pure temporal domain carry over to feature detectors defined over time-causal spatio-temporal and spectro-temporal domains.
symbolic_computation	under investigation in this paper is a (2+1)-dimensional gross-pitaevskii equation with time-varying trapping potential, which describes the dynamics of the (2+1)-dimensional bose-einstein condensate. employing the hirota method and symbolic computation, we obtain the dark one-soliton, two-soliton, three-soliton, breather-wave and rouge-wave solutions, respectively. we graphically study the dark solitons with the time-varying harmonic potential and scaled scattering length. parallel and period solitons are observed. we obtain that when the external trapping potential increases with time, amplitudes of the dark solitons increase and widths of those solitons become narrower; when the external trapping potential is a periodic function, amplitudes and widths of the dark solitons periodically change. decrease in the scaled scattering length leads to the narrower solitons' widths, but does not affect the solitons' amplitudes. breather waves and rouge waves are also displayed: rouge waves emerge when the period of the breather waves go to the infinity.
bioinformatics	campylobacter concisus is a bacterium that is associated with inflammatory bowel disease (ibd). immunosuppressive drugs including azathioprine (aza) and mercaptopurine (mp), and anti-inflammatory drug such as 5-aminosalicylic acid (5-asa) are commonly used to treat patients with ibd. this study aimed to examine the effects of aza, mp, and 5-asa on the growth of ibd-associated bacterial species and to identify bacterial enzymes involved in immunosuppressive drug metabolism. a total of 15 bacterial strains of five species including 11 c. concisus strains, bacteroides fragilis, bacteroides vulgatus, enterococcus faecalis, and escherichia coli were examined. the impact of aza, mp, and 5-asa on the growth of these bacterial species was examined quantitatively using a plate counting method. the presence of enzymes involved in aza and mp metabolism in these bacterial species was identified using bioinformatics tools. aza and mp significantly inhibited the growth of all 11 c. concisus strains. c. concisus strains were more sensitive to aza than mp. 5-asa showed inhibitory effects to some c. concisus strains, while it promoted the growth of other c. concisus strains. aza and mp also significantly inhibited the growth of b. fragilis and b. vulgatus. the growth of e. coli was significantly inhibited by 200 mu g/ml of aza as well as 100 and 200 mu g/ml of 5-asa. bacterial enzymes related to aza and mp metabolism were found, which varied in different bacterial species. in conclusion, aza and mp have inhibitory effects to ibd-associated c. concisus and other enteric microbes, suggesting an additional therapeutic mechanism of these drugs in the treatment of ibd. the strain dependent differential impact of 5-asa on the growth of c. concisus may also have clinical implication given that in some cases 5-asa medications were found to cause exacerbations of colitis.
computer_graphics	the development of technologies nowadays is moving in such speed that the computer graphics and simulations are being convincingly displaced by the augmented reality. the ar sandbox, created by oliver kreylos, is just one of the many examples in which the reality is supplemented with computer generated input. in this case the reality is a box full of sand and the input is hypsometric coloring and elevation contours. a kinect sensor detects the micro relief forms in the sandbox and after unnoticeable computer estimation, a relief map is projected over them. if the sand forms are changing, the coloring and the lines are changing with them to project the new accurate relief. actually ar sandbox represents important conceptions of geology, hydrology, ecology, topographic mapping, etc. in a very entertaining and spectacular way for children and students and this is a main reason this system to be part of our equipment in the laboratory of cartography in uaceg. included in lessons and games the ar sandbox is an irreplaceable tool for improving their knowledge of disastrous events such as floods, drought and fire especially when it gives the opportunity of making virtual rain and isolating flooded areas depending on the relief and the watersheds. in this paper after the detailed presentation of the ar sandbox as a working system, proposals for educational activities for large age range of children and university students are made in order to use the augmented reality as a special instrument for displaying disastrous events. some new ideas are suggested in consideration of future improvement with which ar sandbox will meet more needs of the educational training for disaster response of children.
electrical_network	the objective of the present work is to build and test a solar adsorption refrigeration device with an adsorbent adsorbate silicagel- water pair in the weather conditions of bou-ismail, algeria. the refrigeration system proposed in this study consists of three major components: a solar collector (tubular adsorbent bed, reflecting surface, single glazed cover, and 4.5 kg of silicagel material), an air-cooled condenser, an evaporator and supplementary system components. the working operation parameters of the cooling adsorption system were tested successfully. experimental results indicated that the maximum temperature generated varied from 95 degrees c to 117 degrees c, 33 c of average ambient temperature, the condensing temperature varied from 45 degrees c to 53 degrees c, +5 degrees c of minimum evaporator temperature, and the pressure values recorded in the adsorbent bed during the heating desorption period varied from 80 to 100 mbar. with a total energy received of around 19 mj/m(2), this solar adsorption refrigeration device can provide a solar cop ranging from 0.083 to 0.09. such results show the practicability of our solar adsorption refrigeration module and that it has a favorable design for use in medical storage in areas without an electrical network (e.g. the algeria sahara region). (c) 2016 elsevier ltd. all rights reserved.
electrical_circuits	the crystal structure, the c-13 nmr spectroscopy and the complex impedance have been carried out on [cd-3(scn)(2)br-6(c2h9n2)(2)](n). crystal structure shows a 2d polymeric network built up of two crystallographically independent cadmium atoms with two different octahedral coordinations. this compound exhibits a phase transition at (t=355 +/- 2 k) which has been characterized by differential scanning calorimetry (dsc), x-rays powder diffraction, ac conductivity and dielectric measurements. examination of c-13 cp/mas line shapes shows indirect spin-spin coupling (n-14 and c-13) with a dipolar coupling constant of 1339 hz. the ac conductivity of this compound has been carried out in the temperature range 325-376 k and the frequency range from 10(-2) hz to 10 mhz. the impedance data were well fitted to two equivalent electrical circuits. the results of the modulus study reveal the presence of two distinct relaxation processes. one, at low frequency side, is thermally activated due to the ionic conduction of the crystal and the other, at higher frequency side, gradually disappears when temperature reaches 355 k which is attributed to the localized dipoles in the crystal. moreover, the temperature dependence of dc-conductivity in both phases follows the arrhenius law and the frequency dependence of sigma(omega,t) follows jonscher 's universal law. the near values of activation energies obtained from the conductivity data and impedance confirm that the transport is through the ion hopping mechanism. (c) 2013 elsevier ltd. all rights reserved.
state_space_representation	a power source used in wireless power transfer generates an ac wave to transfer electric power to a load which is not connected electrically but connected electromagnetically to the power source. in this paper, the power and efficiency are compared when a sinusoidal and a square waves which are typical ac waves are applied as power source voltage outputs. the condition under which the two waves respectively transfer equivalent power with electric wires is examined to figure out the effect of different waves. then the power and efficiency are calculated by a mathematical approach with practical values of elements on various situations. finally, this paper explores how input waves should be chosen for ideal wireless power transfer.
digital_control	the impedance-based model of doubly fed induction generator (dfig) systems, including the rotor part (rotor side converter (rsc) and induction machine), and the grid part (grid side converter (gsc) and its output filter), has been developed for analysis and mitigation of the subsynchronous resonance (ssr). however, the high-frequency resonance (hfr) of dfig systems due to the impedance interaction between the dfig system and parallel compensated weak network is often overlooked. this paper, thus, investigates the impedance characteristics of dfig systems for the analysis of hfr. the influences of the rotor speed variation, the machine mutual inductance and the digital control delay are evaluated. two resonances phenomena are revealed, i.e., 1) the series hfr between the dfig system and weak power grid; 2) the parallel hfr between the rotor part and the grid part of dfig system. the impedance modeling of dfig system and weak grid network, as well as the series hfr between dfig system and parallel compensated weak network has been validated by experimental results.
analog_signal_processing	an analog signal processing integrated circuit for microcantilever array has been designed for pressure measurement in biomedical applications. the chip consists of analog multiplexer, instrumentation amplifier, sample-and-hold circuit, on-chip voltage and current references, successive approximation register analog-to-digital converter (adc) and digital control unit. root sum square (rss) error from the overall pressure measurement system including microcantilever array and the application specific integrated circuit (asic) is only +/-1.79 kpa within the measurement range of 0-300 kpa. the 8-bit adc attains 45.4 db signal-to-noise-and-distortion ratio (sndr) and 56.4 db spurious-free dynamic range (sfdr), while operating at 772 khz. the integrated circuit has been fabricated using 0.35-mu 2-poly 4-metal cmos process technology. the chip occupies an area of 1.54 mm(2) and consumes 17.8 mw of power with a single 3.3 v supply.
digital_control	this paper presents a technique for reducing the input current ripple on multiphase power converters that provide multiple heterogeneous power supply rails, such as those present in portable electronics and computers. through asymmetric interleaving of individual phases, the input current ripple can be reduced compared to conventional interleaving. the technique is derived based on an analytic description of the relevant current waveforms. practical requirements of a digital control implementation of the proposed technique are analyzed, and its possible performance improvement is quantified through simulations and experimental results. with the proposed technique, close to a 3x reduction in input current ripple, compared to conventional methods, is demonstrated using an experimental prototype comprising a microcontroller that controls a multiphase 180 nm cmos power management ic.
relational_databases	forensic tools assist analysts with recovery of both the data and system events, even from corrupted storage. these tools typically rely on ""file carving"" techniques to restore files after metadata loss by analyzing the remaining raw file content. a significant amount of sensitive data is stored and processed in relational databases thus creating the need for database forensic tools that will extend file carving solutions to the database realm. raw database storage is partitioned into individual ""pages"" that cannot be read or presented to the analyst without the help of the database itself. furthermore, by directly accessing raw database storage, we can reveal things that are normally hidden from database users. there exists a number of database-specific tools developed for emergency database recovery, though not usually for forensic analysis of a database. in this paper, we present a universal tool that seamlessly supports many different databases, rebuilding table and other data content from any remaining storage fragments on disk or in memory. we define an approach for automatically (with minimal user intervention) reverse engineering storage in new databases, for detecting volatile data changes and discovering user action artifacts. finally, we empirically verify our tool 's ability to recover both deleted and partially corrupted data directly from the internal storage of different databases. (c) 2015 the authors. published by elsevier ltd on behalf of dfrws. this is an open access article under the cc by-nc-nd license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
system_identification	the need for accurate knowledge of complex dynamical behavior for high-performance mechatronic systems led to the development of a vast amount of nonparametric system identification approaches over the recent years. the aim of this paper is to compare several proposed methods based on experiments on a physical complex mechanical system to bridge the gap between identification theory and practical applications in industry where basic identification approaches are often the norm. typical practical implications such as operation under closed-loop control, multivariable coupled behavior and nonlinear effects are included in the analysis. finally, a possible approach for fast and reliable identification is illustrated based on measurement results of an interventional medical x-ray system. (c) 2016 published by elsevier ltd.
software_engineering	the proliferation of information technologies and the diversity of problem domains that heavily rely on software tool applications promote computer-supported cooperative work as a challenging discipline that drives the development process of contemporary and future engineering methods, standards, and tools. consequently, a particular domain of expertise in engineering and scientific fields has emerged, demanding more advanced skills and deeper domain knowledge. the essential role of architectural design (ad) and urban planning (up) is to enable a forward-looking approach to building/facility creation. construction engineering (ce) expresses its routine primarily through a transition phase that transforms ideas to sustainable urban artifacts. the ce role appears as a combination of backward and downward looking to the same process/product all three domains are highly cooperative in the context of environmental engineering (ee). currently available software tools that support the ad, up and ce domains are far from simple. several recent software engineering studies suggest that, instead of developing a complex ""all in one solution"", the federation or orchestration of several related simple methods and tools seems promising. in this article, we discuss the basic ad, up and ce domain-cooperation aspects and suggest an extensible orchestration framework (exof) model that may support them. to verify the exof simulation and orchestration potential, we used its architectural model to orchestrate different software tools when performing the urban blocks daylight illumination simulation for different urban block morphology models. for the exact simulation, we used the normalized sun-exposition data for the city of novi sad, serbia. also presented is an illustration of the methodology, modeling and orchestration potential of exof for the selected case study, together with the results, obtained for typical 3d models of selected urban block morphology patterns. (c) 2016 elsevier b.v. all rights reserved.
electric_motor	this paper presents the system architecture and expected link availability for the sirius satellite radio system for both the contiguous united states (conus) and canada service regions. sirius delivers over 100 channels of talk and music to subscribers in conus. the service is available to different markets, such as vehicles, homes, portables, marine, and aviation, and is offered on a subscription basis. descriptions and performance of the sirius system are detailed herein. copyright (c) 2008 john wiley & sons, ltd.
cryptography	recombined fingerprints have been suggested as a convenient approach to improve the efficiency of anonymous fingerprinting for the legal distribution of copyrighted multimedia contents in p2p systems. the recombination idea is inspired by the principles of mating, recombination and heredity of the dna sequences of living beings, but applied to binary sequences, like in genetic algorithms. however, the existing recombination-based fingerprinting systems do not provide a convenient solution for collusion resistance, since they require ""double-layer"" fingerprinting codes, making the practical implementation of such systems a challenging task. in fact, collusion resistance is regarded as the most relevant requirement of a fingerprinting scheme, and the lack of any acceptable solution to this problem would possibly deter content merchants from deploying, any practical implementation of the recombination approach. in this paper, this drawback is overcome by introducing two non-trivial improvements, paving the way for a future real-life application of recombination-based systems. first, nuida et al. 's collusion-resistant codes are used in segment-wise fashion for the first time. second, a novel version of the traitor-tracing algorithm is proposed in the encrypted domain, also for the first time, making it possible to provide the buyers with security against framing. in addition, the proposed method avoids the use of public-key cryptography for the multimedia content and expensive cryptographic protocols, leading to excellent performance in terms of both computational and communication burdens. in fact, after bootstrapping, the merchant is no longer required to participate in any file transfer, reducing the investment in equipment required for content distribution to the bare minimum. the paper also analyzes the security and privacy properties of the proposed system both formally and informally, whereas the collusion resistance and the performance of the method are shown by means of experiments and simulations. (c) 2016 elsevier ltd. all rights reserved.
electrical_circuits	probing interactions of biological systems at the molecular level is of great importance to fundamental biology, diagnosis, and drug discovery. a rational bioassay design of lithographically integrating individual point scattering sites into electrical circuits is capable of realizing real-time, label-free biodetection of influenza h1n1 viruses with single-molecule sensitivity and high selectivity by using silicon nanowires as local reporters in combination with microfluidics. this nanocircuit-based architecture is complementary to more conventional optical techniques, but has the advantages of no bleaching problems and no fluorescent labeling. these advantages offer a promising platform for exploring dynamics of stochastic processes in biological systems and gaining information from genomics to proteomics to improve accurate molecular and even point-of-care clinical diagnosis.
machine_learning	backgroundthe liver is the major site for alcohol metabolism in the body and therefore the primary target organ for ethanol (etoh)-induced toxicity. in this study, we investigated the invitro response of human liver cells to different etoh concentrations in a perfused bioartificial liver device that mimics the complex architecture of the natural organ. methodsprimary human liver cells were cultured in the bioartificial liver device and treated for 24hours with medium containing 150mm (low), 300mm (medium), or 600mm (high) etoh, while a control culture was kept untreated. gene expression patterns for each etoh concentration were monitored using affymetrix human gene 1.0 st gene chips. scaled expression profiles of differentially expressed genes (degs) were clustered using fuzzy c-means algorithm. in addition, functional classification methods, kegg pathway mapping and also a machine learning approach (random forest) were utilized. resultsa number of 966 (150mm etoh), 1,334 (300mm etoh), or 4,132 (600mm etoh) genes were found to be differentially expressed. dose-response relationships of the identified clusters of co-expressed genes showed a monotonic, threshold, or nonmonotonic (hormetic) behavior. functional classification of degs revealed that low or medium etoh concentrations operate adaptation processes, while alterations observed for the high etoh concentration reflect the response to cellular damage. the genes displaying a hormetic response were functionally characterized by overrepresented cellular ketone metabolism and carboxylic acid metabolism. altered expression of the genes bahd1 and h3f3b was identified as sufficient to classify the samples according to the applied etoh doses. conclusionsdifferent pathways of metabolic and epigenetic regulation are affected by etoh exposition and partly undergo hormetic regulation in the bioartificial liver device. gene expression changes observed at high etoh concentrations reflect in some aspects the situation of alcoholic hepatitis in humans.
electricity	the rapid development of energy, electricity, and transportation industries has created a market for steel pipes; however, buried steel pipelines near high-voltage transmission lines and electrified railways often experience alternating current (ac) corrosion at the damaged coating of pipelines; such phenomenon is mostly due to the resistance between the capacitance and inductance coupling, especially for long-distance pipelines in parallel operation. ac corrosion can cause pipeline corrosion perforation and stress corrosion cracking (scc) in some cases, which has been a vital threat to the pipeline safety. in this work, the influence of ac on corrosion behavior of x80 pipeline steel was investigated in ns4 near-neutral solution by data acquisition technique, electrochemical test, immersion tests and surface analysis techniques. results show that with the increasing of ac density, corrosion morphology changed from uniform corrosion to localized corrosion with many pits. under the full ac interference, x80 steel occurred cathodic and anodic polarization which resulted in iron dissolution and hydrogen precipitation. the negative half wave ac would lead to hydrogen evolution and hydrogen induced anodic dissolution, the pits in x80 steel surface present sharp. however, under disturbance of positive half-wave ac, only anodic dissolution occurred and the pitting appeared spill shape and smoothly. under various ac waveform interference, the corrosion products of x80 steel surface were different. under full ac wave and positive half-wave interference, the corrosion products were loose, had have no alpha-feooh and occurred cracks; however, under negative half-wave ac interference, the corrosion products were denser and contained alpha-feooh which has protective effect on substrates.
computer_programming	computers are the leading technology of the 21st century. programming, the development of software is thus a fundamental activity in which many people are engaged worldwide. therefore programming courses are included as a part of the curriculum. in these courses, students are primarily introduced to language features. traditionally, the students practice by applying the acquired knowledge to solve some logically straightforward problems giving less scope for the programming skills. this paper focuses on application of coding standards, coding techniques, debugging, code review, refactoring, code optimization, test driven programming and pair programming based learning to master not only programming language features, but also an integrated approach to gain problem solving and programming skills. the subject is introduced as a first year course where the students are without any or with smaller amount of background or experience in computer programming. taking this into consideration, activities like programming were designed. these activities enhanced the learning ability, problem solving skills programming skills and debugging skills
algorithm_design	this paper addresses the makespan minimization problem in scheduling flexible job shops whenever there exist separable sequence-dependent setup times. an extension to the neighborhood search functions of mastrolilli and gambradella, developed for the flexible job shop scheduling problem (fjsp), is provided. it is shown that under certain conditions such an extension is viable. accordingly, a randomized neighborhood search function is introduced, and its best search parameters are determined experimentally using modified fjsp benchmark instances. a tabu search approach utilizing the proposed neighborhood search function is then developed, and experimentations are conducted using the modified instances to benchmark it against a lower bound. experimental results show that on average, the tabu search approach is capable of achieving optimality gaps of below 10% for instances with low average setup time to processing time ratios. (c) 2015 elsevier inc. all rights reserved.
computer_graphics	the use of virtual prototypes and digital models containing thousands of individual objects is commonplace in complex industrial applications like the cooperative design of huge ships. designers are interested in selecting and editing specific sets of objects during the interactive inspection sessions. this is however not supported by standard visualization systems for huge models. in this paper we discuss in detail the concept of rendering front in multiresolution trees, their properties and the algorithms that construct the hierarchy and efficiently render it, applied to very complex cad models, so that the model structure and the identities of objects are preserved. we also propose an algorithm for the interactive inspection of huge models which uses a rendering budget and supports selection of individual objects and sets of objects, displacement of the selected objects and real-time collision detection during these displacements. our solution based on the analysis of several existing view-dependent visualization schemes uses a hybrid multiresolution tree that mixes layers of exact geometry, simplified models and impostors, together with a time-critical, view-dependent algorithm and a constrained front. the algorithm has been successfully tested in real industrial environments; the models involved are presented and discussed in the paper. (c) 2016 elsevier ltd. all rights reserved.
analog_signal_processing	this paper presents an embedded signal analyzer for ac impedance identification of the pem fuel cell after a fluctuation signal of current is injected into the stack. the key part of the analyzer is the analog signal processing unit designed with special consideration. the analog signal processing unit has the capability of extracting small fluctuation signals of the current, voltages of the stack and each cell. phase delays caused by the analog circuit are designed to be the same to avoid complicated phase calibration of original signals. then the experiment is performed to validate functions of the proposed signal analyzer.
electric_motor	this paper presents an experimental study on the development, implementation, and tests of a control strategy applied to pressure control in hydraulic pumping systems. the strategy aims at avoiding severe damage on the hydraulic system due to water hammer effects. to accomplish this, it is proposed a suitable modulating control of the pump electric motor torque in order to keep the pressure values in a safe region, for all set of operating conditions. a rig system has been developed to perform experimental tests. from step response tests in the hydraulic rig system, a transfer function model relating the pipe pressure to the motor speed was identified and subsequently applied for pid controller design. the pid control synthesis was performed by using pole-placement techniques and its performance has been assessed in comparison to a pid controller adjusted by using ziegler-nichols rules. the obtained results show that the proposed control strategy was able to assure safe plant operation even in extreme operation conditions, as in case of water hammer effect.
image_processing	this study describes image processing systems based on an artificial neural network to estimate tool wear. the single category-based classifier neural network was used to process tool image data. we present a method to determine the rate of tool wear based on image analysis, and discuss the evaluation of errors. using the proposed algorithm, we made in visual basic the special neural wear software for analysis of the worn part of the cutting edge. for example, the image of worn edge was created determining the optimum setting of neural wear software to automatically indicate the wear area. the result of the analysis was the number of pixels that belonged to the worn area. using these settings, we made an image analysis of edge wear for different working times. we used the calculated parameters of correlation between the number of pixels and v-b index. our results promise a good correlation between the new methods and the commonly used optically measured v-b index, with an absolute mean relative error of 6.7% for the tools' entire life range. automatic detection of wear of the cutting edge can be useful in many applications; for example, in predicting tool life based on the current value of edge wear.
electricity	in the design of nuclear power plants, various natural circulation passive cooling systems are considered to remove residual heat from the reactor core in the event of a power loss and maintain the plant 's safety. these passive systems rely on gravity differences of fluids, resulting from density differentials, rather than using an external power-driven system. unfortunately, a major drawback of such systems is their weak driving force, which can negatively impact safety. in such systems, there is a temperature difference between the heat source and the heat sink, which potentially offers a natural platform for thermoelectric generator (teg) applications. while a previous study designed and analyzed a teg-based passive core cooling system, this paper considers teg applications in other passive cooling systems of nuclear power plants, after which the concept of a teg-based passive cooling system is proposed. in such a system, electricity is produced using the system 's temperature differences through the teg, and this electricity is used to further enhance the cooling process.
electric_motor	the present study focuses on the use of lubricating oil as a coolant for electrical motors. oil is introduced at each side of a 40 kw test machine to directly cool the stator coil end-windings. an experimental setup has been implemented to test different oil injection patterns. the influence of the oil flow rate, rotation speed and oil temperature has been investigated (40 l/h <qv < 360 l/h, 50 degrees c < t-oil < 75 degrees c, 0 < omega <4600 rpm). the results show a strong dependence of the flow rate on global cooling performance, whereas the effect of rotation speed is smaller but can affect local temperature. (c) 2014 elsevier ltd. all rights reserved.
bioinformatics	proteomics is the large-scale analysis of proteins. proteomic techniques, such as liquid chromatography tandem mass spectroscopy (lcms/ms), can characterize thousands of proteins at a time. these powerful techniques allow us to have a systemic understanding of cellular changes, especially when cells are subjected to various stimuli, such as infections, stresses, and specific test conditions. even with recent developments, analyzing the exosomal proteome is time-consuming and often involves complex methodologies. in addition, the resultant large dataset often needs robust and streamlined analysis in order for researchers to perform further downstream studies. here, we describe a silac-based protocol for characterizing the exosomal proteome when cells are infected with hiv-1. the method is based on simple isotope labeling, isolation of exosomes from differentially labeled cells, and mass spectrometry analysis. this is followed by detailed data mining and bioinformatics analysis of the proteomic hits. the resultant datasets and candidates are easy to understand and often offer a wealth of information that is useful for downstream analysis. this protocol is applicable to other subcellular compartments and a wide range of test conditions.
control_engineering	this paper presents a series of devices generating renewable energy from the marine environment, which in recent years have attracted increasing interest. especially we describe the major types of floating wind generators, marine current turbines and various devices based on wave energy. it highlights key requirements to be considered from the point of view of control engineering, considering the objectives of achieving economic viability in view of its stability, reliability and availability in a particularly aggressive marine environment, where maintenance operations are particularly costly.
microcontroller	we propose a new controller for dc-dc converters based on particle swarm optimization (pso). this new converter controller uses the pso optimization method to directly control, by itself, the output voltage of a boost dc-dc converter. in order to validate and qualify the proposed converter controller, we analyzed and implemented some variants of the pso algorithm, namely the standard pso and the global local best pso. the proposed converter controller was then compared with a variant of the classic pi controller with anti-windup, for different operational conditions. the three controllers compared in this work were implemented in the microcontroller tms320f28027 by using the code composer studio from texas instruments. the results show that the proposed controller exhibits better behavior in terms of settling time and overshoot. unlike most popular dc-dc converter controllers, the proposed controller does not require any sort of optimal parameter determination. (c) 2016 elsevier b.v. all rights reserved.
machine_learning	many agitation and mixing processes utilize various sensors for real-time monitoring and control, which can involve complex and costly equipment. for many mixing and agitation processes, such as in dough making, as mixing energy is placed, the resistance to extension increases and then after some point it decreases again. high-quality bread is obtained by stopping mixing at or close to the maximum resistance. the change in resistance causes a change in motor torque. the torque change affects the motor 's current draw for agitation and mixing machines driven by electrical motors. the rheological characteristics of the mixed material are related to motor torque of the mixing machine. therefore, it is related to the motor electric current where the load variation can be estimated by a low-cost current sensor. this paper outlines a novel design for an intelligent agitator/mixer process controller. the design is based on current sensing and on-line learning through reinforcement learning using operator input. the system provides a low-cost approach to automate various kinds of production equipment currently operated manually, which are common in the developing world. additionally, the approach requires minimal modification to the equipment: it requires only a current sensor, an on/off control relay, a set of buttons for operation, and an embedded system. (c) 2017 published by elsevier ltd.
electrical_circuits	combined with fast fourier transform (fft), a mathematical hybrid method for accurately computing the lightning current flowing along the grounding grid buried in multilayered earth model has been developed in this paper. in the hybrid method, electrical circuits consist with ""t"" typical elementary element. to accelerate the calculation, both dynamic state and quasi-static complex image methods, and closed form of green 's function were introduced into this model. the model can be used for study performance of transient lightning response to grounding grid.
operational_amplifier	this paper presents an ultra-low-power low-voltage class-ab fully differential operational amplifier designed in 45-nm cmos technology. the proposed circuit uses transistors operating in sub-threshold region for low-power and low-voltage operation. the proposed op amp offers an open-loop gain of 74.6 db, 1 mhz unity gain frequency, 50-degrees phase margin, and 91.55 db common-mode rejection ratio for 10 pf loads with a power consumption of 0.39 mu w at a +/-0.4 v supply. simulation results illustrate a slew rate of 0.013 v/us and a rail-to-rail output swing, demonstrating its correct functionality.
machine_learning	the security of cryptographic systems is a major concern for cryptosystem designers, even though cryptography algorithms have been improved. side-channel attacks, by taking advantage of physical vulnerabilities of cryptosystems, aim to gain secret information. several approaches have been proposed to analyze side-channel information, among which machine learning is known as a promising method. machine learning in terms of neural networks learns the signature (power consumption and electromagnetic emission) of an instruction, and then recognizes it automatically. in this paper, a novel experimental investigation was conducted on field-programmable gate array (fpga) implementation of elliptic curve cryptography (ecc), to explore the efficiency of side-channel information characterization based on a learning vector quantization (lvq) neural network. the main characteristics of lvq as a multi-class classifier are that it has the ability to learn complex non-linear input-output relationships, use sequential training procedures, and adapt to the data. experimental results show the performance of multi-class classification based on lvq as a powerful and promising approach of side-channel data characterization.
pid_controller	laser heating technology is a type of potential and attractive space heat flux simulation technology, which is characterized by high heating rate, controlled spatial intensity distribution and rapid response. however, the controlled plant is nonlinear, time-varying and uncertainty when implementing the laser-based heat flux simulation. in this paper, a novel intelligent adaptive controller based on proportion-integration-differentiation (pid) type fuzzy logic is proposed to improve the performance of laser-based ground thermal test. the temperature range of thermal cycles is more than 200 k in many instances. in order to improve the adaptability of controller, output scaling factors are real time adjusted while the thermal test is underway. the initial values of scaling factors are optimized using a stochastic hybrid particle swarm optimization (h-pso) algorithm. a validating system has been established in the laboratory. the performance of the proposed controller is evaluated through extensive experiments under different operating conditions (reference and load disturbance). the results show that the proposed adaptive controller performs remarkably better compared to the conventional pid (pid) controller and the conventional pid type fuzzy (f-pid) controller considering performance indicators of overshoot, settling time and steady state error for laser-based ground thermal test. it is a reliable tool for effective temperature control of laser-based ground thermal test. (c) 2016 chinese society of aeronautics and astronautics. production and hosting by elsevier ltd. this is an open access article under the cc by-nc-nd license.
machine_learning	there are many types of dependencies between software requirements, such as the contributions dependencies (make, some+, help, break, some-, hurt) and business dependencies modeled in the i* framework. however, current approaches for prioritizing requirements seldom take these dependencies into consideration, because it is difficult for stakeholders to prioritize requirements considering their preferences as well as the dependencies between requirements. to make requirement prioritization more practical, a method called drank is proposed. drank has the following advantages: 1) a prioritization evaluation attributes tree is constructed to make the ranking criteria selection easier and more operable; 2) rankboost is employed to calculate the subjective requirements prioritization according to stakeholder preferences, which reduces the difficulty of evaluating the prioritization; 3) an algorithm based on the weighted pagerank is proposed to analyze the dependencies between requirements, allowing the objective dependencies to be automatically transformed into partial order relations; and 4) an integrated requirements prioritization method is developed to amend the stakeholders' subjective preferences with the objective requirements dependencies and make the process of prioritization more reasonable and applicable. a controlled experiment performed to validate the effectiveness of drank based on comparisons with case based ranking, analytical hierarchy process, and evolve. the results demonstrate that drank is less time-consuming and more effective than alternative approaches. a simulation experiment demonstrates that taking requirement dependencies into consideration can improve the accuracy of the final prioritization sequence. (c) 2016 elsevier inc. all rights reserved.
machine_learning	this work proposes a clusterization algorithm called k-morphological sets (k-ms), based on morphological reconstruction and heuristics. k-ms is faster than the cpu-parallel k-means in worst case scenarios and produces enhanced visualizations of the dataset as well as very distinct clusterizations. it is also faster than similar clusterization methods that are sensitive to density and shapes such as mitosis and triclust. in addition, k-ms is deterministic and has an intrinsic sense of maximal clusters that can be created for a given input sample and input parameters, differing from k-means and other clusterization algorithms. in other words, given a constant k, a structuring element and a dataset, k-ms produces k or less clusters without using random/pseudo-random functions. finally, the proposed algorithm also provides a straightforward means for removing noise from images or datasets in general.
operating_systems	modern operating systems, such as linux, are capable of executing multiple parallel applications concurrently on many-core platforms. different applications may have different characteristics with regard to how they exercise the computation and memory resources in these platforms. this paper aims to investigate the impact of such differences on the overall energy consumption and performance trade offs. to analyze these tradeoffs, three parsec benchmark applications are chosen with different characteristics-memory-intensive, cpu-intensive and a mixture of both. these applications are then concurrently executed in various combinations in experiments, which also help establish optimized run-time controls in terms of dynamic voltage/frequency scaling (dvfs) and thread-to-core allocations at run-time. such controls are based on state-space models derived through linear regression using the feedback from hardware performance counters. using the benchmark applications, we demonstrate the effectiveness of our proposed method, which shows up to 23% improvement in power normalized performance expressed as the ratio between instructions per second (ips) and power consumption (watt).
microcontroller	the design of analog filter using active building block has been gained significant attention and has become an interesting research topic. a five-inputs single output voltage-mode universal biquadratic filter using active building block, namely voltage differencing differential difference amplifier (vddda) is presented in this paper. the proposed filter consists of two vdddas and two grounded capacitors. the presented circuit has high impedance for all input voltage nodes and low impedance for output voltage node which is ideal for cascade in voltage-mode circuit without the use of buffer circuits. it can provide five output voltage functions which are band-pass (bp), low-pass (lp), band-reject (br), high-pass (hp) and all-pass (ap) responses. for high-pass and band-pass functions, the inverting and non inverting response can be achieved. the matching condition, the inverting and double gain amplifier are not required which is easy to select the output response by digital method. the natural frequency and quality factor can be electronically tuned that is attractive for microcomputer or microcontroller controllability. to verify the validity of proposed filter, the pspice simulation and experimental results using vddda constructed from commercially available ic are included. the measured results agree well with theoretical expect. (c) 2016 elsevier gmbh. all rights reserved.
parallel_computing	the runjags package provides a set of interface functions to facilitate running markov chain monte carlo models in jags from within r. automated calculation of appropriate convergence and sample length diagnostics, user-friendly access to commonly used graphical outputs and summary statistics, and parallelized methods of running jags are provided. template model specifications can be generated using a standard lme4-style formula interface to assist users less familiar with the bugs syntax. automated simulation study functions are implemented to facilitate model performance assessment, as well as drop-k type cross-validation studies, using high performance computing clusters such as those provided by parallel. a module extension for jags is also included within runjags, providing the pareto family of distributions and a series of minimally-informative priors including the dumouchel and half-cauchy priors. this paper outlines the primary functions of this package, and gives an illustration of a simulation study to assess the sensitivity of two equivalent model formulations to different prior distributions.
digital_control	performance of any digital control scheme applied to inverters, or any other power electronic structures, can significantly suffer due to time delays. these time delays can be linear and nonlinear. an example of a linear delay is the delay due to sampling, control calculation and application of the new voltage state, which results in a constant delay present in each control cycle. an example of a non-linear delay is the inverter dead-time, which is different depending on the selected switching state and the direction of the load current. both types of delays are well-known and are addressedin literature. at the same time, the known solutions result in significantly more complicated hardware and/or software implementations. introduction of mpc to power electronics gives a new and unique opportunity to compensate for both types of the delays in a clear and effective way. this can be done by including the delays, both linear and non-linear, in the model predictions. as an illustration, this paper presents an mpc-based design of closed-loop current control with linear delay compensation for voltage source inverters. the paper also proposes a variable rate mpc-based voltage modulator which combines harmonic suppression with inverter dead-time compensation. the main points of the paper are illustrated by extensive simulation and experimenal results.
computer_graphics	the motion of a thin viscous film of fluid on a curved surface exhibits many intricate visual phenomena, which are challenging to simulate using existing techniques. a possible alternative is to use a reduced model, involving only the temporal evolution of the mass density of the film on the surface. however, in this model, the motion is governed by a fourth-order nonlinear pde, which involves geometric quantities such as the curvature of the underlying surface, and is therefore difficult to discretize. inspired by a recent variational formulation for this problem on smooth surfaces, we present a corresponding model for triangle meshes. we provide a discretization for the curvature and advection operators which leads to an efficient and stable numerical scheme, requires a single sparse linear solve per time step, and exactly preserves the total volume of the fluid. we validate our method by qualitatively comparing to known results from the literature, and demonstrate various intricate effects achievable by our method, such as droplet formation, evaporation, droplets interaction and viscous fingering. finally, we extend our method to incorporate non-linear van der waals forcing terms which stabilize the motion of the film and allow additional effects such as pearling.
relational_databases	information over the web is increasingly retrieved from relational databases in which the query language is based on exact matching, data fulfil completely the query or not. the results returned to the user contain only tuples that satisfy the conditions of the query. thereby, the user can be confronted to the problem of empty answers in the case of too selective query. to overcome this problem, several approaches have been proposed in the literature in particularly those based on query conditions relaxation. others works suggest the use of fuzzy sets theory to introduce a flexible queries. another line of research proposes the adaptation of information retrieval (ir) approaches to get an approximate matching in databases. we discuss in this paper, an adaptation of language model of ir to deal with empty answers. the main idea behind our approach is that instead of returning an empty response to the user, a ranked list of tuples that have the most similar values to those specified in user 's query is returned.
electricity	efficient power management in smart grids requires obtaining power consumption data from each resident. however, data concerning user 's electricity consumption might reveal sensitive information, such as living habits and lifestyles. in order to solve this problem, this paper proposes a privacy-preserving cube-data aggregation scheme for electricity consumption. in our scheme, a data item is described as a multi-dimensional data structure (l-dimensional), and users form and live in multiple residential areas (m areas, and at most n users in each area). based on horner 's rule, for each user, we construct a user-level polynomial to store dimensional values in a single data space by using the first horner parameter. after embedding the second horner parameter into the polynomial, the polynomial is hidden by using paillier cryptosystem. by aggregating data from m areas, we hide the area-level polynomial into the final output. moreover, we propose a batch verification scheme in multi-dimensional data to reduce authentication cost. finally, our analysis shows that the proposed scheme is efficient in terms of computation and communication costs, suitable for massive user groups, and supports the flexible and rapid growth of residential scales in smart grids.
parallel_computing	the flux distribution generated by the heliostat field of solar central receiver system (scrs) over the receiver needs to be carefully controlled. it is necessary to avoid dangerous radiation peaks and temperature distributions to maximize the efficiency and keep the system in a safe state. these tasks imply both selecting the subset of heliostats to be activated and assigning each one to a certain aiming point at the receiver. the heliostat field is usually under human control and supervision, what is a potential limiting factor. thus, there is an active research line to define automatic aiming procedures. in fact, a general and autonomous methodology is being developed by the authors of this work. however, the mathematical modeling leads to face a complex large-scale optimization problem. in this work, applying teaching-learning-based optimization (tlbo), a population-based large-scale optimizer, is considered. it is intended to serve to perform large explorations of the search-space to finally deploy further local optimizers over the most promising results. considering the computational cost of the objective function, a parallel version of tlbo has been developed. it significantly accelerates the procedure, and the possibility of being included in a more complex process remains viable. additionally, the parallel version of tlbo is also linked as a generic open-source library.
software_engineering	archivedb is the data archive for all scientific and technical data collected at the wendelstein 7-x project. it is a distributed system allowing continuous data archival. archivedb has demanding requirements regarding performance efficiency (storage performance of 30 gb/s during experiments, expected storage amount of 1.4 pb/year), reliability (availability of 364 days/year), maintainability (testability) and portability (including change of hardware and software). data acquisition with continuous operation and high time resolutions (up to nanoseconds scale) for physics data is supported as well as long-term recording up to 24 h/7 days for operational data (similar to 1 hz rate). moreover, all results of data analysis are stored in the archive. another challenge, uniform retrieval of measured and analyzed data, allowing time and structure information as selection criteria, is mastered as well. the key concepts of data storage and retrieval are: (1) partitioning of incoming data in groups and stream, (2) chunking of data in boxes of manageable size covering a finite time period, and (3) indexing of data using absolute time as ordering and indexing criteria. continuous operation of the archivedb software and hardware for various systems and components relevant to wendelstein 7-x has been done successfully for several years, thus, showing that the key requirements are satisfied. the overall data amount so far has reached 7 terabyte over 9 years of data taking. round-the-clock operation of the archive is in place since 5 years. initial plasma operation op1.1 of wendelstein 7-x has been supported with no downtime during the whole experimental campaign. the paper describes the software engineering concepts that have been used, consolidated and refined over the years of continuing productive archivedb use and development. changes in the underlying techniques, e.g. a change of the data store, have been encapsulated via an application programming interface (api). this api unifies different implementations and is also suitable for data migration. (c) 2016 elsevier b.v. all rights reserved.
symbolic_computation	the paper introduces real logic: a framework that seamlessly integrates logical deductive reasoning with efficient, data-driven relational learning. real logic is based on full first order language. terms are interpreted in n-dimensional feature vectors, while predicates are interpreted in fuzzy sets. in real logic it is possible to formally define the following two tasks: (i) learning from data in presence of logical constraints, and (ii) reasoning on formulas exploiting concrete data. we implement real logic in an deep learning architecture, called logic tensor networks, based on google 's tensorflow (tm) primitives. the paper concludes with experiments on a simple but representative example of knowledge completion.
computer_vision	diabetes disrupts the operation of the eye and leads to vision loss, affecting particularly the nerve layer and capillary vessels in this layer by changes in the blood vessels of the retina. suddenly loss and blurred vision problems occur in the image, depending on the phase of the disease, called diabetic retinopathy. hard exudates are one of the primary signs of diabetic retinopathy. automatic recognition of hard exudates in retinal images can contribute to detection of the disease. we present an automatic screening system for the detection of hard exudates. this system consists of two main steps. firstly, the features were extracted from patch images consisting of hard exudate and normal regions using the daisy algorithm based on the histogram of oriented gradients. after, we utilized the recursive feature elimination (rfe) method, using logistic regression (lr) and support vector classifier (svc) estimators on the raw dataset. therefore, we obtained two datasets containing the most important features. the number of important features in each dataset created with lr and svc was 126 and 259, respectively. afterward, we observed different classifier algorithms' performances by using 5-fold cross validation on these important features' dataset and it was observed that the random forest (rf) classifier is the best classifier. secondly, we obtained important features from the feature vector that corresponds with the region of interest in accordance with the keypoint information in a new retinal fundus image. then we performed detection of hard exudate regions on the retinal fundus image by using the rf classifier.
computer_graphics	discretization by rasterization is introduced into the method of images (mi) in the context of 3d deterministic radio propagation modeling as a way to exploit spatial coherence of electromagnetic propagation for fine-grained parallelism. traditional algebraic treatment of bounding regions and surfaces is replaced by computer graphics rendering of 3d reflections and double refractions while building the image tree. the visibility of reception points and surfaces is also resolved by shader programs. the proposed rasterization is shown to be of comparable run time to that of the fundamentally parallel shooting and bouncing rays. the rasterization does not affect the signal evaluation backtracking step, thus preserving its advantage over the brute force ray-tracing methods in terms of accuracy. moreover, the rendering resolution may be scaled back for a given level of scenario detail with only marginal impact on the image tree size. this allows selection of scene optimized execution parameters for faster execution, giving the method a competitive edge. the proposed variant of mi can be run on any gpu that supports real-time 3d graphics.
software_engineering	the paper presents a series of considerations regarding the role of the conceptual invariants concerning the prevention of the artefacts' obsolescence, with an emphasis on the software engineering. the concept of artefact has the meaning that is defined in (bocu & bocu, 2016). the emphasizing of the invariants' role has the goal to allow the understanding, with the respective approximation, of this invariants' role considering the continuous qualitative progress of the human artefacts, generally speaking, but also in connection to the software systems engineering.
signal-flow_graph	we propose an interleaver based oil the mach-zehnder interferometer with a resonator incorporated in one ann. by using the method of signal flow graph, we get the simple closed-form expressions for transmission of this interleaver. the result indicates that the widths of 0.5 db passband and 25 db stopband of the interleaver are improved remarkably, which are much wider than that of the conventional mach-zehnder interferometer. the interleaver proposed has an ideal rectangular spectral response. finally, we have analyzed the influence exerted by the parameters on its transimission characteristics and found that the transmission spectrum of this device depends highly oil the intensity coupling coefficient of the coupler and fiber loop length.
electrical_network	the electrical response of nh2-functionalized graphene nanoplatelets composite materials under strain was studied. two different manufacturing methods are proposed to create the electrical network in this work: (a) the incorporation of the nanoplatelets into the epoxy matrix and (b) the coating of the glass fabric with a sizing filled with the same nanoplatelets. both types of multiscale composite materials, with an in-plane electrical conductivity of similar to 10(-3) s/m, showed an exponential growth of the electrical resistance as the strain increases due to distancing between adjacent functionalized graphene nanoplatelets and contact loss between overlying ones. the sensitivity of the materials analyzed during this research, using the described procedures, has been shown to be higher than commercially available strain gauges. the proposed procedures for self-sensing of the structural composite material would facilitate the structural health monitoring of components in difficult to access emplacements such as offshore wind power farms. although the sensitivity of the multiscale composite materials was considerably higher than the sensitivity of metallic foils used as strain gauges, the value reached with nh2-functionalized graphene nanoplatelets coated fabrics was nearly an order of magnitude superior. this result elucidated their potential to be used as smart fabrics to monitor human movements such as bending of fingers or knees. by using the proposed method, the smart fabric could immediately detect the bending and recover instantly. this fact permits precise monitoring of the time of bending as well as the degree of bending.
parallel_computing	methods for the polynomial eigenvalue problem sometimes need to be followed by an iterative refinement process to improve the accuracy of the computed solutions. this can be accomplished by means of a newton iteration tailored to matrix polynomials. the computational cost of this step is usually higher than the cost of computing the initial approximations, due to the need of solving multiple linear systems of equations with a bordered coefficient matrix. an effective parallelization is thus important, and we propose different approaches for the message-passing scenario. some schemes use a subcommunicator strategy in order to improve the scalability whenever direct linear solvers are used. we show performance results for the various alternatives implemented in the context of slepc, the scalable library for eigenvalue problem computations. copyright (c) 2016 john wiley & sons, ltd.
cryptography	vote by ballot is the feature in a democratic society and the process of decision-making, tending to achieve the philosophy of democratic politics by having the public who are eligible to vote for competent candidates or leaders. with the rapid development of technologies and network applications, electronization has been actively promoted globally during the social transformation period that the concept of electronic voting is further derived. the major advantages of electronic voting, comparing with traditional voting, lie in the mobility strength of electronic voting, reducing a large amount of election costs and enhancing the convenience for the public. electronic voting allows voters completing voting on the internet that not only are climate and location restrictions overcome, but the voter turnout is also increased and the voting time is reduced for the public. with the development in the past three decades, electronic voting presents outstanding performance theoretically and practically. nevertheless, it is regrettable that electronic voting schemes still cannot be completely open because of lures by money and threats. people to lure by money and threats would confirm the voters following their instructions through various methods that more factors would appear on election results, affecting the quality and fairness of the election. in this study, this project aims to design an electronic voting scheme which could actually defend voters' free will so that lure of money and threats would fail. furthermore, an electronic voting system based on elliptic curve cryptography is proposed to ensure the efficiency and security, and ring signature and signcryption are applied to reducing the computing costs. moreover, this project also focuses on applying voting system to mobile devices. as the system efficiency and security are emphasized, voters do not need to participate in the election, but simply complete voting with smart phones, ipads, and computers. the votes would be automatically calculated and verified the results that the ballots are not necessarily printed, the printing of election mails is reduced, and manual handling is canceled. such a method would effectively reduce voting costs and enhance the economic efficiency.
machine_learning	one of the crucial issues regarding a storm sewer system is the ability to avoid sediment depositions on the pipe invert. in this study, the mean flow velocity under the limit of sediment deposition conditions in partially filled circular storm sewers is evaluated through the use of a support vector machine (svm) model coupled with the firefly algorithm (ffa). the aforemetioned velocity, defined as the velocity at the limit of deposition, and the parameters upon which it depends have been nondimensionalized using the buckingham. theorem. therefore, once the dimensionless parameters are identified, six different functional relationships in terms of dimensionless groups can be obtained. the effects of each of these functional relationships on the dimensionless velocity at limit of deposition, defined as the densimetric particle froude number at the limit of deposition, have been analyzed by using, respectively, the svm-ffa model, svm model, genetic programming (gp) model, and artificial neural network (ann) model. five statistical indices have been used for evaluating the performance of each model (both in training and test phases) and, later, for comparing the performance of the different models between them. finally, the predicted densimetric particle froude number values obtained through the proposed svm-ffa model have been compared with those obtained by three different dimensionless equations for velocity at the limit of deposition. the results indicate that svm-ffa predicts the densimetric particle froude number at limit of deposition fairly accurately. (c) 2016 american society of civil engineers.
operating_systems	one of the fundamental requirements of real time operating systems is the determinism of executing critical tasks and treating multiple periodic or aperiodic events. the present paper presents the hardware support of the nmpra processor (multi pipeline register architecture) dedicated to treating time events, interrupt events and events associated with synchronization and inter-task communication mechanisms. because in real time systems the treatment of events is a very important aspect, this paper describes both the mechanism implemented in hardware for prioritizing and treating multiple events, and the experimental results obtained using virtex-7 fpga circuit. the article 's element of originality is the very short response time required in treating and prioritizing events.
computer_graphics	we proposed the method that generates ground surface texture by evaluating pressure applied at each point. the method standardizes diameter of clod to original size and its 1/2, 1/4, and 1/8 size, then defines condition of land by heft percentage of the clod of the four kinds of size. at each point of the ground, pressure caused by objects that pass through on the point is accumulated. whenever the pressure exceeds the threshold, fixed ratio of weight of clod is shifted to its half size. as a result, at the place where many objects pass, heft percentage of smaller clod increases. ground surface is defined as a multilayered texture. it is created by combining four basic texture images. each of the images is synthesized to correspond to the size of clod by the procedural method. from each of the texture images, round areas are selected and allocated to one of the layers at random. diameter of the area is equal to size of the clod. and the numbers of the area is proportionate to the heft percentage of the clod. the multilayer texture is combined to one layer, after adding shade and shadow. and finally, it is mapped on the ground. (c) 2017 wiley periodicals, inc. electron comm jpn, 100( 2): 25-35, 2017; published online in wiley online library (wileyonlinelibrary.com).
software_engineering	every complex problem now days require multicriteria decision making to get to the desired solution. numerous multi-criteria decision making (mcdm) approaches have evolved over recent time to accommodate various application areas and have been recently explored as alternative to solve complex software engineering problems. most widely used approach is analytic hierarchy process that combines mathematics and expert judgment. analytic hierarchy process suffers from the problem of imprecision and subjectivity. this paper proposes to use fuzzy ahp (fahp) instead of traditional ahp method. the usage of fahp helps decision makers to make better choices both in relation to tangible criteria and intangible criteria. the paper provides a clear guide on how fahp can be applied, particularly in the software engineering area in specific situations. the conclusion of this study would help and motivate practitioners and researchers to use multi-criteria decision making approaches in the area of software engineering.
microcontroller	in this work, a novel electronic lock that can encode and decode optical signals, modulated using morse code conventions, was developed to build a smart home security system based on the internet of things (iot). there are five topics of interest in this research: (1) optical morse code encoder; (2) optical morse code decoder; (3) ambient light sensor circuit; (4) fuzzy controller; (5) cloud monitoring system. we take advantage of the light-emitting components as the encoder, which are readily available in hand-held mobile devices (e.g., smart phones) and photoresistors and a microcontroller as the decoder. by wi-fi transferring, even without a personal computer, real-time information about this lock can be uploaded to the cloud service platform, and helps users to ensure home safety on the remote monitoring system. by using the ambient light sensor and fuzzy controller in this novel optical morse code-based electronic lock, experimental results show that the reliability of this system is much improved from 65% to 100%. that means that it is highly resistant to different illumination conditions in the work environment, and therefore all functions, including coding, emitting, receiving, decoding, uploading and cloud monitoring, can work well. furthermore, besides the convenience and cost reduction, by incorporating traditional keys into smart phones, as a consumer electronics, our proposed system is suitable for users of all ages because of a user-friendly operation interface.
relational_databases	in the last decade, keyword search over relational databases has been extensively studied because it promises to allow users lacking knowledge of structured query languages or unaware of the database schema to query the database in an intuitive way. the existing works about keyword search on databases proposed many approaches and have gain remarkable results. however, most of these approaches are designed for the centralized setting where keyword search is processed by only a single server. in reality, the scale of databases increases sharply and centralized methods hardly can handle keyword queries over these large databases. moreover, processing keyword search over relational databases is a very time-consuming task, and the efficiency of the existing centralized approaches will degrade notably because the single server cannot provide enough computation power for the keyword search over very large databases. to address these challenges, we propose a distributed keyword search (dks) approach with mapreduce and this approach can be well deployed on a cluster of servers to deal with keyword search over large databases in a parallel way.
computer_graphics	in the twenty-first century now, people are accepting the rapid development of the information age, while emphasizing the fast-paced, high efficiency. and we are also the times of higher education, popularization and application of multimedia teaching. so that educators and students are in conflict with traditional teaching and learning methods, and as a special sector of our art and design education, the use of computers is indispensable, and is a very important one to learn and use tools, but the attendant computer renderings can be said to have replaced the traditional hand-painted renderings status in the past, then the design of the manuscript as well as its position ? the answer is yes, fifteen years ago, i purchased a computer began to study adobe photoshop cs. and teaching about the software (corduroy, autocad) so far. and i have always believed in the program design phase, design manuscripts as the behavior of the human brain design thinking process is computer graphics can not be replaced.
relational_databases	the paper proposes a new model, method and algorithms for processing a subject domain (sd). it considers an sd as a tuple (e, v, t), where e is a set of all objects of this domain, v is a set of all connections between these objects, t is a set of mass problems that can be solved in this domain. each object is represented by its essential attributes. this allows us to describe sd, to solve most of the mass problems from t, and to control a state of the domain. the goal of the paper is to develop a method and algorithms that allow us to find essential attributes of domains, described as relational databases or production systems. for a production system, we build a dependency graph with attributes as vertexes, and calculate for each of the vertexes a value that indicates how many other attributes can be found using a particular vertex. high-ranked vertexes are considered as essential. the method is based on considering as essential of the most frequently accessed attributes in a relational database. having essential attributes of objects of a domain, it allows us to define essential attributes of the domain itself.
image_processing	this paper introduces a new method for clustering of documents, which have been written in a language evolving during different historical periods, with an example of the italian language. in the first phase, the text is transformed into a string of four numerical codes, which have been derived from the energy profile of each letter, defining the height of the letters and their location in the text line. each code represents a gray level and the text is codified as a 1-d image. in the second phase, texture features are extracted from the obtained image in order to create document feature vectors. subsequently, a new clustering algorithm is employed on the feature vectors to discriminate documents from different historical periods of the language. experiments are performed on a database of italian documents given in italian vulgar and modern italian. results demonstrate that this proposed method perfectly identifies the historical periods of the language of the documents, outperforming other well-known clustering algorithms generally adopted for document categorization and other state-of-the-art text-based language models.
signal-flow_graph	the analysis, design and performance of a conductor-backed coplanar waveguide (cbcpw) moisture sensor are described. the sensor can be used to determine the moisture content (mc in per cent) in oil palm fruit and other agricultural products. the sensor consists of three parts-the coupling system representing the transition between the coaxial line and the cbcpw, the two-layer structures of the cbcpw and the sensing area with its semi-infinite three-layer cbcpw structure. a relationship between the scattering parameter s-21 or attenuation of the sensor and the moisture content of the sample has been developed. the reflection and transmission phenomena in the sensor structure can be represented by a signal flow graph and can be simplified by the use of non-touching loop rules. the calculation of s-21 is based on the quasi-transverse electromagnetic mode approximation. this work also studies the effect of the thickness of the protective layer and the size of the gap between the conducting line and the upper ground plane on the sensitivity and dynamic range of the sensor. close agreement between the theoretical prediction and experimental results is obtained. the sensitivity and accuracy of the sensors are about 0.5 db/mc and 1% (unit mc, wet basis), respectively. the sensor is suitable for development as a complete instrument and can be used for quality assessments of oil palm fruit and other agricultural products.
relational_databases	we present a logic for reasoning about attribute dependencies in data involving degrees such as a degree to which an object is red or a degree to which two objects are similar. the dependencies are of the form a a double dagger' b and can be interpreted in two ways: first, in data tables with entries representing degrees to which objects (rows) have attributes (columns); second, in database tables where each domain is equipped with a similarity relation. we assume that the degrees form a scale equipped with operations representing many-valued logical connectives. if 0 and 1 are the only degrees, the algebra of degrees becomes the two-element boolean algebra and the two interpretations become well-known dependencies in boolean data and functional dependencies of relational databases. in a setting with general scales, we obtain a new kind of dependencies with naturally arising degrees of validity, degrees of entailment, and related logical concepts. the deduction rules of the proposed logic are inspired by armstrong rules and make it possible to infer dependencies to degrees-the degrees of provability. we provide a soundness and completeness theorem for such a setting asserting that degrees of entailment coincide with degrees of provability, prove the independence of deduction rules, and present further observations.
system_identification	statistical inference subject to nonnegativity constraints is a frequently occurring problem in learning problems. the nonnegative least-mean-square (nnlms) algorithm was derived to address such problems in an online way. this algorithm builds on a fixed-point iteration strategy driven by the karush kuhn tucker conditions. it was shown to provide low variance estimates, but it however suffers from unbalanced convergence rates of these estimates. in this paper, we address this problem by introducing a variant of the nnlms algorithm. we provide a theoretical analysis of its behavior in terms of transient learning curve, steady-state and tracking performance. we also introduce an extension of the algorithm for online sparse system identification. monte-carlo simulations are conducted to illustrate the performance of the algorithm and to validate the theoretical results. (c) 2016 elsevier b.v. all rights reserved.
microcontroller	this study proposes a home-assembled, low-cost blue light-emitting diode (led) photometer that uses simple and low-cost hardware and software, costing about us $150. this 425-nm wavelength photometer is controlled by an 89c51 microcontroller chip. glucose concentration detection experiments involving enzyme coupling reactions were carried out to verify the performance of the proposed system. measurement errors for the system were between 3% and 4%, which can be further improved to less than 2%. the proposed led photometer can be used by students in electronics classes to conduct biotechnological tests as part of their electrical and electronics vocational high school education. this can help them to explore the basic applications of biosensors and enhance their professional abilities in executing fundamental bioelectronics processes. pretest and post-test assessments of students' knowledge of bioelectronics were conducted to determine the efficacy of the proposed system in enhancing students' knowledge. the led photometer can be modified to test various samples in biochemistry and analytical chemistry, and it can also be applied to various fields such as electronics, chemical engineering, and biochemistry.
bioinformatics	the dnaj proteins which function as molecular chaperone played critical roles in plant growth and development and response to heat stress (hs) and also called heat shock protein 40 based on molecular weight. however, little was reported on this gene family in pepper. recently, the release of the whole pepper genome provided an opportunity for identifying putative dnaj homologous. in this study, a total of 76 putative pepper dnaj genes (cadnaj01 to cadnaj76) were identified using bioinformatics methods and classified into five groups by the presence of the complete three domains (j-domain, zinc finger domain, and c-terminal domain). chromosome mapping suggested that segmental duplication and tandem duplication were occurred in evolution. the multiple stress-related cis-elements were found in the promoter region of these cadnaj genes, which indicated that the cadnajs might be involved in the process of responding to complex stress conditions. in addition, expression profiles based on rna-seq showed that the 47 cadnajs were expressed in at least one tissue tested. the result implied that they could be involved in the process of pepper growth and development. qrt-pcr analysis found that 80.60% (54/67) cadnajs were induced by hs, indicated that they could participated in pepper response to high temperature treatments. in conclusion, all these results would provide a comprehensive basis for further analyzing the function of cadnaj members and be also significant for elucidating the evolutionary relationship in pepper.
operational_amplifier	in this paper a cmos operational amplifier is presented. a cmos operational amplifier is presented here which is operating at 2v power supply and 1microamp input bias current at 0.8micrometer technology using nonconventional mode of mos transistors and whose input is dependent on bias current. the unique behavior of the mos transistors in sub threshold region allows a designer to work at low input bias current. it also allows operating at low voltage. while operating the device at weak inversion results low power dissipation but dynamic range is degraded. optimum balance between power dissipation and dynamic range results when the mos transistors are operated at moderate inversion. in comparison with the reported low power, low voltage op-amps at 0.8micrometer technology, this op-amp has very low standby power consumption with a high driving capability and operated at low voltage. operating the device in moderate version is a good solution. also operating the device in sub threshold region not only allows lower power dissipation but also a lower voltage operation is achieved. the proposed op-amp is a simple two stage single ended op-amp. the input stage of the op-amp is a differential amplifier with an nmos pair. operational amplifiers, or opa-mps as they are more commonly called, are one of the basic building blocks of analogue electronic circuits. operational amplifiers are linear devices that have all the properties required for nearly ideal dc amplification and are therefore used extensively in signal conditioning, filtering or to perform mathematical operations such as add, subtract, integration and differentiation.
electric_motor	two omnidirectional and circularly polarized low-gain antennas (the crossed drooping dipole and the tm21-mode circular patch antenna) are developed for direct broadcast satellite radio (dbsr) outdoor mobile terminal applications. two medium-gain circularly polarized microstrip patch arrays [one uses the conventional circular polarization (cp) feed and the other uses the sequentially arranged cp feed techniques] are also developed to provide at least 12-dbic peak gain for dbsr indoor fixed terminal applications. the sequentially arranged cp fed array has a better cp performance over a broader bandwidth than the conventionally fed array. all the antennas are small in size/mass and inexpensive in fabrication cost. the patch antennas also have a low profile. (c) 1994 john wiley & sons, inc.
parallel_computing	we made use of a special algorithm for compute unified device architecture for nvidia graphics cards, a nonlinear conjugate-gradient method to minimize energy functional, and monte-carlo technique to directly observe the forming of the ground state configuration for the 2d hard-core bosons by lowering the temperature and its evolution with deviation away from half-filling. the novel technique allowed us to examine earlier implications and uncover novel features of the phase transitions, in particular, look upon the nucleation of the odd domain structure, emergence of filamentary superfluidity nucleated at the antiphase domain walls of the charge-ordered phase, and nucleation and evolution of different topological structures.
digital_control	the paper postulates the feasibility and optimization of hvac systems using programmable controllers. hvac (heating, ventilating and air conditioning) systems are used for controlled maintenance of indoor ambient characteristics in optimal manner; with regards to outdoor ambient characteristics. the paper includes a simplified sequence of diagrams to represent the architecture of the system. further, it also comprises of the systems and software 's used for the same. also, the paper gives an insight of the advantages of using programmable controllers, and the challenges which are overcome by it. for the ease of understanding a case study of a pharmaceutical company is given who is currently using the system. the main purpose of this project was to create a regulated monitoring system, integration of the utilities like electricity and water, creating a general report of the system for the given or needed time span, also to create a graphical visualization of the real time data and system.
control_engineering	the paper surveys selected state space robust control methods suitable for implementation in motion systems. and their implementation on a laboratory plant the modular servosystem. robust control theory! is taught within control engineering courses in the msc study program applied mechatronics, robust methods and algorithms are developed and verified in the control engineering laboratory during the solution of student and research projects. the project-based learning on suitable laboratory plants is a well-established method for control engineering education in mechatronics. (c) 2016, ifac (international federation of antomatic control) hosting by elsevier ltd. all rights reserved.
signal-flow_graph	linear isotropic dielectrics constitute an important class of linear systems. the paper proposes a novel approach for assigning a suitable structure to describe the dependence of the dynamic behaviour of linear dielectrics on an external parameter of influence. a signal flow graph approach is adopted to arrive at the most general system structure and its subcases. a complex plane representation is used to establish a relationship between the system structure and the pattern of the constant-frequency variable-parameter plots. the one-to-one correspondence between loci patterns and system structure provides a rational basis for the selection of a suitable system structure.
network_security	with the network scales rapidly and new network applications emerge frequently, bandwidth supply for today 's internet could not catch up with the rapid increasing requirements. unfortunately, irrational using of network sources makes things worse. actual network deploys single-next-hop optimization paths for data transmission, but such ""best effort"" model leads to the imbalance use of network resources and usually leads to local congestion. on the other hand multi-path routing can use the aggregation bandwidth of multi paths efficiently and improve the robustness of network, security, load balancing and quality of service. as a result, multi-path has attracted much attention in the routing and switching research fields and many important ideas and solutions have been proposed. this paper focuses on implementing the parallel transmission of multi next-hop data, balancing the network traffic and reducing the congestion. it aimed at exploring the key technologies of the multi-path communication network, which could provide a feasible academic support for subsequent applications of multi-path communication networking. it proposed a novel multi-path algorithm based on node potential in the network. and the algorithm can fully use of the network link resource and effectively balance network link resource utilization.
operational_amplifier	the first step to improving public health is by the assessment of vital signs, which are valuable indicators of overall health. in the present day there are a number of complex, albeit expensive instruments that can measure various parameters accurately. however, these instruments often tend to be bulky, expensive and difficult to operate. hence it is difficult to use these instruments in isolated locations such as rural or disaster stricken areas, for bedside monitoring or even in military camps. the objective of this paper is to introduce the concept of a user friendly modular system which can be used to monitor various physiological parameters efficiently. in the proposed system different sensing circuits are attached to a common microcontroller unit (mcu) which can be updated with the associated firmware. any general computing system such as a laptop is connected to the mcu via a usb-uart bridge. after the connection is established the controller starts sending data to the computer. a javascript is run on the laptop using open-source software called processing 2.0, which initiates a customized display of the various parameters using the incoming data. for data logging we store the serial data in text files. as proof of principle we have measured two parameters, namely the body temperature using the lm35 sensor and the heart rate using photoplethysmography. such a switchable system can be used as a tool to measure various parameters like oxygen saturation, blood pressure, ecg etc. on the computer screen.
state_space_representation	this paper develops a robust h controller for a pitching and plunging airfoil using the state space representation of theodorsen 's lift model employing the linear matrix inequalities method. both parameter uncertainty and the input disturbances are considered in the model. the existence condition for the robust h state-feedback controller is obtained using the lyapunov functional approach. in practical systems, it is difficult to obtain all the states of the model needed for the controller. thus, the observer existence condition is proposed to provide the states' information for the model. several examples are used to demonstrate the effectiveness of the designed controller and the designed observer.
operational_amplifier	lc parallel resonance circuit, the equivalent impedance is purely resistive and the value of the maximum, by using this feature, the resonant circuit in the integrated operational amplifier feedback resistor position, can be at the resonant frequency to achieve specific signal of a frequency selection amplifying. this design is mainly by the attenuation frequency selection network, a frequency selection amplifying module and automatic gain control module, the two integrated operational amplifier and frequency selection network combination, to achieve stable resonant amplification, amplification of up to 81db, resonant frequency of 15mhz; by using 3.6v single power supply, the power consumption is only 320mw, observed in the spectrum analyzer waveform of high q value, the smaller rectangle coefficient, frequency offset in 100khz, 3db bandwidth in the 300khz, the whole system has stable output, no excitation signal output.
system_identification	in this work, pa-6 nanocomposites containing different amounts of nanoclay (nc) were prepared using a corotating twin-screw extruder. in practice, it is hard task to identify the relationship between the extrusion process parameters and the tensile modulus of pa-6 nanocomposites by performing several experiments. one approach to map the relationship between the process parameters and the tensile modulus of pa-6 nanocomposites is the use of a non-linear system identification tool called the adaptiveneuro fuzzy inference system (anfis). in this study, to achieve high modeling accuracy and generalization capability, an efficient shuffled frog leaping (sfl) algorithm is proposed to learn all the parameters of the network. a multi-input single-output (miso) anfis model is constructed and learned to predict the tensile modulus of pa-6 nanocomposites. the anfis model is constructed, trained and tested based on a collection of experimental data sets. acceptable agreement has been observed between the experimental results and the predicted results by the proposed model. the statistical quality of the proposed model is significant due to its good correlation coefficient r-2 values >0.98 between predicted values and experimental ones during the training and testing phase. also, comparison results indicate the superior performance of the proposed scheme over the conventional reported methods due to its high approximation accuracy and good generalization capability.
algorithm_design	large-scale network and graph analysis has received considerable attention recently. graph mining techniques often involve an iterative algorithm, which can be implemented in a variety of ways. using pagerank as a model problem, we look at three algorithm design axes: work activation, data access pattern, and scheduling. we investigate the impact of different algorithm design choices. using these design axes, we design and test a variety of pagerank implementations finding that data-driven, push-based algorithms are able to achieve more than 28x the performance of standard pagerank implementations (e.g., those in graphlab). the design choices affect both single-threaded performance as well as parallel scalability. the implementation lessons not only guide efficient implementations of many graph mining algorithms, but also provide a framework for designing new scalable algorithms.
electricity	renewable energy projects in korea have two avenues that provide subsidies to increase their financial viability. feed-in-tariffs (fits) offer cost based prices for renewable electricity to compete with conventional energy producers. the clean development mechanism (cdm) issues certified emission reduction (cer) credits that generate additional revenues, enhancing renewable projects' return on investment. this study investigated how these subsidies impact the financial returns on korea 's cdm projects. an investment analysis was performed on four cases including solar, hydropower, wind and landfill gas projects. revenues from electricity sales, fits and cers were compared using financial indicators to measure their relative contributions on profitability. results indicate that cdm is partial towards large scale projects with high emission reductions. moreover, conflicts with fit schemes can deter small scale, capital intensive projects from pursuing registration. the analysis highlights cdm 's bias for particular project types, which is in part due to its impartiality towards carbon credit prices. it also reveals that korea, a key benefactor of cdm, is susceptible to such biases, as demonstrated by the disproportionate distribution of issued cers. improving incentives for bundled, small scale projects, cer price differentiation, and excluding domestic subsidies during additionality testing are proposed as possible reforms.
computer_programming	geographers of technology illustrate software code 's contexts, effects, and agencies as they shape urban space and everyday life, but the consequences of code for nature remain understudied. political ecologists have critiqued remote sensing and geographic information systems (gis) based conservation projects, but have not engaged more broadly with the role of software in the contested production, circulation, and application of ecological knowledge. yet, around the world, data analytics firms and conservation nonprofits argue for optimizing environmental management through faster and bigger data collection and new techniques of data manipulation and visualization. i present a case study from the us state of oregon, illustrating how conservationists and environmental regulators employ computer programming to plan markets in which entrepreneurs restore stream and wetland ecosystem services to earn offset credits. in these markets, code-executed algorithms constituting spreadsheets, web maps, and gis utilities generate, relate, and make sense of the data that define credit commodities. i argue that code tends toward three effects: producing a landscape defined by wetlands' modeled value, performing social relations associated with nature 's neoliberalization and financialization, and legitimating these moves. although emphasis on the performativity of code and other technological objects is warranted, the contexts in which these are authored, deployed, and evaluated should remain central to understanding environmental governance. this is to caution against seeing technology as reducing nature and society to state or capitalist rationalities and to hesitate to differentiate prima facie code 's work on space and on nature. i call for bridging political ecology and geographies of technology in ways that can explain how code is generative of environmental knowledge, change, and conflict.
electrical_circuits	the battery state of charge (soc) is an important parameter of the battery capacity state. it can only be indirectly estimated through measurable variables such as voltage, current and temperature. accurate estimation of soc is one of the key problems in a battery management system. a battery model based on equivalent electrical circuits has been used to describe the battery dynamics. the model has been experimentally validated using a laboratory test. the battery soc has been estimated in real time by means of two methods: luenberger observer and kalman filter. this paper presents a comparison between the two model based soc estimation algorithms.
electric_motor	this paper concerns a light electric vehicle (ev) application, based on magnetic transmission. this magnetic transmission is capable to offer extended speed range and it contains an in-wheel motor, which integrates a magnetic gear. in our case, the magnetic gear is multiplying the in-wheel motor speed with a factor of 3.4, offering the possibility to have very high speed for our light ev, without the necessity to supply the electric motor at high frequencies; it means that an efficiency improvement is expected for such magnetic gear integrated topology. this study is carried out by means of numerical analysis and the performances of the in-wheel motor with integrated magnetic gear are evaluated with the finite element method.
lorentz_force_law	to facilitate the motion control of ironless planar motors with stationary circular coils, in this paper, a real-time model is proposed to predict the force and torque exerted on a magnet array. the force and torque are calculated with lorentz force law, which can be essentially expressed as the calculation of the volume integral. due to the symmetry of the circle, the force and torque generated by the coil will not change when the circular coil rotates around its z-axis. this characteristic is then significantly utilized in the calculation of the volume integral, and the integral in the real-time model calculation is independent of the position and the rotation angle of the moving magnet array. the calculation result of the numerical integrals can be considered as constants, and thus the real-time model in this paper can be computed quickly. finally, experiments are carried out to provide verification of the proposed real-time model. the computation time of the model on a digital signal processor system is <15 mu s, and the force and torque predicted by the model are rigidly consistent with the measurement data.
operating_systems	a significant challenge faced by the mobile application industry is developing and maintaining multiple native variants of mobile applications to support different mobile operating systems, devices and varying application functional requirements. the current industrial practice is to develop and maintain these variants separately. any potential change has to be applied across variants manually, which is neither efficient nor scalable. we consider the problem of supporting multiple platforms as a 'software product-line engineering' problem. the paper proposes a novel application of product-line model-driven engineering to mobile application development and addresses the key challenges of feature-based native mobile application variants for multiple platforms. specifically, we deal with three types of variations in mobile applications: variation due to operation systems and their versions, software and hardware capabilities of mobile devices, and functionalities offered by the mobile application. we develop a tool moppet that automates the proposed approach. finally, the results of applying the approach on two industrial case studies show that the proposed approach is applicable to industrial mobile applications and have potential to significantly reduce the development effort and time. (c) 2016 elsevier inc. all rights reserved.
digital_control	design and implementation of a low cost grid-connected 5kva solar photovoltaic (pv) system is proposed in this paper. since the inverter is a major component of the pv system, the b4 inverter used in this paper reduces the total cost of the pv system. in order to eliminate the massive transformer, the pv system is connected to the grid through igbt switches. in addition to injection of active power into the grid, the b4 inverter can compensate reactive power and reduce harmonics of the nonlinear loads. a tms320f28335 dsp processor is used for effective control of the b4 inverter. various features of this processor enable the implementation of the necessary control algorithms. as a first step, the pv system is simulated and evaluated in matlab/simulink. in the second step, hardware circuits are designed and implemented based on the simulation results. the operation of the pv system has been evaluated under balanced, unbalanced, linear and nonlinear loads which proves its accuracy and efficiency.
image_processing	one of the main complications caused by diabetes mellitus is the development of diabetic foot, which in turn, can lead to ulcerations. because ulceration risks are linked to an increase in plantar temperatures, recent approaches analyze thermal changes. these approaches try to identify spatial patterns of temperature that could be characteristic of a diabetic group. however, this is a difficult task since thermal patterns have wide variations resulting on complex classification. moreover, the measurement of contralateral plantar temperatures is important to determine whether there is an abnormal difference but, this only provides information when thermal changes are asymmetric and in absence of ulceration or amputation. therefore, in this work is proposed a quantitative index for measuring the thermal change in the plantar region of participants diagnosed diabetes mellitus regards to a reliable reference (control) or regards to the contralateral foot (as usual). also, a classification of the thermal changes based on a quantitative index is proposed. such classification demonstrate the wide diversity of spatial distributions in the diabetic foot but also demonstrate that'it is possible to identify common characteristics. an automatic process, based on the analysis of plantar angiosomes and image processing, is presented to quantify these thermal changes and to provide valuable information to the medical expert. (c) 2017 elsevier b.v. all rights reserved.
parallel_computing	in multivariate or spatial extremes, inference for max-stable processes observed at a large collection of points is a very challenging problem and current approaches typically rely on less expensive composite likelihoods constructed from small subsets of data. in this work, we explore the limits of modern state-of-the-art computational facilities to perform full likelihood inference and to efficiently evaluate high-order composite likelihoods. with extensive simulations, we assess the loss of information of composite likelihood estimators with respect to a full likelihood approach for some widely used multivariate or spatial extreme models, we discuss how to choose composite likelihood truncation to improve the efficiency, and we also provide recommendations for practitioners. this article has supplementary material online.
structured_storage	this article leads the concept of data visualization into the huge amounts of news data, design and implements a system of news data visual system (ndvs). it is a news gathering, analysis, structured storage and visual analysis system. ndvs collects news data in the schedule time from seeds website by a web spider that written by java every day. the structured documents that processed and analyzed by detached parameters from url and classify news will be saved in distributed database of nosql - mongodb. web will visually and interactively animate the documents in the means of d3.js. design and realization of ndvs will be emphasized in the article, and we find that ndvs has a good capability when lots of clients concurrent access. we believe ndvs will become a useful tool between news and media works, because system follows the usability policy that helps people to find the potential tendency of news' development and guide the public opinion in the stage of visualization design.
parallel_computing	algorithms for extracting hydrologic features and properties from digital elevation models (dems) are challenged by large datasets, which often cannot fit within a computer 's ram. depression filling is an important preconditioning step to many of these algorithms. here, i present a new, linearly scaling algorithm which parallelizes the priority-flood depression-filling algorithm by subdividing a dem into tiles. using a single-producer, multi-consumer design, the new algorithm works equally well on one core, multiple cores, or multiple machines and can take advantage of large memories or cope with small ones. unlike previous algorithms, the new algorithm guarantees a fixed number of memory access and communication events per subdivision of the dem. in comparison testing, this results in the new algorithm running generally faster while using fewer resources than previous algorithms. for moderately sized tiles, the algorithm exhibits similar to 60% strong and weak scaling efficiencies up to 48 cores, and linear time scaling across datasets ranging over three orders of magnitude. the largest dataset on which i run the algorithm has 2 trillion (2 x 10(12)) cells. with 48 cores, processing required 4.8 h wall-time (93 compute-days). this test is three orders of magnitude larger than any previously performed in the literature. complete, well commented source code and correctness tests are available for download from a repository. (c) 2016 elsevier ltd. all rights reserved.
distributed_computing	the programming of heterogeneous clusters is inherently complex, as these architectures require programmers to manage both distributed memory and computational units with a very different nature. fortunately, there has been extensive research on the development of frameworks that raise the level of abstraction of cluster-based applications, thus enabling the use of programming models that are much more convenient that the traditional one based on message-passing. one of such proposals is the hierarchically tiled array (hta), a data type that represents globally distributed arrays on which it is possible to perform a wide range of data-parallel operations. in this paper we explore for the first time the development of heterogeneous applications for clusters using htas. in order to use a high level api also for the heterogenous parts of the application, we developed them using the heterogeneous programming library (hpl), which operates on top of opencl but providing much better programmability. our experiments show that this approach is a very attractive alternative, as it obtains large programmability benefits with respect to a traditional implementation based on mpi and opencl, while presenting average performance overheads just around 2%.
electrical_circuits	the software support for simulation of electrical circuits has been developed for more than sixty years. currently, the standard tools for simulation of analogous circuits are the simulators based on the open source package simulation program with integrated circuit emphasis generally known as spice (biolek 2003). there are many different applications that provide graphical interface and extended functionalities on the basis of spice or, at least, using spice models of electronic devices. the author of this paper performed a simulation of a circuit that acts as an electronic diode in multisim and provides a comparison of the simulation results with the results obtained from measurements on the real circuit.
state_space_representation	inter-turn short-circuit (itsc) fault is one of the most typical fault in different types of magnetically coupled circuits such as transformers and rotating or linear electrical machines. this paper presents a general study to approach the itsc understanding and modeling as long as the circuit can be represented in state-space (ss) equations. the itsc in any magnetically coupled windings can be accurately modelled by means of step-down autotransformer circuit in the faulty winding. moreover, considerations about the leakage inductances estimation are studied and generalized. a case of study of itsc is proposed: three-phase squirrel-cage induction machine. ss representation of the system is presented and simulated in matlab environment by means of ode and simulink. also, equivalent circuits derived from the ss representation are shown. for verification purposes finite element analysis (fea) and experimental test are conducted. a comparison between the proposed theoretical models, simulations and experimental results is performed.
microcontroller	wood is a widely used material in various applications where its dimensional stability is of practical interest in the design and performance of wooden materials. the change in geometry of wood depends upon the environmental conditions (such as relative humidity) as well as internal structure and composition of wood. this work presents a measurement technique and development of the associated system for the measurement of strain changes of wood samples with relative humidity. the developed system is capable of measuring the strain change and relative humidity (rh) with temperature compensation. the system comprises of strain gauge based strain measurement unit and rh sensor with its related signal conditioning circuit along with temperature sensor. the strain gauge signal conditioning is based on quarter bridge method with high precision resistors which is excited by an ac source. the whole system is centered on an 8-bit risc microcontroller (pic18f43k22). the built in 10-bit analog to digital converter (adc) is used to read the strain and ambient rh. the temperature is directly read from temperature to digital converter using zacwire (tm) interface. the measurement system is calibrated using a cantilever of stainless steel and is used for collecting and analyzing data of four wood samples. the uncertainties associated with the measurements are reported in the paper. experimental results obtained for a few wood samples are presented. (c) 2016 elsevier ltd. all rights reserved.
operating_systems	smartphones have become an integral part of our daily life. businesses now offer services through smartphones. users also store sensitive personal information on their smartphones and perform financial transactions. consequently, security attacks on smartphone platforms have also increased significantly. traditional desktop anti-virus software are not very effective in smartphones due to the restrictive security model and they are heavily dependent on their definition updates. in this paper, we propose a secure anti-malware framework (sam) for smartphone operating systems to prevent malicious activities. the core idea of the framework resembles a smart city. the framework acts as the government of the city and treats the applications as citizens. it has components to enforce laws (prevent) and perform policing (monitor and control). it also provides apis to aid anti-virus software and third-party applications to leverage the functionalities of the framework. our goal is to design an operating system framework that hinders malicious activities and thus protects user resources.
digital_control	this article presents basic concepts and recent research directions about the stability of sampled-data systems with aperiodic sampling. we focus mainly on the stability problem for systems with arbitrary time-varying sampling intervals which has been addressed in several areas of research in control theory. systems with aperiodic sampling can be seen as time-delay systems, hybrid systems, input/output interconnections, discrete-time systems with time-varying parameters, etc. the goal of the article is to provide a structural overview of the progress made on the stability analysis problem. without being exhaustive, which would be neither possible nor useful, we try to bring together results from diverse communities and present them in a unified manner. for each of the existing approaches, the basic concepts, fundamental results, converse stability theorems (when available), and relations with the other approaches are discussed in detail. results concerning extensions of lyapunov and frequency domain methods for systems with aperiodic sampling are recalled, as they allow to derive constructive stability conditions. furthermore, numerical criteria are presented while indicating the sources of conservatism, the problems that remain open and the possible directions of improvement. at last, some emerging research directions, such as the design of stabilizing sampling sequences, are briefly discussed. (c) 2016 elsevier ltd. all rights reserved.
electrical_network	modeling of cancerous and healthy homo sapiens colon gene using electrical network is proposed to study their behavior. in this paper, the individual amino acid models are designed using hydropathy index of amino acid side chain. the phase and magnitude responses of genes are examined to screen out cancer from healthy genes. the performance of proposed modeling technique is judged using various performance measurement metrics such as accuracy, sensitivity, specificity, etc. the network model performance is increased with frequency, which is analyzed using the receiver operating characteristic curve. the accuracy of the model is tested on colon genes and achieved maximum 97% at 10-mhz frequency.
electrical_network	among various nanofillers for composite systems, carbon-based fillers such as graphite, carbon fibers, carbon black, carbon nanotubes, graphene, etc. are attracting great attention in both academia and industry for the advent of highly integrated electronic devices. the objective in fabricating such composite materials is to obtain distinct properties evolved from the synergistic effects of the component materials that may be exploited for various applications such as electronics and optical devices. in the present work, polyurethane/graphite composites have been synthesized with the aim of using them for electromagnetic shielding applications. the polyurethane/graphite composites were prepared through an in situ polymerization method in the presence of graphite nanoparticles. the prepared composites were characterized by scanning electron microscope, transmission electron microscope (tem), and x-ray diffraction techniques. the shifting of the major peak of graphite nanoplatelets (gnps) in prepared nanocomposites towards the left from 26.336a degrees d-spacing = 3.381 to 25.374a degrees d-spacing = 3.507 on a 2 theta scale indicates the intercalation type of dispersion in the prepared nanocomposites. this was further validated with the tem characterization. the introduction of gnps in polyurethane (pu) during in situ polymerization creates an electrical network in the resulting composite, which therefore makes it highly conductive. the prepared nanocomposite showed an electrical network at 2.2 vol.% of the percolation threshold in dc condition and a similar percolation threshold was found at 100 hz in ac conditions. the maximum conductivity found at 6.5 vol.% of filler loading was 0.01 s/cm. the resulting composites were evaluated for electromagnetic interference (emi) shielding at different filler loadings. the prepared pu/gnps composites were found to be highly effective with shielding effectiveness of 19.34 db, and with electromagnetic interference shielding materials at 0.9-1 ghz.
electricity	the present study focuses on measuring the effects of industrial wastewater disposed from thermal electricity power plant as by-product on the geotechnical properties of sandy soil and applying washing process to remediate the contaminated soil samples and measure the efficiency of washing technique. the disturbed sandy soil samples were obtained from al-kufa city located to the southwest of iraq and the industrial wastewater obtained from al-musayib thermal electricity power plant. the intact sandy soil was contaminated in the laboratory with four percentages of industrial wastewater (10, 20, 40 and 100%) calculated according to the weight of dry soil. the industrial wastewater is mixed with distilled water to constitute the solution used in the contamination process of soil through soaking the soil by this solution for 30 days. the study results showed that with increasing the percentages of the contaminant, there was a slight increase in both the liquid limit and particle size, while there was a significant increase in the optimum water content. nevertheless, a slight decrease was observed in the specific gravity, maximum dry unit weight, and void ratio, while, a considerable decrease was noticed in the angle of the internal friction and coefficient of permeability of soil. the proposed remediation technique ""soil washing"" is efficient, economical, and time saving when used to remediate sandy soils. after remediation, the results showed an increase in the cohesion, angle of internal friction and maximum dry unit weight. also, a slight increase was observed in the specific gravity, void ratio and permeability coefficient of remediated soil samples when compared with that of contaminated samples. the removal efficiencies of contaminant from soil were (97.63, 96.79, 96.58, and 93.87%) for the soil samples contaminated with industrial wastewater by (10, 20, 40 and 100%), respectively.
relational_databases	in recent years, the database technology has been widely used in a few fields. the keyword search technology based on relational databases does not require users to master any knowledge of sql grammar and database schema. users only need to input keywords, and conveniently search information via keyword like internet search engines. as results, users are pleased to use the technology. in this paper, we employee a query expansion plan based on the query sentence, and propose a query expansion method based on thesaurus. the method matches key words with the thesaurus. if the key word matches a word in the thesaurus, and the words in the same row are used as a synonym for the key word. test results show that the recall and precision ratio of the system are satisfied with needs of applications.
analog_signal_processing	renewable energy sources are likely to become essential due to continuously increasing energy demands together with the depletion of natural resources that are currently used for power generation, such as coal and gas. they are also advantageous in terms of their reduced environmental impact. here, the generation of electrical power from vortex-induced vibration (viv) of a cylinder is investigated numerically. the cylinder is free to oscillate in the direction transverse to the incoming flow. the cylinder is attached to a magnet that can move along the axis of a coil made from conducting wire. the magnet and the coil together constitute a basic electrical generator. when the cylinder undergoes viv, the motion of the magnet creates a voltage across the coil, which is connected to a resistive load. by lenz 's law, induced current in the coil applies a retarding force to the magnet. effectively, the electrical generator applies a damping force on the cylinder with a spatially varying damping coefficient. for the initial investigation reported here, the reynolds number is restricted to re <= 200, so that the flow is laminar and two-dimensional (2d). the incompressible 2d navier-stokes equations are solved using an extensively validated spectral-element based solver. the effects of the electromagnetic (em) damping constant xi(m), coil dimensions (radius a, length l), and mass ratio on the electrical power extracted are quantified. it is found that there is an optimal value of xi(m) (xi(opt)) at which maximum electrical power is generated. as the radius or length of the coil is increased, the value of xi(opt) is observed to increase. although the maximum average power remains the same, a larger coil radius or length results in a more robust system in the sense that a relatively large amount of power can be extracted when xi(m) is far from xi(opt) unlike the constant damping ratio case. the average power output is also a function of reynolds number, primarily through the increased maximum oscillation amplitude that occurs with increased reynolds number at least within the laminar range, although the general qualitative findings seem likely to carry across to high reynolds number viv.
software_engineering	context: software engineering (se) has a multidisciplinary and dynamic nature that makes it challenging to design its educational material. guide to the software engineering body of knowledge (swebok) which has evolved to become iso/iec 19759 standard has identified various knowledge areas to be part of any se curricula. although there is a number of studies that address the gap between se curricula and software industry, the literature lacks defining a process that can be leveraged for continuously improving se curricula to fulfill the software development market demands. objective: in this paper, we propose a software engineering curricula development and evaluation process (secdep) that takes advantage of the swebok guidelines to improve the quality of se programs based on objective and subjective evidences. method: our process consists of multi-steps in which the local software market needs and the target se program objectives and constraints are all taken into consideration. as a case study, we follow our process to investigate the core se courses delivered as part of the se curricula in a set of universities in our region. results: the conducted case study identifies the factors that might contribute to mitigating the skills shortages in the target software market. we demonstrate the effectiveness of our process by identifying the weaknesses of the studied se curricula and presenting recommendations to align the studied curricula with the demands of the target software market, which assists se educators in the design and evaluation of their se curricula. conclusion: based on the obtained results, the studied se curricula can be enhanced by incorporating latest se technologies, covering most of the swebok knowledge areas, adopting se curricula standards, and increasing the level of industrial involvement in se curricula. we believe that achieving these enhancements by se educators will have a positive impact on the se curricula in question. (c) 2016 elsevier b.v. all rights reserved.
electric_motor	the determination of the efficiency of an electric motor or an inverter in an electric vehicle requires power measurements on the ac side of the inverter. voltage and current signals arise there from the switching operation of the inverter and are therefore hardly bandlimited. the finite bandwidth of measurement devices, like sensors or adcs, yields to a bandwidth limitation of the measured signals. this limitation modifies the measured signals and has an effect on the calculated power. measurement uncertainty considerations require the evaluation of the relation between this bandwidth limitation and the resulting error in the power measurement. this relation allows then for evaluating the significance of the spectral components for the power calculation and the decision which components are relevant and must not be filtered out by a bandwidth limitation. this paper presents an evaluation method for determining the bandwidth limitation error and identifies critical quantities in a numerical study.
microcontroller	today the 3d reconstruction of faces is an actual task. it is being used in various fields, for example, in scientific research, in recognition, in video games and in the movie industry. one of the existing methods of reconstructing 3d models of faces uses stereo cameras. the reconstruction process usually consists of several steps: calibration of cameras, acquiring the depth map (disparity map) and the creation of the 3d model. in this paper a method of acquiring a depth map is proposed that can later be used for the reconstruction of a 3d model of a face. the proposed method was tested in a virtual environment- a 3d editor ""autodesk 3ds max"" was used to create a virtual scene containing stereo cameras and a human head. the proposed method was also tested using two ""visar"" cameras, and an ""arduino micro"" microcontroller. ""arduino"" software allows to ensure synchronization of cameras, when using the ""arduino micro"" microcontroller. the images are captured from the cameras by using the ""flycap"" program. since the initial images contain distortions, the first step of the algorithm is the calibrations of cameras. for calibration, similar points are found on both stereo images. these points are later used to calculate the degree of distortion, and the images are rectified accordingly. the rectified images are used to calculate the depth map. the depth map is created from the front half-tone images of faces. (c) 2017 the authors. published by elsevier b.v.
signal-flow_graph	this paper presents a systematic development of steady-state, small-signal models of interleaved dual boost converter operating in a continuous current mode. these models are derived by employing the well-known signal flow graph method. this signal flow graph approach provides a means to directly translate the switching converter into its equivalent graphic model, from which a complete behaviour of the converter can easily be studied. steady-state performance, small-signal characteristic transfer functions are derived using mason 's gain formula. the bode plots of audiosusceptibility, input impedance, output impedance, and control-to-output transfer functions are determined and illustrated using matlab for different values of load resistances, duty ratios. small-signal frequency responses obtained from the signal flow graph method are validated with pspice simulator results. to validate the signal flow graph modelling equations, sample steady-state experimental results are provided. copyright (c) 2001 john wiley & sons, ltd.
distributed_computing	this work presents a parallel approach of the kinetic monte carlo (kmc) algorithm using a distributed memory architecture. the resulting computer software was tested by conducting crystal growth simulations on barite (001) face. execution times, simulated times and crystallization velocities are compared with a shared memory parallel kmc software (mmonca). finally, a approximate to 1 mu m(2) crystal growth simulation is performed and compared with atomic force microscopy crystal growth experiments. the capability of this approach is demonstrated: a) a significant reduction of parallel overhead is achieved when comparing to the shared memory parallel version of the software, b) a distributed memory approach achieves an increase in memory resources enough to perform simulations with lattice sizes about 1 mu m(2), allowing the study of larger structures than those in shared memory or sequential implementations, c) this approach should be used only with large scale simulations to take advantage of the distributed memory architecture, d) further improvements are needed for parallel kmc to be faster than serial kmc in small scale simulations, e) the kmc algorithm used is able to adequately simulate two-dimensional nucleation on large areas of barite (001) faces.
computer_vision	with the growing interest in computational models of visual attention, saliency prediction has become an important research topic in computer vision. over the past years, many different successful saliency models have been proposed especially for image saliency prediction. however, these models generally do not consider the dynamic nature of the scenes, and hence, they work better on static images. to date, there has been relatively little work on dynamic saliency that deals with predicting where humans look at videos. in addition, previous studies showed that how the feature integration is carried out is very crucial for more accurate results. yet, many dynamic saliency models follow a similar simple design and extract separate spatial and temporal saliency maps which are then integrated together to obtain the final saliency map. in this paper, we present a comparative study for different feature integration strategies in dynamic saliency estimation. we employ a number of low and high-level visual features such as static saliency, motion, faces, humans and text, some of which have not been previously used in dynamic saliency estimation. in order to explore the strength of feature integration strategies, we investigate four learning-based (svm, gradient boosting, nnls, random forest) and two transformation based (mean, max) fusion methods, resulting in six new dynamic saliency models. our experimental analysis on two different dynamic saliency benchmark datasets reveal that our models achieve better performance than the individual features. in addition, our learning-based models outperform the state-of-the-art dynamic saliency models.
operational_amplifier	we investigate analog single event transient (aset) generation in an lm124 operational amplifier using focused pulsed x-rays and 800 nm femtosecond laser pulses. we report improvements that have been made to the pulsed x-ray experimental apparatus which include normal incidence geometry and a high speed x-ray chopper that allows us to reduce the pulse repetition frequency of the synchrotron derived x-ray pulse train. the addition of the chopper allows us to measure asets that have long relaxation times. we show that asets can be generated through metallization on the lm124, and that for equivalent pulse energy incident on the part, the x-ray response from areas covered by metal (and inaccessible to the laser) are different than the x-ray response from areas with no metallization, i.e. ""metal-free"". we use the laser pulses to generate asets at the same metal-free locations of x-ray induced asets. the shapes of the asets generated by the two methods are compared. we use the differences seen from the two generation methods to estimate the charge generation/collection produced by the pulsed x-rays and then estimate what let this would correspond to for heavy ions. this work shows that pulsed x-rays can be used to characterize analog devices for single event effects.
distributed_computing	as distributed generators in distribution networks have brought much influence to the fault current, the traditional fault-section locating algorithm of distribution networks may not work. in this paper, a new switching function is built which can be used in the distribution network with single power supply and multi power supplies. a regional processing method is used in this paper, which divides the distribution network into several independent regions, then the fault locating algorithm is used in these independent regions. the regions without dg connection are eliminated if fault current is not detected. so the complexity of computation of fault-section location is reduced. ant colony algorithm is a good optimization algorithm of swarm intelligence. because of its positive feedback, fault tolerance and distributed computing features, good application effect of locating faulty section in distribution network can be attained. in order to overcome the disadvantages such as large amounts of calculation, long searching time, local optimal. ant colony algorithm is improved by adaptive dynamic modifying pheromone. ant system with elitist strategy and mmas are also used in this paper. this improved algorithm is used in distribution network with multi distributed generators. the results of example analysis show the effective and good fault tolerance of the algorithm.
state_space_representation	subspace-based model predictive control (smpc) is a combination of a result in subspace system identification with model predictive control (mpc) method. particularly, it uses the subspace linear predictor equation to predict the future value of the system in the mpc implementation, instead of the usual state-space representation. the recursive subspace identification which updates the estimation of the extended observability matrix online is presented here for a multi input- ulti output (mimo) system specifically for a nonlinear biological waste water treatment process. givens rotation is applied for recursive updating of qr decomposition of a matrix in this smpc. in smpc, the need to have an explicit state-space representation of the system is abolished, resulting in a control algorithm that performs system identification and controller design in a single simultaneous step. additionally, smpc algorithm will inherit the numerical robustness typical of subspace-based methods thus giving us an easily deployable control implementation in adaptive framework.
computer_graphics	the present paper establishes a homotopy based on marcus-wyse (for brevity m-) topology, which can contribute to the classification of 2d digital images in an m-topological approach. since m-topology is considered in the euclidean 2d space with integer coordinates, it can be used in studying 2d digital images from the viewpoints of both digital topology and digital geometry such as image processing, image analysis, computer graphics, mathematical morphology and so forth. to develop the homotopy, the present paper uses two maps such as an m-continuous map and marcus-wyse adjacency (for brevity ma-) map because they have their own features and merits. besides, using this homotopy, the present paper proposes an ma-homotopy equivalence and further, ma-contractibility which can be also used in classifying digital images. finally, the paper establishes an ma-homotopic thinning derived from the above homotopy, which can contribute to the compression of 2d digital images. (c) 2015 elsevier b.v. all rights reserved.
signal-flow_graph	in this paper, a design procedure for the realization of all current-mode biquadratic transfer functions is presented. the synthesis technique is deduced from a signal flow graph representation using current follower transconductance amplifiers (cftas). the proposed configuration has single low-impedance input and five high-impedance outputs, and comprises three cftas and two grounded capacitors. no passive resistor is required for the circuit realization, thus it is an active-c structure suitable for integration.
system_identification	identification of nonlinear block-oriented models has been extensively studied. the presence of the process noise and more precisely its location in the block-oriented model essentially influence the development of a consistent identification algorithm. this paper is proposed with the aim to localize the process noise in the block-oriented model for accurate nonlinear modeling. to this end, the response of a wiener-hammerstein system is theoretically analyzed, and the disturbance component in the output, caused by the process noise preceding the static nonlinearity, is shown to be dependent on the input signal. inspired by such a theoretical observation, a simple and new protocol is developed to determine the location of the process noise with respect to the static nonlinearity using an input signal that is periodic but nonstationary within one period. in addition, the proposed technique is promising to detect the type of certain static nonlinearity (e.g., dead zone and saturation). finally, it is validated on a simulated example and a real-life benchmark.
data_structures	the massive amounts of data processed in modern computational systems is becoming a problem of increasing importance. this data is commonly stored directly or indirectly through the use of data exchange languages, such as javascript object notation (json), for human-readable platform agnostic access. this paper focuses on describing and analyzing sjson, a library that explores succinct representations of json documents as a means to achieve reduced memory usage of tiles in main memory, and to permit the compression of json files stored in disk. in sjson we represent the document structure with succinct trees, as opposed to the usual pointer-based implementation. furthermore, the remaining raw data are organized in arrays of attributes and values. attributes are stripped of redundancies and stored in a simple contiguous array, while values are represented through a hit string indexed array. the scheme here proposed is then evaluated with respect to a number of metrics comparing its performance with popular libraries, and possible improvements to the representation are then presented.
relational_databases	lifecycle structural health monitoring (shm) systems provide an abundance of information that is greatly beneficial for securing structural safety over the whole service life. in application to large-scale structures, the management of accumulated massive data from a sophisticated long-term shm system poses a challenge. a robust data management system (dms), which not only facilitates spatiotemporal data management but also enables display in an attractive way, is highly desirable. this article presents the development of an effective visualized dms specific for managing immense and heterogeneous shm data by integrating nested relational database, three-dimensional (3d) model, and virtual reality (vr) technology and demonstrates its application to an instrumented supertall structure. a custom nested data model is designed to store redundant inherent temporal data and hierarchical inherent spatial data. strategies for speeding up querying massive data are set up in the database. making use of openscenegraph (osg) 3d engine, a 3d model is reconstructed from the 3d spatial data, which serves as a platform for data visualization. a four-dimensional (4d) animation protocol is presented by tying temporal data and construction schedule to the 3d model. the efficiency of the proposed dms is exemplified through its application to a supertall structure instrumented with a sophisticated long-term shm system. (c) 2016 american society of civil engineers.
electrical_network	this paper deals with the electrical modeling of lithium-ion polymer battery, from complementary characterization tests. the first aim of this work is to understand the electrical behavior of this battery through experimentations in the same environmental conditions as the final application 's ones. the second goal of this work is to identify battery models with different precision levels and to implement them in specific models of the considered aircraft electrical network. in this paper, two equivalent electrical circuit models are presented: a quasi-static model, which is functional and sufficient for the electrical energy management in the aircraft; a dynamic model, which is behavioral and necessary for the analysis of the embedded network quality. the identification of their parameters is carried out with adapted characterization tests, such as chronopotentiometry at constant current and electrochemical impedance spectroscopy at different temperatures. the complementarity of these tests is particularly underlined in this paper because it is useful for the parameter identification. the results from model simulation and from experimentation are compared through a mission profile and are analyzed. eventually, this paper presents complete experimental data for a commercial 4.8 ah lithium-ion polymer battery including the temperature influence. (c) 2014 elsevier ltd. all rights reserved.
distributed_computing	to solve the adverse effects brought by resource node transfering the using right to local task and the difficult problem of resource load balancing, a two-phase pricing strategy based on qos constraints is proposed in this paper. on the premise of guaranteeing the benefits of the resource provider in the cost price, this strategy balances the load of the resource provider by the profit price. the theoretical analysis proves the effectiveness of the pricing strategy, and the algorithm of the pricing strategy is designed in this paper. resources node information in the real distributed systems is used as the performance parameters of experimental node in the simulation experiments, and the performance of the pricing strategy is tested in a large-scale grid mission. experimental results show that, compared with the traditional pricing strategies, the two-phase pricing strategy based on qos constraints has vastly superior performance on the benefits of the resource provider and the balance of resource utilization.
parallel_computing	in this work we aim to detect faces in violence scenes, in order to help the security control. we used the violent flow (vif) descriptor with horn-schunck proposed in [ 50] for violence scenes detection at first stage. then we applied the non-adaptive interpolation super resolution algorithm to improve the video quality and finally we fire a kanade-lucas-tomasi (klt) face detector. in order to get a very low time processing, we paralleled the super resolution and face detector algorithms with cuda. for the experiments we used the boss dataset and also we built a violence dataset, taking scenes from surveillance cameras. we have promising results detecting faces in this environment, because of the benefits of our proposal.
machine_learning	background: the fourth round of the critical assessment of small molecule identification (casmi) contest (www. casmi-contest. org) was held in 2016, with two new categories for automated methods. this article covers the 208 challenges in categories 2 and 3, without and with metadata, from organization, participation, results and postcontest evaluation of casmi 2016 through to perspectives for future contests and small molecule annotation/identification. results: the input output kernel regression (csi: iokr) machine learning approach performed best in ""category 2: best automatic structural identification-in silico fragmentation only"", won by team brouard with 41% challenge wins. the winner of ""category 3: best automatic structural identification-full information"" was team kind (msfinder), with 76% challenge wins. the best methods were able to achieve over 30% top 1 ranks in category 2, with all methods ranking the correct candidate in the top 10 in around 50% of challenges. this success rate rose to 70% top 1 ranks in category 3, with candidates in the top 10 in over 80% of the challenges. the machine learning and chemistry-based approaches are shown to perform in complementary ways. conclusions: the improvement in (semi-) automated fragmentation methods for small molecule identification has been substantial. the achieved high rates of correct candidates in the top 1 and top 10, despite large candidate numbers, open up great possibilities for high-throughput annotation of untargeted analysis for ""known unknowns"". as more high quality training data becomes available, the improvements in machine learning methods will likely continue, but the alternative approaches still provide valuable complementary information. improved integration of experimental context will also improve identification success further for ""real life"" annotations. the true ""unknown unknowns"" remain to be evaluated in future casmi contests.
system_identification	due to intermittent and adulatory properties of wind energy, when large-scale wind farm connected to the grid, it will have much impact on the power system, which is different from traditional power plants. therefore it is necessary to establish an effective wind farm model to simulate and analyze the influence wind farms have on the grid as well as the transient characteristics of the wind turbines when the grid is at fault. however we must first establish an effective wtgs model. as the doubly-fed vscf wind turbine has become the mainstream wind turbine model currently, this article first investigates the research progress of doubly-fed vscf wind turbine, and then describes the detailed building process of the model. after that investigating the common wind farm modeling methods and pointing out the problems encountered. as wams is widely used in the power system, which makes online parameter identification of the wind farm model based on off-output characteristics of wind farm be possible, with a focus on interpretation of the new idea of identification-based modeling of large wind farms, which can be realized by two concrete methods.
symbolic_computation	korteweg-de vries (kdv)-type equation can be used to characterise the dynamic behaviours of the shallow water waves and interfacial waves in the two-layer fluid with gradually varying depth. in this article, by virtue of the bilinear forms, rational solutions and three kind shapes (soliton-like, kink and bell, anti-bell, and bell shapes) for the nth-order soliton-like solutions of a coupled kdv system are derived. propagation and interaction of the solitons are analyzed: (1) potential u shows three kind of shapes (soliton-like, kink, and anti-bell shapes); potential v exhibits two type of shapes (soliton-like and bell shapes); (2) interaction of the potentials u and v both display the fusion phenomena.
computer_programming	the main contribution of this paper is the introduction of a continuous improvement cycle for devising teaching scenarios and conducting learning experiences in engineering. the proposed cycle consists of seven steps on which gamification theory and abet criteria are combined. it arose from the adaptation of a gamification design framework, commonly used in industry, into the specific context of high quality education in engineering. it is formulated at high level. consequently, it should be useful for practitioners having different requirements and expectations. a developed practice, following the proposed cycle, is presented, discussed and evaluated. in particular, the proposal is applied and exemplified, in a scenario for teaching introductory concepts of computer programming in a first-year course. a digital game was used within a gamified learning experience, as a teaching tool. however, the learning process does not rely solely on the use of the game by itself. moreover, the devised scenario has a purpose beyond edutainment: contributing to achievement of student outcomes, under a continuous improvement approach, according to abet. a quantitative and qualitative evaluation of the developed practice was performed. a positive impact on students' emotional engagement and behavior was observed as a result of the evaluation process.
electric_motor	the condition monitoring of an electric motor is critical to its stable and reliable operation. the consequence of a fault is the variation in output performance and changes in the input electrical signature. one of the most common methods of fault detection is by analyzing the input current signature but this often requires expensive sensors. the other symptom of a faulty machine is when it runs ""hot"" due to an increase in losses generated. temperature changes could be a useful indicator of the underlying fault. in this paper, a method of condition monitoring using temperature sensors embedded in an electric motor is presented. the components of electromagnetic losses generated are determined indirectly from temperature measurement in real time for a continuous drive cycle simulating normal and faulty operations. this is achieved through the inversion of the thermal model of the machine coupled with the application of a recursive parameter estimation method. using temperature measurement for condition monitoring is advantageous since temperature sensors are low cost and already embedded in the machine for thermal protection. however, application of the method to a faulty motor and evaluation of its effectiveness in fault detection will be reported in a future work.
state_space_representation	in this paper, the development of a novel controller for a bidirectional buck and boost converter is studied to implement an active capacitance. to this end, an averaging method is used to obtain a nonlinear state-space model of the converter in the continuous conduction mode (ccm) for buck and boost configurations, separately. these models are then combined into a state-space representation for the whole range of operation. using the obtained model, a controller is designed to track a desired input current based on the applied input voltage such that the circuit exhibits a capacitive effect between the input terminals. the converter along with its proposed control method is a suitable replacement for the commonly used electrolytic capacitors in different applications. simulation results are presented that demonstrate performance of the proposed current control method. experimental verification is currently under investigation.
microcontroller	this study presents an animal mobility system, equipped with a positioning running wheel (prw), as a way to quantify the efficacy of an exercise activity for reducing the severity of the effects of the stroke in rats. this system provides more effective animal exercise training than commercially available systems such as treadmills and motorized running wheels (mrws). in contrast to an mrw that can only achieve speeds below 20 m/min, rats are permitted to run at a stable speed of 30 m/min on a more spacious and high-density rubber running track supported by a 15 cm wide acrylic wheel with a diameter of 55 cm in this work. using a predefined adaptive acceleration curve, the system not only reduces the operator error but also trains the rats to run persistently until a specified intensity is reached. as a way to evaluate the exercise effectiveness, real-time position of a rat is detected by four pairs of infrared sensors deployed on the running wheel. once an adaptive acceleration curve is initiated using a microcontroller, the data obtained by the infrared sensors are automatically recorded and analyzed in a computer. for comparison purposes, 3 week training is conducted on rats using a treadmill, an mrw and a prw. after surgically inducing middle cerebral artery occlusion (mcao), modified neurological severity scores (mnss) and an inclined plane test were conducted to assess the neurological damages to the rats. prw is experimentally validated as the most effective among such animal mobility systems. furthermore, an exercise effectiveness measure, based on rat position analysis, showed that there is a high negative correlation between the effective exercise and the infarct volume, and can be employed to quantify a rat training in any type of brain damage reduction experiments.
symbolic_computation	we present two new matrix spectral problems, and construct the corresponding soliton hierarchies of levi type with the aid of symbolic computation by maple. bi-hamiltonian structures of the resulting soliton hierarchies are obtained by means of the trace identity. thus it is shown that these soliton hierarchies are liouville integrable. (c) 2014 elsevier b.v. all rights reserved.
electrical_network	this paper presents a load control method for small data centers, which are rarely studied although they account for more than 50% of all data centers. the method utilizes the data network and the electrical network to control power usage for participation in demand response (dr) programs, which are regarded as the killer applications of the emerging smart grid (sg). traditional data center power management often directly manipulates energy usage, which may be ineffective or impractical for small data centers due to their limited resources. both the sg and the data centers are considered to be the cyber-physical systems (cpss). this article proposes an approach that performs the data center dr load management through the cyberspaces of the sg and the targeted data center. the proposed method instructs the workload dispatcher to select the best-suited algorithm when a dr event is issued. additionally, this method also adjusts the temperature set-points of the air conditioners. the simulation result shows that this approach can achieve a 30% power reduction for dr. (c) 2013 elsevier b.v. all rights reserved.
cryptography	the authors describe a method for producing boolean functions of degree d3 in n=2dk-1 (k=1, 2, ...) variables, such that the functions are plateaued and balanced, have high nonlinearity and have no linear structures. the nonlinearity is 2(n-1)-2((n-1)/2), which is the same as the largest possible nonlinearity for a quadratic function in n (odd) variables (the so-called quadratic bound'). their theorem uses some new ideas to generalise a theorem, which gave the case d=3, in a 2009 paper by fengrong zhang et al. they discuss the cryptographic properties and applications for the functions.
network_security	network structures and human behaviors are considered as two important factors in virus defense currently. however, due to ignorance of network security, normal users usually take simple activities, such as reinstalling computer system, or using the computer recovery system to clear virus. how system recovery influences virus spreading is not taken into consideration currently. in this paper, a new virus propagation model considering the system recovery is proposed first, and then in its steady-state analysis, the virus propagation steady time and steady states are deduced. experiment results show that models considering system recovery can effectively restrain virus propagation. furthermore, algorithm with system recovery in ba scale-free network is proposed. simulation result turns out that target immunization strategy with system recovery works better than traditional ones in ba network.
software_engineering	context: over the past 50 years numerous studies have investigated the possible effect that software engineers' personalities may have upon their individual tasks and teamwork. these have led to an improved understanding of that relationship; however, the analysis of personality traits and their impact on the software development process is still an area under investigation and debate. further, other than personality traits, ""team climate"" is also another factor that has also been investigated given its relationship with software teams' performance. objective: the aim of this paper is to investigate how software professionals' personality is associated with team climate and team performance. method: in this paper we detail a systematic literature review (slr) of the effect of software engineers' personality traits and team climate on software team performance. results: our main findings include 35 primary studies that have addressed the relationship between personality and team performance without considering team climate. the findings showed that team climate comprises a wide range of factors that fall within the fields of management and behavioral sciences. most of the studies used undergraduate students as subjects and as surrogates of software professionals. conclusions: the findings from this slr would be beneficial for understanding the personality assessment of software development team members by revealing the traits of personality taxonomy, along with the measurement of the software development team working environment. these measurements would be useful in examining the success and failure possibilities of software projects in development processes. general terms: human factors, performance. (c) 2016 elsevier b.v. all rights reserved.
operational_amplifier	in this paper, we elaborate a program based on multi-objective genetic algorithms (mogas) to allow automated optimization of analog circuits. the proposed methodology is used to find the optimal transistors sizes (length and width) in order to obtain operational amplifier performances for analog and mixed cmos-based circuit applications. eight performances are considered in this study, direct current (dc) gain, unity-gain bandwidth (gbw), phase margin (pm), power consumption (p), area (a), slew rate (sr), thermal noise and signal to noise ratio (snr). the program is solved using matlab optimization toolbox (tm) solvers. also by using variables obtained from genetic algorithms, the operational transconductance amplifier (ota) is simulated by using cadence virtuoso spectre circuit simulator in standard tsmc (taiwan semiconductor manufacturing company) rf 0.18 mu m cmos technology. a good agreement is observed between the program optimization and electric simulation.
operational_amplifier	a two-stage large-capacitive-load amplifier with multiple cross-coupled small-gain stages is proposed in this paper. the cross-coupled structure of the small-gain stages augments the large-signal responses, providing significant improvement in the effective output-stage transconductance and, hence, the gain-bandwidth product (gbw). implemented in a standard 0.13-mu m cmos technology and powered by a 0.7 v supply with a current consumption of 20 mu a, the proposed amplifier achieves the gbw of 1.17 mhz and the phase margin of 74.8 degrees while driving a capacitive load of 9.5 nf. the average slew rate is 0.3679 v/mu s. the on-chip compensation capacitor is only 1.62 pf. the active chip area is 0.0056 mm(2).
electric_motor	efficient utilization of the satellite radio resource is of paramount importance to a satellite system 's performance and economic competitiveness. the likely use of ka band and above frequencies for future satellite systems and the need for a better quality of service (qos) complicate the radio resource management process especially in the return link of a satellite system, one that connects the user to the gateway or hub. this paper discusses the research themes that are part of the phd research, carried out at supaero, aimed at developing radio resource management algorithms that will ultimately improve the resource utilization and the qos for the return link of interactive broadband satellite systems employing fade mitigation techniques at ka/q/v band frequencies. the inputs and optimization criteria for the resource management process are identified. various physical layer issues that confront the process are also identified. the duration of the research is about 3 years from march 2007 to end of 2009.
network_security	in recent years, distributed and zero-day attacks have emerged as one of the most serious security threats. the incomplete knowledge and information of a stand-alone intrusion detection system (ids) is one of the main reasons for the success of these attacks. collaborative ids (cids) is one solution to address this problem. idss in this framework share their knowledge and consult with each other. having access to a larger number of detection libraries for ids configuration, along with the possibility of more cooperation with other participants in this collaborative system can lead to improved overall performance. however, a larger number of libraries and more collaborative activities increase resource consumption and communication overhead, which may in turn reduce system performance. there are a large number of papers in the literature that have utilized game theory to describe the optimal configuration of standalone or networked idss. in this paper, those works have been extended and the interactions between the attackers and idss in a cids framework have been modeled with a nonzero-sum stochastic game. in this regard, the solution concept of stationary nash equilibrium has been applied to this game to describe the optimal configuration of each ids in a cids and the expected behavior of attackers.
electricity	in this paper, a novel mixed iterative adaptive dynamic programming (adp) algorithm is developed to solve the optimal battery energy management and control problem in smart residential microgrid systems. based on the data of the load and electricity rate, two iterations are constructed, which are p-iteration and v-iteration, respectively. the v-iteration is implemented based on value iteration, which aims to obtain the iterative control law sequence in each period. the p-iteration is implemented based on policy iteration, which updates the iterative value function according to the iterative control law sequence. properties of the developed mixed iterative adp algorithm are analyzed. it is shown that the iterative value function is monotonically nonincreasing and converges to the solution of the bellman equation. in each iteration, it is proven that the performance index function is finite under the iterative control law sequence. finally, numerical results and comparisons are given to illustrate the performance of the developed algorithm.
electricity	a new facultative anaerobic exoelectrogenic strain lz-1, belonging to citrobacter freundii, has been isolated. this strain can produce current densities of 843.9 and 865.6 mu a cm(-2) using citrate or acetate as carbon source in a three-electrode configuration. the electricity generation performance was also analyzed in a dual-chamber mfc system, reaching a maximum power density of 1233 mw m(-2). in addition to acetate and citrate, other carbon sources such as pyruvate, formate, acetate, citrate and fumarate could also be utilized to produce current by strain lz-1. data supports the presence of electroacfive c-type cytochromes in c. freundii sp. when grown on ito electrodes, by linking spectroscopy and electrochemistry in situ. since facultative strains possess many desirable properties compared to anaerobic strains, strain lz-1 represents a promising exoelectrogenic species in engineering of biological catalysts for microbial electrochemistry.
bioinformatics	viral myocarditis is a common cardiovascular disease, which seriously endangers the health of people and even leads to sudden unexpected death. micrornas play very important roles in various physical and pathological processes including cardiogenesis and heart diseases. in recent years, mir-20b has been implicated in various diseases such as breast cancer, gastric cancer, hepatocellular carcinoma, cardiovascular diseases. however, the function of mir-20b in the pathological progress of viral myocarditis has not been reported. in this study, we found that mir-20b was up-regulated in mouse heart tissues post coxsackievirus b3 (cvb3) infection. bioinformatics analysis identified zfp-148, a transcription factor that plays essential roles in the regulation of virus replication, is one of the predicted targets of mir-20b. mir-20b expression was found to be up-regulated and zfp-148 protein level was markedly repressed during viral myocarditis. further studies demonstrated that mir-20b directly binds to the 3'-utr of zfp-148 and suppresses its translation. moreover, aberrant expression of mir-20b promoted the expression of anti-apoptosis proteins bcl-2 and bcl-xl, suggesting that altered gene expression might promote cardiomyocytes survival in viral myocarditis. our findings indicated that mir-20b might be a potential therapeutic target for cvb3-induced viral myocarditis and a useful marker for the diagnosis of viral myocarditis.
voltage_law	the power supply rejection (psr) based on closed-loop low-dropout regulator (ldo) is analyzed to achieve high psr in ldo, and help the designer meet the psr requirement when considering the other performances of ldo. using small signal model of mos transistor, kirchhoff 's current/voltage law, and the tool of mathematica, the psr with dc gain, poles, and zeros of power stage and six kinds of basic amplifiers in ldo is analyzed theoretically, and proved by the simulation of cadence spectre. by tabling the psr of eight error amplifier (ea) composite structures of two stages, the best combination of nmos differential input amplifier (n-da) + pmos input common source amplifier (p-cs) is proposed on account of dc psr property. an ldo containing an ea of the best structure has been designed with tsmc standard 0.35 mu m cmos process. the measurement result of psr is -75 db @ 1 khz. a novel guideline to improve psr of ldo is proposed and it provides afresh design idea. measurement results are in agreement with the analysis also.
image_processing	understanding of images via features like edges plays a vital role in many image processing applications. however, obtaining an optimum edge detector that performs well in every possible imaging condition is still an open challenge to researchers. in this paper, a quantitative analysis of some significant state of art edge detection techniques such as canny 's, prewitt, sobel, laplacian of gaussian, fuzzy based edge detection, wavelet based edge detector with hybrid edge detection technique is proposed based on the correspondence between their outcomes. the hybrid edge detection method utilizes fuzzy logic partitioning along with wavelet transformation to maintain a proper balance in the false detections i.e., false positives and false negatives rates and provides better tracking of edge information. various subjective as well as objective quality measures are provided for quantitative analysis of edge detectors. the experimental results confirm that compared to other techniques the hybrid edge detection technique outperform in terms of edge detection accuracy exclusively when the images are corrupted by noises.
relational_databases	in the today 's high-tech world the amount of data and especially spatial data is growing from day to day. databases are one of the best ways to store data. several database concepts exist for storing data, while the mostly used is the relational database concept. relational databases are very well in use for the storage of geo and non-spatial data. but in social media, like facebook or twitter, relational databases often reach their limit of performance. for huge amounts of data and frequent data changes nosql-databases can be used. these nosql-databases can be used as basis for the provision of a geo web service, like wms, wfs. the paper gives an overview of selected sql and nosql-databases according to their performance as backend for wms.
software_engineering	context: methods and processes, along with the tools to support them, are at the heart of software engineering as a discipline. however, as we all know, that often the use of the same method neither impacts software projects in a comparable manner nor the software they result in. what is lacking is an understanding of how methods affect software development. objective: the article develops a set of concepts based on the practice-concept in philosophy of sociology as a base to describe software development as social practice, and develop an understanding of methods and their application that explains the heterogeneity in the outcome. practice here is not understood as opposed to theory, but as a commonly agreed upon way of acting that is acknowledged by the team. method: the article applies concepts from philosophy of sociology and social theory to describe software development and develops the concepts of method and method usage. the results and steps in the philosophical argumentation are exemplified using published empirical research. results: the article develops a conceptual base for understanding software development as social and epistemic practices, and defines methods as practice patterns that need to be related to, and integrated in, an existing development practice. the application of a method is conceptualized as a development of practice. this practice is in certain aspects aligned with the description of the method, but a method always under-defines practice. the implication for research, industrial software development and teaching are indicated. conclusion: the theoretical/philosophical concepts allow the explaining of heterogeneity in application of software engineering methods in line with empirical research results. (c) 2015 elsevier b.v. all rights reserved.
distributed_computing	the internet shopping optimization problem arises when a customer aims to purchase a list of goods from a set of web-stores with a minimum total cost. this problem is np-hard in the strong sense. we are interested in solving the internet shopping optimization problem with additional delivery costs associated to the web-stores where the goods are bought. it is of interest to extend the model including price discounts of goods. the aim of this paper is to present a set of optimization algorithms to solve the problem. our purpose is to find a compromise solution between computational time and results close to the optimum value. the performance of the set of algorithms is evaluated through simulations using real world data collected from 32 web-stores. the quality of the results provided by the set of algorithms is compared to the optimal solutions for small-size instances of the problem. the optimization algorithms are also evaluated regarding scalability when the size of the instances increases. the set of results revealed that the algorithms are able to compute good quality solutions close to the optimum in a reasonable time with very good scalability demonstrating their practicability.
distributed_computing	cloud computing is the long envisaged vision of computing as a utility. innovative advances in hardware, networking, middleware, and virtual machine technologies have led to an emergence of new, globally distributed computing platforms, namely cloud computing. cloud computing provides computation facilities and storage as services accessible from anywhere via the internet without investing in new infrastructure, training, or software licensing. in other words, cloud computing is a way to increase the capacity or add capabilities dynamically. the main advantage of cloud computing is that users only utilize what they require and only pay for what they really use. with an exponential growth of the mobile applications and evolution of cloud computing concept, mobile cloud computing (mcc) has been presented as a potential technology for mobile services. mcc incorporates the cloud computing into the mobile environment. mobile cloud computing refers to an infrastructure where data processing and storage can happen away from mobile device. mobile cloud computing (mcc) has transformed the way in which mobile users across the globe leverage services on the go. the obstacles related to performance (e. g. battery life, storage, and bandwidth), environment (e. g. heterogeneity, scalability, availability) and security (e. g. reliability and privacy) are overcome by integrating cloud computing into the mobile environment using mcc. mobile cloud is a service model, where a mobile device can use the cloud for information storage, searching, data mining and multimedia processing. cloud computing technology also brings forth many new challenges for data security and access control when users store sensitive data on cloud servers. as the users no longer have physical possession of the outsourced data, makes the data integrity, privacy and authenticity protection in cloud computing a very challenging and potentially difficult task. though the cloud computing benefits are clear, surrendering physical possession of user data, inevitably poses new security risks. in this paper, we discuss mobile cloud computing security frameworks found in the literature related to cloud computing and its environment.
digital_control	leakage current reduction of the single-phase transformerless cascaded h-bridge pv inverter is investigated in this paper. the high-frequency common-mode loop model of a typical single-phase cascaded h-bridge pv system is established. based on the model, the main factors that affect the leakage current are discussed. the reason why the typical single-phase cascaded h-bridge inverter fails to reduce the leakage current is explained. in order to solve the problem, a cascaded topology based on the h5 inverter is presented, along with a new modulation strategy, which can ensure that the stray capacitor voltage is free of high-frequency components. in this way, the leakage current can be effectively reduced. finally, a prototype with tms320f28335dsp+xc3s400fpga digital control is built. the performance tests of cascaded h-bridge and the proposed topologies are carried out. the experimental results verify the effectiveness of the proposed solution.
electrical_network	smart grid integrates electrical network, communication systems and information technologies, where increasing architecture interdependency is introducing new challenges in the evaluation of how possible threats could affect security and reliability of power system. while cyber-attacks have been widely studied, consequences of physical failures on real-time applications are starting to receive attention due to implications for power system security. this paper presents a methodology to quantify the impact on observability in state estimation of possible disruptive failures of a common transmission infrastructure. numerical results are obtained by calculating observability indicators on an ieee 14-bus test case, considering the simultaneous disconnection of power transmission lines and communication links installed on the same infrastructure.
relational_databases	in this paper, we propose a persistent watermarking technique of information systems supported by relational databases at the back-end. the persistency is achieved by identifying an invariant part of the database which remains unchanged w.r.t. the operations in the associated applications. to achieve this, we apply static data-flow analysis technique to the applications. the watermark is then embedded into the invariant part of the database, leading to a persistent watermark. we also watermark the associated applications in the information system by using opaque predicates which are obtained from the variant part of the database.
image_processing	a new experimental, image-based methodology suitable to track the changes in orientation of non-spherical particles and their influence on the drag coefficient as they settle in fluids is presented. given the fact that non spherical solids naturally develop variations in their angular orientation during the fall, none-intrusiveness of the technique of analysis is of paramount importance in order to preserve the particle/fluid interaction undisturbed. three-dimensional quantitative data about the motion parameters is obtained through single-camera stereo vision whilst qualitative visualizations of the adjacent fluid patterns are achieved with schlieren photography. the methodology was validated by comparing the magnitudes of the drag coefficient of a set of spherical particles at terminal velocity conditions against those estimated from drag correlations published in the literature. a noteworthy similarity was attained. during the fall of non-spherical solids, once the particle reynolds number approximated 163 for disks, and 240 for cylinders, or exceeded those values, secondary motions composed by regular oscillations and tumbling were present they altered the angular orientation of the particles with respect to the main motion direction and caused complete turbulent patterns in the surrounding flow, therefore affecting the instantaneous projected area, drag force, and coefficient of resistance. the impact of the changes in angular orientation onto the drag coefficient was shown graphically as a means for reinforcing existing numerical approaches, however, an explicit relation between both variables could not be observed. (c) 2017 elsevier b.v. all rights reserved.
electric_motor	this paper focuses on the design and control of an active suspension system, where a tubular linear motor is integrated into a spring damper system of a vehicle. the spring takes up the weight of the vehicle. therefore the electric linear motor can be designed very compact as it has to provide forces to adjust the damping characteristic only. design and construction of the active suspension system, a control strategy and validation measurements at a test bench are presented.
analog_signal_processing	analog multipliers are one of the most important building blocks in analog signal processing circuits. the performance with high linearity and wide input range is usually required for analog four-quadrant multipliers in most applications. therefore, a highly linear and wide input range four-quadrant cmos analog multiplier using active feedback is proposed in this paper. firstly, a novel configuration of four-quadrant multiplier cell is presented. its input dynamic range and linearity are improved significantly by adding two resistors compared with the conventional structure. then based on the proposed multiplier cell configuration, a four-quadrant cmos analog multiplier with active feedback technique is implemented by two operational amplifiers. because of both the proposed multiplier cell and active feedback technique, the proposed multiplier achieves a much wider input range with higher linearity than conventional structures. the proposed multiplier was fabricated by a 0.6 mu m cmos process. experimental results show that the input range of the proposed multiplier can be up to 5.6v(pp) with 0.159% linearity error on vx and 4.8v(pp) with 0.51% linearity error on vy for +/- 2.5v power supply voltages, respectively.
computer_programming	in this chapter, we report two studies in which 3rd- and 4th-grade students used a distributed computing infrastructure (vimap-tangible) in order to collaboratively invent ""mathematical machines"" for generating geometric shapes. vimap-tangible combines the vimap visual programming language with a distributed computing infrastructure, in which students collaboratively control the behavior of a virtual agent using both mechanical devices and virtual algorithms. the curricular activities integrate engineering practices such as user-centered design; agent-based computer programming; mathematical reasoning about multiplication, rates, and geometry; and physical science concepts central to learning newtonian mechanics. in study 1, we investigate the key affordances of such a distributed computing environment for learning integrated stem, and identify the relationships between the various elements of students' physical constructions and computational models, and their stem learning outcomes. study 2 is a deeper investigation of the effect of iterative user testing on the refinement of children 's designs and their stem learning.
cryptography	in this paper, we propose an innovative quantum private comparison(qpc) protocol based on partial bell-state measurement from the view of linear optics, which enabling two parties to compare the equality of their private information with the help of a semi-honest third party. partial bell-state measurement has been realized by using only linear optical elements in experimental measurement-device-independent quantum key distribution(mdi-qkd) schemes, which makes us believe that our protocol can be realized in the near future. the security analysis shows that the participants will not leak their private information.
electric_motor	the paper presents a tribo-dynamic model for planetary gear sets of hybrid-electric-vehicle configurations. the model comprises a six degree-of-freedom torsional multi-body dynamic system, as well as a tribological contact model in order to evaluate the lubricant film thickness, friction and efficiency of the meshing gear teeth contacts. the tribological model takes into account the non-newtonian, thermal-mixed elastohydrodynamic regime of lubrication. analysis is performed for a hybrid electric c-segment vehicle. the simulated conditions correspond to cases of power supplied by either the engine or the electric motor. the results illustrate that in the electric motor drive mode, improved noise, vibration and harshness refinement would be expected, whereas better transmission efficiency is achieved in the internal combustion engine drive mode.
distributed_computing	in this paper, we present an intelligent, reliable and storage-efficient video surveillance system using apache storm and opencv. as a storm topology, we have added multiple information extraction modules that only write important content to the disk. our topology is extensible, capable of adding novel algorithms as per the use case without affecting the existing ones, since all the processing is independent of each other. this framework is also highly scalable and fault tolerant, which makes it a best option for organisations that need to monitor a large network of surveillance cameras.
electrical_circuits	this paper proposes a novel inerter-based electromagnetic device and investigates its performance as a vehicle suspension strut. the inerter-based electromagnetic device is obtained by placing the flywheel employed in an existing inerter prototype into a constant magnetic field. during rotation of the flywheel, the flywheel is doing the magnetic line cutting motion, which makes the flywheel perform as a faraday generator. the influences of different types of loads on the behaviour of the inerter-based electromagnetic device are analyzed, and it is shown that the resistive, capacitive and inductive loads can contribute to the damping, the inertance, and the stiffness of the whole device, respectively. moreover, the proposed device can also be used to realize higher-order mechanical admittances by using electrical circuits. the performance of the device as a suspension strut is also studied. numerical simulations show that the proposed device can not only provide improvements on the suspension performance (ride comfort and road holding) compared with the conventional strut, but also generate an amount of electric energy that can be utilized by other parts of the vehicle.
network_security	in this paper of computer network information security, network strategy were reviewed in this article, on the basis of all kinds of network safety measures, and the technology to carry on the analysis to banding mechanical electronic technical computer network as an example, introduces the computer network networking strategy and the computer network information safety protection strategy. the actual operation of the computer network to the hardware, software, internet use management rules and regulations a series of protective measures, set up for the actual situation of the network security environment, guarantee the stable operation of the network, for the education teaching provided support for the computer network construction and computer information safety protection provide the beneficial reference.
network_security	getting higher occurrence of cybercrimes by means of hacking, identity theft, and network security violations necessitates a robust system for resolving these issues. for the new era of it, using conventional user authentication methods like providing login ids, passwords /pin and other two-factor authentication methods are fading to offer the required level of security required. since biometrics come forward as an efficient alternative technique to provide security. keystroke and typing dynamics uses behavioral characteristics like typing rhythms of a person for authentication. this protection method effortlessly integrates with the existing environment and it could be scaled across the web also. this technology is will be getting promoted in the upcoming years because of its non-invasiveness, unobtrusiveness and low deployment cost. thereby security of the physical and logical access can be improved. this proposed technique acts as a supplementary security layer besides the traditional user ids & passwords/pin, most organizations are making supplementary investments in keystroke and typing dynamics to ensure a more robust user authentication system.
computer_vision	the most common way to deal with the uncertainty present in noisy sensorial perception and action is to model the problem with a probabilistic framework. maximum likelihood estimation is a well-known estimation method used in many robotic and computer vision applications. under gaussian assumption, the maximum likelihood estimation converts to a nonlinear least squares problem. efficient solutions to nonlinear least squares exist and they are based on iteratively solving sparse linear systems until convergence. in general, the existing solutions provide only an estimation of the mean state vector, the resulting covariance being computationally too expensive to recover. nevertheless, in many simultaneous localization and mapping (slam) applications, knowing only the mean vector is not enough. data association, obtaining reduced state representations, active decisions and next best view are only a few of the applications that require fast state covariance recovery. furthermore, computer vision and robotic applications are in general performed online. in this case, the state is updated and recomputed every step and its size is continuously growing, therefore, the estimation process may become highly computationally demanding. this paper introduces a general framework for incremental maximum likelihood estimation called slam++, which fully benefits from the incremental nature of the online applications, and provides efficient estimation of both the mean and the covariance of the estimate. based on that, we propose a strategy for maintaining a sparse and scalable state representation for large scale mapping, which uses information theory measures to integrate only informative and non-redundant contributions to the state representation. slam++ differs from existing implementations by performing all the matrix operations by blocks. this led to extremely fast matrix manipulation and arithmetic operations used in nonlinear least squares. even though this paper tests slam++ efficiency on slam problems, its applicability remains general.
electrical_circuits	the programme of discretization of famous completely integrable systems and associated linear operators was launched in the 1990s. in particular, the properties of second-order difference operators on triangulated manifolds and equilateral triangular lattices have been studied by novikov and dynnikov since 1996. this study included laplace transformations, new discretizations of complex analysis, and new discretizations of gl(n)-connections on triangulated n-dimensional manifolds. a general theory of discrete gl(n)-connections 'of rank one' has been developed (see the introduction for definitions). the problem of distinguishing the subclass of sln-connections (and unimodular sln +/--connections, which satisfy det a - +/- 1) has not been solved. in the present paper it is shown that these connections play an important role (which is similar to the role of magnetic fields in the continuous case) in the theory of self-adjoint schrodinger difference operators on equilateral triangular lattices in r-2. in appendix 1 a complete characterization is given of unimodular sln +/--connections of rank 1 for all n >1, thus correcting a mistake (it was wrongly claimed that they reduce to a canonical connection for n >2). with the help of a communication from korepanov, a complete clarification is provided of how the classical theory of electrical circuits and star-triangle transformations is connected with the discrete laplace transformations on triangular lattices.(1)
computer_graphics	multi-view image-based rendering consists in generating a novel view of a scene from a set of source views. in general, this works by first doing a coarse 3d reconstruction of the scene, and then using this reconstruction to establish correspondences between source and target views, followed by blending the warped views to get the final image. unfortunately, discontinuities in the blending weights, due to scene geometry or camera placement, result in artifacts in the target view. in this paper, we show how to avoid these artifacts by imposing additional constraints on the image gradients of the novel view. we propose a variational framework in which an energy functional is derived and optimized by iteratively solving a linear system. we demonstrate this method on several structured and unstructured multi-view datasets, and show that it numerically outperforms state-of-the-art methods, and eliminates artifacts that result from visibility discontinuities.
microcontroller	nowadays with the increasing amount of waste generated and limited landfill space for waste disposal, recycling is one of the important approaches to manage the waste effectively. the current manual recycling practice in which the user need to bring the waste in bulk to the recycling center might be hassle and hence become a discouraging factor for them to recycle. to overcome such an issue, in this project an automated recycle bin with a reward feature is proposed that derived from a reverse vending machine (rvm) concept. basically, the system is implemented in a standard recycle bin provided by local municipal that equipped with microcontroller and collection of sensors. throughout the process, the sensors responsible to identifying user information, weight the scale and eventually convert the weight to the corresponding points automatically. once the process completed, the user can claim their points by using rfid point card. all the mentioned process will be controlled by a microcontroller. the system has been implemented in a small scale user testing and the framework shows its effectiveness for handling the whole process. the prototype is expected to aid in accelerating the motivation among malaysian to recycle their waste, and can be one of the frameworks to overcome urban poverty issue by using waste to wealth concept. (c) 2017 the authors. published by elsevier b.v.
operating_systems	introduction worldwide the transport sector faces several issues related to the rising of traffic demand such as congestion, energy consumption, noise, pollution, safety, etc. trying to stem the problem, the european commission is encouraging a modal shift towards railway, considered as one of the key factors for the development of a more sustainable european transport system. the coveted increase in railway share of transport demand for the next decades and the attempt to open up the rail market (for freight, international and recently also local services) strengthen the attention to capacity usage of the system. this contribution proposes a synthetic methodology for the capacity and utilisation analysis of complex interconnected rail networks; the procedure has a dual scope since it allows both a theoretically robust examination of suburban rail systems and a solid approach to be applied, with few additional and consistent assumptions, for feasibility or strategic analysis of wide networks (by efficiently exploiting the use of big data and/or available open databases). method in particular the approach proposes a schematization of typical elements of a rail network (stations and line segments) to be applied in case of lack of more detailed data; in the authors' opinion the strength points of the presented procedure stem from the flexibility of the applied synthetic methods and from the joint analysis of nodes and lines. the article, after building a quasiautomatic model to carry out several analyses by changing the border conditions or assumptions, even presents some general abacuses showing the variability of capacity/utilization of the network 's elements in function of basic parameters. results this has helped in both the presented case studies: one focuses on a detailed analysis of the naples' suburban node, while the other tries to broaden the horizon by examining the whole european rail network with a more specific zoom on the belgium area. the first application shows how the procedure can be applied in case of availability of fine-grained data and for metropolitan/regional analysis, allowing a precise detection of possible bottlenecks in the system and the individuation of possible interventions to relieve the high usage rate of these elements. the second application represents an on-going attempt to provide a broad analysis of capacity and related parameters for the entire european railway system. it explores the potentiality of the approach and the possible exploitation of different 'open and big data' sources, but the outcomes underline the necessity to rely on proper and adequate information; the accuracy of the results significantly depend on the design and precision of the input database. conclusion in conclusion, the proposed methodology aims to evaluate capacity and utilisation rates of rail systems at different geographical scales and according to data availability; the outcomes might provide valuable information to allow efficient exploitation and deployment of railway infrastructure, better supporting policy (e.g. investment prioritization, rail infrastructure access charges) and helping to minimize costs for users. the presented case studies show that the method allows indicative evaluations on the use of the system and comparative analysis between different elementary components, providing a first identification of 'weak' links or nodes for which, then, specific and detailed analyses should be carried out, taking into account more in depth their actual configuration, the technical characteristics and the real composition of the traffic (i.e. other elements influencing the rail capacity, such as: the adopted operating systems, the station traffic/route control & safety system, the elastic release of routes, the overlap of block sections, etc.).
relational_databases	in relational databases and their applications, there are opportunities for evaluating a stream of knn queries submitted one by one at different times. for this issue, we propose a new method with learning-based techniques, region clustering methods and caching mechanisms. this method uses a knowledge base to store related information of some past knn queries, groups the search regions of the past queries into larger regions, and retrieves the tuples from the larger regions. to answer a newly submitted query, our strategy tries to obtain a majority or all of the results from the previously retrieved tuples cached in main memory. thus, this method seeks to minimize the response time by reducing the search region or avoiding the accesses to the underlying database. meanwhile, our method remains effective for high-dimensional data. extensive experiments are carried out to measure the performance of this new strategy and the results indicate that it is significantly better than the state-of-the-art naive methods of evaluating a stream of knn queries for both low-dimensional (2, 3 and 4) and high-dimensional (25, 50 and 104) data.
analog_signal_processing	inductance simulator is a useful component in the circuit synthesis theory especially for analog signal processing applications such as filter, chaotic oscillator design, analog phase shifters and cancellation of parasitic element. in this study, new four inductance simulator topologies employing a single current feedback operational amplifier are presented. the presented topologies require few passive components. the first topology is intended for negative inductance simulation, the second topology is for lossy series inductance, the third one is for negative lossy parallel inductance (-r) (-l) and the fourth topology is for negative parallel (-r) (-l) (-c) simulation. the performance of the proposed cfoa based inductance simulators is demonstrated on both a second-order low-pass filter and inductance cancellation circuit. pspice simulations are given to verify the theoretical analysis.
operational_amplifier	an auto-zero and chopper operational amplifier with a 4.5-60 v supply voltage range is realized, using a 0.18 mu m cmos process augmented by 5 v cmos and 60 v dmos transistors. it achieves a maximum offset voltage drift of 0.02 mu v/degrees c, a minimum cmrr of 145 db, a noise psd of 6.8 nv/root hz, and a 3.1 mhz unity gain bandwidth, while dissipating 840 mu a of current. up-modulated chopper ripple is suppressed by auto-zeroing. furthermore, glitches from the charge injection of the input switches are mitigated by employing six parallel input stages with 800 khz interleaved clocks. this moves the majority of the glitch energy up to 4.8 mhz, while leaving little energy at 800 khz. as a result, the requirements on an external low-pass glitch filter is relaxed, and a wider usable signal bandwidth can be obtained. maximum input bias current due to charge injection mismatch is reduced from 1.5 na to 150 pa by post production trimming with an on-chip charge mismatch compensation circuit.
signal-flow_graph	the methods for switched-capacitor (sc) noise analysis published up to this date fall in two groups: one group contains methods suitable for analysis by hand that are not easily applicable to all sc circuits. the other group contains methods that are applicable to all sc circuits, but require matrix manipulations with a computer algebra tool. in this paper, we show a universally applicable hand-analysis method. the main reason why sc noise analysis is so difficult is that noise is sampled on many different capacitors, and when being sampled, its spectrum is aliased. the core idea of making analysis by hand possible is to use an intuitive rather than an algebraic method to derive the continuous-time noise spectra in the different phases. our method combines charge-equation analysis for the discrete-time aspects with signal-flow-graph analysis for the continuous-time aspects of a circuit. we show in tutorial style how to apply it, and demonstrate that it is very useful for getting insight into sc circuits, deriving simplified expressions, and getting a good correspondence with behavioural simulations using spectrerf.
cryptography	modular exponentiation and modular multiplications are two fundamental operations in various cryptographic applications, and hence the performance of public-key cryptographic algorithms is strongly influenced by the efficient implementation of these operations. reducing the frequency of modular multiplications and the time requirements for modular multiplication will help in developing efficient modular exponential algorithms. this work proposes an energy efficient modular exponential algorithm based on bit forwarding techniques. in particular, two algorithms, bit forwarding 1-bit (bfw1) and bit forwarding 2-bits (bfw2), which are modifications of the existing binary exponential algorithm, have been developed. hardware realizations of the proposed algorithms have been evaluated in terms of throughput, power and energy. results show increased throughput of the order of 11.02% and 15.13%, reduction in power to 1.93% and 6.35% and energy saving of the order of 1.9% and 6.35% for bfw1 and bfw2 algorithms respectively. xilinx ise-14.2 on virtex-5 evaluation board and icarus verilog simulation and synthesis tool are used for hardware realization for fpga and synthesized using cadence for asic. (c) 2016 elsevier b.v. all rights reserved.
microcontroller	this paper presents a portable radar system for short-range localization, inverse synthetic aperture radar imaging, and vital sign tracking. the proposed sensor incorporates frequency-modulated continuous-wave (fmcw) and interferometry (doppler) modes, which enable this radar system to obtain both absolute range information and tiny vital signs (i.e., respiration and heartbeat) of human targets. these two different operation modes can be switched through an on-board microcontroller. to simplify the system, the proposed radar utilizes the audio card of a laptop to sample the baseband signal. the fmcw mode of the radar uses operational-amplifierbased circuits to generate an analog sawtooth signal and a reference pulse sequence (rps). the rps is locked to the sawtooth signal to obtain coherence for the radar system. for the interferometry mode, a low-intermediate-frequency modulation method is implemented to avoid the slow vital signs from being distorted by the high-pass filter of the audio card. several experiments were carried out to reveal the capability and distinct operational features of the proposed portable hybrid radar. the experiments also showed that the system can easily detect glass, which is usually difficult to identify for optical-based sensors. in addition, 2-d scanning in a complex environment revealed that the proposed radar was able to differentiate human targets from other objects. moreover, isar images were used to isolate moving human targets from surrounding clutter. finally, the proposed radar also demonstrated its ability to accurately measure vital signs when a human subject sits still.
system_identification	monitoring and analyzing floor vibrations to determine human activity has major applications in fields such as health care and security. for example, structural vibrations could be used to determine if an elderly person living independently falls, or if a room is occupied or empty. monitoring human activity using floor vibration promises to have advantages over other methods. for example, it does not have the privacy concerns of other methods such as vision-based techniques, or the compliance challenges of wearable sensors. the analysis of the signals becomes a classification problem determining the type of human activity. unfortunately only a few research groups are performing research of this subject even though there is a significant number of techniques that could be applied to this field. to date, no systematic study about the challenges and advantages of using different types of algorithms for this problem has been performed. this paper proposes a benchmark problem to: (i) encourage researchers to design new algorithms for monitoring human activity using floor vibrations, (ii) provide a dataset to test new algorithms, and (iii) allow the comparison of proposed methods based on a set of standard metrics. the benchmark consists of seven different cases of increasing difficulty. each case has a specific number of sensors, calibration signals, and type of floor excitation forces to be considered. the paper also proposes specific metrics that enable the direct comparison of different techniques. research groups interested in monitoring human activity using floor vibrations are encouraged to use the experimental data and evaluation metrics published in this paper to develop their own methodologies. this will enable the community of researchers to easily compare and contrasts techniques and better understand what type of methods will be appropriate in different applications. (c) 2016 elsevier ltd. all rights reserved.
parallel_computing	we consider the problem of solving large sparse linear systems where the coefficient matrix is possibly singular but the equations are consistent. block two-stage methods in which the inner iterations are performed using alternating methods are studied. these methods are ideal for parallel processing and provide a very general setting to study parallel block methods including overlapping. convergence properties of these methods are established when the matrix in question is either m-matrix or symmetric matrix. different parallel versions of these methods and implementation strategies, with and without overlapping blocks, are explored. the reported experiments show the behavior and effectiveness of the designed parallel algorithms by exploiting the benefits of shared memory inside the nodes of current smp supercomputers. (c) 2015 civil-comp ltd. and elsevier ltd. all rights reserved.
state_space_representation	in the frame structure of stacker cranes during non-stationary phases of movement due to inertial forces undesirable mast vibrations may occur. this effect can reduce the stability and positioning accuracy of these machines. the aim of this paper is to introduce an accurate and quite simple dynamical model of single-mast stacker cranes, which is suitable for investigating the mast vibrations of these machines. the multi-body modelling approach is selected to generate the differential equations of motion for this model. the solution of these equations is performed by means of the so-called modal coordinate transformation or modal superposition method. in this model structural damping is taken into consideration by means of the so-called proportional damping (rayleigh damping) approach. the main advantage of the presented multi-body model is that with this model the mast-vibrations can be investigated in various positions of the mast. dynamic models with varying lifted load positions can also be generated in simple way by using the introduced modelling technique. the main properties, i.e., the state space representation of our model as well as time domain simulation results, are also introduced.
operational_amplifier	this paper presents the three stage cmos operational amplifier (op amp) with class a output stage designed in silterra 's 130 nm cmos technology. the designed three stage op amp employed an indirect feedback compensation technique produces an open loop gain (aol), for both schematic and layout are 102 db and 117 db respectively. the op amp produces 40.5 mhz gain-bandwidth product (gbw), 90 degrees phase margin(pm) and 54.6 v/mu s slew rate (sr) for 5 pf load. furthermore, the op amp has capability to drive the 15 pf load, produces 25.5 mhz gbw and 45 degrees pm. the circuit was operated at the single supply voltage of 2.5 v with power consumption of 0.977 mw and the layout area was 0.0022 mm(2).
image_processing	the effects of target emissivity on apparent thermal contrast as well as on detection range capabilities of thermal imagers in long wave infrared and middle wave infrared bands were evaluated. the apparent thermal contrast (to be seen by the thermal imager at standoff distance), considering only the emission from target and background, was first computed in both the ir bands in terms of target emissivity and secondly the apparent thermal contrast, considering the background radiation reflected off the target, was also computed. a graphical user interface simulation in matlab was prepared for the estimation of total apparent thermal contrast taking into account both the emission and reflection. this total apparent thermal contrast was finally used in night vision thermal and image processing model for predicting the detection range performance of thermal imagers. results of the analysis show that the effect of target emissivity on thermal contrast estimates is more pronounced in lwir. the lower thermodynamic temperature difference between target and background at lower values of target emissivity leads to negative thermal contrast which in-turn leads to higher detection ranges.
operating_systems	this paper describes the memory architecture to improve the data transfer and storage in a small satellite. the main objective during the design stage of the architecture is to find a good balance between power consumption, cost, reliability and data processing capability. these variables directly impact each other, and it is important to achieve a suitable balance. for this, a low power flash memory is selected in conjunction with a faster static random access memory to improve the performance of the on-board computer on the satellite. in-built buffers of flash are suitably used to improve system performance. an extensive study of timing requirements to store data in memory is done. a comparison of performance at different voltage levels above the required minimum is done to get a balance between the required speed of programming the memory and power consumption. a highly modular and optimized algorithm is proposed for data transfer and storage which can be easily incorporated into a real time operating system. a method to further save the power is proposed by switching the flash memory to the power saving mode when its usage is not required.
symbolic_computation	the paper describes the mathematica-based software for studying nonlinear control systems. the software relies on an algebraic method, called functions' algebra. the advantage of this approach, over well-known linear algebraic and differential geometric methods is that it is applicable to certain non-smooth systems. the drawback is that the computations are more complicated since the approach manipulates directly with the functions related to the system equations and not with the differential one-forms/vector fields that simplify (linearize) the computations. we have implemented the basic operations of functions' algebra, i.e., partial order, equivalence, summation, and multiplication, but also finding the simplest representative of an equivalence class. the next group of functions is related to the control system and involves binary relation, operators m, m, and computation of certain sequences of invariant vector functions on the basis of system equations. finally, we have developed mathematica functions, allowing us to solve the following control problems in case of discrete-time systems: checking accessibility, static state feedback linearization, and disturbance decoupling.
signal-flow_graph	ambulatory monitoring and health care using wireless body area networks is an active area of applied research. in this study, a new method is presented to compute the connectance and reliability of wireless body area networks based on an improved approach to the topological analysis of the network 's digraph using mason 's rule. the procedure outlined is simple and fast and may be used to compute quantitative measures of a wireless body area network 's reliability. [life science journal 2010; 7(2): 52-56]. (issn: 1097-8135).
electricity	a new microbent in-line microfiber interferometer (mi-mi) is proposed and demonstrated as a compact temperature and current sensor. the mi-mi is capable of generating interference fringes with a high extinction ratio of about 12.0 db and a free spectral range of 1.9 nm at a wavelength of 1545 nm. when employed as a temperature sensor, a copper wire carrying a direct current is placed against the mi-mi sensor, and the interference fringes of the mi-mi sensor shifts toward the longer wavelength as the heat generated by the copper wire increases. as the temperature increase corresponds linearly to the current, thus the measurement of the current can be extrapolated as well. the sensor has a temperature responsivity of 33.0 pm/degrees c with a linearity of more than 0.97 as well as a current responsitivity of 1.46 degrees c/a(2), and has significant potential for application as a health and warning sensor for electricity generation and distribution grids.
cryptography	extreme learning machine (elm) is a well-known algorithm for the training of neural networks for two modes of functionality: regression and classification. this paper presents a novel model using elm in ciphering. the study begins with an investigation of the real-time recurrent neural network (rrnn) derived from the gradient-based learning for symmetric cipher. the weakness of this cipher is that the error converges to zero, and that the rrnn will not change regardless of how the plaintext is changed. given the nature of the elm, a technique with an elm-based cipher is proposed to provide the capability of performing the training independently from the input and the error gradient. different simulation scenarios were used to evaluate and validate the effectiveness of the proposed cipher. results revealed that the elm-based cipher performed better than rrnns, especially in terms of security. moreover, the elm-based cipher demonstrated significantly competing performance for a wide range of evaluation measures. using an elm-based cipher instead of an aes or other type of ciphers has the added advantage of providing an addition level of securityby allowing the user to change the algorithmic core of the cipher by simply changing the weights of the neural network. this allows hardware programmed ciphers to be more secure while costing less compared to other ciphers. copyright (c) 2016 john wiley & sons, ltd.
operational_amplifier	the effective transconductance (g(m)) of a bulk-driven operational amplifier opamp) can significantly vary with the input common-mode voltage. this variation of g(m) complicates frequency compensation and creates harmonic distortion. thus, this brief presents a g(m)-stabilizing technique to reduce the variation of g(m) across the input common-mode range (icmr). the idea is to use a variable positive feedback structure to adaptively control g(m) to the input common-mode voltage. a low-voltage bulk-driven opamp with the proposed g(m)-stabilizing technique has been implemented in a 0.18-mu m n-well cmos process. the opamp consumes 261 mu w from a 900-mv supply voltage. the variation of g(m) is reduced from 132% to 25% across the rail-to-rail icmr. the measured dc gain is 76.8 db and the unity-gain bandwidth is 7.11 mhz when the opamp is loaded with 17 pf parallel to 1 m omega.
parallel_computing	a parallel version of the nemo complex ocean circulation model has been implemented for the black sea basin; the results of circulation numerical modeling with a high spatial resolution are presented. analysis of the spatial variability is performed for the reconstructed hydrophysical fields in 2005-2008. the resulting simulated spatial variability characteristics of the sea surface temperature are compared with available satellite observational data.
microcontroller	multimodal electrochemical technique incorporating both open circuit potential (ocp) and amperometric techniques have been conceptualized and implemented to improve the detection of specific analyte in systems where more than one analyte is present. this approach has been demonstrated through the detection of ethanol while eliminating the contribution of water in a micro fuel cell sensor system. the sensor was interfaced with lmp91000 potentiostat, controlled through msp430f5529lp microcontroller to implement an auto-calibration algorithm tailored to improve the detection of alcohol. the sensor was designed and fabricated as a three electrode system with nafion as a proton exchange membrane (pem). the electrochemical signal of the interfering phase (water) was eliminated by implementing the multimodal electrochemical detection technique. the results were validated by comparing sensor and potentiostat performances with a commercial sensor and potentiostat respectively. the results suggest that such a sensing system can detect ethanol at concentrations as low as 5 ppm. the structure and properties such as low detection limit, selectivity and miniaturized size enables potential application of this device in wearable transdermal alcohol measurements. (c) 2016 elsevier b.v. all rights reserved.
distributed_computing	cloud computing is a specialized form of distributed computing in which the resources such as storage, processors, memory etc. are completely abstracted from the consumer. the number of cloud service providers (csps) who offer computing as a service has increased in recent times and often the customers need to interact with unknown service providers to carry out transactions. in such an open and anonymous environments, trust helps to build consumer confidence and provides a reliable environment for them. a trust based ranking system could also help them to choose between the services as per their requirement. in this paper, multi criteria decision making methods have been used to rank the service providers based on their infrastructure parameters. a combination of analytic and fuzzy method gives a better trust estimate as compared to an analytic method alone.
symbolic_computation	in this paper, we investigate the coupled cubic-quintic nonlinear schrodinger equations with variable coefficients, which describe the effects of quintic nonlinearity for the ultra-short optical pulse propagation in a non-kerr medium, or in the twin-core nonlinear optical fiber or waveguide. under certain constraints on the variable coefficients in such equations, mixed-type (bright-dark) vector one- and two-soliton solutions are derived via the hirota method and symbolic computation, and such vector-soliton solutions are only related to the delayed nonlinear response effect and nonlinearity. through the graphic analysis, we find that the delayed nonlinear response effect and nonlinearity can both affect the vector-soliton amplitude, while the vector-soliton velocity merely depends on the delayed nonlinear response effect. with the choice on the variable coefficients representing the delayed nonlinear response effect and nonlinearity, interactions between the amplitude- and velocity-unchanging, amplitude-changing, velocity-changing and amplitude- and velocity-changing vector two solitons are obtained. we see that the interaction between the vector two solitons is elastic. we also find that the interaction period of the bound vector solitons decreases as the increase of the delayed nonlinear response effect or increases as the decrease of the delayed nonlinear response effect, but is independent of the nonlinearity.
network_security	in recent years, image encryption algorithms have been developed rapidly in order to ensure the security of image transmission. with the assistance of our previous work, this paper proposes a novel chaotic image encryption algorithm based on self-adaptive model and feedback mechanism to enhance the security and improve the efficiency. different from other existing methods where the permutation is performed by the self-adaptive model, the initial values of iteration are generated in a novel way to make the distribution of initial values more uniform. unlike the other schemes which is on the strength of the feedback mechanism in the stage of diffusion, the piecewise linear chaotic map is first introduced to produce the intermediate values for the sake of resisting the differential attack. the security and efficiency analysis has been performed. we measure our scheme through comprehensive simulations, considering key sensitivity, key space, encryption speed, and resistance to common attacks, especially differential attack.
cryptography	aiming at the problem that the fixed radio frequency identification (rfid) system with lightweight cryptography may be easily illegally controlled, a communication authentication protocol based on quantum key distribution using decoy-state method is proposed and developed in this study. a new rfid-system model using quantum key distribution is introduced, which indicates that the quantum keys are distributed to the rfid tags and reader and epc information server via weakly coherent photons transmitted through optical fiber. this work mainly presents the protocol description with detailed theoretical analyses, including rfid system 's initialization, the transmission, reception, and acquisition of the random quantum key, and the authentication process between the epc information server and the rfid tag and reader. the security analysis of the protocol is finally carried out, which proves that the proposed protocol can prevent various eavesdropper 's attacks with solid security.
parallel_computing	this work presents the uncertainty quantification, which includes parametric inference along with uncertainty propagation, for co2 adsorption in a hollow fiber sorbent, a complex dynamic chemical process. parametric inference via bayesian approach is performed using sequential monte carlo, a completely parallel algorithm, and the predictions are obtained by propagating the posterior distribution through the model. the presence of residual variability in the observed data and model inadequacy often present a significant challenge in performing the parametric inference. in this work, residual variability in the observed data is handled by three different approaches: (a) by performing inference with isolated data sets, (b) by increasing the uncertainty in model parameters, and finally, (c) by using a model discrepancy term to account for the uncertainty. the pros and cons of each of the three approaches are illustrated along with the predicted distributions of co2 breakthrough capacity for a scaled-up process. (c) 2016 american institute of chemical engineers
bioinformatics	multiprotein bridging factor 1 (mbf1) is a transcriptional co-activator that mediates transcriptional activation by bridging sequence-specific activator like proteins and the tata-box binding protein (tbp). mbf1 has been well-studied in arabidopsis thaliana, saccharomyces cerevisiae, drosophila melanogaster, and homo sapiens, but it is not well understood in filamentous fungi. in this study, we report the identification and characterization of a mbf1 ortholog (mombf1) in the rice blast fungus magnaporthe oryzae), which causes the devastating rice blast disease and is an ideal model for studying the growth, development and pathogenic mechanisms of filamentous fungi. mombf1 encodes a 161 amino acid protein with a typical mbf1 domain and hth domain. bioinformatics were used to analyze the structural domains in mombf1 and its phylogenetic relationship to other homologs from different organisms. we have generated mombf1 deletion mutants (delta mombf1) and functional complementation transformants, and found that the deletion mutants showed significant defects in vegetative growth and tolerance to exogenous stresses, such as 1 m sorbitol, 0.5 m nacl, and 5 mm h2o2. moreover, delta mombf1 showed reduced pathogenicity with smaller infection lesions than wild type and the complementation strain, and decreased response to the accumulation of ros (reactive oxygen species) in planta at the initial infection stage. taken together, our data indicate that mombf1 is required for vegetative growth, pathogenicity and stress response in m. oryzae.
operational_amplifier	this paper presents new topologies for emulating floating immittance functions using three to five passive elements and only two current-feedback operational-amplifiers (cfoas). the feasibility of using only two cfoas and two passive components is explored. the proposed topologies can emulate lossy positive and negative inductances and capacitance-, inductance-, resistance-multipliers, and frequency dependent negative and positive conductances. the functionality of the proposed circuits was experimentally verified using the commercially available ad844 cfoa. the experimental results are in excellent agreement with theoretical calculations.
computer_programming	this paper addresses the road toll pricing and capacity investment problem in a congested road network in a multicriteria decision-making framework. a goal programming approach is used in which the following four major goals are considered: (1)cost recovery, (2)service level, (3)environmental, and (4)equity. the multiobjective road toll pricing and capacity investment problem is formulated as a bilevel goal programming model. the upper level of the model aims to minimize the deviations from stated goals for a given priority ranking of the goals, while the lower level is the road users' route choice equilibrium problem. a simulated annealing-based solution algorithm is developed to solve the proposed model. numerical results show that the priority structure of the goals can significantly affect the road toll pricing and capacity investment decisions. the simulated annealing-based solution algorithm outperforms the sensitivity analysis-based solution algorithm in terms of solution quality. the proposed methodology provides an avenue for understanding the trade-offs among conflicting objectives and for designing a financially and environmentally sustainable transportation system.
microcontroller	brushless dc (bldc) motors are widely used in various low-power drive applications owing to their several advantages over conventional motors. this study describes a fuzzy logic-based improved loss minimisation technique for the bldc motor drive system. the proposed algorithm uses selective harmonic elimination-based pulse-width modulation to optimise both the converter switching losses along with machine core and copper losses based on a speed- and load-dependent fuzzy rule matrix. the optimum switching angles eliminating lower-order harmonics are calculated offline and stored in microcontroller memory for online application. the suitability of the proposed control is well demonstrated through simulation and experimental results on a practical 350 w bldc machine.
algorithm_design	the vertical distribution of plant physiological composition plays an important role in vegetation growth and carbon stock. the hyperspectral lidar was thought to be the most promising solution to assess the vertical distribution of vegetation physiological parameters, such as lai (leaf area index) and chlorophyll content. however, the instrument was not fully feasible, so the simulation and experiment of its response to these parameters was necessary. in this paper, the hyperspectral lidar waveform was simulated with the consideration of single scatter of plant radiative transfer model. the variation of lai and chlorophyll along plant height was investigated and tree scenarios were assumed in the simulation. the hyperspectral lidar data experiment was also carried out to validate the simulation and method. the result showed that the hyperspectral lidar waveform could reflect the variation of plant physiological composition and facilitate the inversion algorithm design and it could play a significant role in parameter estimation and precision agriculture application in future.
image_processing	image segmentation is a crucial step in image processing, especially for medical images. however, the existence of partial volume effect, noise and other artifacts makes this problem much more complex. fuzzy c-means (fcm), as an effective tool to deal with partial volume effect, cannot deal with noise and other artifacts. in this paper, one modified fcm algorithm is proposed to solve the above problems, which includes three main steps: (1) peak detection is used to initialize cluster centers, which can make the initial centers close to the final ones and in turn decrease the number of iterations; (2) fuzzy clustering incorporating spatial information is implemented, which can make the algorithm robust to image artifacts; (3) the segmentation results are refined further by detecting and reallocating the misclassified pixels. experiments are performed on both synthetic and medical images, and the results show that our proposed algorithm is more effective and reliable than other fcm-based algorithms.
data_structures	in 1953, shannon proposed the question of quantification of structural information to analyze communication systems. the question has become one of the longest great challenges in information science and computer science. here, we propose the first metric for structural information. given a graph g, we define the k-dimensional structural information of g (or structure entropy of g), denoted by h-k (g), to be the minimum overall number of bits required to determine the k-dimensional code of the node that is accessible from random walk in g. the k-dimensional structural information provides the principle for completely detecting the natural or true structure, which consists of the rules, regulations, and orders of the graphs, for fully distinguishing the order from disorder in structured noisy data, and for analyzing communication systems, solving the shannon 's problem and opening up new directions. the k-dimensional structural information is also the first metric of dynamical complexity of networks, measuring the complexity of interactions, communications, operations, and even evolution of networks. the metric satisfies a number of fundamental properties, including additivity, locality, robustness, local and incremental computability, and so on. we establish the fundamental theorems of the one-and two-dimensional structural information of networks, including both lower and upper bounds of the metrics of classic data structures, general graphs, the networks of models, and the networks of natural evolution. we propose algorithms to approximate the k-dimensional structural information of graphs by finding the k-dimensional structure of the graphs that minimizes the k-dimensional structure entropy. we find that the k-dimensional structure entropy minimization is the principle for detecting the natural or true structures in real-world networks. consequently, our structural information provides the foundation for knowledge discovering from noisy data. we establish a black hole principle by using the two-dimensional structure information of graphs. we propose the natural rank of locally listing algorithms by the structure entropy minimization principle, providing the basis for a next-generation search engine.
electrical_network	high penetration of wind energy into the network may introduce stability and power quality problems due to the fluctuating nature of the wind and the increasing complexity of the power system. this paper describes a novel approach to voltage and power control of a radial electrical distribution network, using a wind farm. the wind farm consists of seven 75 kw induction generators (dfig) supplying two ac/dc converters. the feed structure of the dfig allows operating the system conversion in a wide range of speed variations. that is why it is a recommended solution, due to its capacity to increase the generator power to twice its nominal power; consequently, the system 's size and cost are reduced. another advantage is that the system is decoupled with an electrical network, so the disturbances do not affect the dfig and this also avoids the problems of coupling the machine to the power grid. through a 14-node distribution network, this study proves that the method is feasible. a simulation work was carried out with the software matlab/simulink. the results obtained prove that this control is suitable for regulating the desired power flows in a power network and providing the best voltage profile in the system, as well as minimizing the system transmission losses when inserting the wind farm into the electrical network.
software_engineering	a crucial problem in modern software engineering is maturity assessment of organizations developing software, however, research has shown that efficiency is a clearer indicator of agile transformation readiness. we propose utilizing a process model of rup development methodology, as a pattern for comparing it with the examined process. two factors were proposed to assess maturity and factor determining the efficiency of the rup process. the above mentioned rup model concept is based on a multi-agent based simulation (mabs). it presents goals and behaviours of agents as well as components of the agent system environment. to confirm the usefulness of the method for assessment of organization 's maturity, a two-fold experiment was undertaken. the results confirm the usefulness of the model in efficiency and maturity assessment. first part consisted of tuning the simulation internal parameters to the development process. in the second part we propose three factors that can be used to assess efficiency and maturity of a rup it organization. the proposed coefficients are an extension of previous research by the authors, devoted to the assessment of organizational readiness for agile processes transformation.
signal-flow_graph	in this study, a fifth-order lowpass log-domain butterworth filter, which is appropriate for bluetooth/wi-fi receiver, is designed with signal flow graph approach. the filter is realized by using a unique translinear integrator circuit. bluetooth and wi-fi modes are obtained without changing the circuit configuration. to change the mode of the filter, it is needed to change the cutoff frequency of the filter that can be electronically tuned by adjusting the external currents. wi-fi and bluetooth receivers have 6 mhz and 600 khz cutoff frequencies, respectively. only bjts and grounded capacitors were utilized to achieve the desired circuit. lowpass log-domain butterworth filter was simulated by using spice simulation program. a validated bjt and idealized bjt models are used to obtain simulation results confirming the theoretical analysis.
operating_systems	switching cost is an important factor for policy makers to consider because it sets a higher price for locked-in consumers by making the market less competitive. though there has been some empirical research analyzing switching costs in the mobile telecommunications market, studies considering the characteristics of smartphones, which have their own operating systems and applications, are still rare. in this study, we conduct a hypothetical conjoint survey to analyze switching cost in the smartphone handset market and derive the cost by using the hierarchical bayesian multinomial logit model to consider respondents' heterogeneity. switching costs of handsets and os are empirically estimated, and the magnitudes depend on the levels of searching cost, learning cost, and uncertainty when purchasing new smartphones. (c) 2016 elsevier ltd. all rights reserved.
computer_vision	recent literature has explored automated pornographic detection a bold move to replace humans in the tedious task of moderating online content. unfortunately, on scenes with high skin exposure, such as people sunbathing and wrestling, the state of the art can have many false alarms. this paper is based on the premise that incorporating motion information in the models can alleviate the problem of mapping skin exposure to pornographic content, and advances the bar on automated pornography detection with the use of motion information and deep learning architectures. deep learning, especially in the form of convolutional neural networks, have striking results on computer vision, but their potential for pornography detection is yet to be fully explored through the use of motion information. we propose novel ways for combining static (picture) and dynamic (motion) information using optical flow and mpeg motion vectors. we show that both methods provide equivalent accuracies, but that mpeg motion vectors allow a more efficient implementation. the best proposed method yields a classification accuracy of 97.9% an error reduction of 64.4% when compared to the state of the art on a dataset of 800 challenging test cases. finally, we present and discuss results on a larger, and more challenging, dataset.
software_engineering	context: the global software industry and the software engineering (se) academia are two large communities. however, unfortunately, the level of joint industry-academia collaborations in se is still relatively very low, compared to the amount of activity in each of the two communities. it seems that the two 'camps' show only limited interest/motivation to collaborate with one other. many researchers and practitioners have written about the challenges, success patterns (what to do, i.e., how to collaborate) and anti-patterns (what not do do) for industry-academia collaborations. objective: to identify (a) the challenges to avoid risks to the collaboration by being aware of the challenges, (b) the best practices to provide an inventory of practices (patterns) allowing for an informed choice of practices to use when planning and conducting collaborative projects. method: a systematic review has been conducted. synthesis has been done using grounded-theory based coding procedures. results: through thematic analysis we identified 10 challenge themes and 17 best practice themes. a key outcome was the inventory of best practices, the most common ones recommended in different contexts were to hold regular workshops and seminars with industry, assure continuous learning from industry and academic sides, ensure management engagement, the need for a champion, basing research on real world problems, showing explicit benefits to the industry partner, be agile during the collaboration, and the co-location of the researcher on the industry side. conclusion: given the importance of industry-academia collaboration to conduct research of high practical relevance we provide a synthesis of challenges and best practices, which can be used by researchers and practitioners to make informed decisions on how to structure their collaborations. (c) 2016 elsevier b.v. all rights reserved.
cryptography	digital watermarking protocols are the one, which have combined fingerprinting technique with watermarking, for embedding digital signal or watermark into an original multimedia object. buyer-seller watermarking protocol is fundamentally applied to continue the digital rights of both buyers and seller. we proposed an identity-based buyer-seller watermarking protocol that encounters various weaknesses of zhang et al. 's watermarking protocol. we ensured that by pointing out these weaknesses, inaccuracy can be minimised for further implementing the buyer-seller watermarking protocol. the suggested protocol uses id-based public key cryptography and digital watermarking scheme to place the ownership of digital content. hence, copyright protection is attained. we claim that our suggested protocol is efficient and has adequate security as compared to traditionally proposed protocols, and therefore suitable for any practical buyer-seller watermarking scheme.
system_identification	the well-known reweighted zero-attracting least mean square algorithm (rza-lms) has been effective for the estimation of sparse system channels. however, the rza-lms algorithm utilizes a fixed step size to balance the steady-state mean square error and the convergence speed, resulting in a reduction in its performance. thus, a trade-off between the convergence rate and the steady-state mean square error must be made. in this paper, utilizing the nonlinear relationship between the step size and the power of the noise-free prior error, a variable step-size strategy based on an error function is proposed. the simulation results indicate that the proposed variable step-size algorithm shows a better performance than the conventional rza-lms for both the sparse and the non-sparse systems.
electric_motor	improvement of quality and value addition of agricultural produces has gained higher concern in recent times in sri lanka due to creation of new opportunities for sale of agricultural commodities in open market at competitive prices. grading according to the sizes is an important value adding technique for most agricultural products. and also the price of the many agricultural products varies significantly according to their uniformity in size. uniformity in size not only makes the produce more attractive to consumers but also improve its processing qualities. at present, size grading of most agricultural crops including big onion are carried out manually by crop collectors, whole sellers and retail sellers, most of farmers market their products without any grading. in sri lanka, persons engaging in post-harvest crop handling such as collectors, whole sellers, retail sellers, and farmers have less chance to use high technical and costly grading technique. and also local market survey reported, retail market price of the big onion bulbs are significantly varied according to its size. hence, this research study attempted to design and development of a low cost size grading machine for size grading of big onion bulbs. size grading machine was fabricated by cast iron and pvc tube and it was designed for grading of onion bulbs into three sizes i.e. small (phi<4 cm), medium (4 < phi6cm). grading machine was also fabricated to operate either by manual or electric motor. the machine was tested for grading efficiency/quality accordingly, machine performance was optimized. optimized machine adjustments for its maximum performance were 3 degrees inclined angle of the grading cylinder against horizontal axis and 15 rpm rotating speed of the grading cylinder. maximum grading qualities/efficiencies under optimized machine adjustments for small, medium and large sizes were reported 84.47%, 93.46% and 90.14 respectively. the capacity of the grading machine was 630 kg/hour under the optimized operational conditions. (c) 2016 the authors. published by elsevier ltd.
electric_motor	this paper deals with the losses caused by the welding to fix laminated cores of a traction motor. although a number of studies have been performed on the motor design to increase the motor efficiency, there are few technical studies to implement the effect of manufacturing process, such as welding, on the motor design. however, the losses may have a significant effect on the motor performances. thus, in this paper, welding loss models considering flux densities, frequencies, stack length and the number of welding passes are proposed from the data measured directly by welded ring cores. finally, the effect of these welding loss models are verified through a comparison with measured motor losses.
algorithm_design	the current paper describes a hybrid control algorithm for fuel consumption minimization of a compound hybrid excavator. the power train of the excavator integrates an engine assist motor, a super capacitor, and a dc/dc converter for hybridization of the original power train. this power train also incorporates an electrically propelled swing motor, which replaces the conventional hydraulic swing motor, to remove hydraulic loss and recuperate the kinetic energy of the swing motion. since the super capacitor provides the required energy for the electric swing motor, sustaining the charge presents an important consideration in the power management algorithm design. first, the optimal control problem has been applied to the fuel consumption minimization problem, and an algorithm based on the equivalent fuel minimization strategy (ecms) has been applied by analyzing the behavior of the co-state of the optimal control problem. the ecms algorithm is integrated with an engine set speed regulator to increase the overall efficiency of the diesel engine. the engine set speed regulator was designed to change the engine set speed, depending on the engine load. simulations show that the ecms is near optimum compared to the dynamic programming results, maintaining an approximately 3% fuel improvement compared to a thermostat controller, which determines power distribution based on the state of charge. excellent charge-sustaining performance was also achieved. the performance of the control algorithm was verified through real-world vehicle tests, resulting in an approximately 30% improvement in fuel economy, compared to the conventional excavator. (c) 2016 published by elsevier b.v.
system_identification	thermoacoustic instabilities in gas turbines and aeroengine combustors fall within the category of complex systems. they can be described phenomenologically using nonlinear stochastic differential equations, which constitute the grounds for output-only model-based system identification. it has been shown recently that one can extract the governing parameters of the instabilities, namely the linear growth rate and the nonlinear component of the thermoacoustic feedback, using dynamic pressure time series only. this is highly relevant for practical systems, which cannot be actively controlled due to a lack of cost-effective actuators. the thermoacoustic stability is given by the linear growth rate, which results from the combination of the acoustic damping and the coherent feedback from the flame. in this paper, it is shown that it is possible to quantify the acoustic damping of the system, and thus to separate its contribution to the linear growth rate from the one of the flame. this is achieved by postprocessing in a simple way simultaneously acquired chemiluminescence and acoustic pressure data. it provides an additional approach to further unravel from observed time series the key mechanisms governing the system dynamics. this straightforward method is illustrated here using experimental data from a combustion chamber operated at several linearly stable and unstable operating conditions.
computer_vision	segmentation and classification of objects in images is one of the most important and yet one of the most complex problems in computer vision. in this work we propose a new model for natural image object classification using contextual information at the level of image segments. context modeling is largely independent of appearance-based classification and proposed model enables simple upgrade of existing systems with information from global and/or local context. context modeling is based on non-parametric use of appearance-based classification results which is a novel approach compared to previous systems that model context on a limited number of rules expressed with a fixed set of parameters. model implementation resulted in a system that, in our simulations, showed stable improvement of the appearance-based object classification.
bioinformatics	introduction: the effectiveness of lantibiotics against mdr pathogens and the progression of agents mu1140, nai-107, nvb302 and duramycin into pre-clinical and clinical trials have highlighted their potential in the fight against bacterial resistance. the number of known lantibiotics and knowledge of their biosynthetic pathways has increased in recent years due to higher quality genomic data being delivered by next generation sequencing technologies combined with the development of specific genome mining tools, enabling the prediction of lantibiotic clusters. areas covered: in this review, the author describes how the increase of high quality genomic data has increased the discovery of novel lantibiotics. expert opinion: novel apparatus such as the ichip enabling the isolation of uncultable bacteria will undoubtedly increase the identification rate of novel antimicrobial peptides including lantibiotics. the ability to then assess the lantibiotic clusters via recombinant production or synthesis using a high throughput method is one of the next challenges for developing these agents into the clinical environment.
digital_control	this work presents a control system suitable for high-precision pulsed current sources. the proposed control system is based on the detection of events so as to define changes in the power converter state to produce the required current waveform with a good dynamic response. additionally, this control system is designed to regulate the flat-top current with a well-defined precision. in order to mitigate the effect of the measurement noise, an estimation algorithm for the controlled current is incorporated. this algorithm generates a filtered version of the controlled variable without affecting the control dynamics. the use of the estimated current allows to improve the detection of the events and to avoid an increase in the number of commutations due to possible erratic comparisons. then, the estimator gains are tuned by using genetic algorithm techniques to optimize the root-mean-square value for a typical pulse. furthermore, in order to independently perform the required set of tasks, the proposed control system is implemented by using a digital platform based on a field-programmable gate array. additionally, due to the demanding precision in these applications, different considerations regarding its implementation, such as the digital wordlength, binary point position, rounding method, and overflow behavior, have been taken into account. experimental results obtained from the application of the proposed control system to a laboratory prototype are presented.
parallel_computing	in the present paper, an ultrafast and scalable parallel program for the radial pair function (rpf) is presented via pure message passing interface (mpi) paradigm. the parallel code computes the radial distribution function for the single-component as well as multi-component systems. the single-component and multi-component systems have been extracted for benchmarking purposes by means of user-written codes in c++ for the graphite structure and mpi c++ for hydrogen adsorption via grand canonical monte carlo (gcmc) in the single-walled carbon nanotube (swnt), respectively. the speedup and efficiency curves substantiate an excellent performance in terms of computing time and computation size as well. additionally, the mentioned mpi paradigms are nearly five times (single-component systems) and two times (multi-component systems) faster than the relevant parallel codes using a machine with 48 cpus and nvidia quadro k5200/pcie/sse2. some conclusions and outlooks pertaining to the numerical implementations, algorithm optimization involving the space decomposition idea have been discussed and provided.
software_engineering	sets of common features are essential assets to be reused in fulfilling specific needs in software product line methodology. in requirements reuse (rr), the extraction of software features from software requirement specifications (srs) is viable only to practitioners who have access to these software artefacts. due to organisational privacy, srs are always kept confidential and not easily available to the public. as alternatives, researchers opted to use the publicly available software descriptions such as product brochures and online software descriptions to identify potential software features to initiate the rr process. the aim of this paper is to propose a semi-automated approach, known as feature extraction for reuse of natural language requirements (fenl), to extract phrases that can represent software features from software reviews in the absence of srs as a way to initiate the rr process. fenl is composed of four stages, which depend on keyword occurrences from several combinations of nouns, verbs, and/or adjectives. in the experiment conducted, phrases that could reflect software features, which reside within online software reviews were extracted by utilising the techniques from information retrieval (ir) area. as a way to demonstrate the feature groupings phase, a semi-automated approach to group the extracted features were then conducted with the assistance of a modified word overlap algorithm. as for the evaluation, the proposed extraction approach is evaluated through experiments against the truth data set created manually. the performance results obtained from the feature extraction phase indicates that the proposed approach performed comparably with related works in terms of recall, precision, and f-measure (c) 2016 elsevier b.v. all rights reserved.
cryptography	the continuous auxiliary inputs leakage is more strong side-channel attacks. in this article, we first propose a continuous auxiliary inputs leakage model for the hierarchical attribute-based encryption scheme. under the security model, an adversary has ability to gain partial updated master keys and updated secret keys continually by certain leakage attacks. moreover, a resilient-leakage hierarchical attribute-based encryption scheme is constructed. the security proof for this scheme is provided under the standard model. furthermore, we give the performance comparison between our scheme and relevant scheme. (c) 2016 john wiley & sons, ltd.
operating_systems	partitionfinder 2 is a program for automatically selecting best-fit partitioning schemes and models of evolution for phylogenetic analyses. partitionfinder 2 is substantially faster and more efficient than version 1, and incorporates many new methods and features. these include the ability to analyze morphological datasets, new methods to analyze genome-scale datasets, new output formats to facilitate interoperability with downstream software, and many new models of molecular evolution. partitionfinder 2 is freely available under an open source license and works on windows, osx, and linux operating systems. it can be downloaded from www.robertlanfear.com/partitionfinder. the source code is available at https://github.com/brettc/partitionfinder.
parallel_computing	managing servers integration to realize distributed data computing framework is an important concern. regardless of the underlying architecture and the actual distributed system 's complexity, such framework gives programmers an abstract view of systems to achieve variously data-intensive applications. however, some state-of-the-art frameworks need too much library dependencies and parameters configuration, or lack extensibility in application programming. moreover, general framework 's precise design is a nontrivial work, which is fraught with challenges of task scheduling, message communication and computing efficiency, etc. to address these problems, we present a general, scalable and programmable parallel computing framework called sunwaymr, which only needs gcc/g++ environment. we argue it from the following aspects: (1) distributed data partitioning, message communication and task organization are given to support transparent application execution on parallel hardware. by searching threads table of each node, the task gets an idle thread (with preferred node ip address) for executing data partition. a novel communication component, sunwaymrhelper, is employed to merge periodical results synchronously. through identifying whether current node is master or slave, sunwaymr deals with the periodical task 's results differently. (2) as for optimizations, a simple fault tolerance is given to resume data-parallel applications, and thread-level stringstream is utilized to boost computing. to ensure ease-of-use, open application programming interface (api) excerpts can be invoked by various of applications with fewer handwritten code than openmpl/mpi. we conduct extensively experimental studies to evaluate the performance of sunwaymr over real-world datasets. results indicate that sunwaymr (runs on 16 computational nodes) outperforms spark in various applications, and has good scaling with data sizes, nodes and threads. (c) 2017 elsevier b.v. all rights reserved.
system_identification	rule-based classification systems constructed upon linguistic terms in the antecedent and consequent of the rules lack sufficient generalization capabilities. this paper proposes a new multivariate fuzzy system identification algorithm to design binary rule-based classification structures through making use of the repulsive forces between the cluster prototypes of different class labels. this approach is coupled with the potential discrimination power of each dimension in the feature space to increase the generalization potential. to address this issue, first the multivariate variant of a newly proposed soft clustering algorithm along with its mathematical foundations is proposed. next, the discriminatory power of each individual feature is computed, using the multivariate membership values in the proposed clustering algorithm to achieve the most accurate firing degree in each rule. the main advantage of this method is to handle unbalanced datasets yielding superior true positive measure while keeping the false positive rate low enough to avoid the natural bias toward class labels containing larger number of training samples. to validate the proposed approaches, a series of numerical experiments on publicly available datasets and a real clinical dataset collected by our team were conducted. simulation results demonstrated achievement of the primary goals of this research. (c) 2017 elsevier b.v. all rights reserved.
operational_amplifier	an amplifier and capacitor sharing technique with applications in a multiplying digital-to-analog converter (mdac) of cmos pipelined acdc is presented. the amplifier used in this implementation is a recycling amplifier based on the folded cascode operational amplifier with gain improved using positive feedback. the operational amplifier designed in 0.35um cmos process show a simulated gain of 75 db, frequency bandwidth of 95 mhz, phase margin of 75 degree and power consumption of 0.75 mw on a 1.8v power supply. the simulation results in mdac of 1.5 bits show that this configuration can be used in a implementation of a 10 bits 10 msample/s cmos pipelined adc with 2.8 mw power consumption (analog part) on a 1.8v supply.
symbolic_computation	under investigation in this paper is a discrete (2+1)-dimensional ablowitz-ladik equation, which has certain applications in nonlinear optics and bose-einstein condensation. employing the hirota method and symbolic computation. we obtain the bright/dark one-, two-, three-and n-soliton solutions. asymptotic analysis indicates that the interactions between the bright/dark two solitons are elastic. amplitudes and velocities of the bright and dark solitons increase with the value of the coupling strength increasing. head-on and overtaking interactions between the bright two solitons as well as the bound state two solitons are depicted. overtaking interaction between the dark two solitons are also plotted. the increasing value of the coupling strength can lead the increasing amplitudes and velocities of the bright/dark two solitons. (c) 2017 published by elsevier b.v.
pid_controller	in this paper, an advanced control strategy has been validated on a liquid vessel and a heat exchanger applications. the principal characteristics of this strategy, which is the predictive functional control, are presented. due to its simplicity in implementation and tuning, this algorithm is adopted for large wide systems. compared with pid controller, the performances of this approach are improved by simulation results even with perturbations and under constraints in addition to the qualitative results. (c) 2016 hydrogen energy publications llc. published by elsevier ltd. all rights reserved.
digital_control	this paper presents the design of a digital control strategy for a dc-dc type buck converter used as an efficient lead acid battery charger in isolated electric, photovoltaic systems. the strategy is designed to be implemented in a digital signal processor (dsp). the control acts depending on the state of charge of the batteries by regulating the drive duty cycle with the proper combination of incremental conductance mppt technique and precise control of the battery current according to three charging stages, providing a joint solution which on one hand maximizes the production of solar energy available in the pv array, and on the other ensures a long battery lifetime, both aspects, which are generally investigated independently in technical literature, are treated simultaneously in our approach. the work explains in detail the converter modeling, the project of the compensator, as well as the development of mppt used. validation simulations are done via matlab and experimental results from a prototype low power tms320f2812 using a dsp from texas instruments, are provided and discussed, which show satisfactory performance of the proposed control system. (c) 2016 elsevier ltd. all rights reserved.
system_identification	presented herein is a new computational strategy to eliminate the thermal effect in measured responses. the internal forces of a structure and its thermal load components are estimated alternately at each time step based on a recursive least-squares algorithm. the noise effect in the measured data and the estimated force in previous steps are removed with the kalman filter. this approach directly models the thermal effects on the dynamic responses without the temperature information. this approach adopts force identification technique which has been researched extensively in the last two decades. the effectiveness of the proposed approach is validated via numerical studies with a bridge structure with or without noise in the measured data. the thermal load in the structural components can be estimated accurately with the proposed strategy with less than 8% error when there is 10% noise in the measured responses of the structure.
digital_control	this paper discusses a discrete-time loop shaping algorithm for servo enhancement at multiple wide frequency bands. such design considerations are motivated by a large class of practical control problems such as vibration rejection, active noise control, and periodical reference tracking; as well as recent novel challenges that demand new design in the servo technologies. a pseudo youla-kucera parameterization scheme is proposed using the inverse system model to bring enhanced control at selected local frequency regions. design methodologies are created to control the waterbed amplifications that come from the fundamental limitations of feedback control. finally, simulation and experimental verification are conducted in precision control and semiconductor manufacturing. (c) 2015 elsevier ltd. all rights reserved.
electrical_network	this paper discusses the grid interface challenges for cern 's proposed compact linear colliders' (clic) klystron modulators, including a 280 mw power system optimisation. the modular multilevel converter is evaluated as a candidate topology for a medium voltage grid interface along with a control method for reducing the impact of klystron modulators on the electrical network.
parallel_computing	the interaction simulations between particles and structures are often performed in the context of the combined discrete-finite element (dem-fem) method, where an efficient, robust and accurate contact algorithm for challenging contact problems is essential. a three-dimensional (3d) discrete and finite element contact algorithm, named zgl here, has been proposed in our research group (zang, m.y. et al., 2011. a contact algorithm for 3d discrete and finite element contact problems based on penalty function method. comput. mech. 48, 541-550.). despite being quite well-established, zgl algorithm may lack efficiency, robustness and accuracy in certain situations, e.g., when special mesh pattern is applied. however, since such cases are readily to appear in practice engineering application, an algorithm named dzceii is developed to resolve these issues and thus significantly applicable to challenging contact problems. the proposed dzcell algorithm includes an improved global phase to directly find the potential segments rather than the nearest node for discrete elements as contact counterparts. furthermore, both the memory cost and time consumption of this algorithm are linear, and the algorithm is readily to extend to parallel computing. several numerical examples demonstrate the achievable improvements in terms of efficiency, robustness and accuracy for 3d contact analysis and validate the capability of the dzceii algorithm in the granular science and mechanical engineering. (c) 2016 elsevier b.v. all rights reserved.
computer_graphics	the current development in the area of computer graphics focuses itself on 3d visualization. this direction, set by contemporary trends, further utilizes 3d visualization, increases its quality and improves visualization devices for 3d graphics. this change must be reflected by teaching methods as well, through which future specialists of advanced graphics, modellers, but also programmers and implementation coders. the article presents its own software solution and innovative approach to teaching computer graphics. the solution and all principles are based on the montessori method of child education.
symbolic_computation	in this paper, based on a variable-coefficient nonlinear schrodinger (vcnls) equation, amplification of the fundamental and second-order unchirped solitons in the dispersion-decreasing fiber without any external amplification device, which is different from those in the existing literatures, is studied. via symbolic computation, soliton solutions of the vcnls equation are obtained. for a fundamental-soliton pulse, the amplitude is amplified by the gain during the propagation, whereas the width keeps unchanged. because of the equilibrium between the gain, nonlinearity and varying dispersion, soliton structure is not destroyed, and the amplified fundamental soliton is free from the pedestal and chirp. with the increase of the absolute value of the gain coefficient , magnification of the fundamental-soliton amplitude is enhanced in the same propagation distance. for the second-order soliton, the width is compressed and the amplitude is amplified, because the amplification process is accompanied by the compression of the soliton. period of the second-order soliton decreases exponentially during the propagation, and decreases with the increase of the absolute value of in the same propagation distance.
computer_graphics	realistic animation of an expressive human face has been a great challenge in computer graphics due to the human perception of human faces. it is a complex, costly and time-consuming process requiring a great detail in many aspects. in this paper, a three-stage method is presented that simplifies the creation of realistic facial animations by transferring the expressions from 2d videos onto 3d models with a joint-based system on a real-time basis. the first stage covers the preparation of the model with a joint-based rig for the transfer. the second includes the real time tracking of a human face with a single camera to obtain 2d positions of facial landmarks. also it covers the transfer of 3d relative movement data to animate the prepared model by moving the respective joints. the last stage covers the recording of animation using a partially automated key-framing technique. the presented method provides a fast, easy to use and affordable system that produces visually satisfying facial animations.
distributed_computing	in grid computing environment, several classes of multi-component applications exist. these types of applications may often require additional resources of different types that go beyond what is available in any of the sites making up the grid resource composition. the heterogeneity nature of both the user application and the computing environment makes this a challenging problem. however, the current off-the-shelf scheduling software can hardly cope with these diversities in distributed computing application frameworks. therefore, there is the need for an adequate scheduling system that would grant simultaneous or coordinated access to application of multi-component nature that requires resources of possibly multiple types, in multiple locations, managed by different resource providers. the main focus of this paper is to develop a mobile agent scheduling model that addresses the aforementioned challenge. a scheduling policy that pertains to job scheduling and resource allocation is proposed. the scheduling policy treats different multi-component applications requiring diverse heterogeneous resources fairly. the policy is used by mobile agents to schedule user applications and to also find available and suitable distributed resource that are capable of executing user application at a very minimal time. copyright (c) 2015 john wiley & sons, ltd.
computer_programming	virtual blended learning as the use of virtual 3d environments in education has already delivered utility in a number of cases. this article presents a concept and a prototype of a 3d environment used in the current semester to employ the new medium in programming education at universities. the concept brings gamification aspects as well as interaction mechanisms from social media to the virtual 3d environment. it thereby aims to reduce the large number of student dropouts due to failing the programming modules by motivating more and less capable students alike to an increased participation in the practical exercises. it is concluded that the concept is applicable in a much broader spectrum of exercise and tutorial settings.
digital_control	the performance of some fourier transform based fundamental current detection algorithms is evaluated and compared in this paper. some difficult conditions are imposed by a load which draws a highly distorted current with a slight fluctuation, i. e. with non-equal semi-periods. the implemented algorithms are recursive discrete fourier transform (rdft), discrete fourier transform (dft) implemented through a finite impulse response (fir) filter and respectively the fast fourier transform (fft) with butterfly operation and radix-2 decimation in time (dit). a digital signal processor (dsp) based solution is used for real-time implementation, namely a dspace 1103 controller development board. matlab/simulink software is used for the design of the algorithms because it provides specialized tools and blocks. for the performance comparison one used criteria like total harmonic distortion (thd) and settling time of detected fundamental current and also the run time for the dsp. this study may be useful as a guide for engineers in selecting the suitable fourier transform based control algorithm for active power filters or other grid-synchronized equipments which are operating in difficult load conditions.
machine_learning	the ability to derive new insights from data using advanced machine learning or analytics techniques can enhance the decision-making process in companies. nevertheless, researchers have found that the actual application of analytics in companies is still in its initial stages. therefore, this paper studies by means of a descriptive survey the application of analytics with regards to five different aspects as defined by the delta model: data, enterprise or organization, leadership, targets or techniques and applications, and the analysts who apply the techniques themselves. we found that the analytics organization in companies matures with regards to these aspects. as such, if companies started earlier with analytics, they apply nowadays more complex techniques such as neural networks, and more advanced applications such as hr analytics and predictive analytics. moreover, analytics is differently propagated throughout companies as they mature with a larger focus on department-wide or organization-wide analytics and a more advanced data governance policy. next, we research by means of clustering how these characteristics can indicate the analytics maturity stage of companies. as such, we discover four clusters with a clear growth path: no analytics, analytics bootstrappers, sustainable analytics adopters and disruptive analytics innovators. (c) 2016 elsevier ltd. all rights reserved.
computer_graphics	the presented simulation model of surface tension and wettability based on physical properties of liquids is designed for use in computer graphics. due to the relatively small surface tension forces the model is useful for simulating liquid of small volume such as droplets. this model can be used in conjunction with various fluid simulation methods, one of the most popular - marker and cell - has been selected for this paper. the paper describes also a simple and rapid method of determining the liquid surface as a mesh of triangles. the presented method improves the final visual effect and is well suited for determining the surface of the droplets. the simulation method was applied to create realistic animations of flowing liquid droplets of different types.
computer_graphics	image splicing is a common and widespread type of manipulation, which is defined as pasting a portion of an image onto a second image. several forensic methods have been developed to detect splicing, using various image properties. some of these methods exploit the noise statistics of the image to try and find discrepancies. in this paper, we propose a new counter-forensic approach to eliminate the noise differences that can appear in a spliced image. this approach can also be used when creating computer graphics images, in order to endow them with a realistic noise. this is performed by changing the noise statistics of the spliced elements so that they are closer to those of the original image. the proposed method makes use of a novel way to transfer density functions. we apply this to image noise in order to impose identical noise density functions from a source to a destination image. this method can be used with arbitrary noise distributions. the method is tested against several noise-based splicing detection methods, in order to prove its efficacy.
distributed_computing	mobile agent technology is becoming more popular and has been implemented in many distributed computing domains. several research have been conducted to address its challenges including two most important ones which are agent spawning and agent mobility. this paper discusses the issues of mobile agent technology, the background of mobile agent cloning and spawning, agent mobility as well as the problems faced by many researchers in their research on mobile agents. the paper finally proposes new agent spawning and mobility models to resolve some of the researchers' problems.
network_security	key predistribution schemes for resource-constrained networks are methods for allocating symmetric keys to devices in such a way as to provide an efficient trade-off between key storage, connectivity and resilience. while there have been many suggested constructions for key predistribution schemes, a general understanding of the design principles on which to base such constructions is somewhat lacking. indeed even the tools from which to develop such an understanding are currently limited, which results in many relatively ad hoc proposals in the research literature. it has been suggested that a large edge-expansion coefficient in the key graph is desirable for efficient key predistribution schemes. however, attempts to create key predistribution schemes from known expander graph constructions have only provided an extreme in the trade-off between connectivity and resilience: namely, they provide perfect resilience at the expense of substantially lower connectivity than can be achieved with the same key storage. our contribution is twofold. first, we prove that many existing key predistribution schemes produce key graphs with good expansion. this provides further support and justification for their use, and confirms the validity of expansion as a sound design principle. second, we propose the use of incidence graphs and concurrence graphs as tools to represent, design and analyse key predistribution schemes. we show that these tools can lead to helpful insights and new constructions.
electricity	apples are a widely consumed fruit and have a high polyphenol content. the aim of this study was to analyse the combined effects of osmotic dehydration (od) and ohmic heating (oh) with a pulsed vacuum (pv) on polyphenol retention during the stored refrigeration of apple cubes. treatments were performed using a 65 degrees brix sucrose solution at 30, 40 or 50 degrees c for 120 min, and then, samples were stored for 28 days at 5 degrees c. oh provides an electric field of 13 v cm(-1), and a pulsed vacuum was applied for 5 min at the beginning of the process. the results indicated that a lower temperature process (30-40 degrees c) resulted in the retention of more polyphenol compounds after treatment than a higher temperature process (50 degrees c). nevertheless, during refrigerated storage, we observed that 50 degrees c preserved these compounds better due to polyphenol oxidase inactivation. pvod/oh treatment at 50 degrees c was determined to be the best retention of polyphenols from the fresh apple for dehydrating apples.
data_structures	formal language theory plays, in computer science, a fundamental role that allows, among other things, the development of one of the cornerstones of information technology: programming languages. they define the mandatory grammatical rules that programmers need to follow to create the tools that enable humans to interact with machines. despite its significance, formal language theory is often taken for granted, even by software developers, who regularly follow the rules of their programming domain. unless the developer is creating its own programming language, data structure, or describing the formal background of an existing one, he will not need to dive deep into formal languages, grammar or automaton theory. those who do need to develop their own rules will first have to understand the theory of formal languages, and the limitations they impose. this paper will do an introduction to the fundamentals of language theory, their classification, restrictions and representation. once this ground rules are set, we will use a worldwide known data structure format such as the javascript object notation (json), to formally define its grammar rules and automaton. all of this formal background will allow us to transform theory into bits, by developing an algorithm that will analyze streams of texts, accepting or rejecting them as they comply or not with the predefined rules. finally, we will analyze the outcomes of this implementation, its benefits, limitations, and alternatives that could have been followed.
analog_signal_processing	the system dynamics computer simulation modeling methodology is one of the most suitable and effective ways of dynamics modeling of complex non-linear, natural, technical and organization systems. studying the dynamics behavior of marine electric power systems, as one of the more complex dynamic non-linear technical systems, requires the application of only the most effective modeling methods. the aim of this paper is to show the efficiency of the system dynamics computer simulation modeling of the dynamics behavior of marine diesel-drive generating set, as one of the most complex and non-linear marine technical systems. the marine diesel-drive generating set will be presented as a qualitative and quantitative system dynamics computers model with a special automation aspect provided by two unieg-pid-regulators (electronics universal pid regulators). one of them will be used for diesel-motor speed (frequency) regulation and the other will be used for the synchronous electrical generator voltage regulation. this computer simulation model of the marine diesel-drive synchronous generating set is very suitable education simulator software, especially for marine students and marine system engineers because it provides them with the means to conduct numerous simulations for various productive scenarios.
operating_systems	traditional network architecture is inflexible and complex. this observation has led to a paradigm shift toward software-defined networks (sdns), in which the network control level is separated from the data link layer. this change became possible because of the control plane transfer from switching equipment to software modules that run on a dedicated server called a controller (or a network operating system) or to network applications that work with this controller. methods of presentation, storage, and communication interfaces with network topology elements available to sdn controller users are the most important aspects of network operating systems because the operation of some key controller modules depends heavily on the internal representation of the network topology. firewall and routing modules can be cited as examples of these modules. this paper considers the methods used to represent and store the network topology, as well as communication interfaces with corresponding modules of the floodlight controller. an alternative algorithm for exchanging messages on the changes in the network topology between the controller and network applications has been proposed and developed. the algorithm makes it possible to issue notifications based on a subscription to relevant events. an api for the module of interacting with applied programs of the sdn controller has been developed. the topology tracker module has been designed based on this algorithm and api. in active mode, this module can inform network applications about the changes in the network topology and store its compact representation for the interaction acceleration.
microcontroller	a thermoelectric energy harvesting system designed to harvest tens of microwatts to several milliwatts from low-voltage thermoelectric generators is presented in this paper. the proposed system is based-on a two-stage boost scheme with self-startup ability. a maximum power point tracking technique based on the open-circuit voltage is adopted in the boost converter for high efficiency. experimental results indicate that the proposed system can harvest thermoelectric energy and run a microcontroller unit and a wireless sensor node under low input voltage and power with high efficiency. the harvest system and wireless sensor node can be self-powered with minimum thermoelectric open-circuit voltage as 62 mv and input power of 84 mu w. with a self-startup scheme, the proposed system can self-start with a 20 mv input voltage. low power designs are applied in the system to reduce the quiescent dissipation power. it results in better performance considering the conversion efficiency and self-startup ability compared to commercial boost systems used for thermal energy harvesting.(c) 2017 elsevier ltd. all rights reserved.
distributed_computing	cloud computing is a set of information technology services that are provided to a customer over a network on a leased basis and with the ability to scale up or down their service requirements. cloud computing is a new general purpose internet-based technology through which information is stored in servers and provided as a service and on-demand to the clients. it builds on decades of research in virtualization, distributed computing, utility computing, and more recently networking, web and software services. it implies a service oriented architecture, reduced information technology overhead for the end-user, great flexibility, reduced total cost of ownership, on-demand services and many other things. this paper discusses the concept of cloud computing, some of the issues it tries to address, and available cloud computing implementation.
distributed_computing	in this paper, we focus on detecting a special type of anomaly in wireless sensor network (wsn), which appears simultaneously in a collection of neighboring nodes and lasts for a significant period of time. existing point-based techniques, in this context, are not very effective and efficient. with the proposed distributed segment-based recursive kernel density estimation, a global probability density function can be tracked and its difference between every two periods of time is continuously measured for decision making. kullback-leibler (kl) divergence is employed as the measure and, in order to implement distributed in-network estimation at a lower communication cost, several types of approximated kl divergence are proposed. in the meantime, an entropic graph-based algorithm that operates in the manner of centralized computing is realized, in comparison with the proposed kl divergence-based algorithms. finally, the algorithms are evaluated using a real-world data set, which demonstrates that they are able to achieve a comparable performance at a much lower communication cost.
analog_signal_processing	this paper describe methods of analysis concerning efficiency in electrical power consumption (efficiency in electrical power transfer from the electrical generator to the electrical consumers). in the presence of unbalanced or/and non-linear consumers, the analysis gets more complicated; in those situations, the described analysis points upon the importance of electrical current flow computation (more precise, about flow of sequence negative component of electrical current or harmonic components).
analog_signal_processing	electrocardiogram (ecg) detection in patients with heart health is an important technical means. because the load of heart is added in motion, heart diseases are likely to be induced by signal. the detection of ecg in the moving state is more necessary. but the ecg signal, a weak bioelectrical signal, is susceptible to environmental interference. especially in the state of motion, the ecg includes the main interference signals: motion jitter interference, frequency interference, baseline drift and capacitively coupled noise between the electrode line interference. this paper studies the noise signals. 50hz band-stop filter, the right leg driven circuit and 0.1-150hz band pass filter are used in the analog signal processing, and the wavelet transform algorithm is used in digital signal processing. ecg can be detected in a strong movement noise background. the results show that the sensor has the advantages of anti-interference, high fidelity, fast response speed and good stability.
electrical_network	the paper describes the development of a hardware-in-the-loop (hil) test platform for the performance assessment of a pmu-based sub-second linear real-time state estimator (rtse) for active distribution networks (adns). the estimator relies on the availability of data coming from phasor measurement units (pmus) and can be applied to both balanced and unbalanced adns. the paper first illustrates the architecture of the experimental hil setup that has been fully designed by the authors. it consists of a real-time simulator (rts) that models the electrical network model as well as the measurement infrastructure composed by virtual pmus. these virtual devices stream their data to a real phasor data concentrator (pdc) suitably coupled with a discrete kalman filter state estimator (dkf-se). by using this experimental setup, the paper discusses the performance assessment of the whole process in terms of estimation accuracy and time latencies. in the rts, a real adn located in the netherlands has been modeled together with the associated pmus.
electricity	the research ""behavior change and energy use"" (us department of energy and climate change, 2011) [1] shows that with better information in the monthly electricity bill, the energy performance certificate (epc) can encourage people to reduce their energy usage. that is why smart meters - the emerging technology to help people to know their monthly energy consumption, are gradually replacing mechanical power meters. in this paper, we investigate a special energy monitoring process named non-intrusive appliance load monitoring (nialm), which is potentially the best method to give consumers pertinent information with respect to power consumption. however, real-time feedback feature in a low cost nialm system is still a big challenge in such technology because of the complication in nialm 's algorithms. system on chip (soc) technology can solve this challenge. besides including high-speed interconnection and multi-processors, integrating field-programmable gate array (fpga) into socs may be the most important evolution, which provides developers a powerful tool to develop a low cost but high performance system. therefore, in this paper we proposed a development of a real-time nialm system based on the soc with fpga acceleration. (c) 2017 elsevier ltd. all rights reserved.
digital_control	this paper introduces a high power density step-up converter for led applications, based on a hybrid serial-output (hso) architecture [1], which is suitable for on-chip implementation. in this system, the output voltage is formed by stacking the output of a switched-capacitor (sc) converter on top of a boost converter output. the high power density sc converter processes around a half of the power of the system and is left unregulated. the boost converter processes the remainder of the power and regulates the output voltage. in comparison with conventional boost-based solutions, the introduced boost-sc hso drastically reduces the passive component volume and decreases peak voltage stress of switches. experimental results obtained with a 3.7 v to 13 v, 2.6 w, 1080 khz prototype show that the introduced sc-boost hso converter has about three times smaller reactive component area than a conventional boost having the same power processing efficiency.
operating_systems	the internet of things (iot) is projected to soon interconnect tens of billions of new devices, in large part also connected to the internet. iot devices include both high-end devices which can use traditional go-to operating systems (oss) such as linux, and low-end devices which cannot, due to stringent resource constraints, e.g., very limited memory, computational power, and power supply. however, large-scale iot software development, deployment, and maintenance requires an appropriate os to build upon. in this paper, we thus analyze in detail the specific requirements that an os should satisfy to run on low-end iot devices, and we survey applicable oss, focusing on candidates that could become an equivalent of linux for such devices, i.e., a one-size-fits-most, open source os for low-end iot devices.
electrical_circuits	this paper presents an effective technique for both synchronization and secure communication. in particular, an adaptive sliding mode observer is developed and practically implemented. only one component of the state vector of the transmitter, that satisfies the observability matching condition, is sent to the receiver via a public channel, which is a sliding mode observer. this observer is able to estimate the state vector of the transmitter and then, reconstruct the unknown information hidden in the transmitted with inclusion encryption. finally, the chaotic secure communication system is simulated with matlab and then practically implemented by electrical circuits with multisim software and ultiboard software.
electric_motor	the paper deals with the motion control of an induction motor. because the nonlinear state equations describing the dynamics of such a machine can be embedded into a linear model with the rotor speed as a varying parameter, advantage is taken of some recent results on the control of linear parameter-varying systems, thus ensuring stability independently of how the varying parameter changes in time within a compact set. the adopted control structure consists of a fast inner electric loop that controls the stator currents and an outer mechanical loop that generates the torque acting on the motor shaft. of crucial importance is the design of the internal model controller for the current loop. in particular, it is proved that an algebraically equivalent electric motor model admits a lyapunov function that, together with its lyapunov derivative, is independent of and of all motor parameters. this result allows us to find an upper bound on the norm of the youla-kucera parameter that ensures robust stability against speed measurement errors. simulations carried out on a benchmark motor model show that the adopted control strategy performs well. copyright (c) 2014 john wiley & sons, ltd.
electrical_network	power systems are getting complicated as load centers get connected through network thus forming power grids. since then black outs of power systems have become common. in an interconnected system, the loss of generation in one area can be replaced by generation from other areas. thus, several systems interconnected can survive contingencies that the individual systems could not. thus one benefit of interconnected power systems is the potential for increased reliability. this paper discusses the implementation of an automatic load transfer program in a ring electrical network using supervisory control and data acquisition (scada) system that automates electric power system operations thus maintaining reliability.
electric_motor	aluminum can be absorbed through the digestive system from water and drinks and the food that contains natural traces and processed food or the food cooked in aluminum cookware. some studies show that the people exposed to high levels of aluminum may develop kidney, bone and brain diseases. aluminum foil (alfesi) is daily used as packaging for food and drugs stored in the refrigerator where an electric motor induces a magnetic field of a few microteslas. the purpose of this work is to study the corrosion behavior of various aluminum packaging foils and the effect of a weak magnetic field on the morphology and the corrosion kinetics in the 0.3 % and 3 % of mass fractions of nacl solutions. the mean results for various aluminum packaging foils show that localized corrosion is controlled by the electrochemical potentials of different phases constituting the aluminum foil and the concentration of the precipitates from the other phases. the morphology and the corrosion kinetics of aluminum packaging foil in the 0.3 % and 3 % of mass fractions of nacl solutions are different with and without an application of a weak magnetic field. electrochemical tests applied to cheese packaging paper show that the introduction of a magnetic field decreases the polarization resistance, the potential of passivation and the value of the open-circuit potential at the beginning of the corrosion; however, its passivation-current density increases at the beginning of the corrosion. the values of the open-circuit potential with and without a weak magnetic field are the same after thirty days of corrosion.
image_processing	a novel depth from defocus (dfd) measurement system is presented, where the extension of the measurement range is performed using an emergent technology based on liquid lenses. a suitable set of different focal lengths, obtained by properly changing the liquid lens supply voltage, provides multiple camera settings without duplicating the system elements or using moving parts. a simple and compact setup, with a single camera/illuminator coaxial assembly, is obtained. the measurement is based on an active dfd technique using modulation measurement profilometry for the estimation of the contrast at each image point as a function of the depth range. two different measurement methods are proposed, both based on a combination of multiple contrast curves, each derived at a specific focal length. in the first method (intensity contrast method), the depth information is recovered directly from the contrast curves, whereas in the second (differential contrast method), the depth is measured using contrast curve pairs. we obtained a measurement sigma(0) of 0.55 mm over a depth range of 60 mm with the intensity contrast method (0.92% of the total range) and an sigma(0) of 0.76 mm over a depth range of 135 mm with the differential contrast method (0.56% of the total range). thus, the intensity contrast method is within the state-of-the-art dfd systems, whereas the differential contrast method allows, sigma(0) being almost equal, a remarkable extension of the depth range.
image_processing	aim of this paper was to assess the clinical effectiveness of a novel ultrasound (us) approach for the estimation of bone fragility. a total of 85 female patients (40-80 years) were recruited and underwent conventional dxa investigations of both lumbar spine and proximal femur, an abdominal us scan of the lumbar spine and the frax (r) questionnaire for the calculation of osteoporotic fracture probabilities. acquired us data were analyzed through an automatic algorithm that calculated the fragility score (f. s.), a parameter that estimates skeletal fragility from dedicated spectral and statistical analyses. f.s. showed a good correlation with the most reliable fracture risk predictions obtained by frax (r) (r=0.71, p<0.001). since this correlation level with frax (r) outcomes was much better than lumbar bmd one ( vertical bar r vertical bar = 0.43) and very similar to that obtained for femoral neck bmd (vertical bar r vertical bar = 0.72), f.s. has the potential to become a simple and non-ionizing method for bone fragility assessment. (c) 2016 elsevier ltd. all rights reserved.
microcontroller	this paper presents a developed methodology for the detection of bovine milk adulteration by applying electrical impedance measurements. this parameter allows characterizing samples of raw and ultrahigh temperature milk, adulterated with different proportions of drinking water, deionized water, hydrogen peroxide (h2o2), sodium hydroxide (naoh), and formaldehyde (ch2o). the samples were electrically analyzed by applying the electrical impedance spectroscopy measurements and a dedicated microcontroller system, developed for this application. in both cases, the measures allowed classifying the milk quantitatively, enabling the development of real-time monitoring systems for fraud detection in milk composition. a classification of the results is proposed through a k-nearest neighbors algorithm that allows to quantitatively qualify the samples of pure and adulterated milk.
computer_programming	novice programmers have a misconception of what programming is in the early stages of learning programming. a flowchart-based programming environment (fpe) is developed in this research with the aim of introducing the early stages of learning programming to clarify matters. an attempt is made to introduce the basic programming algorithms prior to surface structure using an automatic text-to-flowchart conversion approach in order to improve students' problem-solving skills. thus, this system allows students to focus less on language and syntax and more on solution designing in the form of flowchart development. the main objective of this study is to support the problem-solving ability through designing activities. how exactly fpe employs text-to-flowchart conversion as a visualization-based approach to provide the students with their final flowchart for subsequent stages of programming is discussed in this paper. the proposed system is evaluated using 50 first-year undergraduate students taking their first introductory courses in programming called ""programming 1"" at university of malaya, who gave very positive feedback. a very awarding finding was that an automatic text-to-flowchart conversion approach applied in fpe successfully motivated almost all participants in problem-solving activities. consequently, the results suggest further development of a text-to-flowchart conversion approach in the form of a multi-agent system (mas) in future in order to make the early stages of learning programming more encouraging for students.
electric_motor	we present a theoretical and experimental analysis of the model for diffusion of engineering innovations that has recently been proposed by cao and yang (2012). in particular, under a very mild and realistic assumption on the innovation coefficients, we show that a unique solution defined on the whole set of (positive) times does always exist. moreover, a numerical method to solve the model by cao and yang is developed whose convergence is proven theoretically and which is shown by direct simulation to be very accurate and fast. finally, an experimental assessment of the model is performed by considering the case of the us satellite radio market. such an analysis highlights that the model by cao and yang can be very useful to predict the dynamics of the firms already present in the market as well the time evolution of new start-ups.
state_space_representation	this paper addresses the partial synchronization problem for the interconnected boolean networks (bns) via the semi-tensor product (stp) of matrices. first, based on an algebraic state space representation of bns, a necessary and sufficient criterion is presented to ensure the partial synchronization of the interconnected bns. second, by defining an induced digraph of the partial synchronized states set, an equivalent graphical description for the partial synchronization of the interconnected bns is established. consequently, the second partial synchronization criterion is derived in terms of adjacency matrix of the induced digraph. finally, two examples (including an epigenetic model) are provided to illustrate the efficiency of the obtained results.
machine_learning	identifying network traffics at their early stages accurately is very important for network management and security. recent years, more and more studies have devoted to find effective machine learning models to identify traffics with few packets at the early stage. in this paper, we try to build an effective early stage traffic identification model by applying flexible neural trees (fnt). three network traffic data sets including two open data sets are used for the study. we first extract both packet-level features and statistical features from the first six continuous packets and six noncontinuous packets of each flow. packet sizes are applied as packet-level features. and for statistical features, average, standard deviation, maximum and minimum are selected. eight classical classifiers are employed as the comparing methods in the identification experiments. accuracy, true positive rate (tpr) and false positive rate (fpr) are applied to evaluate the performances of the compared methods. fnt outperforms the other methods for most cases in the identification experiments, and it behaves very well for both tpr and fpr. furthermore, it can show the selected features in the optimal tree result. experiment result shows that fnt is effective for early stage traffic identification.
signal-flow_graph	based on pebb concept, a multi-phase bidirectional dc-dc converter is proposed. the signal flow graph sfg models for ccm and dcm mode with positive power flow or reverse power flow are deduced. the dual closed loop controller are designed to improve system stability and dynamic performance. the current/voltage ripples are analyzed thoroughly. the design of coupled inductors is given. finally, a prototype of 150kva bi-directional dc-dc converter is developed. with this converter system, the high output voltage and high current is possible with low cost. experimental results are provided to confirm the analysis and control concept.
digital_control	digitally controlled oscillators are the main cores in all-digital phase-locked loops (adpll), which are important for determining the range of frequency and power consumption in adplls. in the conventional digitally controlled oscillator (dco) designs, one single band of operation is assigned to the dco. the following paper presents a new approach in the design of dcos, which works in dual-band and wide-band modes with a control unit. in dual-band mode, the dco works in two different ranges of frequencies simultaneously via digital control bits. the wide-band dco (wbdco) works in one wider range of frequencies consecutively. it seems that in the wide-band dco, the gap width for the dual-band dco (dbdco) is zero. the previously mentioned designs allow the designer to have standard frequencies with the help of direct or multiplied frequencies. so, we can have a trade-off between power and performance. this means that we can have low power consumption in low-frequency applications and vice versa. the proposed designs are based on using digitally controlled capacitors, current starving gates and schmitt triggers in critical points of the dco loop, while preserving coarse and fine tunings. the non-delay linearity factors are clearly investigated and resolved with the use of a new combined control unit. the simulations of the proposed designs are performed in hspice with a voltage of v in 180 nm cmos technology for 64- and 128-bit input coarse codes. our simulation and evaluation results showed that in the dual-band dco, a 14.8 ps jitter was calculated at 134 mhz with 1.2131 mw power consumption, while in the wide band with overlap mode, a 68.7 ps jitter was measured at 184.61 mhz with 1.604 mw power consumption. our designs are proper for reconfigurable and multi-standard adpll designs.
analog_signal_processing	a current-mode universal biquadratic filter with five inputs and one output employing three inverting second-generation current conveyors (icciis), two grounded capacitors and two resistors is presented. the new circuit offers the following advantage features: very low active and passive sensitivities, using of grounded capacitors that is ideal for integrated circuit implementation, the versatility to synthesize any type of active filter transfer functions without requirements for critical component matching conditions, very high output impedance and needs not another current follower to duplicate the input current signal for the realization of notch or allpass responses.
signal-flow_graph	we address the problem of testing digital shapers used for nuclear spectroscopy. particularly, we propose a solution based on the oscillation-based test (obt) for testing the finite impulse response (fir) filters of the shaper. the obt strategy developed here exploits the natural partition of the system in high-pass and low-pass sections for implementing two different non-linear oscillators. the oscillation parameters are obtained in advance using two different approaches: one based on the filter signal flow-graph; the other based oil the describing function technique. the fault simulation results show high fault coverage and acceptable test time. additionally, we suggest the use of this test strategy in a bist environment, because it does not need resources for pattern generation and presents both low system intrusion and low hardware overhead.
data_structures	this study contains an examination of the missing data structures, occurring in many fields, especially in livestock. it also examines the processes to obtain the solution for the missing data. for this purpose, linolenic acid measurements obtained from four different anatomic regions of two animal species were taken as dependent variables. for the dependent variable, the observations were deleted at the ratio of 10% and 20%, creating the missing structures of missing completely at random (mcar) and missing at random (mar). subsequently, these data sets were completed using multiple imputation (mi) method. generalized estimating equation (gee) and mixed model methods were used in the missing data structures and for the purpose of evaluating the data completed with mi. the study were obtained almost same results obtained from gee and mixed model in the missing data structures. at the same time, there was not found difference between the methods in completed data using mi method. as a result, it is stated that valid results obtained in missing data structures by used gee and mixed model analysis. when these results are also compared, it can be concluded that multiple imputation (with these ratio of missing) is not necessary before gee and mixed model.
computer_programming	we teach computer programming to students aged 17 through 18 years. the course is structured into two units, with the first and second term each consisting of two 90-minute sessions per week conducted over 30 weeks. the course combines lectures with practical exercises. every year we conduct a survey following the first term of two 90-minute sessions per week held over 30 weeks. the survey 's results show that not a few students consider themselves to have insufficient understanding of programming or think that they are not good at programming. in response, we adopted and implemented a part of the computer science unplugged (cs unplugged) method, which is considered an effective way of teaching information science. however, although cs unplugged has generated considerable results in motivating students to learn and in initial learning, we feel that it is not sufficiently connected to full-fledged programming languages such as c and java. accordingly, we propose a new method of advancing from cs unplugged to full-fledged programming. the proposed method begins with conducting a cs unplugged activity, and then continues on to the writing of a program on the same theme and further to its abstraction in java. in this paper, we describe the thinking and concepts behind this proposed method.
system_identification	this study reports on the assessment of the vibrational serviceability performance of a parallel cable-stayed bridge, which was subjected to a vortex-induced vibration (viv) in 2011, by identifying modal damping ratios from the operational monitoring data that were obtained. the natural excitation technique (next) combined with the eigen realization algorithm (era) was applied for the output-only modal analysis. parameters regarding the next and era procedures were determined from a sensitivity analysis of identified damping ratios. because a multiple tuned mass damper (mtmd) was installed at the center of the main span to mitigate viv, the modal damping ratios before and after the installation of the mtmd were also compared. several sets of operational monitoring data that had been collected under various windy conditions were used to develop a relationship between the identified damping ratios and the corresponding viv level of the bridge. on the basis of these findings, the performance of the bridge was enhanced regarding vibrational serviceability. (c) 2016 american society of civil engineers.
network_security	the rapid growth of residential broadband connections and internet-enabled home devices have driven the success of many useful applications such as video streaming and remote healthcare. however, poorly managed routers and connected devices in the home are vulnerable under persistent threats and exploitations from cyber attackers across the internet who continuously identify, compromise, and control devices as part of botnets for launching click fraud, denial of service attacks, spam campaigns. these growing threats and broad damages have made it imperative to understand, characterize, filter, and reduce exploit traffic towards millions of home routers and billions of connected devices in the home. this paper presents a bloom-filter based analytics framework to capture persistent threats towards the same home routers and to identify correlated attacks towards distributed home networks. our experimental results based on network traffic collected from real homes over 18 months have revealed a number of interesting findings on persistent and correlated threats towards home networks, which calls for improved security and management of home networks. to the best of our knowledge, this paper is the first effort to characterize cyber threats towards home networks and to propose a simple and yet effective approach to identify persistent and aggressive attacks towards home networks. copyright (c) 2016 john wiley & sons, ltd.
electric_motor	a novel motor design methodology and optimization is proposed, which is applied to a srm. it greatly reduces the finite element analysis use. a multi physics study is realized in order to couple the thermal, magnetic and electric motor analysis. then, the information obtained with this study allows creating different behaviors maps in order to evaluate the motor in all operating area. with the joule and iron losses, the thermal network obtains a temperature map for each current and angular speed. then, the electric model uses the parameters obtained on reluctances network and the phase resistance variation obtained on thermal lumped parameter. finally, the optimal motor obtained is validated on fea. to sum up, the motor design is obtained using multi physics analysis taking into account different operating points, i.e. it is a range operation optimization. in addition, reducing fea computation time is achieved with the methodology proposed.
electrical_network	in this work, the problem of intracellular currents in longilinear bacteria, such as escherichia coli, suspended in a physiological medium and submitted to a harmonic voltage (ac), is analyzed using the finite-element-based software comsol multiphysics. bacterium was modeled as a cylindrical capsule, ended by semi-spheres and surrounded by a dielectric cell wall. an equivalent single-layer cell wall was defined, starting from the well-recognized three-shell modeling approach. the bacterium was considered immersed in a physiological medium, which was also taken into account in the modeling. a new complex transconductance was thus introduced, relating the complex ratio between current inside the bacterium and voltage applied between two parallel equipotential planes, separated by a realistic distance. when voltage was applied longitudinally relative to the bacterium main axis, numerical results in terms of frequency response in the 1-20 mhz range for e. coli cells revealed that transconductance magnitude exhibited a maximum at a frequency depending on the cell wall capacitance. this occurred in spite of the purely passive character of the model and could be explained by an equivalent electrical network giving very similar results and showing special conditions for lateral paths of the currents through the cell wall. it is shown that the main contribution to this behavior is due to the conductive part of the current. (c) 2016 wiley periodicals, inc.
software_engineering	the problem of automatically constructing a software component such that when executed in a given environment satisfies a goal, is recurrent in software engineering. controller synthesis is a field which fits into this vision. in this paper we study controller synthesis for partially observable lts models. we exploit the link between partially observable control and non-determinism and show that, unlike fully observable lts or kripke structure control problems, in this setting the existence of a solution depends on the interaction model between the controller-to-be and its environment. we identify two interaction models, namely interface automata and weak interface automata, define appropriate control problems and describe synthesis algorithms for each of them.
electrical_network	this design paper proposes few improvements on the existing electrical network in the aircraft system. it also suggests improvement in the starter circuitry by introducing super capacitors to reduce the number of batteries on board to ensure improved safety and reliability. it proposes higher frequency of power distribution owing to several benefits. there are several advantages of high frequency ac power distribution over conventional dc distribution and low frequency ac power distribution. this paper explores the idea of employing switched capacitor and switched inductor converters to design multi-level inverters for high frequency ac power supplies for power distribution.
analog_signal_processing	the recent developments of electron quantum optics in quantum hall edge channels have given us new ways to probe the behavior of electrons in quantum conductors. it has brought new quantities called electronic coherences under the spotlight. in this paper, we explore the relations between electron quantum optics and signal processing through a global review of the various methods for accessing single- and two-electron coherences in electron quantum optics. we interpret electron quantum optics interference experiments as analog signal processing, converting quantum signals into experimentally observable quantities such as current averages and correlations. this point of view also gives us a procedure to obtain quantum information quantities from electron quantum optics coherences. we illustrate these ideas by discussing two-mode entanglement in electron quantum optics. we also sketch how signal processing ideas may open new perspectives for representing electronic coherences in quantum conductors and understand the properties of the underlying many-body electronic state.
digital_control	there has been a growing demand of using multi-function inverters for grid-connected systems applied to nonconventional energy sources, such as solar, wind and so on. in addition to power quality conditioning, the inverter can also be used for bidirectional active power exchange with a three-phase four-wire grid. therefore, the inverter acts as a multi-function compensator. the functions of the proposed inverter system include active power injection, rectification and active power filtering (apf) (including phase power balancing). this paper presents design and implementation of a three-leg split-capacitor shunt multi-function inverter with division-summation (d-sigma) digital control. the adopted d-sigma digital control can accommodate filter inductance variation, reducing core size significantly, and its control laws can be derived directly to cancel the variation effects of dc-bus voltage, switching period and filter inductance. an average power method is adopted in this paper for determining fundamental currents at the source side. in the design and implementation, the inductances corresponding to various inductor currents were estimated at the startup and stored in the microcontroller for scheduling loop gain cycle by cycle, which can insure system stability. measured results from a three-phase four-wire inverter have confirmed the analysis and discussion.
electricity	resources scarcity and electricity demand have been dramatically increasing. wastewater is recognized as one of resources for water, energy and plant fertilizing nutrients. nevertheless, current wastewater treatment technologies have limitations due principally to their energy- and cost-intensive for achieving the conversion target of wastewater recovery. it is desired to develop a new technology to generate alternatives to conventional energy sources in a sustainable manner. an innovative technology based on the use of microbial fuel cells (mfcs) has been proved as a critical pathway for bioconversion processes towards electricity generation, then for addressing energy and environmental problems. three special features including energy saving, less sludge production and less energy production make mfcs outstanding compared with the existing technologies. multiform wastewaters could be efficiently degraded through advancing mfcs alone or integrating mfcs with other processing units. however, the low power density and the high operating cost of mfcs have greatly limited their applications on large-scale problems, and then result in some debates and doubts about their development and applications. therefore, this paper objectively discussed the problems and applications of mfcs in wastewater treatment. moreover, the integration of mfcs with other treatment processes was presented to verify the practicality and effectiveness of mfcs in contaminants removal. furthermore, the primary challenges and opportunities for scaling-up and future applications of mfcs in wastewater were analyzed.
computer_graphics	the technology of vr (virtual reality) is the result of the progress of science and technology since the 20th century, it embodied the computer technology, computer graphics, multimedia technology, sensor technology, display technology, human body engineering, human-computer interaction theory, the latest achievements of artificial intelligence, and other fields, has become the latest achievements after relay information field of multimedia technology and network technology is widely attention and research, development and application of hot spots, is currently the fastest growing a multi-disciplinary comprehensive technology. rapid generating equipment and interaction changed in the past, between people and computer dull, stiff, passive way of communication, make the man-machine interaction between become more humanized, blazed a new research field of human-computer interaction interface, which provides a new interface for the application of intelligent engineering tools, for all kinds of engineering provides a new description method of large-scale data visualization, but also changed the way people work and lifestyle and ideology.
electricity	this paper presents a fast and novel method to determine the optimal capacity of a battery and a hydrogen system for a grid-connected photovoltaic (pv) system based on the required grid dependency (gd) and the minimum levelized cost of energy (lce). the gd is calculated from the weather data at 9 locations throughout japan during 25 years considering different sizing of pv, battery, and hydrogen system. based on the results, the relationship between the gd and the capacities of the devices and the weather parameter is established. the results show that the gd depends on the annual total solar insolation and the devices' capacities as well. the empirical gd formula is then examined at a different location in japan. the proposed gd calculation agrees well with the gd obtained from the real 25 - year weather data and shows great advantages over the conventional method in the simplicity and calculation time. in addition, the optimal capacity of the system can be obtained directly from the gd formula and the objective function of the lce. (c) 2017 elsevier ltd. all rights reserved.
network_security	in a node replication attack, an adversary creates replicas of captured sensor nodes in an attempt to control information that is reaching the base station or, more generally, compromise the functionality of the network. in this work, we develop fully distributed and completely decentralized schemes to detect and evict multiple imposters in mobile wireless sensor networks (mwsns). the proposed schemes not only quarantines these malicious nodes but also withstand collusion against collaborating imposters trying to blacklist legitimate nodes of the network. hence the completeness and soundness of the protocols is guaranteed. our protocols are coupled with extensive mathematical and experimental results, proving the viability of our proposals, thus making them fit for realistic mobile sensor network deployments. (c) 2016 elsevier b.v. all rights reserved.
signal-flow_graph	for the problem of 1553b bus system testability modeling which has the character of bidirectional information transmission, to put forward a method of testability modeling for 1553b bus system based on multi-signal flow graph. on the basis of analyzing the bus topology, information transmission mechanism and fault mode of 1553b bus, to construct the multi signal flow graph model of 1553b bus system by modeling of bi-redundancy bus structure, multi-dimension function attribute definition, multi-work mode and test item definition. finally, by analyzing of an example, it proved the effectiveness of this 1553b multi-signal flow graph constructed in this paper.
algorithm_design	recently, degree-of-freedom (dof)-based models have been widely used to study mimo network performance. existing dof-based models differ in their interference cancellation (ic) behavior and many of them suffer from either loss of solution space or possible infeasible solutions. to overcome these limitations, a new dof-based model, which employs an ic scheme based on node-ordering was proposed. in this paper, we apply this new dof ic model to study a throughput maximization problem in a multihop mimo network. the problem formulation involves joint consideration of flow routing and dof allocation and falls in the form of a mixed-integer linear program (milp). our main contribution is an efficient polynomial time algorithm that offers a competitive solution to the milp through a series of linear programs (lps). the algorithm employs a sequential fixing framework to obtain an initial feasible solution and then improves the solution by exploiting: 1) the impact of node ordering on dof consumption for ic at a node and 2) route diversity in the network. simulation results show that the solutions obtained by our proposed algorithm are competitive and feasible.
data_structures	multicore architectures are becoming the most promising computing platforms thanks to their high performance. the soft error rate in multicore systems increases by the trend in the transistor sizes and the reduction of the voltage of the transistors. evaluating the impact of soft errors on parallel applications is critical to understand the fault characteristics and to decide the fault tolerance strategies for the reliable execution. in this paper, we examine the soft error vulnerabilities of shared data in parallel java applications. to analyze fault behavior of shared data in parallel programs, we design and implement a bytecode instrumentation based analysis and fault injection framework. we evaluate the fault behavior of shared data fields on a set of parallel applications from nas benchmark suite. our experimental evaluation demonstrates data type and access characteristics of the shared fields, and shows that shared data structures of parallel applications are more vulnerable to soft errors. while error rates for unshared local data stay around 20% in our target applications, the rate for shared data exceeds above 30% for some applications. we further discuss potential directions of our results and how shared data analysis can be employed to apply partial fault tolerance techniques. (c) 2016 elsevier b.v. all rights reserved.
image_processing	to help the clinicians to segment the borders of the left ventricle (lv) efficiently during measurement of the heart, the authors come up with a semi-automatic approach in this study that is capable of identifying the endocardial borders robustly from cine magnetic resonance images. firstly, the deformation flow is computed between the inputted boundary in the previous frame and the extracted edge of the lv in the current frame based on boundary minimum distance principle (bmdp). then, the deformation flow is constrained by optical flow calculated by a partial differential equation model. a smooth deformation boundary is then formed by minimising the energy between the previously inputted boundary and the rough boundary obtained by bmdp and optical flow constraint. to extract edge of the lv as accurate as possible, a threshold selection method is used and improved based on the previous study. the proposed approach is tested on the open access dataset. the computed average perpendicular distance is 1.36 +/- 0.24mm and the computed dice measure is 90.7%+/- 0.15%. experimental results show that the proposed approach is significantly more accurate than the referenced state of art methods.
computer_graphics	the aspect ratio of a plot can strongly influence the perception of trends in the data. arc length based aspect ratio selection (al) has demonstrated many empirical advantages over previous methods. however, it is still not clear why and when this method works. in this paper, we attempt to unravel its mystery by exploring its mathematical foundation. first, we explain the rationale why this method is parameterization invariant and follow the same rationale to extend previous methods which are not parameterization invariant. as such, we propose maximizing weighted local curvature (mlc), a parameterization invariant form of local orientation resolution (lor) and reveal the theoretical connection between average slope (as) and resultant vector (rv). furthermore, we establish a mathematical connection between al and banking to 45 degrees and derive the upper and lower bounds of its average absolute slopes. finally, we conduct a quantitative comparison that revises the understanding of aspect ratio selection methods in three aspects: (1) showing that al, awo and rv always perform very similarly while ms is not; (2) demonstrating the advantages in the robustness of rv over al; (3) providing a counterexample where all previous methods produce poor results while mlc works well.
computer_programming	among the computer science courses intended for high school non-majors, the visual basic (vb) program design is a very important foundation curriculum. however, in the traditional vb teaching, acquiring programming theory knowledge is especially difficult for the non-computer major students. it is urgent to find an effective way to cultivate a solid theoretical foundation and strong practical ability of students in university computer teaching. problem based learning is a novel teaching method based on the guidance of the construct theory, which has good teaching effects in many cases. the paper presented a brief introduction to the pbl teaching method, and proposed a novel instruction design method for computer programming course teaching. the extra high teaching effects obtained in the practical application of the vb program design course has demonstrated the effectiveness of our proposed instruction design method with problem based learning.
computer_graphics	to assist the rehearsal and planning of robot-assisted partial nephrectomy, a real-time simulation platform is presented that allows surgeons to visualise and interact with rapidly constructed patient-specific biomechanical models of the anatomical regions of interest. coupled to a framework for volumetric deformation, the platform furthermore simulates intracorporeal 2d ultrasound image acquisition, using preoperative imaging as the data source. this not only facilitates the planning of optimal transducer trajectories and viewpoints, but can also act as a validation context for manually operated freehand 3d acquisitions and reconstructions. the simulation platform was implemented within the gpu-accelerated nvidia flex position-based dynamics framework. in order to validate the model and determine material properties and other simulation parameter values, a porcine kidney with embedded fiducial beads was ct-scanned and segmented. acquisitions for the rest position and three different levels of probe-induced deformation were collected. optimal values of the cluster stiffness coefficients were determined for a range of different particle radii, where the objective function comprised the mean distance error between real and simulated fiducial positions over the sequence of deformations. the mean fiducial error at each deformation stage was found to be compatible with the level of ultrasound probe calibration error typically observed in clinical practice. furthermore, the simulation exhibited unconditional stability on account of its use of clustered shape-matching constraints. a novel position-based dynamics implementation of soft tissue deformation has been shown to facilitate several desirable simulation characteristics: real-time performance, unconditional stability, rapid model construction enabling patient-specific behaviour and accuracy with respect to reference ct images.
state_space_representation	the problem of controlling doubly fed induction generators (dfig) associated with wind turbines is addressed. the control objective is twofold: maximum power point tracking and reactive power regulation in the dfig. unlike previous works, we seek the achievement of this control objective without resorting to physical sensors of mechanical variables (e.g., wind turbine velocity and dfig rotor speed). interestingly, wind velocity is also not assumed to be accessible to measurements. the control problem is dealt with using an output feedback controller designed on the basis of the nonlinear state-space representation of the controlled system. the controller is constituted of a high-gain nonlinear state observer and a nonlinear sliding state feedback mode. using tools from lyapunov 's stability, it is formally shown that the closed-loop control system, expressed in terms of the state estimation errors and the output-reference tracking errors, enjoys a semi-global practical stability. accordingly, it is possible to tune the controller design parameters so that it meets its objectives with an arbitrarily high accuracy, whatever the initial conditions are. these theoretical results are confirmed by simulations involving wide range variation of the wind speed.
relational_databases	relational learning algorithms mine complex databases for interesting patterns. usually, the search space of patterns grows very quickly with the increase in data size, making it impractical to solve important problems. in this work we present the design of a relational learning system, that takes advantage of graphics processing units (gpus) to perform the most time consuming function of the learner, rule coverage. to evaluate performance, we use four applications: a widely used relational learning benchmark for predicting carcinogenesis in rodents, an application in chemo-informatics, an application in opinion mining, and an application in mining health record data. we compare results using a single and multiple cpus in a multicore host and using the gpu version. results show that the gpu version of the learner is up to eight times faster than the best cpu version.
software_engineering	nowadays, remote collaborative learning tools for computer science education mostly emphasize providing learning resources and realizing virtual collaborative learning environment for students. many people in this field tend to have their mind fixed on the process improvement of such a collaboration as a whole, while few notice that individuals may have different roles and impacts on this type of teamwork. there usually is a ""supervisor'' on the team, who offers support to all members in the collaborative learning environment. however, such support may not always be as accessible as students demand it to be. therefore, this paper describes a cloud-based tool to support software engineering practice courses in collaboration with remote tutors. this system utilizes a cloud storage platform to provide sharing of multimedia study materials and a better management of project developing cycles. a remote collaborative component called the virtual debug laboratory is designed to improve and share students' debugging experience in the same team. the most innovative feature of this system is that it amplifies the role of tutoring in remote collaborative learning environments so that tutors can, in real time, assist students in debugging during actual project developing and demonstrate step by step to the students the process of debugging. the results of the analyzed data regarding the use of this system indicate that the system can potentially enhance students' abilities in project developing and debugging in software engineering practice courses. it is our hope that these preliminary data can provide a future reference for the software education community.
electric_motor	assisting the control of a vehicle 's speed while driving downhill improves the vehicle 's safety and reduces the driver 's workload in both internal-combustion engine vehicles and hybrid electric vehicles. the current technology widely used in internal-combustion engine vehicles is a hill descent control system. however, hill descent control can be achieved only at lower speeds, but it may also lead to thermal wear of the brake components during prolonged intensive braking. there is currently no effective downhill safety assistance control technology for hybrid electric vehicles that is effective across the full range of speeds and can take advantage of regenerative braking. to address the limitations of previous studies, a novel downhill safety assistant control strategy for hybrid electric vehicles, which adapts to the characteristics of different drivers and takes advantage of all braking subsystems of hybrid electric vehicles, is proposed in this paper to improve the vehicle safety, the fuel economy and the ride comfort for the full range of speeds. to adapt to the characteristics of different drivers, the downhill driver 's intention model is established on the basis of a statistical data analysis of questionnaires and experiments, which is used to determine the control mode 's switching conditions and the control objective for downhill safety assistant control. to improve the vehicle safety, the fuel economy and the ride comfort for the full speed range, a coordinated control strategy for the electric motor 's braking subsystem, the engine 's braking subsystem and the hydraulic braking subsystem is developed, which includes six braking assistant modes, an identifying strategy and torque control of the electric motor based on coordinated control strategies. simulations and experimental results show that the proposed control strategy improves the vehicle safety, the fuel economy and the ride comfort of hybrid electric vehicles during downhill driving.
image_processing	wave theories of heating of the chromosphere, corona and solar wind due to photospheric fluctuations are strengthened by the existence of the wave coherency observed up to the transition region. the coherency of intensity oscillations of solar spicules was explored using the solar optical telescope (sot) on the hinode spacecraft with increasing height above the solar limb in the active region. we used time sequences near the south-east region from the hinode/sot for the ca ii h line obtained on 2015 april 3 and applied the de-convolution procedure to the spicule to illustrate how effectively our restoration method works on fine structures such as spicules. moreover, the intensity oscillations at different heights above the solar limb were analysed through wavelet transforms. afterwards, the phase difference was measured between oscillations at two heights in search of evidence for coherent oscillations. the results of the wavelet transformations revealed dominant period peaks for 2, 4, 5.5 and 6.5 min at four separate heights. the dominant frequencies for a coherency level higher than 75 per cent were found to be around 5.5 and 8.5 mhz. mean phase speeds of 155-360 km s (1) were measured. we found that the mean phase speeds increased with height. the results suggest that the energy flux carried by coherent waves into the corona and heliosphere may be several times larger than previous estimates that were based solely on constant velocities. we provide compelling evidence for the existence of upwardly propagating coherent waves.
computer_graphics	nowadays, in romania, centralized district heating is still widely used in many romanian cities. all the heating facilities were made during 1950-1970. the whole system is largely improper due to large amounts of heat leakage, lack of heat and energy efficiency measures and financial shortages. all these limitations are made worst due to the continuous limitation of resources and also due to the high price of the energy. by taking this aspects in consideration, the measurement and the management of the heating agent is a real priority for the power plants and also for the heating distribution companies from romania. the construction of small and efficient cogenerative plants is another major issue for the municipalities. there is a huge trend in the romanian district heating industry to introduce as many as possible it and tc solutions, or excellent measuring capacities. this paper presents human-machine interface, conceived by the authors and applied in the case of the small power plant located in freidorf-timisoara. starting from computer science, computer graphics and thermal engineering, to electronics and electrical engineering, this paper is a true example of a multidisciplinary research.
bioinformatics	premise of the study: dna metabarcoding has broad-ranging applications in ecology, aerobiology, biosecurity, and forensics. a bioinformatics pipeline has recently been published for identification using a comprehensive database of its2, one of the common plant dna barcoding markers. there is, however, no corresponding database for rbcl, the other primary marker used in plants. methods: using publicly available data, we compiled a reference library of rbcl sequences and trained databases for use with utax and rdp classifier algorithms. we used this reference library, along with the existing bioinformatics pipeline and its2 reference library, to identify species in an artificial mixture of nine species of pollen. we have made this database publicly available in multiple formats, to allow use with multiple bioinformatics pipelines, now and in the future. results: using the rbcl database, in addition to the its2 database, we succeeded in making species-level identifications for eight species and a family-level identification of the ninth species. this is an improvement on its2 sequence alone. discussion: the reference library described here will assist with identification of plant species using rbcl. by making another gene region available for standard barcoding, this will increase the resolution and accuracy of identifications.
cryptography	in this paper, homomorphic visual cryptographic scheme (hvcs) is proposed. the proposed hvcs inherits the good features of traditional vcs, such as, loss-tolerant (e.g., (k, n) threshold) and simply reconstructed method, where simply reconstructed method means that the decryption of the secret image is based on human visual system (hvs) without any cryptographic computation. in addition, the proposed hvcs can support signal processing in the encrypted domain (sped), e.g., homomorphic operations and authentication, which can protect the user 's privacy as well as improve the security in some applications, such as, cloud computing and so on. both the theoretical analysis and simulation results demonstrate the effectiveness and security of the proposed hvcs.
data_structures	let be a collection of d string documents of n characters in total, that are drawn from an alphabet set . the top-k document retrieval problem is to preprocess into a data structure that, given a query , can return the k documents of most relevant to the pattern p. the relevance is captured using a predefined ranking function, which depends on the set of occurrences of p in . for example, it can be the term frequency (i.e., the number of occurrences of p in ), or it can be the term proximity (i.e., the distance between the closest pair of occurrences of p in ), or a pattern-independent importance score of such as pagerank. linear space and optimal query time solutions already exist for the general top-k document retrieval problem. compressed and compact space solutions are also known, but only for a few ranking functions such as term frequency and importance. however, space efficient data structures for term proximity based retrieval have been evasive. in this paper we present the first sub-linear space data structure for this relevance function, which uses only o(n) bits on top of any compressed suffix array of and solves queries in time. we also show that scores that consist of a weighted combination of term proximity, term frequency, and document importance, can be handled using twice the space required to represent the text collection.
microcontroller	power-on reset (por), power supply monitor (psm) and control of dc-dc converters are required circuits in embedded systems. mobile systems often need special power down modes where these three functions por, psm and dc-dc control must be executed taking less than 1 mu a of current in total. traditional design techniques meet a fatal area problem as they try to reduce current by increasing the area of the design. this paper presents a power management (pmg) system designed in a 1.2v/90nm cmos process. the system is part of a cortex m3-based microcontroller. the pmg offers the por, psm and dcdc converter control functions for a 1.2v regulated supply and por, psm for the battery. this paper presents the best published combination of high precision (< 1.2% variation of trip voltages), power consumption (250nw), area (0.044mm(2)), and number of trip points observed (18).
system_identification	the well-known variable step-size least-mean-square (vsslms) algorithm provides faster convergence rate while maintaining lower mean-square error than the conventional lms algorithm. the performance of the vsslms algorithm can be improved further in a channel estimation problem if the impulse response of the channel is sparse. recently, a zero-attracting (za)-vsslms algorithm was proposed to exploit the sparsity of a channel. this was done by imposing an l(1) -norm penalty to the original cost function of the vsslms algorithm which utilizes the sparsity in the filter taps during the adaptation process. in this paper, we present the mean-square deviation (msd) analysis of the za-vsslms algorithm. a steady-state msd expression for the za-vsslms algorithm is derived. an upper bound of the zero-attractor controller (p) that provides the minimum msd is also provided. moreover, the effect of the noise distribution on the msd performance is shown theoretically. it is shown that the theoretical and simulation results of the algorithm are in good agreement with a wide range of parameters, different channel, input signal, and noise types.
software_engineering	context a software system 's structure often degrades due to repetitive maintenance. to make a sustainable evolution of such systems, it becomes mandatory to improve their modular structure after a certain time. many remodularization approaches were proposed to improve the modular structure of software systems. most of the existing approaches rely on structural or lexical dependencies. however, there is a lack of research that distinguishes different types of structural (e.g., inheritance, method calls, references, etc.) or lexical (name of classes, methods, variables, etc.) dependencies, but assumes that they are equivalent, which is illogical from a software developer 's point of view. objective: in this paper, we propose an approach that considers various types of structural as well as lexical dependencies along with their relative importance to remodularize the object-oriented (00) systems. the main goal of the paper is to generate remodularization solutions that can reflect the developers' perspective (as visible in the well-modularized software system) of remodularization, which is highly desirable in software evolution. method: the paper computes coupling strength among classes using different weights (computed on basis of well-modularized software system) in terms of various mechanisms of structural and lexical dependencies. software remodularization problem is formulated as a single and multi-objective optimization problem and solved using genetic algorithnis (ga). based on the different types of structural and lexical dependencies and as per their un-weighted/weighted variants, we have designed following 24 coupling schemes: structural-based (i.e., sbuw, sbw, sauw, saw, stfuw, stfw, stfidfuw, and stfidfw), lexical based (i.e., lbuw, lbw, lauw, law, ltfuw, ltfw, ltfidfuw, and ltfidfw), and combined structural lexical based (i.e., slbuw, slbw, slauw, slaw, sltfuw, sltfw, sltfidfuw, and sltfidfw). values obtained through these coupling schemes are used in coupling and cohesion objective function of the ga. along with this objective, some supportive objective functions such as mci and msi have been used to drive the optimization process towards a good quality modularization solution. results: we assess the effectiveness of our proposed remodularization approach over eight real-world object-oriented software systems in terms of original design of the experimented software systems and modularization decisions provided by the developers. results indicate that tfidf based weighted variants (i.e. stfidfw, ltfidfw, and sltfidfw) of each broad three categories outperformed rest of variants within each category. however, tfidf weighted variant in the third broad category (i.e., sltfidfw) outperformed all others. conclusion: our combined lexical-structural approach (sltfidfw) considering various types of dependencies along with their relative weights performs well and results into better remodularization compared to rest of considered alternates. it also shows significant improvement over techniques based on only lexical or structural information. thus this approach can be very useful to improve the quality of the software whose remodularization quality deteriorates beyond accepted level. (c) 2016 elsevier b.v. all rights reserved.
electrical_circuits	burgers-huxley equations and their reduced form are of vital importance in modeling the interaction between reaction mechanisms, convection effects and diffusion transports. in this paper, we applied the reduced form of differential transform method (reduced-dtm), present in previous works (abazari and borhanifar, comput math appl 59:2711-2722, 2010; borhanifar and abazari, j appl math comput 35:37-51, 2011; borhanifar and abazari, opt commun 283:2026-2031, 2010; abazari and ganji, int j comput math 88(8):1749-1762, 2011; abazari and abazari, commun nonlinear sci numer simul 17:619629, 2012), to solving burgers-huxley equations and their three reduced equations, namely, the burgers equation, the huxley equation and the burgers-fisher equation. the results obtained employing rdtm are compared with previous semi-analytical methods, such as hpm (he, appl math comput 135:73-79, 2003), ham (liao, beyond perturbation: introduction to the homotopy analysis method. chapman & hall/crc press, boca raton, 2003), dtm (zhou, differential transformation and its application for electrical circuits. huazhong university press, wuhan, 1986) and exact solution. as an important result, it is depicted that the rdtm results are more accurate in comparison with those obtained by classic hpm, ham and dtm. the numerical results reveal that the rdtm is very effective, convenient and quite accurate to time dependance kind of nonlinear equations. it is predicted that the rdtm can be found widely applicable in engineering.
signal-flow_graph	in this paper we propose a novel technique for tuning and enhancing performances of current conveyor based active circuits. the basic idea consists of judiciously adding controlled sources in the signal flow graph representing the active circuits. the potentiality of the proposed technique is showcased with five different examples (namely, enhancing performances of parallel and serial 'simplified circuits, enhancing performances of an fourth order ladder filter, tuning performances of an active second order filter, and tuning inductance value of active inductors), and its viability is supported with spice simulation results.
symbolic_computation	in this paper, a (2 + 1)-dimensional nonlinear evolution equation generated via the jaulent-miodek hierarchy is investigated. based on the bell polynomials and hirota method, bilinear forms and backlund transformations are derived. one- and two-soliton solutions are constructed via symbolic computation. soliton solutions are obtained through the backlund transformations. we can get three types by choosing different parameters: the kink, bell-shape, and anti-bell-shape solitons. propagation of the one soliton and elastic interactions between the two solitons are discussed graphically. after the interaction of the two bell-shape or anti-bell-shape solitons, solitonic shapes and amplitudes keep invariant except for some phase shifts, while after the interaction of the kink soliton and anti-bell-shape soliton, the anti-bell-shape soliton turns into a bell-shape one, and the kink soliton keeps its shape, with their amplitudes unchanged.
operational_amplifier	in this paper, using lab view graphical programming environment are made a number of virtual instruments which are used at the demo/study of low power active filters with operational amplifiers (op-amp). there are analyzed the active first order low pass, high pass and band pass filters. the results are included in two papers. the first one contains the simulation of active filters. the different values of passive components (feedback or input resistor and capacitors) around the op-amp can be selected with numerical controls for each type of filter. the effect is seen using the bode characteristic (frequency response curve for filter). the ac (alternating current) frequency characteristic is best described in term of a bode plot where the gain is plotted on a log scale on the vertical axis and the frequency is plotted on a log scale on the horizontal axis. the op-amp ideal frequency response curve (open loop) it is also displayed in the chart. the values of open loop gain and frequency cut-off are also set with numerical control. the validity of the program is done by comparing simulation results with data obtained by calculation using the theory. the program is designed in a modular manner and it can be used successfully in education and training courses.
analog_signal_processing	jitter limitations pose significant challenges for high-resolution and sampling-rate analog-to-digital converters (adcs). this paper describes an integrate-and-sample (ias) receiver suitable for use in an optical parametric photonic adc. rate-scalable photonic-sampling techniques provide low-jitter optical sampling and analog-to-digital conversion of the wideband signal up to 10 ghz and beyond. an 8-bit 2-gs/s ias receive channel is described for a rate-scalable photonic adc. electronic measurements are shown for an rf tone and a photonic gaussian pulse source and compared to simulations. a two-channel ias array is fabricated in a 120-nm sige bicmos process and packaged onto a printed circuit board for integration into the photonic-sampling setup. a single 2-gs/s channel achieves a measured performance higher than 8.1 enob. the two-channel integrated circuit consumes 890 ma per channel from 5- and 2.5-v supplies and occupies an area of 1.6 x 2.0 mm(2).
computer_programming	providing adaptive support to users engaged in learning tasks is the central focus of intelligent tutoring systems. there is evidence that female and male users may benefit differently from adaptive support, yet it is not understood how to most effectively adapt task support to gender. this paper reports on a study with four versions of an intelligent tutoring system for introductory computer programming offering different levels of cognitive (conceptual and problem-solving) and affective (motivational and engagement) support. the results show that female users reported significantly more engagement and less frustration with the affective support system than with other versions. in a human tutorial dialogue condition used for comparison, a consistent difference was observed between females and males. these results suggest the presence of the mars and venus effect, a systematic difference in how female and male users benefit from cognitive and affective adaptive support. the findings point toward design principles to guide the development of gender-adaptive intelligent tutoring systems.
electricity	demand response, defined as the shifting of electricity demand, is generally believed to have value both for the grid and for the market: by matching demand more closely to supply, consumers could profit from lower prices, while in a smart grid environment, more renewable electricity can be used and less grid capacity may be needed. however, the introduction of residential demand response programmes to support the development of smart grids that includes renewable generation is hampered by a number of barriers. this paper reviews these barriers and categorises them for different demand programmes and market players. the case study for the netherlands shows that barriers can be country specific. two types of demand response programmes have been identified as being the most promising options for households in smart grids: price-based demand response and direct load control, while they may not be beneficial for market players or distribution system operators. (c) 2016 the authors. international journal of energy research published by john wiley & sons ltd.
computer_programming	in this paper two types of tensor product finite macro-elements are contrasted, the former being the well known lagrange type and the latter the bezier (bernstein) type elements. although they have a different mathematical origin and seemingly are irrelevant, they both are based on complete polynomials thus sharing the same functional space, i.e. the classes {x(n)} and {y(n)}. therefore, from the theoretical point of view it is anticipated that they should lead to numerically identical results in both static and dynamic analysis. for both types of elements details are provided concerning the main computer programming steps, while selective parts of a typical matlab((r)) code are presented. numerical application includes static (laplace, poisson), eigenvalue (acoustics) and transient (heat conduction) problems of rectangular, circular and elliptic shapes, which were treated as a single macroelement. in agreement to the theory, in all six examples the results obtained using bezier and lagrange polynomials were found to be identical and of exceptional accuracy. (c) 2014 elsevier ltd. all rights reserved.
network_security	various security devices which produce a large volume of logs and alerts have been used widely. it is such a troublesome and time-consuming task for network managers to analyze and deal with the information. this paper presented an improved alerts aggregation method based on grey correlation and attribute similarity method. we used grey correlation to ascertain the importance of alert attributes in network security, and considered it as the weight of attributes. then we combined with the attribute similarity method and calculated the overall feature similarity in order to complete alert aggregation. experiments results showed that this method had a strict mathematical theory basis and a higher practical value, which can effectively reduce raw alerts and reduce redundancy for alert data fusion.
network_security	the determination of network equipment weaknesses and the discovery of intrusion intention is one of the difficulties that troubled network security management personnel. based on previous studies, further proposed a double attack graph based on domain equipment. by the underlying network topology data collected and analyzed, using bayesian theory to complete the quantify for the double attack graph and generation strategy in minimal power key set, with the cost of calculation of key equipment in the automatic recognition network topology, we provide an important basis for network maintenance. experimental results show that the measure of using quantitative domain equipment double attack graph to recognize the intrusion intention is not only effective and feasible, but also has the feature of easy promotion.
symbolic_computation	in this paper, we investigate a (2+ 1)-dimensional bogoyavlenskii-kadontsev-petviashili equation in a fluid, plasma or ferromagnetic thin film. through the bell polynomials, hirota method and symbolic computation, the one-and two-kink-soliton solutions are derived. backlund transformation, lax pair and conservation laws are presented. elastic collisions including the oblique, parallel, unidirectional and bidirectional collisions between the two-kink solitons are discussed. in addition, the relation between the velocities and wave numbers of the two-kink solitons are analysed. when wave numbers b(j) >0, upsilon(jx), the velocities in the x axis, increase with wave numbers a(j) increasing. with b(j) increasing, upsilon(jx) increase when a(j)(4) - 3b(2) j >0, while decrease when a(j)(4) - 3b(j)(2) < 0. upsilon(jy), the velocities in the y axis, increase with a(j) increasing and b(j) decreasing.
bioinformatics	the organization of the mammalian genome into gene subsets corresponding to specific functional classes has provided key tools for systems biology research. here, we have created a web-accessible resource called the mammalian metabolic enzyme database ( https:// hpcwebapps. cit. nih. gov/ esbl/database/metabolicenzymes/metabolicenzymedatabase. html) keyed to the biochemical reactions represented on iconic metabolic pathway wall charts created in the previous century. overall, we have mapped 1,647 genes to these pathways, representing similar to 7 percent of the protein-coding genome. to illustrate the use of the database, we apply it to the area of kidney physiology. in so doing, we have created an additional database (database of metabolic enzymes in kidney tubule segments: https://hpcwebapps. cit. nih. gov/esbl/database/metabolicenzymes/), mapping mrna abundance measurements (mined from rna-seq studies) for all metabolic enzymes to each of 14 renal tubule segments. we carry out bioinformatics analysis of the enzyme expression pattern among renal tubule segments and mine various data sources to identify vasopressin-regulated metabolic enzymes in the renal collecting duct.
electricity	large wind parks (wps) are an essential priority, mainly in non-residential districts. especially the offshore wps, in areas with valuable energy potential, without legislation prohibits and without causing disturbance to the nearby community, could release enormous land for other uses (culture, recreation areas, tourism, etc.). the aim of this paper is to present a methodology for the sustainable siting of an offshore wp based on legal limitations, with a particular respect of ecological and economic resources using as example the island of crete. it will also be considered the visual, acoustic and aesthetic disturbance of the coastal area residents and visitors and integrate them into the context. one of the essential issues that make the region unique is the undersea relief, which makes difficult the numerous and large-scale intervention, because some areas are strictly protected by the eu. three steps have been followed: (i) exception of unsuitable areas (geological restrictions, visual and acoustical disturb and safety and of course due to environmental conditions); (ii) evaluation of environmental impacts on birdlife, special protection areas and sites of community importance; (iii) assessment of wind potential and needs of electricity in the regional unit of chania, in the western crete. (c) 2017 elsevier ltd. all rights reserved.
computer_graphics	in computer graphics and related fields, bidirectional texture function (btf) is used for realistic and predictive rendering. btf allows for the capture of fine appearance effects such as self-shadowing, inter-reflection and subsurface scattering needed for true realism when used in rendering algorithms. the goal of current research is to get a surface representation indistinguishable from the real world. we developed, produced and tested a portable instrument for btf acquisition based on kaleidoscopic imaging. here we discuss the colour issues we experienced after the initial tests. we show that the same colour balance cannot be applied to the whole picture as the spectral response of the instrument varies with the position in the image. all optical elements were inspected for their contributions to the spectral behaviour of the instrument. the off-the-shelf parts were either measured or the manufacturer 's data were considered. the custom made mirrors' spectral reflectivity was simulated. the mathematical model of the instrument was made. we found a way how to implement all these contributions to the image processing pipeline. in this way, a correct white balance for each individual pixel in the image is found and applied, allowing for a more faithful colour representation. also proposed is an optimized dielectric protective layer for the kaleidoscope 's mirrors.
relational_databases	a multi-craft asteroid survey has significant data synchronization needs. limited communication speeds drive exacting performance requirements. tables have been used in relational databases, which are structure; however, domba (distributed objects management based articulation) deals with data in terms of collections. with this, no read/write roadblocks to the data exist. a master/slave architecture is created by utilizing the gossip protocol. this facilitates expanding a mission that makes an important discovery via the launch of another spacecraft. the open space box framework facilitates the foregoing while also providing a virtual caching layer to make sure that continuously accessed data is available in memory and that, upon closing the data file, recharging is applied to the data.
symbolic_computation	this paper provides a selective eraser of curvature extrema for b-spline curves. it is introduced as an extension to the standard least squares method for approximating a series of points using a b-spline. the extension consists in adding constraints to produce segments of curve with monotone increase or decrease of curvature. the primal-dual interior point method is used to solve the constrained optimization problem. the method requires gradients that are computed using b-spline symbolic operators. therefore, the algorithm relies on the arithmetic and differential properties of b-splines. the variation-diminishing property of b-splines is also exploited to apply the constraints. the application examples consist in producing fair curves from measured points over airfoils. the data come from the publicly available uiuc database. the data contains a fair amount of noise for some airfoils. especially in these circumstances, a fixed number of segments with monotonic variation of curvature hold great promise to produce curves that are, at once, very general and uncompromising over oscillations. (c) 2015 elsevier ltd. all rights reserved.
computer_vision	automated computer vision-based fire detection has gained popularity in recent years, as every fire detection needs to be fast and accurate. in this paper, a new fire detection method using image processing techniques is proposed. we explore how to create a fire flame-based colour space via a linear multiplication of a conversion matrix and colour features of a sample image. we show how the matrix multiplication can result in a differentiating colour space, in which the fire part is highlighted and the non-fire part is dimmed. particle swarm optimization (pso) and sample pixels from an image are used to obtain the weights of the colour-differentiating conversion matrix, and k-medoids provides a fitness metric for the pso procedure. the obtained conversion matrix can be used for fire detection on different fire images without performing the pso procedure. this allows a fast and easy implementable fire detection system. the empirical results indicate that the proposed method provides both qualitatively and quantitatively better results when compared to some of the conventional and state-of-the-art algorithms. (c) 2016 elsevier ltd. all rights reserved.
image_processing	reconstruction of the point-spread function (psf) is a critical process in weak lensing measurement. we develop a real-data based and galaxy-oriented pipeline to compare the performances of various psf reconstruction schemes. making use of a large amount of the cfhtlens data, the performances of three classes of interpolating schemes-polynomial, kriging, and shepard-are evaluated. we find that polynomial interpolations with optimal orders and domains perform the best. we quantify the effect of the residual psf reconstruction error on shear recovery in terms of the multiplicative and additive biases, and their spatial correlations using the shear measurement method of zhang et al. we find that the impact of psf reconstruction uncertainty on the shear-shear correlation can be significantly reduced by cross correlating the shear estimators from different exposures. it takes only 0.2 stars (s/n greater than or similar to >100) per square arcmin on each exposure to reach the best performance of psf interpolation, a requirement that is satisfied in most of the cfhtlens data.
operating_systems	the growing computational power of modern cpus allows increasingly complex signal processing applications to be successfully implemented and executed on general-purpose processors and operating systems. in this regard, the application 's architecture, its design, and operating system integration directly affect the maximal achievable processing bandwidth. in this paper, we present alternative driver architectures for signal processing applications that differ in the distribution of processing stages between kernel space and user space. using the processing of ads-b air traffic radio signals for civil aviation as case study, we evaluate the performance of the design alternatives on a linux system and quantify their strengths and weaknesses with respect to data overhead, usage of vector units, applicable compiler optimizations, and cache behavior. based on our results, we determine the best design choice and derive guidelines for the development of efficient signal processing applications.
operational_amplifier	this paper presents a column-level 14-bit two-stage analog-to-digital converter (adc) based on pseudo-differential operational amplifier, which is designed for the readout circuit of x-ray sensor array. this low-power hybrid adc employs an incremental sigma-delta adc and a cyclic adc, achieving a good trade-off between accuracy and conversion speed. the two stages share the same analog circuit to reduce area and power consumption. a test chip is fabricated in 0.18 mu m cmos technology. the hybrid adc in each column is performed in parallel with power consumption of 218.813 mu w. the simulation result reveals the effective number of bits (enob) is 13.775 bits.
analog_signal_processing	the predictions of the different magnetic core losses with acceptable accuracy are key parameters for temperature-rise calculations for any considered up-rate in large hydro electrical machines. it is common practice for hydro electrical designers to compute the core losses in different section of the machine function of the flux density given only at 60 hz by the manufacturer of the steel lamination which probably leads to inaccurate prediction of the magnetic core losses. in this paper, certain currently available core loss models are used to compute the electromagnetic core losses in large hydro electrical machine. the obtained results are discussed and compared with the available test data.
computer_graphics	recent research on interactive electronic systems, like computers, can improve the quality of life of many researchers, students, professors, etc. in the case of disabled people, technology helps them to engage more fully into the world. our study aims to evaluate interfaces for curves drawing with movements of the face. this article discusses about motivations to build such software, how the software works, iterative development of the software, and user testing by people with and without disabilities.
data_structures	the article presents an innovative concept of applying graph databases in transport information systems. the model of a graph database has been presented together with implementation of data structures and search operations in a graph. the transformation concept of relational model to a graph data model has been developed. the schema of graph database has been proposed for public transport information system purposes. the realization methods have been illustrated by the use of search function based on the cypher query language.
electricity	early integration of sustainability decisions and mineralogical attributes into the design of minerals processing units offers potential for reducing environmental impacts at mining and processing sites. the objective of this study is to demonstrate how the integration of sustainability indicators and mineralogical attributes could be achieved in developing an integrated modelling framework of a magnetic separator. a magnetic separator unit model based on existing literature was developed to include process stream mineralogical data and to output sustainability indicators. the overall sustainability of processing three ore types (low, medium and high grade iron ore) was evaluated using the developed model. novel measures for evaluating magnetic separation (grade recovery deviation index (grdi)) and energy efficiency (rotational energy transfer efficiency (rete)) that incorporate the use of ore characteristics were developed in this study. these measures were used to calculate the separation and energy efficiency sustainability indicator ratings. in total eleven magnetic separator sustainability indicators were identified. each indicator was assigned a weighting value out of 10 based on its importance. of the 11 sustainability indicators identified; safety, reliability, carbon dioxide (co2) emissions, water use, noise and job creation ratings did not vary with changing mineralogical attributes of the feed ore. grdi, rete, electricity cost, particle emissions and waste generation ratings were observed to be dependent on the ore characteristics and therefore their values varied with different feed ore grades. the analytic hierarchy process (ahp) and weighted sum method (wsm) methods were applied to the sustainability indicator ratings and weightings to evaluate an overall sustainability cardinal score of processing a particular ore feed. results of this study demonstrate the dependence of overall process sustainability indicators on feed ore mineralogical attributes. the results also provide an indication of the effect of ore variability (typical within a single deposit) on sustainability indicators. (c) 2016 elsevier ltd. all rights reserved.
digital_control	based on the orthogonal superposition theorem of three alternating magnetic components, a universal uniform magnetic spin vector is superimposed using tri-axial helmholtz coils, achieving successive digital control of the orientation, the rotational speed, and the magnetic flux density of the universal magnetic spin vector. for increasing the magnitude and orientation accuracy of the magnetic spin vector, this paper presents a mathematical model associated with the magnitude error and orientation error of the universal magnetic spin vector, along with a double error compensation method for the magnitude and orientation of the universal magnetic spin vector superimposed by three alternating magnetic components. the double error compensation method includes the current magnitude compensation by three different structural coefficients of tri-axial helmholtz coils and the current phase compensation by two relative phase differences under linear polarization. the results have shown that the double compensation method can increase the magnitude and orientation accuracy of the rotating magnetic vector effectively, which would achieve an accurate posture adjustment and steering control on the capsule robots in curving environment.
microcontroller	we created an easy-to-use device for operant licking experiments and another device that records environmental variables. both devices use the raspberry pi computer to obtain data from multiple input devices (e.g., radio frequency identification tag readers, touch and motion sensors, environmental sensors) and activate output devices (e.g., led lights, syringe pumps) as needed. data gathered from these devices are stored locally on the computer but can be automatically transferred to a remote server via a wireless network. we tested the operant device by training rats to obtain either sucrose or water under the control of a fixed ratio, a variable ratio, or a progressive ratio reinforcement schedule. the lick data demonstrated that the device has sufficient precision and time resolution to record the fast licking behavior of rats. data from the environment monitoring device also showed reliable measurements. by providing the source code and 3d design under an open source license, we believe these examples will stimulate innovation in behavioral studies.
software_engineering	the relationship between customers and suppliers remains a challenge in agile software development. two trends seek to improve this relationship, the increased focus on value and the move towards continuous deployment. in this special section on continuous value delivery, we describe these emerging research themes and show the increasing interest in these topics over time. further, we discuss implications for future research. (c) 2016 the authors. published by elsevier b.v.
system_identification	background: tracking the changes of neural dynamics based on neuronal spiking activities is a critical step to understand the neurobiological basis of learning from behaving animals. these dynamical neurobiological processes associated with learning are also time-varying, which makes the modeling problem challenging. new method: we developed a novel multiwavelet-based time-varying generalized laguerre-volterra (tvglv) modeling framework to study the time-varying neural dynamical systems using natural spike train data. by projecting the time-varying parameters in the tvglv model onto a finite sequence of multiwavelet basis functions, the time-varying identification problem is converted into a time invariant linear-in-the-parameters one. an effective forward orthogonal regression (for) algorithm aided by mutual information (mi) criterion is then applied for the selection of significant model regressors or terms and the refinement of model structure. a generalized linear model fit approach is finally employed for parameter estimation from spike train data. results: the proposed multiwavelet-based tvglv approach is used to identify both synthetic input-output spike trains and spontaneous retinal spike train recordings. the proposed method gives excellent the performance of tracking either sharply or slowly changing parameters with high sensitivity and accuracy regardless of the a priori knowledge of spike trains, which these results indicate that the proposed method is shown to deal well with spike train data. comparison with existing methods: the proposed multiwavelet-based tvglv approach was compared with several state-of-art parametric estimation methods like the steepest descent point process filter (sdppf) or chebyshev polynomial expansion method. the conventional sdppf algorithm, or sdppf with b-splines wavelet expansion method was shown to have the poor performance of tracking the time varying system changes with the synthetic spike train data due to the slow convergence of the adaptive filter methods. although the chebyshev polynomial basis function method gave the good parametric estimation results, it requires prior parameter estimation. it was shown that the proposed multiwavelet-based tvglv method can track the time-varying parameter changes rapidly and accurately. conclusions: the multiwavelet-based tvglv modeling framework developed in this paper can not only provide a computational modeling scheme for investigating such nonstationary properties, track more general forms of changes in time-varying neural dynamics, and but also may potentially be applied to investigate the spatial-temporal information underlying biomedical spiking signals. (c) 2016 elsevier b.v. all rights reserved.
computer_vision	unmanned aerial vehicles have become more widely used for entertainment, security, building inspection and for other similar tasks. inertial navigations systems (ins) is one of the main area of research for uavs to control their flights through buildings or near constructions where flight paths must be controlled or recorded. in this paper is collected some approaches, which can be used for uav onboard trajectory determination where gps cannot be used are determined. approach includes onboard inertial measurement unit system and image sensors. fusing uavs controlling methods and computer vision gives possibility to increase inertial navigation system accuracy. to determine distance to obstacles dual vision cameras must be used. (c) 2017 the authors. published by elsevier b.v.
software_engineering	this work describes a system for the automatic generation of full-fledged api layers from rdf schemas, providing the whole set of object-oriented functionalities to retrieve, store, edit and delete the corresponding data in a semantic triplestore. the layers the system is capable of producing range from an underlying domain model, resulting from the classes, data properties and object properties of the input schema, to the related lower-level data source and access components, up to higher-level facades and web service interfaces, all of which are immediately operational and can be used out-of-the-box for development purposes either as stand-alone components or integrated into external applications. a user-friendly graphical interface allows for an easy configuration and customization of the generation process to suit specific development needs. once configured, the execution of the generation process takes place almost instantaneously, bringing about a full set of api components in a matter of seconds and thus dramatically saving design and development time and effort. experimentation of the system has been carried out within the context of a eu-funded research project featuring a large semantic schema, a significant portion of which represented a learning model specifically engineered to be used for a plethora of e-learning solutions; nevertheless, the system is generic enough to be employed for a variety of applications relying upon semantic schemas and data.
machine_learning	rice (oryza sativa) is one of the most important staple foods for more than half of the global population. many rice traits are quantitative, complex and controlled by multiple interacting genes. thus, a full understanding of genetic relationships will be critical to systematically identify genes controlling agronomic traits. we developed a genome-wide rice protein-protein interaction network (riceppinet, ) using machine learning with structural relationship and functional information. riceppinet contained 708819 predicted interactions for 16895 non-transposable element related proteins. the power of the network for discovering novel protein interactions was demonstrated through comparison with other publicly available protein-protein interaction (ppi) prediction methods, and by experimentally determined ppi data sets. furthermore, global analysis of domain-mediated interactions revealed riceppinet accurately reflects ppis at the domain level. our studies showed the efficiency of the riceppinet-based method in prioritizing candidate genes involved in complex agronomic traits, such as disease resistance and drought tolerance, was approximately 2-11 times better than random prediction. riceppinet provides an expanded landscape of computational interactome for the genetic dissection of agronomically important traits in rice. significance statement a genome-wide rice protein-protein interaction network is developed by using machine-learning with structural evidence and functional information. it provides an expanded landscape of protein interactome to help plant biologists better understand complex agronomic traits in rice.
state_space_representation	the widely used instantaneous unit hydrograph (iuh) based on the nash cascade reservoir model was obtained under a zero initial condition, or equivalently an empty reservoir assumption. in this study, a more general case with a non-zero initial condition is considered in the derivation of the classical nash model. a generalized nash model (gnm) has been deduced using the laplace transform and the principle of mathematical induction. for river flow routing, the gnm physically interprets the formation of downstream outflow, i.e. the summation of the recession flow of the initial channel storage and the response to upstream inflow. the gnm, written in a state-space representation, is able to update the state of the river system in time, and hence can be applied in real-time forecasting. two separate case studies have been used for illustration. it is indicated that the proposed updating procedure results in improved river flow forecasts when compared with the traditional iuh method. (c) 2015 elsevier b.v. all rights reserved.
structured_storage	to achieve energy-conservation and prompt responses simultaneously, in this paper we propose a novel energy-saving data placement strategy, called striping-based energy-aware (sea), which can be applied to raid-structured storage systems to noticeably save energy while providing quick responses. further, to illustrate the effectiveness of sea, we implement two sea-powered raid-based data placement algorithms, sea0 and sea5, by incorporating the sea strategy into raid-0 and raid-5, respectively. extensive experimental results demonstrate that compared with three well-known data placement algorithms greedy, sp, and rp, sea0 and sea5 reduce mean response time on average at least 52.15% and 48.04% while saving energy on average no less than 10.12% and 9.35%, respectively.
electricity	cyclic stability is a key factor in the design of thermochemical heat storage systems. because carbon dioxide (co2) may react with heat storage materials and lead to a decrease in energy storage efficiency, the effect of co2 on ca(oh)(2)/cao and mg(oh)(2)/mgo systems is investigated in this study. the experimental results show that co2 reacts with cao in the water vapor that appears during the heat release process. therefore, in the design of ca(oh)(2)/cao systems, co2 should be cleared from the system. the results from mg(oh)(2)/mgo systems show that co2 only slightly reacts with mgo and mg(oh)(2) during heat storage and release processes. this study indicates that carbonic acid (h2co3) could easily react with cao/ca(oh)(2) to form caco3 during heat release processes. generally, the remaining co2 reduces the reversibility of ca(oh)(2)/cao systems but has only a slight influence on mg(oh)(2)/mgo systems. in addition, the experimental results show that carbonate shell does not exist in rehydration for both of the cao/mgo samples, but the influence of co2 on the entire process increases after each cycle. (c) 2017 elsevier ltd. all rights reserved.
operational_amplifier	an analog front-end (afe) for a multifunction environmental sensor is proposed. the afe is designed to be able to sense 1 mu v, 1 fc, and 1 pa level signals in a low-frequency band around dc, and consists of an instrumentation amplifier (ia), a charge amplifier (ca), and a continuous time delta-sigma (ct-delta sigma) adc. to reduce the low-frequency noise of operational amplifier (opamp) which is used for signal path, this paper proposes a weak-inversion biasing technique. the designed ia achieved 26 nvrms input-referred noise (irn) in the band of 0.1-10 hz with 0.22 mm(2) die area. the designed ca achieved 25 acrms irn in charge sensing mode and 19 farms irn in current sensing mode in the band of 0.01-1 hz, respectively, and occupies 0.12 mm(2) die area. the afe has been fabricated in a 0.18 mu m cmos process with 4.5 mm(2) die area. the current consumption at 2.56 khz output data rate (odr) is 2.5 ma, reducing to 2 mu a at 0.01 hz odr.
machine_learning	multi-label learning draws great interests in many real world applications. it is a highly costly task to assign many labels by the oracle for one instance. meanwhile, it is also hard to build a good model without diagnosing discriminative labels. can we reduce the label costs and improve the ability to train a good model for multi-label learning simultaneously? active learning addresses the less training samples problem by querying the most valuable samples to achieve a better performance with little costs. in multi-label active learning, some researches have been done for querying the relevant labels with less training samples or querying all labels without diagnosing the discriminative information. they all cannot effectively handle the outlier labels for the measurement of uncertainty. since maximum correntropy criterion (mcc) provides a robust analysis for outliers in many machine learning and data mining algorithms, in this paper, we derive a robust multi-label active learning algorithm based on an mcc by merging uncertainty and representativeness, and propose an efficient alternating optimization method to solve it. with mcc, our method can eliminate the influence of outlier labels that are not discriminative to measure the uncertainty. to make further improvement on the ability of information measurement, we merge uncertainty and representativeness with the prediction labels of unknown data. it cannot only enhance the uncertainty but also improve the similarity measurement of multi-label data with labels information. experiments on benchmark multi-label data sets have shown a superior performance than the state-of-the- art methods.
machine_learning	background: brain networks in fmri are typically identified using spatial independent component analysis (ica), yet other mathematical constraints provide alternate biologically-plausible frameworks for generating brain networks. non-negative matrix factorization (nmf) would suppress negative bold signal by enforcing positivity. spatial sparse coding algorithms (l1 regularized learning and k-svd) would impose local specialization and a discouragement of multitasking, where the total observed activity in a single voxel originates from a restricted number of possible brain networks. new method: the assumptions of independence, positivity, and sparsity to encode task-related brain networks are compared; the resulting brain networks within scan for different constraints are used as basis functions to encode observed functional activity. these encodings are then decoded using machine learning, by using the time series weights to predict within scan whether a subject is viewing a video, listening to an audio cue, or at rest, in 304 fmri scans from 51 subjects. results and comparison with existing method: the sparse coding algorithm of l1 regularized learning outperformed 4 variations of ica (p < 0.001) for predicting the task being performed within each scan using artifact-cleaned components. the nmf algorithms, which suppressed negative bold signal, had the poorest accuracy compared to the ica and sparse coding algorithms. holding constant the effect of the extraction algorithm, encodings using sparser spatial networks (containing more zero-valued voxels) had higher classification accuracy (p < 0.001). lower classification accuracy occurred when the extracted spatial maps contained more csf regions (p < 0.001). conclusion: the success of sparse coding algorithms suggests that algorithms which enforce sparsity, discourage multitasking, and promote local specialization may capture better the underlying source processes than those which allow inexhaustible local processes such as ica. negative bold signal may capture task-related activations. (c) 2017 elsevier b.v. all rights reserved.
digital_control	in high-quality education, topics concerning the behavior and control of electrical machines and power electronics have to be taught not only theoretically but also in a practical manner. hard-and software tools are necessary to fulfil this obligation. nevertheless, commercial systems partially lack of functionality or full accessibility to implement custom solutions, which is obligatory in the research and education domain. therefore, a digital signal processing system is presented, that allows full modification of every used device, both in hardware and in software.
parallel_computing	the audio-to-score framework consists of two separate stages: preprocessing and alignment. the alignment is commonly solved through offline dynamic time warping (dtw), which is a method to find the path over the distortion matrix with the minimum cost to determine the relation between the performance and the musical score times. in this work we propose a parallel online dtw solution based on a client-server architecture. the current version of the application has been implemented for multi-core architectures (86, 64 and arm), thus covering either powerful systems or mobile devices. an extensive experimentation has been conducted to validate the software. the experiments also show that our framework allows to achieve a good score alignment within the real-time window using parallel computing techniques.
microcontroller	we report the design, implementation and testing of an instrument for rapid dry rubber content (drc) determination in rubber latex. it is composed of rectangular waveguide antennae, microwave generator, power detector, and microcontroller. according to the theory of microwave transmission, the power loss of microwaves passing through latex is related to the drc. this attenuation is determined by measuring the transmitted microwave intensity with a power detector. the appropriate frequency that gives the best correlation between drc and attenuation was found to be about 2.36 ghz. the microwave power measurement is processed by the microcontroller using the empirical calibration equation to estimate drc in rubber latex. the instrument was tested using new latex samples with various drc, sampled locally in songkhla province, thailand, and the drc estimates by the instrument were compared to the slow but accurate standard oven-drying results. the estimates had an 0.21 % mean error and r (2) = 0.9983, indicating good practical performance.
machine_learning	in this paper, we propose a novel fuzzy inference system on picture fuzzy set called picture inference system (pis) to enhance inference performance of the traditional fuzzy inference system. in pis, the positive, neutral and negative degrees of the picture fuzzy set are computed using the membership graph that is the combination of three gaussian functions with a common center and different widths expressing a visual view of degrees. then, the positive and negative defuzzification values, synthesized from three degrees of the picture fuzzy set, are used to generate crisp outputs. learning in pis including training centers, widths, scales and defuzzification parameters is also discussed. the system is adapted for all architectures such as the mamdani, the sugeno and the tsukamoto fuzzy inferences. experimental results on benchmark uci machine learning repository datasets and an example in control theory - the lorenz system are examined to verify the advantages of pis.
microcontroller	vortex flowmeter is installed in piping to measure the fluid flow rate. the piping is easily disturbed by strong transient impact in the application fields, such as other components impacting on the pipeline, manual knocking on the pipe, and opening and closing of valves. the strong transient impact will be picked up by the vortex flow sensor, which makes the vortex flowmeter output wrong measurement results. the current commonly used digital signal processing method can do nothing about it. to solve this problem, an experimental setup is built in our laboratory to study the impact interference, and a large number of vortex flow sensor output signals are collected. the characteristics of transient impacts outputted by the vortex sensor are analyzed so as to describe this type of signal quantitatively. the pattern of transient impact is that the signal amplitudes increase suddenly and then attenuate gradually. a segmented kalman filter based digital signal processing method is proposed according to this pattern. the data segment containing strong transient impact is found first; the transient impact power is reduced by filtering the data segment second; and through spectral analysis of the filtered signal, the maximum peak of the spectrum is extracted as the vortex flow signal finally. the algorithm is implemented in real time by a low-power microcontroller. both gas and water flow experiments have been conducted to verify the validity and reliability of the antistrong transient impact algorithm.
data_structures	the internet, as a global system of interconnected networks, carries an extensive array of information resources and services. key requirements include good quality-of-service and protection of the infrastructure from nefarious activity [e.g., distributed denial of service (ddos) attacks]. network monitoring is essential to network engineering, capacity planning, and prevention/mitigation of threats. we develop an open-source architecture, all-packet monitor (amon), for online monitoring and analysis of multi-gigabit network streams. it leverages the high-performance packet monitor pf_ring and is readily deployable on commodity hardware. amon examines all packets, partitions traffic into sub-streams by using rapid hashing and computes certain real-time data products. the resulting data structures provide views of the intensity and connectivity structure of network traffic at the time-scale of routing. the proposed integrated framework includes modules for the identification of heavy-hitters as well as for visualization and statistical detection at the time-of-onset of high-impact events such as ddos. this allows operators to quickly visualize and diagnose attacks, and limit offline and time-consuming post-mortem analysis. we demonstrate our system in the context of real-world attack incidents, and validate it against state-of-the-art alternatives. amon has been deployed and is currently processing multi-gigabit live internet traffic at merit network. it is extensible and allows the addition of further statistical and filtering modules for real-time forensics.
system_identification	in this paper, we present a novel model updating method for damage detection of multi-story shear buildings during severe earthquakes. the story stiffnesses are explicitly presented in an incremental manner; this enables a simple and robust algorithm for the purpose of identification of the story stiffnesses. the estimated modal data, including natural frequencies and mode shapes of lower modes, are used in the proposed algorithm; moreover, sensitivity analysis of natural circular frequencies is incorporated to reduce possible errors. the story stiffnesses are identified by an iterative algorithm, and the window shift technique is adopted to present change of the story stiffness due to damages in the buildings during earthquakes. numerical examples demonstrate that the proposed method is of high accuracy, even when the recorded responses are polluted by a relatively high level of (white) noises. copyright (c) 2016 john wiley & sons, ltd.
image_processing	proposed is a smart single viewing axis optical laser line illumination-based 3-d shape sensor that uses an electronically controlled variable focus lens (ecvfl) for 3-d optical beamforming. specifically, the novel sensor design deploys laser line illumination scanning and camera-based spatial image processing of the target illuminated laser line spot that leads to a faster 3-d shape reconstruction versus the previously demonstrated point scanned ecvfl-based 3-d shape sensor. the proposed sensor is experimentally demonstrated using a liquid ecvfl and transverse direction motion mechanics to successfully 3-d map 40-mm depth steep surface profile objects with a mean measurement error of <5%. the line illumination sensor demonstrates a 53 times shorter 3-d mapping time per scanned point when compared with the point-scan-based sensor. the proposed 3-d shape sensor is suitable for scenarios where high transverse resolution inspections is required of objects having holes, crevices, or other complex external structures.
analog_signal_processing	non-linear semi active vibration control devices have experienced a significant development in recent years, due to their performance and advantages compared with the passive and active approaches. pulse switching techniques, which were developed in the field of piezoelectric damping, lead to effective trade-offs between performance, simplicity and the required power supply. the control law in this method is based on triggering an inverting switch on each extremum of the produced voltage (or displacement); however, in the case of random excitation, false switching on the local maxima can reduce the efficiency overwhelmingly. a successful approach, to overcome this limitation is based on windowed statistical examination of the vibration signal to determine the optimum triggering voltage level. according to this approach, this paper presents a modified method and for the first time presents a novel circuit structure to predict the optimum trigger time of the damping switch. this circuit structure is implementable using compact analog devices which can be embedded in the vibration energy extraction system. the proposed circuit calculates statistical parameters of the displacement sensor signal then estimates the value of the threshold. results for a cantilever beam excited by different excitation forces, such as harmonic, random samples and pulse forces are presented and compared with the numerical simulations. (c) 2011 elsevier bm. all rights reserved.
operating_systems	modern operating systems use hardware support to protect against control-flow hijacking attacks such as code-injection attacks. typically, write access to executable pages is prevented and kernel mode execution is restricted to kernel code pages only. however, current cpus provide no protection against code-reuse attacks like rop. aslr is used to prevent these attacks by making all addresses unpredictable for an attacker. hence, the kernel security relies fundamentally on preventing access to address information. we introduce prefetch side-channel attacks, a new class of generic attacks exploiting major weaknesses in prefetch instructions. this allows unprivileged attackers to obtain address information and thus compromise the entire system by defeating smap, smep, and kernel aslr. prefetch can fetch inaccessible privileged memory into various caches on intel x86. it also leaks the translation-level for virtual addresses on both intel x86 and armv8-a. we build three attacks exploiting these properties. our first attack retrieves an exact image of the full paging hierarchy of a process, defeating both user space and kernel space aslr. our second attack resolves virtual to physical addresses to bypass smap on 64-bit linux systems, enabling ret2dir attacks. we demonstrate this from unprivileged user programs on linux and inside amazon ec2 virtual machines. finally, we demonstrate how to defeat kernel aslr on windows 10, enabling rop attacks on kernel and driver binary code. we propose a new form of strong kernel isolation to protect commodity systems incuring an overhead of only 0. 06-5.09%.
operating_systems	ip identification (ipid) is an ip header field which is designed to identify a packet in a communication session. the main purpose of ipid is to recover from ip fragmentation. to the best of our knowledge, most existing ipid based information hiding methods assume that the ipid number is a pseudo random number, which is found to be false. in this paper, we propose a steganographic method by exploiting the ipid field while considering the information from the user data field. first, we analyze the ipid distribution of various operating systems. subsequently, we put forward a simple data embedding method, which is then refined to mimic the ordinary ipid traffic. experiments are carried out and the results empirically prove that the proposed method is of high undetectability as compared to the existing ipid based steganographic methods. (c) 2016 elsevier ltd. all rights reserved.
cryptography	lightweight cipher designs try to minimize the implementation complexity of the cipher while maintaining some specified security level. using only a small number of and gates lowers the implementation costs, and enables easier protections against side-channel attacks. in our paper we study the connection between the number of and gates (multiplicative complexity) and the complexity of algebraic attacks. we model the encryption with multiple right-hand sides (mrhs) equations. the resulting equation system is transformed into a syndrome decoding problem. the complexity of the decoding problem depends on the number of and gates, and on the relative number of known output bits with respect to the number of unknown key bits. this allows us to apply results from coding theory, and to explicitly connect the complexity of the algebraic cryptanalysis to the multiplicative complexity of the cipher. this means that we can provide asymptotic upper bounds on the complexity of algebraic attacks on selected families of ciphers based on the hardness of the decoding problem.
control_engineering	decisions made in the early design phase enormously contribute to the performance of a product during its life cycle. since users' preferences may change over time, a product design should be revised under the preference change. providing accurate data for designers ensures an optimal decision for product design; this research presents a new method to assess effects of the quantified changes on product cost and development time. in addition, two models to optimize design under unexpected disturbances are proposed. normally, optimal parameters require several search iterations in design process before finalizing a product. the design time in terms of number of iterations can be reduced by adding resources in each iteration using modern control engineering methods. however, adding resources will increase the design cost. the proposed method in this research minimizes the total product design cost and environmental impacts under changes of users' preferences. the method is validated using an example of the smartphone design. the research novelty is a method of applying quantified changes of external disturbances (such as changes in users' preferences) in the design process, addressing a real problem in industry, and proposing optimal models of products for reduced cost and environmental impacts.
relational_databases	the semantic web uses ontological descriptions, in particularly web ontology language owl, as a universal medium to formally describe and exchange knowledge of various domains. currently, many owl ontologies for different domains come into being successively. therefore, how to store owl ontologies becomes one of ordinary needs of the semantic web. based on the efficient storage mechanism of object-oriented databases, they may be used to store owl ontologies for realizing the management of large amounts of knowledge in the semantic web. to this end, the main objective of this paper is to investigate how to store owl ontologies in object-oriented databases, and we propose a formal approach and develop a prototype tool for storing owl ontologies in object-oriented databases. firstly, after giving a complete formal definition of owl ontologies, we propose an overall architecture of storing owl ontologies in object-oriented databases. based on the architecture, we further give storage rules and explain how to store owl ontologies in object-oriented databases with a running example in detail. the correctness and quality of the storage approach are proved and analyzed. finally, we implement a prototype tool which can store owl ontologies in a widely used open source object database db4o. also, a query interface is developed in the prototype tool for querying the stored owl ontologies. the storage and query examples are provided to show that the approach is feasible and the tool is efficient. (c) 2014 elsevier b.v. all rights reserved.
symbolic_computation	two classes of rational solutions to a shallow water wave-like non-linear differential equation are constructed. the basic object is a generalized bilinear differential equation based on a prime number, p = 3. through this new transformation and with the help of symbolic computation with maple, both the new equation and its rational solutions are obtained.
signal-flow_graph	performance and design methodology of 8x1 multiplexer (mux) and all-optical reconfigurable logic circuit using gaas-algaas-based optical micro-ring resonator (omrr) are presented in current paper. proposed design of reconfigurable logic circuit is capable to perform eight different logic operations. performances of the logic circuits have been theoretically analyzed using z-domain modeling. numerical simulation results confirming the method are explained in the present paper. proposed circuit is simple, compact, efficient as it have minimum number of omrr, low operating power, high operating speed and high q-factor. different 'figure of merits' of the purposed model are calculated from the simulation results.
signal-flow_graph	an useful modification of well known signal flow graph technique for the circuit synthesis is described in this paper in order to obtain the filters working in the current mode, with maximally variable parameters, namely characteristic frequency, quality factor, bandwidth and basic gain. procedure is based on reciprocal conversion of the branch variables (v ->i and i ->v) with the adjustable conversion constants. the obtained structures are discussed in detail and then is described an example of current-mode multifunctional rc active biquadratic filter, what is today very popular analogue application. theoretic assumptions are supported by experimental results using modern functional blocks cc ii(-).
signal-flow_graph	this paper performs a generalized steadystate analysis on various developed series of cascade boost converters based on the switching signal flow graph (sfg) method. a unified switching model is constructed and can be applied to all the circuits. the effects caused by diodes are considered. with the applications to the example, the proposed generalized analytical method shows the advantages of high convenience and practicability. the experimental results are provided to support the theoretical analysis.
control_engineering	this paper addresses the development of the supervision/control software for a multipurpose three-tank system to teach control engineering fundamentals. the laboratory equipment consists in a three series tanks with industrial instrumentation. the design requirements were determined by the users that perform academic activities in the area of process control. the requirements for the software include: data acquisition; clear visualization of the components involve in the process; communication with the different actuators; alarm generation, recorder; data logger; selection of different control strategies and technological systems (plc, industrial controller or pc); and a friendly human machine interface. the equipment is being used to teach undergrad courses, grad courses, industrial training, and research projects. (c) 2016, ifac (international federation of antomatic control) hosting by elsevier ltd. all rights reserved.
pid_controller	in this article, two different state space models for a distributed solar collector field have been extracted. design of an iterative extended kalman filter (iekf) and an appropriate controller for the distributed solar collector field and their simulations are the other purposes of this study. a feed forward controller, moreover the pid controller, has been used in the designed controller the in order to attenuate the disturbances effects caused by solar radiation, inlet oil temperature and environmental temperature. both of the models can be used to estimate the distributed solar collector field temperature profile. it has been shown that the temperature of all parts of the solar collector field such as inlet oil temperature can be estimated by using the models in iterative extended kalman filter (iekf) only by use of one sensor to measure the temperature along the collectors. also it has been exposed that the used kalman filter could greatly eliminate the applied noises to the system, and thus makes the system robust against the influencing noises such as sensors errors. all required parameters for implementation of the iterative extended kalman filter and the controller and simulation has been extracted from shiraz solar power plant. (c) 2016 elsevier ltd. all rights reserved.
electric_motor	a hybrid safety injection tank (h-sit) can enhance the capability of an advanced power reactor plus (apr+) during a station black out (sbo) that is accompanied by a severe accident. it may a useful alternative to an electric motor. the operations strategy of the h-sit has to be investigated to achieve maximum utilization of its function. in this study, the master logic diagram (i.e., an analysis for identifying the differences between an h-sit and a safety injection pump) and an accident case classification were used to determine the parameters of the h-sit operation. the conditions that require the use of an h-sit were determined using a decision-making process. the proper timing for using an h-sit was also analyzed by using the multi-dimensional analysis of reactor safety (mars) 1.3 code (korea atomic energy research institute, daejeon, south korea). the operation strategy analysis indicates that a h-sit can mitigate five types of failure: (1) failure of the safety injection pump, (2) failure of the passive auxiliary feedwater system, (3) failure of the depressurization system, (4) failure of the shutdown cooling pump (scp), and (5) failure of the recirculation system. the results of the mars code demonstrate that the time allowed for recovery can be extended when using an h-sit, compared with the same situation in which an h-sit is not used. based on the results, the use of an h-sit is recommended, especially after the pilot-operated safety relief valve (posrv) is opened. copyright (c) 2015, published by elsevier korea llc on behalf of korean nuclear society.
algorithm_design	two players wishing to communicate are placed each in a room with n telephones connecting the two rooms. the players do not know how the telephones are interconnected. in each round, each player picks up a phone and says ""hello"" until when they hear each other. the problem is to devise an algorithm minimising the delay to establish communication. the above problem, called the telephone coordination game, also termed as the telephone problem, is of fundamental importance in distributed algorithm design. in this paper, we investigate a generalised version where among n telephones, only a subset can establish communication between the two players. we are interested in devising the deterministic strategy achieving bounded rendezvous delay and minimising the worst-case rendezvous delay. specifically, we first establish the lower-bound of worst-case rendezvous delay. we then characterise the structure of the phone pick sequences that can guarantee rendezvous without any prior coordination. assuming each player has a globally unique id, we further devise a deterministic strategy that (1) guarantees rendezvous between the players regardless of their telephone labeling functions and their relative time difference and (2) approaches the performance bound within a constant factor proportional to the id length.
pid_controller	a novel proportional-integral-derivative-based fuzzy neural network (pid-based fnn) controller is proposed in this study to control the speed of a vane-type air motor (vam) servo system for tracking periodic speed command. first, the structure and operating principles of the vam servo system are introduced. then, the dynamics of the vam servo system is analyzed to derive the second-order state equation of the vam. moreover, due to the dynamic characteristics and system parameters of the vam servo system are highly nonlinear and time-varying, a pid-based fnn controller, which integrates conventional proportional-integral-derivative neural network (pidnn) control with fuzzy rules, is proposed to achieve precise speed control of vam servo system under the occurrences of the inherent nonlinearities and external disturbances. the network structure and its on-line learning algorithm using delta adaptation law are described in detail. meanwhile, the convergence analysis of the speed tracking error is given using the discrete-type lyapunov function. to enhance the control performance of the proposed intelligent control approach, a 32-bit floating-point digital signal processor (dsp), tms320f28335, is adopted for the implementation of the proposed control system. finally, experimental results are illustrated to show the validity and advantages of the proposed pid-based fnn controller for vam servo system.
distributed_computing	on one hand, compared with traditional relational and xml models, graphs have more expressive power and are widely used today. on the other hand, various applications of social computing trigger the pressing need of a new search paradigm. in this article, we argue that big graph search is the one filling this gap. we first introduce the application of graph search in various scenarios. we then formalize the graph search problem, and give an analysis of graph search from an evolutionary point of view, followed by the evidences from both the industry and academia. after that, we analyze the difficulties and challenges of big graph search. finally, we present three classes of techniques towards big graph search: query techniques, data techniques and distributed computing techniques.
computer_programming	the purpose of this study is to examine the effectiveness of review question and content object as advanced organizer used for prior knowledge activation in an introductory computer programming. the students' engagement when using the strategies was examined to reach the primary findings. content object (co) as the advanced organizer to activate prior knowledge used before a new programming concept was learnt. review questions (rq) on programming concepts and solutions were designed to encourage the paper-pen method. findings have shown similar performance in post-test. the outcome of this study showed co useful to foster better learning programming. (c) 2015 published by elsevier ltd.
electrical_network	the accurate monitoring of battery cell temperature is indispensible to the design of battery thermal management system. to obtain the internal temperature of a battery cell online, an adaptive temperature estimation method based on kalman filtering and an equivalent time-variant electrical network thermal (eent) model is proposed. the eent model uses electrical components to simulate the battery thermodynamics, and the model parameters are obtained with a least square algorithm. with a discrete state-space description of the eent model, a kalman filtering (kf) based internal temperature estimator is developed. moreover, considering the possible time-varying external heat exchange coefficient, a joint kalman filtering (jkf) based estimator is designed to simultaneously estimate the internal temperature and the external thermal resistance. several experiments using the hard-cased lifepo4 cells with embedded temperature sensors have been conducted to validate the proposed method. validation results show that, the eent model expresses the battery thermodynamics well, the kf based temperature estimator tracks the real central temperature accurately even with a poor initialization, and the jkf based estimator can simultaneously estimate both central temperature and external thermal resistance precisely. the maximum estimation errors of the kf- and jkf-based estimators are less than 1.8 degrees c and 1 degrees c respectively. (c) 2015 elsevier b.v. all rights reserved.
machine_learning	skilled human full-body movements are often planned in a highly predictive manner. for example, during walking while reaching towards a goal object, steps and body postures are adapted to the goal position already multiple steps before the goal contact. the realization of such highly predictive behaviors for humanoid robots is a challenge because standard approaches, such as optimal control, result in computation times that are prohibitive for the predictive control of complex coordinated full body movements over multiple steps. we devised a new architecture that combines the online-planning of complex coordinated full-body movements, based on the flexible combination of learned dynamic movement primitives, with a walking pattern generator (wpg), based on model predictive control (mpc), which generates dynamically feasible locomotion of the humanoid robot hrp-2. a dynamic filter corrects the zero moment point (zmp) trajectories in order to guarantee the dynamic feasibility of the executed behavior taking into account the upper-body movements, at the same time ensuring an accurate approximation of the planned motion trajectories. we demonstrate the high flexibility of the chosen movement planning approach, and the accuracy and feasibility of the generated motion. in addition, we show that a na ve approach, which generates adaptive motion by using machine learning methods by the interpolation between feasible training motion examples fails to guarantee the stability and dynamic feasibility of the generated behaviors. (c) 2017 elsevier b.v. all rights reserved.
distributed_computing	wireless technologies combined with advanced computing are changing industrial communications. industrial wireless networks can improve the monitoring and the control of the entire system by jointly exploiting massively interacting communication and distributed computing paradigms. in this paper, we develop a wireless cloud platform for supporting critical data publishing and distributed sensing of the surrounding environment. the cloud system is designed as a self-contained network that interacts with devices exploiting the time synchronized channel hopping protocol (tsch), supported by wirelesshart (iec 62591). the cloud platform augments industry-standard networking functions as it handles the delivery (or publishing) of latency and throughput-critical data by implementing a cooperative-multihop forwarding scheme. in addition, it supports distributed sensing functions through consensus-based algorithms. experimental activities are presented to show the feasibility of the approach in two real industrial plant sites representative of typical indoor and outdoor environments. validation of cooperative forwarding schemes shows substantial improvements compared with standard industrial solutions. distributed sensing functions are developed to enable the autonomous identification of recurring cochannel interference patterns.
microcontroller	as clean and high energy efficient, the microwave drying system has gained popularity for a wide variety of food preservation and processing of bio-commodities. the main advantage is the acceleration of the drying process which is quite limited comparing to conventional hot air drying system. however, during microwave drying process, pressure and temperature will increase continuously and this might cause undesired side effects such as degradation and physical damages. in order to eliminate the mentioned problems and enhance higher performance of control system flexibility, in this paper, a design of multi-stage phase-controlled converter for microwave drying system is proposed. the objective of this multi-stage power control is to track the drying characteristics under microwave drying process at different power level depending on the stage of drying cycle period. this control approach is achieved by controlling the triggering events at appropriate phase angle of triac based on predefined power profiles. by varying the pulse width, the average power output of the magnetron can be controlled. as the focus of this paper, the hardware design and component selections are discussed. the system flowchart and control algorithm based on microcontroller arduino mega 2560 are also presented in details. experimental results of the proposed multi-stage phased-control converter are investigated and discussed.
algorithm_design	this article examines the effectiveness of different forms of performance-based adaptive automation (pbaa). using data from three experiments (n = 10, n = 38, n = 40), different models of algorithm design were compared for their effectiveness in driving pbaa. the following components were varied: type of task (i.e. primary or secondary tasks), baseline of performance data (e.g. moving average), and triggering criterion (i.e. level of deviation from standard performance). the data were generated by operators working with a computer-based simulation of a process control environment. the results showed that none of the models enjoyed a convincing level of effectiveness. the automation algorithms generally achieved higher levels of miss prevention than false alarm prevention. surprisingly, primary task performance was generally better at driving pbaa than secondary task performance. the results suggest that it may be difficult to design an effective algorithm of pbaa if the work environment is highly complex.
machine_learning	background and objective: various digital pathology tools have been developed to aid in analyzing tissues and improving cancer pathology. the multi-resolution nature of cancer pathology, however, has not been fully analyzed and utilized. here, we develop an automated, cooperative, and multi-resolution method for improving prostate cancer diagnosis. methods: digitized tissue specimen images are obtained from 5 tissue microarrays (tmas). the tmas include 70 benign and 135 cancer samples (tma1), 74 benign and 89 cancer samples (tma2), 70 benign and 115 cancer samples (tma3), 79 benign and 82 cancer samples (tma4), and 72 benign and 86 cancer samples (tma5). the tissue specimen images are segmented using intensity- and texture-based features. using the segmentation results, a number of morphological features from lumens and epithelial nuclei are computed to characterize tissues at different resolutions. applying a multiview boosting algorithm, tissue characteristics, obtained from differing resolutions, are cooperatively combined to achieve accurate cancer detection. results: in segmenting prostate tissues, the multiview boosting method achieved >= 0.97 auc using tma1. for detecting cancers, the multiview boosting method achieved an auc of 0.98 (95% ci: 0.97-0.99) as trained on tma2 and tested on tma3, tma4, and tma5. the proposed method was superior to single view approaches, utilizing features from a single resolution or merging features from all the resolutions. moreover, the performance of the proposed method was insensitive to the choice of the training dataset. trained on tma3, tma4, and tma5, the proposed method obtained an auc of 0.97 (95% ci: 0.96-0.98), 0.98 (95% ci: 0.96-0.99), and 0.97 (95% ci: 0.96-0.98), respectively. conclusions: the multiview boosting method is capable of integrating information from multiple resolutions in an effective and efficient fashion and identifying cancers with high accuracy. the multiview boosting method holds a great potential for improving digital pathology tools and research. (c) 2017 elsevier b.v. all rights reserved.
data_structures	purpose-additive manufacturing (am) processes are the integration of many different science and engineering-related disciplines, such as material metrology, design, process planning, in-situ and off-line measurements and controls. major integration challenges arise because of the increasing complexity of am systems and a lack of support among vendors for interoperability. the result is that data cannot be readily shared among the components of that system. in an attempt to better homogenization this data, this paper aims to provide a reference model for data sharing of the activities to be under-taken in the am process, laser-based powder bed fusion (pbf). design/methodology/approach-the activity model identifies requirements for developing a process data model. the authors' approach begins by formally decomposing the pbf processes using an activity-modeling methodology. the resulting activity model is a means to structure process-related pbf data and align that data with specific pbf sub-processes. findings-this model in this paper provides the means to understand the organization of process activities and sub-activities and the flows among them in am pbf processes. research limitations/implications-the model is for modeling am activities and data associated with these activity. data modeling is not included in this work. social implications-after modeling the selected pbf process and its sub-processes as activities, the authors discuss requirements for developing the development of more advanced process data models. such models will provide a common terminology and new process knowledge that improve data management from various stages in am. originality/value-fundamental challenges in sharing/reusing data among heterogeneous systems include the lack of common data structures, vocabulary management systems and data interoperability methods. in this paper, the authors investigate these challenges specifically as they relate to process information for pbf-how it is captured, represented, stored and accessed. to do this, they focus on using methodical, information-modeling techniques in the context of design, process planning, fabrication, inspection and quality control.
electrical_circuits	a new method of reliability monitoring of electrical devices based on carbon fibres is presented. due to the thermo-mechanical stress on electronic circuits a loss of fibre network integrity can take place and potential difference may appear between the edges of broken carbon fibres. this potential difference causes an intensive field-emission from surfaces of these broken carbon fibres and an acceleration of emitted electrons. due to the acceleration of electrons a microwave emission is generated. a cfrp was used to simulate the behaviour of a carbon based electronic device. the sequence of microwave impulses was detected in a frequency bandwidth from 8 to 12 ghz. the rise time of detected microwave impulses is about of few nanoseconds. this time is in agreement with crack formation time in carbon fibre. the correlation between the change of electrical resistance of composites and microwave impulses by fibres fracture is observed. thus, the breakdown of current that flows through carbon fibres induces detectable microwave emission. that means that defects in electrical circuits can be wireless detected online.
parallel_computing	computing performance is one of the key problems in embedded systems for high-resolution face detection applications. to improve the computing performance of embedded high-resolution face detection systems, a novel parallel implementation of embedded face detection system was established based on a low power cpu-accelerator heterogeneous many-core architecture. first, a basic cpu version of face detection prototype was implemented based on the cascade classifier and local binary patterns operator. second, the prototype was extended to a specified embedded parallel computing platform that is called parallella and consists of xilinx zynq and adapteva epiphany. third, the face detection algorithm was optimized to adapt to the parallella architecture to improve the detection speed and the utilization of computing resources. finally, a face detection experiment was conducted to evaluate the computing performance of the proposal in this paper. the experimental results show that the proposed implementation obtained a very consistent accuracy as that of the dual-core arm, and achieved 7.8 times speedup than that of the dual-core arm. experiment results prove that the proposed implementation has significant advantages on computing performance.
signal-flow_graph	we introduce a graphical syntax for signal flow diagrams based on the language of symmetric monoidal categories. using universal categorical constructions, we provide a stream semantics and a sound and complete axiomatisation. a certain class of diagrams captures the orthodox notion of signal flow graph used in control theory; we show that any diagram of our syntax can be realised, via rewriting in the equational theory, as a signal flow graph. (c) 2016 elsevier inc. all rights reserved.
parallel_computing	digital down converter (ddc) is a time-intensive and data-intensive computing task and considered as the key technology in software defined radio. this paper proposes a high-performance implementation of ddc on a graphics processing unit (gpu) using cuda, which is composed of a numerically controlled oscillator stage, a cascaded integrator-comb (cic) decimation filter stage, and a finite impulse response (fir) filter stage. the gpu implementation and optimizing of all the stages are studied in detail. additionally, for handling a long-duration signal, the signal data sequence is truncated into segments; the overlap-save and overlap-add mechanisms were applied in cic stage and fir stage, respectively. finally, experiments were conducted to evaluate the performance of gpu-based ddc with respect to a sequential version cpu implementation and an openmp implementation (16 threads). experimental results demonstrate that the ddc achieves significant improvements on the gpu; the maximum speed ups in numerically controlled oscillator stage, cic stage, and fir stage can achieve more than 1242, 527, and 179 times, including data-transfer, kernel execution, and other processing operations; the overall speed up of ddc can achieve more than 180. in the meantime, the speed ups of gpu implementation are far above the openmp implementation (about 2.5-6.4 times).
symbolic_computation	in this paper, the truncated painlev'e analysis and the consistent tanh expansion (cte) method are developed for the (2+1)-dimensional breaking soliton equation. as a result, the soliton-cnoidal wave interaction solution of the equation is explicitly given, which is difficult to be found by other traditional methods. when the value of the jacobi elliptic function modulus m = 1, the soliton-cnoidal wave interaction solution reduces back to the two-soliton solution. the method can also be extended to other types of nonlinear evolution equations in mathematical physics.
electricity	the physicochemical properties of anode material are important for the electron transfer of anode bacteria and electricity generation of microbial fuel cells (mfcs). in this work, carbon cloth anode was pretreated with isopropanol, hydrogen peroxide (h2o2) and sodium hypochlorite (naocl) in order to reduce the anode functional groups. the influence of functional groups on the electrochemical properties of carbon cloth anode and power generation of mfcs was investigated. the anode pretreatments removed the surface sizing layer of carbon cloth and substantially reduced the contents of c-o and pyridinic/pyrrolic n groups on the anode. electrochemical impedance spectroscopy and cyclic voltammetry analyses of the biofilm-matured anodes revealed an enhanced electrochemical electron transfer property because of the anode pretreatments. as compared with the untreated control (612 +/- 6mwm(-2)), the maximum power density of an acetate-fed single-chamber mfc was increased by 26% (773 +/- 5mwm(-2)) with the isopropanol treated anode. additional treatment with h2o2 and naocl further increased the maximum power output to 844 +/- 5mwm(-2) and 831 +/- 4 mwm(-2). a nearly inverse liner relationship was observed between the contents of c-o and pyridinic/pyrrolic n groups on anodes and the anodic exchange current density and the power output of mfcs, indicating an adverse effect of these functional groups on the electricity production of anodes. results from this study will further our understanding on the microbial interaction with carbon-based electrodes and provide an important guidance for the modification of anode materials for mfcs in future studies. copyright (c) 2016 john wiley & sons, ltd.
electricity	power-to-x concepts promise a reduction of greenhouse gas emissions simultaneously guaranteeing a safe energy supply even at high share of renewable power generation, thus becoming a cornerstone of a sustainable energy system. power-to-syngas, that is, the electro-chemical conversion of steam and carbon dioxide with the use of renewably generated electricity to syngas for the production of synfuels and high-value chemicals, offers an efficient technology to couple different energy-intense sectors, such as ""traffic and transportation"" and ""chemical industry"". syngas produced by co-electrolysis can thus be regarded as a key-enabling step for a transition of the energy system, which offers additionally features of co2-valorization and closed carbon cycles. here, we discuss advantages and current limitations of low-and high-temperature co-electrolysis. advances in both fundamental understanding of the basic reaction schemes and stable high-performance materials are essential to further promote co-electrolysis.
computer_graphics	in the oil and gas industry, processing and visualizing 3d models is of paramount importance for making exploratory and production decisions. hydrocarbons reservoirs are entities buried deep in the earth 's crust, and a simplified 3d geological model that mimics this environment is generated to run simulations and help understand geological and physical concepts. for the task of visually inspecting these models, we advocate the use of cutaways: an illustrative technique to emphasize important structures or parts of the model by selectively discarding occluding parts, while keeping the contextual information. however, the complexity of reservoir models imposes severe restrictions and limitations when using generic illustrative techniques previously proposed by the computer graphics community. to overcome this challenge, we propose an interactive cutaway method, strongly relying on screen-space gpu techniques, specially designed for inspecting 3d reservoir models represented as corner-point grids, the industry 's standard. (c) 2016 elsevier inc. all rights reserved.
distributed_computing	performance modeling for mapreduce applications with large-scale data is a very important issue in the study of optimization, evaluation, prediction and resource scheduling of the jobs over big data and cloud computing platforms. in this paper, we study the hadoop distributed computing framework, which is the current trend of big data solutions. we use the locally weighted linear regression (lwlr) algorithm and linear regression (lr) algorithm to establish three kinds of computing models based on different characteristics to estimate the execution time of the applications that have large-scale data and run on the hadoop framework, and at the same time we make comparison and improvement to the three models. by building different types of experimental environments, and running different types of jobs, we can draw a conclusion that all the three models have very good results in predicting the execution time and evaluating the performance of large-scale data applications with small-scale data.
network_security	attempting to educate practitioners of computer security can be difficult if for no other reason than the breadth of knowledge required today. the security profession includes widely diverse subfields including cryptography, network architectures, programming, programming languages, design, coding practices, software testing, pattern recognition, economic analysis, and even human psychology. while an individual may choose to specialize in one of these more narrow elements, there is a pressing need for practitioners that have a solid understanding of the unifying principles of the whole. we created the playground network simulation tool and used it in the instruction of a network security course to graduate students. this tool was created for three specific purposes. first, it provides simulation sufficiently powerful to permit rigorous study of desired principles while simultaneously reducing or eliminating unnecessary and distracting complexities. second, it permitted the students to rapidly prototype a suite of security protocols and mechanisms. finally, with equal rapidity, the students were able to develop attacks against the protocols that they themselves had created. based on our own observations and student reviews, we believe that these three features combine to create a powerful pedagogical tool that provides students with a significant amount of breadth and intense emotional connection to computer security in a single semester.
analog_signal_processing	this paper contributes to the field of low-power high-order cmos log-domain filters by: (a) suggesting a log-domain synthesis path which bypasses the need for e-minus cells and (b) by assessing the practicality of the proposed synthesis path by means of a 6th-order cmos log-domain bessel filter fabricated in the commercially available ams 0.35 mu m process. measured results from the 19nw, 8-200 hz, 940 mu m(2) bessel filter chip confirm the validity of the proposed approach. the filter reported here is particularly useful for biomedical instruments such as portable ecg devices and pulse-oximeters. (c) 2009 elsevier ltd. all rights reserved.
data_structures	this work presents a low-complexity audio coder-decoder (codec) based on fixed-point arithmetic to save the usage of system resources in a low-end embedded system. to reduce time complexity and memory usage, a simplified discrete wavelet transform (dwt) with only integer operations is developed. the simplified dwt reduces the computation that is required for the trigonometric operations in the fixed-point system. moreover, separating the even and odd orders of wavelet coefficients halves the computation time of the original dwt. additionally, a tri-mode zeroes recording algorithm (tzra) is proposed. the proposed tzra utilizes different encoding modes with their corresponding bit data structures to record the locations of zero wavelet coefficients, and determines the optimal encoding mode that uses the fewest bits. to further improve the compression performance, a dynamic wavelet level selecting algorithm is developed to decide the wavelet level for compressing each of frame. this algorithm can dynamically select the optimal wavelet level with the fewest bits by using the determined mode from the tzra. the experimental results herein reveal that the encoder in the proposed codec can multiply computation by factors of 164 and 112 and reduce the size of the execution file by approximately 95.61 and 98.42% relative to baseline audio compression codecs. such results indicate that the efficiency when used in real consumer products with fixed-point arithmetic.
electricity	the importance of the performance of frequency regulation has already been acknowledged by regulators and independent system operators (isos). a performance-based frequency regulation market model considering both regulation capacity and regulation mileage constraints is proposed in this paper. in the proposed market, high-performance regulation resources have higher priorities to be selected in the market. market clearing prices are derived with lagrange relaxation. the analysis of the components of market clearing prices accurately indicates the correlation between regulation capacity and regulation mileage. to accommodate the proposed regulation market design, agc allocation algorithm is adjusted based on the market clearing results. the clearing procedure of the market model is demonstrated on an illustrative case. the proposed market design is tested and verified with market simulations and system dynamic simulations. simulation results are discussed and compared to show the effectiveness of the proposed market design. (c) 2016 elsevier ltd. all rights reserved.
bioinformatics	eva1a is an autophagy-related protein, which plays an important role in embryonic neurogenesis. in this study, we found that loss of eva1a could decrease neural differentiation in the brain of adult eva1a(-/-) mice. to determine the mechanism underlying this phenotype, we performed label-free quantitative proteomics and bioinformatics analysis using the brains of eva1a(-/-) and wild-type mice. we identified 11 proteins that were up-regulated and 17 that were down-regulated in the brains of the knockout mice compared to the wild-type counterparts. bioinformatics analysis indicated that biological processes, including atp synthesis, oxidative phosphorylation, and the tca cycle, are involved in the eva1a regulatory network. in addition, gene set enrichment analysis showed that neurodegenerative diseases, such as alzheimer 's disease and huntington 's disease, were strongly associated with eva1a knockout. western blot experiments showed changes in the expression of nicotinamide nucleotide transhydrogenase, an important mitochondrial enzyme involved in the tca cycle, in the brains of eva1a knockout mice. our study provides valuable information on the molecular functions and regulatory network of the eva1a gene, as well as new perspectives on the relationship between autography-related proteins and neural differentiation.
distributed_computing	due to technical bottlenecks and errors caused by artificial operation, the problem of incomplete data always exists in big data research. traditional data imputation algorithms incur high complexity and the accuracy cannot reach the desired level. at the same time, analysis and computation involved in mass data makes limitation of traditional algorithms and computing platform more noticeable. in this paper, we propose a data imputation method based on apriori algorithm, and implement the corresponding algorithm on the distributed computing system built with spark, the experimental results show that the proposed algorithm outperforms a traditional data imputation algorithm in terms of efficiency and accuracy.
parallel_computing	the robust conjugate direction search (rcds) method is used to optimize the collimation system for the rapid cycling synchrotron (rcs) of the china spallation neutron source (csns). the parameters of secondary collimators are optimized for a better performance of the collimation system. to improve the efficiency of the optimization, the objective ring beam injection and tracking (orbit) parallel module combined with matlab parallel computing is used, which can run multiple orbit instances simultaneously. this study presents a way to find an optimal parameter combination of the secondary collimators for a machine model in preparation for csns/rcs commissioning.
image_processing	the contact structure of asphalt mixtures has been considered as an important micromechanical mixture property related to the rutting performance. in this study, a two-dimensional (2d) image acquisition and processing procedure was utilized to acquire the contact structure of asphalt mixtures with varying compactness, gradation types, nominal maximum aggregate sizes (nmas) and binder types. new indices for contact structure of different asphalt mixtures were developed based on three aspects: contact distance distribution, contact length distribution and contact orientation, including average contact distance (d(ave)), proportion for contact distance no more than 0.5 mm (p-d <= 0.5mm), proportion for contact distance no more than 1 mm (p-d <= 1mm), total contact length (l-sum), number of contact (no. contact), average contact length (l-ave), the average contact angle of inclination 0 and the vector magnitude delta. flow number and strain rate from dynamic creep test were determined to be the rutting indicators for varying asphalt mixtures. a linear regression model was used to investigate the relationship between new contact indices and rutting indicators. the results indicated that the contact structure of varying mixtures could be successfully differed by the new indices proposed. new indices, such as l-sum, l-ave and d(ave), could be ranked in a similar trend as the flow number. furthermore, a more comprehensive index represented the contact structure of asphalt mixtures was developed to better uncover the mechanism of rutting in micromechanical perspective. (c) 2016 published by elsevier ltd.
state_space_representation	this paper presents a mathematical model of a wind turbine that includes a permanent magnet synchronous machine (pmsg) for real time simulations. the dynamic model considers a stochastic model of the wind, a state-space representation of the wind turbine with the pmsg, avoiding the use of a gear box, and a back-to-back converter for the interconnection of system with the grid. a field oriented control technique in the dq reference frame was used for the converter, also a control loop for the pitch angle of the wind turbine was implemented. in order to show the performance of the controllers, they were implemented in an arduino card and then connected to a specialized station in real time simulations. case studies that show the dynamic behavior of the wind turbine are presented and discussed.
relational_databases	in many institutions relational databases are used as a tool for managing information related to day to day activities. institutions may be required to keep the information stored in relational databases accessible because of many reasons including legal requirements and institutional policies. however, the evolution in technology and change in users with the passage of time put the information stored in relational databases in danger. in the long term the information may become inaccessible when the operating system, database management system or the application software is not available any more or the contextual information not stored in the database may be lost thus affecting the authenticity and understandability of the information. this paper presents an approach for preserving relational databases for the long-term. the proposal involves migrating a relational database to a dimensional model which is simple to understand and easy to write queries against. practical transformation rules are developed by carrying out multiple case studies. one of the case studies is presented as a running example in the paper. systematic implementation of the rules ensures no loss of information in the process except for the unwanted details. the database preserved using the approach is converted to an open format but may be reloaded to a database management system in the long-term.
digital_control	field programmable gate arrays (fpgas) have established themselves as one of the preferred digital implementation platforms in a plethora of current industrial applications, and extensions and improvements are still continuously being included in the devices. this paper reviews recent advancements in fpga technology, emphasizing the novel features that may significantly contribute to the development of more efficient digital systems for industrial applications. special attention is paid to the design paradigm shift caused by the availability of increasingly powerful embedded (and soft) processors, which transformed fpgas from hardware accelerators to very powerful system-on-chip (soc) platforms. new analog resources, floating-point operators, and hard memory controllers are also described, because of the great advantages they provide to designers. software tools are being strongly influenced by the design paradigm shift, which requires fromthem a much better support for software developers. focusing mainly on this issue, recent advancements in software resources [intellectual property (ip) cores and design tools] are also reviewed. the impact of new fpga features in industrial applications is analyzed in detail in three main areas, namely digital real-time simulation, advanced control techniques, and electronic instrumentation, with focus on mechatronics, robotics, and power systems design. the way digital systems are being currently designed in these areas is comprehensively reviewed, and a critical analysis of how they could significantly benefit from new fpga features is presented.
pid_controller	this paper presents an eso-based ipi control for common rail pressure. first, a detailed mathematical model of high pressure common rail injection system (hpcris) is built. the mathematical model is validated by the software matlab and commercial software amesim. for the considered hpcris, an effective model free controller which is called extended state observer - based intelligent proportional integral (eso-based ipi) controller is designed. and this proposed eso-ipi controller is composed mainly of the referred eso observer, and the ipi controller. finally, to demonstrate the performances and effectiveness of the proposed controller, the proposed controller is implemented and compared with a conventional pid controller and active disturbance rejection control (adrc), and their corresponding simulations are carried out.
data_structures	hashing is an important technique to achieve high code performance in a variety of data processing applications. the concept is emphasized in computer science curricula, and the it industry values graduates who can use hashing skillfully. although several implementation details of hashing are routinely handled by software libraries, it remains the responsibility of the programmer to choose a suitable hash function (a poor hash function can degrade performance). researchers have designed a number of generic hash functions, but environments for code development do not offer these as off-the-shelf solutions. it is also curious that textbooks and reference books do not point learners to this rich resource. our paper remedies this deficiency by providing learners with an easy way to compare their own hash function 's performance with these alternatives. our assistive tool is an eclipse plugin for java programs, and we have focused only on traditional hash functions (non-cryptographic hash functions that do not preserve distance). however, our approach can be extended easily to other programming languages, development environments and hash function classes.
pid_controller	this study aims to mathematical modeling of a mechanism for a solar tracker system of two axes as well as the modeling of stepper motors that drive each axis, that to get the best angle of incidence between the sun and photovoltaic plate (90o). the proposed architecture was modeled using the conversion method of the kinetic energy and potential of lagrange and stepper motors were modeled by detailed analysis of their internal characteristics. with ready models, we used the software matlab (r) to perform simulations in order to view the system response to the step. as engine speed is too high the system response is oscillatory, the need of using a pid controls system to improve system position control efficiency. for this, we used the second method of ziegler and nichols for determining the parameters of the pid controller gains. thus, the system modeling was completed through the fine tuning of the pid controller in order to find the best values for the controller parameters using the embedded system arduino uno r3.
analog_signal_processing	in this study, a new versatile active element, namely multifunction current differencing cascaded transconductance amplifier (mcdcta) is proposed. the proposed mcdcta enjoys the advantages of low voltage, low-input and high-output impedance, wide bandwidth etc., and it simplifies the design of the current-mode analog signal processing circuit greatly, especially the design of high-order filter and oscillator circuits. moreover, an example, a new current-mode multiphase sinusoidal oscillator (mso) using the proposed mcdcta is described in this paper. the proposed mso consists only one mcdcta and minimum grounded passive elements, it could provide 2n (n a parts per thousand 2) output current signals with equally phase difference, and the output current signals are all at high output impedance terminals. the oscillation condition and the oscillation frequency of the mso could be linearly and electronically adjusted by controlling the bias currents of mcdcta, and it is suitable for variable frequency oscillator application. the operation of the proposed oscillator has been verified through pspice simulation and experimental results.
pid_controller	the recco control algorithm, presented in this article, is based on the fuzzy rule-based (frb) system named anya which has non-parametric antecedent part. it starts with zero fuzzy rules (clouds) in the rule base and evolves its structure while performing the control of the plant. for the consequent part of recco pid-type controller is used and the parameters are adapted in an online manner. the recco does not require any off-line training or any type of model of the controlled process (e.g. differential equations). moreover, in this article we propose a normalization of the cloud (data) space and an improved adaptation law of the controller. due to the normalization some of the evolving parameters can be fixed while the new adaptation law improves the performance of the controller in the starting phase of the process control. to assess the performance of the recco algorithm, firstly a comparison study with classical pid controller was performed on a model of a plate heat-exchanger (phe). tuning the pid parameters was done using three different techniques (ziegler-nichols, cohen-coon and pole placement). furthermore, a practical implementation of the recco controller for a real phe plant is presented. the phe system has nonlinear static characteristic and a time delay. additionally, the real sensor 's and actuator 's limitations represent a serious problem from the control point of view. besides this, the recco control algorithm autonomously learns and evolves the structure and adapts its parameters in an online unsupervised manner. (c) 2016 elsevier b.v. all rights reserved.
system_identification	this article deals with the ability of fractional modeling to describe the bounded diffusion behavior encountered in modern thin film and nanoparticles lithium battery electrodes. indeed, the diffusion impedance of such batteries behaves as a half order integrator characterized by the warburg impedance at high frequencies and becomes a classical integrator described by a capacitor at low frequencies. the transition between these two behaviors depends on the particles geometry. three of them will be considered in this paper: planar, cylindrical and spherical ones. the fractional representation proposed is a gray box model able to perfectly fit the low and high frequency diffusive impedance behaviors while optimizing the frequency response transition. identification results are provided using frequential simulation data considering the three electrochemical diffusion models based on the particles geometry. furthermore, knowing this geometry allows to estimate the diffusion ionic resistance and time constant using the relationships linking these physical parameters to the structural fractional model parameters. finally, other simulations using randles impedance models including the charge transfer impedance and the external resistance demonstrate the interest of fractional modeling in order to identify properly not only the charge transfer impedance but also the diffusion physical parameters whatever the particles geometry. (c) 2016 elsevier b.v. all rights reserved.
electricity	a comparative analysis of electricity and gas demand in the industrial sector over a long period of time appears to be absent in the literature. in fact, unlike electricity demand, natural gas demand in the industrial sector has not been well researched. our paper aims to cover this gap. it analyses electricity and gas consumption patterns by the spanish manufacturing sector, between 1995 and 2010. a novel and innovative quantitative approach based on, both, homogenous and heterogeneous estimators was used for this purpose. the results of the no-spurious estimations (the augmented mean group estimator) show that the price elasticity of gas demand is significantly negative and within the -0.44 to -0.48 range. in contrast, the price elasticity of electricity demand is not statistically significant. the income elasticities show the opposite pattern: those of natural gas are not statistically significant, whereas the income elasticities for electricity are statistically significant and within the 0.22 to 0.29 range. compared to previous findings, our preferred estimation shows some variation regarding price elasticities of natural gas demand. (c) 2017 elsevier ltd. all rights reserved.
symbolic_computation	in this paper is presented a criterion for identification of heat transfer regime through convection ( natural, forced or mixed) by making use of the mathematica system symbolic computation capabilities. the criterion is based on a comparison of buoyancy and viscous forces. the analysis is realized at the interior of two vertical plates submitted to uniform heat flux density, in steady and laminar state in a fully developed flow. thus, it was proposed the dimensionless numbers product rire to be the only representative parameter in order to identify the convective thermal regime, instead of the idea based only on the dimensionless number richardson or grashof. (c) 2015 the authors. published by elsevier ltd.
analog_signal_processing	micromagnetic materials characterization requires sensors which essentially consist of two critical elements: an electromagnet which introduces a well-defined magnetic field to the material, and a sensor system which detects the material 's response to the applied magnetic field. the devices developed at fraunhofer izfp obtain a multiparametric ""magnetic fingerprint"" with these sensors by means of several methods. the magnetic fingerprints of calibration samples are used as input for pattern recognition or regression analysis, thus allowing the prediction of mechanical-technological material characteristics (hardness, yield strength, etc.) or residual stress. this approach is called micromagnetic multiparameter microstructure and stress analysis (3ma). the long-term stability and reproducibility of the sensor and device characteristics are crucial for the reliability of the measured results. therefore, the measuring hardware should follow a minimalistic approach. in this paper, we propose a way of simplifying the measuring hardware by multiple use of sensor elements, reducing the analog signal processing chain and transferring most signal processing tasks to the pc.
bioinformatics	cancer transcriptome analysis is one of the leading areas of big data science, biomarker, and pharmaceutical discovery, not to forget personalized medicine. yet, cancer transcriptomics and postgenomic medicine require innovation in bioinformatics as well as comparison of the performance of available algorithms. in this data analytics context, the value of network generation and algorithms has been widely underscored for addressing the salient questions in cancer pathogenesis. analysis of cancer trancriptome often results in complicated networks where identification of network modularity remains critical, for example, in delineating the druggable molecular targets. network clustering is useful, but depends on the network topology in and of itself. notably, the performance of different network-generating tools for network cluster (nc) identification has been little investigated to date. hence, using gastric cancer (gc) transcriptomic datasets, we compared two algorithms for generating pathway versus gene regulatory network-based ncs, showing that the pathway-based approach better agrees with a reference set of cancer-functional contexts. finally, by applying pathway-based nc identification to gc transcriptome datasets, we describe cancer ncs that associate with candidate therapeutic targets and biomarkers in gc. these observations collectively inform future research on cancer transcriptomics, drug discovery, and rational development of new analysis tools for optimal harnessing of omics data.
cryptography	cooperative spectrum sensing, despite its effectiveness in enabling dynamic spectrum access, suffers from location privacy threats, merely because secondary users (sus)' sensing reports that need to be shared with a fusion center to make spectrum availability decisions are highly correlated to the users' locations. it is therefore important that cooperative spectrum sensing schemes be empowered with privacy preserving capabilities so as to provide sus with incentives for participating in the sensing task. in this paper, we propose privacy preserving protocols that make use of various cryptographic mechanisms to preserve the location privacy of sus while performing reliable and efficient spectrum sensing. we also present cost-performance tradeoffs. the first consists on using an additional architectural entity at the benefit of incurring lower computation overhead by relying only on symmetric cryptography. the second consists on using an additional secure comparison protocol at the benefit of incurring lesser architectural cost by not requiring extra entities. our schemes can also adapt to the case of a malicious fusion center as we discuss in this paper. we also show that not only are our proposed schemes secure and more efficient than existing alternatives, but also achieve fault tolerance and are robust against sporadic network topological changes.
network_security	with the tremendous growth of internet, large amounts of data are generated and create big challenges for nowadays computing technologies and systems. however, on the other hand, it also sheds new light on the areas of data analytics and mining which enables uncovering the patterns and laws beneath the big data. in recent years, big data analytics have been successfully applied to many areas, such as e-commerce, healthcare, and industry. as the same time, security analytics based on big data also receive great attention from both academic and industry. in this paper, we give a comprehensive sketch of techniques about the applications of big data in network security analytics. the existing research works are classified into three types: supervised, unsupervised and hybrid approaches. then we elaborate the technical issues of the three kinds of approaches and compare their advantages and disadvantages. finally we outlook the potentials and research directions in the future.
analog_signal_processing	the electrical generator maintenance scheduling problem has been tackled by a variety of traditional optimisation techniques over the years. this paper proposes a method to solve the maintenance scheduling problem, called the parallel co-operating cultural algorithm (parca). in the proposed model, a variety of selection mechanisms, operators, communication methods, and local search procedures are applied to each solution generated by genetic operators and parameters as explained in the sequel. our cultural algorithm framework combines the weak search method with the knowledge representation scheme for collecting and reasoning knowledge about individual experience. (c) 2002 imacs. published by elsevier science b.v. all rights reserved.
control_engineering	the concurso de ingenieria de control (cic) (engineering control challenge) is a student challenge organized by the comite espanol de automatica - cea (spanish committee of automation) from spain. it was set as an educational and motivational tool for control engineering students. although originally devised for spanish pupils, several non-spanish teams ended up participating at the two editions, 2012 and 2013. this article describes details about the challenge and its organization, and it shows, as well, some of the impressions obtained by polls and testimonials from participants.
analog_signal_processing	we report on the design and measurements of a multichannel asic fsdr16 prototype implemented in umc 180 nm cmos technology and dedicated for the readout of silicon strip detectors. the fsdr16 chip contains 16 channels with the size of 60 mu m x 880 mu m each, which are built with: charge sensitive amplifier, pole-zero cancellation circuit, 5th order complex shaper based on the follow-the-leader architecture and 7-bit trim dac. to achieve low noise performance and high speed analog signal processing, the proper signal shaping has to be involved in order to obtain voltage pulse which is as symmetrical and short as possible at the shaper output. the functionality of the chip allows to make a comparison between a typical cr-(rc)(5) shaper based on real poles and a complex semi-gaussian shaper based on complex poles. we present both, the design procedure of such filters and the measurements results with the emphasis on the spread of analog front-end parameters of these architectures in the multichannel system. the fsdr16 chip characterizes low power dissipation p-diss = 3.5mw per single channel. the peaking time t(p) measured from 1% to the peak of complex semi-gaussian shaper is set to 75 ns (fast mode) or 180 ns (slow mode). its architecture allows to obtain a shorter pulse width t(w) (t(w)/t(p) = 2.85) measured form 1% to 1% of the curve than in case of a typical cr-(rc)(5) shaper (t(w)/t(p) = 3.54). the front-end electronics has been optimized for detector capacitance of c-det = 30 pf and for fast mode of complex semi-gaussian shaper an equivalent noise charge enc = 172 e(-) + 26.2 e(-)/pf, while for slow mode enc = 139 e(-) + 18.9 e(-)/pf.
microcontroller	in this work the energy harvesting performance of a piezoelectric curved energy generator (thin layer unimorph driver (thunder)) is studied via experimental and analytical methods. the analytical model of the thunder is created based on the linear mechanical electrical constitutive law of the piezoelectric material, the linear elastic constitutive law of the substrate, and the euler-bernoulli beam theory. with these linear modal functions, the rayleigh-ritz approach was used to obtain the reduced mechanical-electrical coupled modulation equations. the analytical model is verified by the experimental results. both the experimental and analytical results of the thunder 's ac power output, dc power output with rectifier bridge and a capacitor, as well as the power output with a microcontroller energy harvesting circuit are reported. based on the theoretical model, the analytical solution of the dc power is derived in terms of the vibration amplitude, frequency, and the electrical load. to harvest energy from low-frequency vibration source by a piezoelectric generator requires the piezoelectric device possessing low resonance frequency and good flexibility. the. thunder developed by langley research center exhibits high power when it is used as an energy generator and large displacement when it is used as an actuator. compared to the less flexible pzt, although thunder is more difficult to model, thunder has better vibration absorption capacity and higher energy recovery efficiency. the effect of the thunder 's radius of curvature on energy harvesting efficiency is mainly investigated. we set the thunder 's radius of curvature as a dynamic tuning parameter which can tune the piezoelectric generators' frequency with the source excitation frequency.
computer_vision	saliency detection is the task of locating informative regions in an image, which is a challenging task in computer vision. in contrast to the existing saliency detection models that focus on either local or global image property, an effective salient object detection method is introduced based on joint modeling global shape and local consistency. to this end, restricted boltzmann machine (rbm) is utilized to model salient object shape as global image property and conditional random field (crf), on the other hand, is adopted to achieve its local consistency. in order to obtain the final saliency map, a universal framework is introduced to combine the results of rbm and crf. experimental results on five benchmark datasets demonstrate that the proposed saliency detection method performs favorably against the existing state-of-the-art algorithms.
operational_amplifier	we present for the first time analytic solutions for the nonlinear dynamics of a wien bridge oscillator stabilised by three common methods: an incandescent lamp, signal diodes, and the field effect transistor. the results can be used to optimise oscillator design, and agree well with measurements. the effect of operational amplifier marginal nonlinearity on oscillator performance at high frequencies is clarified. the oscillator circuits and their analysis can be used to demonstrate nonlinear dynamics in the undergraduate laboratory.
electric_motor	improving the estimation accuracy for the energy consumption of electric vehicles (evs) would greatly contribute to alleviating the range anxiety of drivers and serve as a critical basis for the planning, operation, and management of charging infrastructures. to address the challenges in energy consumption estimation encountered due to sparse global positioning system (gps) observations, an estimation model is proposed that considers both the kinetic characteristics from sparse gps observations and the unique attributes of evs: (1) work opposing the rolling resistance; (2) aerodynamic friction losses; (3) energy consumption/generation depending on the grade of the route; (4) auxiliary load consumption; and (5) additional energy losses arising from the unstable power output of the electric motor. two quantities, the average energy consumption per kilometer and the energy consumption for an entire trip, were focused on and compared for model fitness, parameter, and effectiveness, and the latter showed a higher fitness. based on sparse gps observations of 68 evs in aichi prefecture, japan, the traditional linear regression approach and a multilevel mixed-effects linear regression approach were used for model calibration. the proposed model showed a high accuracy and demonstrated a great potential for application in using sparse gps observations to predict the energy consumption of evs.
computer_vision	automatic image annotation has been an active topic of research in the field of computer vision and pattern recognition for decades. in this paper, we present a new method for automatic image annotation based on gaussian mixture model (gmm) considering cross-modal correlations. to be specific, we first employ gmm fitted by the rival penalized expectation-maximization (rpem) algorithm to estimate the posterior probabilities of each annotation keyword. next, a label similarity graph is constructed by a weighted linear combination of label similarity and visual similarity by seamlessly integrating the information from both image low level visual features and high level semantic concepts together, which can effectively avoid the phenomenon that different images with the same candidate annotations would obtain the same refinement results. followed by the rank-two relaxation heuristics over the built label similarity graph is applied to further mine the correlation of the candidate annotations so as to capture the refining annotation results, which plays a crucial role in the semantic based image retrieval. the main contributions of this work can be summarized as follows: (1) exploiting gmm that is trained by the rpem algorithm to capture the initial semantic annotations of images. (2) the label similarity graph is constructed by a weighted linear combination of label similarity and visual similarity of images associated with the corresponding labels. (3) refining the candidate set of annotations generated by the gmm through solving the max-bisection based on the rank-two relaxation algorithm over the weighted label graph. compared to the current competitive model sgmm-rw, we can achieve significant improvements of 4% and 5% in precision, 6% and 9% in recall on the corel5k and mirflickr25k, respectively. (c) 2017 elsevier inc. all rights reserved.
computer_vision	intersections are known for their integral and complex nature due to a variety of the participants' behaviors and interactions. this paper presents a review of recent studies on the behavior at intersections and the safety analysis for three types of participants at intersections: vehicles, drivers, and pedestrians. this paper emphasizes on techniques which are strong candidates for automation with visual sensing technology. a new behavior and safety classification is presented based on key features used for intersection design, planning, and safety. in addition, performance metrics are introduced to evaluate different studies, and insights are provided regarding the state of the art, inputs, algorithms, challenges, and shortcomings.
electricity	a load estimation algorithm based on k-means cluster analysis was developed. the algorithm applies cluster centres - of previously clustered load profiles - and distance functions to estimate missing and future measurements. canberra, manhattan, euclidean, and pearson correlation distances were investigated. several case studies were implemented using daily and segmented load profiles of aggregated smart meters. segmented profiles cover a time window that is less than or equal to 24 h. simulation results show that canberra distance outperforms the other distance functions. results also show that the segmented cluster centres produce more accurate load estimates than daily cluster centres. higher accuracy estimates were obtained with cluster centres in the range of 16-24 h. the developed load 'estimation algorithm can be integrated with state estimation or other network operational tools to enable better monitoring and control of distribution networks. (c) 2016 the authors. published by elsevier ltd.
cryptography	bent functions are maximally nonlinear boolean functions with an even number of variables. they have attracted a lot of research for four decades because of their own sake as interesting combinatorial objects, and also because of their relations to coding theory, sequences and their applications in cryptography and other domains such as design theory. in this paper we investigate explicit constructions of bent functions which are linear on elements of spreads. after presenting an overview on this topic, we study bent functions which are linear on elements of presemifield spreads and give explicit descriptions of such functions for known commutative presemifields. a direct connection between bent functions which are linear on elements of the desarguesian spread and oval polynomials over finite fields was proved by carlet and the second author. very recently, further nice extensions have been made by carlet in another context. we introduce oval polynomials for semifields which are dual to symplectic semifields. in particular, it is shown that from a linear oval polynomial for a semifield one can get an oval polynomial for transposed semifield.
bioinformatics	backgroundorofacial clefts are congenital malformations of the orofacial region, with a global incidence of one per 700 live births. interferon regulatory factor 6 (irf6) (omim:607199) gene has been associated with the etiology of both syndromic and nonsyndromic orofacial clefts. the aim of this study was to show evidence of potentially pathogenic variants in irf6 in orofacial clefts cohorts from africa. methodswe carried out sanger sequencing on dna from 184 patients with nonsyndromic orofacial clefts and 80 individuals with multiple congenital anomalies that presented with orofacial clefts. we sequenced all the nine exons of irf6 as well as the 5 and 3 untranslated regions. in our analyses pipeline, we used various bioinformatics tools to detect and describe the potentially etiologic variants. resultswe observed that potentially etiologic exonic and splice site variants were nonrandomly distributed among the nine exons of irf6, with 92% of these variants occurring in exons 4 and 7. novel variants were also observed in both nonsyndromic orofacial clefts (p.glu69lys, p.asn185thr, c.175-2a>c and c.1060+26c>t) and multiple congenital anomalies (p.gly65val, p.lys320asn and c.379+1g>t) patients. our data also show evidence of compound heterozygotes that may modify phenotypes that emanate from irf6 variants. conclusionsthis study demonstrates that exons 4 and 7 of irf6 are mutational hotspots' in our cohort and that irf6 mutants-induced orofacial clefts may be prevalent in the africa population, however, with variable penetrance and expressivity. these observations are relevant for detection of high-risk families as well as genetic counseling. in conclusion, we have shown that there may be a need to combine both molecular and clinical evidence in the grouping of orofacial clefts into syndromic and nonsyndromic forms.
electricity	this paper investigates the impact of stock market developments on oil and electricity demand of oecd member countries. we conduct different panel data methodologies and use annual data ranging from 1996 to 2011. the overall findings substantiate that income, real prices, size of the stock market and liquidity are important determinants for both oil and electricity demand. we also compute long-run elasticity coefficients by using a simple partial adjustment model (pam) and find that the long run elasticity coefficients are larger than the short run parameters. moreover, our results show that the demand for oil and electricity is inelastic with respect to both own real price and real income over the short-run and the long-run. from a policy making perspective, the findings suggest that potential policy tools to reduce energy consumption may not be useful as the demand for energy is inelastic with respect to energy prices. our results also manifest that although stock market deepening variables do not have a large effect on energy use as energy price and economic growth have, market size and liquidity significantly affect energy consumption. therefore, energy demand estimations based on solely energy price and income may be inaccurate when some stock market development indicators are excluded. the empirical findings of this paper provide further insights for policy makers, energy companies and energy economists in terms of demand management policies and pricing decisions.
electrical_network	multimodal damping can be achieved by coupling a mechanical structure to an electrical network exhibiting similar modal properties. focusing on a plate, a new topology for such an electrical analogue is found from a finite difference approximation of the kirchhoff-love theory and the use of the direct electromechanical analogy. discrete models based on element dynamic stiffness matrices are proposed to simulate square plate unit cells coupled to their electrical analogues through two-dimensional piezoelectric transducers. a setup made of a clamped plate covered with an array of piezoelectric patches is built in order to validate the control strategy and the numerical models. the analogous electrical network is implemented with passive components as inductors, transformers and the inherent capacitance of the piezoelectric patches. the effect of the piezoelectric coupling on the dynamics of the clamped plate is significant as it creates the equivalent of a multimodal tuned mass damping. an adequate tuning of the network then yields a broadband vibration reduction. in the end, the use of an analogous electrical network appears as an efficient solution for the multimodal control of a plate.
computer_programming	personalized e-learning environment is desirable in computer programming education. an important issue on personalized e-learning environment is to know the learning status of each student. this article proposes a method, skp-based student learning status description(skp-based slsd), to help instructors to know student individual 's learning status in c programming. skp-based slsd focus on the syntactic knowledge called syntax knowledge point(skp) extracted from program source code. firstly, it gathers all syntactic knowledge that should be learned by the students by extracting skp from the source code in teaching materials or exercises' model answers. then, for each student, it collects his learning activities on each skp by extracting skp from the source code the student have read or taught at lectures and wrote at exercises or tests. finally, for each student, his understanding of each skp is estimated based on the collected data. student learning status can be described by his understanding of all skps. by skp-based slsd, the information used to describe student learning status can be more detail, be better-defined and better-handled by computer systems. we have also conducted experiments and proved that skp-based slsd is effective and feasible.
microcontroller	the paper considers a realization of quasi-sliding mode control for dc-dc boost-type converter on atmega8 microcontroller. the proposed control law represents a combination of discretetime sliding mode and generalized minimum variance control techniques. the control design is based on input-output converter model and only the sensed output voltage is used for generating control signal. this approach simplifes the practical realization of boost converter since there is no need for current sensors. by introducing an additional discrete-time integrator in control, the converter accuracy in steady-state under load and input voltage variations is enhanced. the experimental prototype is developed and several experiments are conducted to validate the functionalities of the proposed solution. the maximum load and line regulation errors of the proposed converter are 1.55% and 2.9%, respectively.
cryptography	in this paper, a simple and efficient watermarking method is proposed by using visual cryptography, singular value decomposition and chaotic maps. the proposed scheme uses a gray-level image as watermark instead of binary logo or bit sequence. the proposed scheme is a zero-watermarking scheme, where the watermark is not embedded directly in the host image. the host image is encrypted with secret watermark image by constructing two shares- master share and ownership share. the two shares separately do not give any information about the watermark but when stacked together, the watermark is revealed. singular value decomposition has been used to select the robust features of the host image and chaotic maps have been used to improve the security. experimental study is conducted to evaluate the robustness of the algorithm against various signal processing and geometrical attacks.
cryptography	through generating the d-dimensional ghz state in the z-basis and measuring it in the x-basis, a dynamic quantum secret sharing scheme is proposed. in the proposed scheme, multiple participants can be added or deleted in one update period, and the shared secret does not need to be changed. the participants can be added or deleted by themselves, and the dealer does not need to be online. compared to the existing schemes, the proposed scheme is more efficient and more practical.
control_engineering	with increasingly strict requirements for control speed and system performance, the unavoidable time delay becomes a serious problem. fractional-order feedback is constantly adopted in control engineering due to its advantages, such as robustness, strong de-noising ability and better control performance. in this paper, the dynamical characteristics of an autonomous duffing oscillator under fractional-order feedback coupling with time delay are investigated. at first, the first-order approximate analytical solution is obtained by the averaging method. the equivalent stiffness and equivalent damping coefficients are defined by the feedback coefficient, fractional order and time delay. it is found that the fractional-order feedback coupling with time delay has the functions of both delayed velocity feedback and delayed displacement feedback simultaneously. then, the comparison between the analytical solution and the numerical one verifies the correctness and satisfactory precision of the approximately analytical solution under three parameter conditions respectively. the effects of the feedback coefficient, fractional order and nonlinear stiffness coefficient on the complex dynamical behaviors are analyzed, including the locations of bifurcation points, the stabilities of the periodic solutions, the existence ranges of the periodic solutions, the stability of zero solution and the stability switch times. it is found that the increase of fractional order could make the delay-amplitude curves of periodic solutions shift rightwards, but the stabilities of the periodic solutions and the stability switch times of zero solution cannot be changed. the decrease of the feedback coefficient makes the amplitudes and ranges of the periodic solutions become larger, and induces the stability switch times of zero solution to decrease, but the stabilities of the periodic solutions keep unchanged. the sign of the nonlinear stiffness coefficient determines the stabilities and the bending directions of delay-amplitude curves of periodic solutions, but the bifurcation points, the stability of zero solution and the stability switch times are not changed. it could be concluded that the primary system parameters have important influences on the dynamical behavior of duffing oscillator, and the results are very helpful to design, analyze or control this kind of system. the analysis procedure and conclusions could provide a reference for the study on the similar fractional-order dynamic systems with time delays.
parallel_computing	the next-generation high speed wireless technologies, such as wirelesshd, bring the concept of several gigabits per second data communication. however, forward error correction that takes place at the receiver side has become a real computational challenge. so far, only hardware solutions have offered such high-speed convolutional decoding, which could not be achieved by software solutions. our paper aims to fill this gap and proposes a software level solution offering such multi-gbps convolutional decoding. for this intend, we use the massively parallel computing power of nvidia gpgpus and cuda programming environment to implement a solution. as a decoding method, the fano algorithm is selected for its relatively low memory requirements and computational complexity. a look-ahead mechanism and compact history in the form of circular queue is presented to support such high throughput. conducted tests showed that our gpu based algorithm can decode up to 9.25 gbps. (c) 2016 elsevier ltd. all rights reserved.
analog_signal_processing	in this paper, a cmos low-power high-speed low-error four-quadrant analog multiplier based on a simple current squarer circuit, is presented. the new squarer circuit consists of a mos transistor which operating in saturation region and a resistor. the proposed multiplier has a balanced structure composed of four squarer cells and a simple current mirror. the performance of the proposed design has been simulated using hspice software in 0.18 mu m tsmc cmos technology. simulation results with +/- 0.7 v dc supply voltages show that the linearity error is 0.35%, the -3db bandwidth is 903 mhz, the thd is 0.3% (at 1 mhz), maximum and static power consumption are 41.25 mu w and 14.5 mu w, respectively. monte carlo analysis with 5% variations in channel width and length, gate oxide thickness and threshold voltage of all transistors and resistance values are also performed to verify the satisfactory robustness and reliability of the proposed work.
digital_control	in the study of engineering, experimentation plays a great role in understanding the concepts. teaching in engineering is always challenging as theoretical study should be augmented with experiments so that students get a feel of the real life applications of the concepts they study. automation and control laboratory is an area where students can not verify the ladder diagrams; they develop for various applications, unless they have a programmable logic controller, plc in the lab. but the new concept of virtual lab has enabled us to teach the concepts of ladder diagrams and development of control systems using plc very easily. students could develop ladder diagrams and design digital control systems using the simulation environment given in the virtual lab platform and implement the logics developed by them. study carried out at institute and the exit surveys shows that the students are more convinced about the results, as they could test them on a platform.
computer_programming	a common way to learn is by studying written step-by-step tutorials such as worked examples. however, tutorials for computer programming can be tedious to create since a static text-based format cannot convey what happens as code executes. we created a system called codepourri that enables people to easily create visual coding tutorials by annotating steps in an automatically-generated program visualization. using codepourri, we developed a novel crowdsourcing workflow where learners who are visiting an educational website (www.pythontutor.com) collectively create a tutorial by annotating execution steps in a piece of code and then voting on the best annotations. since there are far more learners than experts, using learners as a crowd is a potentially more scalable way of creating tutorials. our experiments with 4 expert judges and 101 learners adding 145 raw annotations to two pieces of textbook python code show the learner crowd 's annotations to be accurate, informative, and containing some insights that even experts missed.
data_structures	vector and raster are two types of spatial data structures used in a geographic information system (gis). with the development of gis and remote sensing (rs) technologies, how to rapidly convert raster to vector data and establish topological relations among vectorized polygons is becoming a bottleneck in data integration between gis and rs. based on the previous work, an improved vectorization method is proposed to vectorize classified rs raster data quickly and automatically establish topological relations. in accordance with the connection information of arcs and nodes and both-sides polygonal attributes of arcs, the next arc can be searched directly by attribute matching when constructing polygons, thereby improving search efficiency. moreover, our method addressed the problems of self-intersecting polygons, shared-boundary, and multi-nested islands and gave corresponding solutions, which can establish the topological relations of an entire image quickly. two experiments, one for comparison between before and after vectorization of two different classified rs raster maps, and the other for comparison with several methods, are carried out to test the accuracy and efficiency of our method. results show that the method solves the self-intersecting polygons, shared-boundary, and multi-nested islands problems. in addition, its vectorization speed is more than double that of commercial software arcgis, and the advantage of our method becomes more obvious as the number of polygons increases. thus, our method can vectorize large and complex classified rs raster data with sufficient efficiency for practical use and establish topological relations among vectorized polygons.
pid_controller	a disrupted oppositional based gravitational search algorithm (dogsa) tuned sliding mode controller (smc) is proposed in this study for the solution of automatic generation control of interconnected multi-area power system under deregulated environment. the novelty of the control scheme is established by performing the sensitivity analysis under different conditions such as variation of the system load, turbine time constant, governor time constant and tie-line power coefficient. the dynamic response of the system under consideration is also studied and analysed in the presence of non-linear constraints namely generation rate constraint with reheat steam turbine, governor deadband and time delay during signal processing. further, in order to validate the effectiveness of the proposed dogsa tuning over the genetic algorithm and differential evolution tuned schemes reported in the literature, it is also employed to tune the integral (i), proportional-integral (pi), integral-derivative (id) and proportional integral derivative (pid) controllers. moreover, the performance of the optimised smc scheme is also compared with i, pi, id and pid controllers. the comparative results reveal that smc scheme tuned using dogsa gives better results than the conventional controllers.
pid_controller	this paper is devoted to the problem of regulating the heart rate response along a predetermined reference profile, for cycle-ergometer exercises designed for training or cardio-respiratory rehabilitation. the controller designed in this study is a non-conventional, non-model-based, proportional, integral and derivative (pid) controller. the pid controller commands can be transmitted as biofeedback auditory commands, which can be heard and interpreted by the exercising subject to increase or reduce exercise intensity. however, in such a case, for the purposes of effectively communicating to the exercising subject a change in the required exercise intensity, the timing of this feedback signal relative to the position of the pedals becomes critical. a feedback signal delivered when the pedals are not in a suitable position to efficiently exert force may be ineffective and this may, in turn, lead to the cognitive disengagement of the user from the feedback controller. this note examines a novel form of control system which has been expressly designed for this project. the system is called an ""actuator-based event-driven control system"". the proposed control system was experimentally verified using 24 healthy male subjects who were randomly divided into two separate groups, along with cross-validation scheme. a statistical analysis was employed to test the generalisation of the pid tunes, derived based on the average transfer functions of the two groups, and it revealed that there were no significant differences between the mean values of root mean square of the tracking error of two groups (3.9 vs. 3.7 bpm, ). furthermore, the results of a second statistical hypothesis test showed that the proposed pid controller with novel synchronised biofeedback mechanism has better performance compared to a conventional pid controller with a fixed-rate biofeedback mechanism (group 1: 3.9 vs. 5.0 bpm, group 2: 3.7 vs. 4.4 bpm, ).
microcontroller	the continuous growth of the internet of things in recent years has meant it is increasingly more present, as internet of things scenarios such as smart homes and smart cities become part of our everyday lives. the internet of things devices involved can be divided into two categories in most internet of things scenarios. the devices can constitute a black box with specific sensors which complicates their configuration, for example, wearable products. other internet of things devices can be composed through configurable microcontrollers, enabling customizable environments to be designed. however, the necessary tools and knowledge for programming and configuring microcontrollers are not accessible to everyone. this article proposes a run-time deployment and management system through the constrained application protocol that bridges the gap between end users and customizable environments. with our system, end users can incorporate new sensors or actuators in their installed microcontroller without having to access and program the microcontroller board. rather, they can manage the resources of the constrained application protocol servers through an accessible and transparent web user interface.
pid_controller	this paper deals with the real implementation of an event-based control structure for the classical rotary inverted pendulum. the communication between controller and plant is performed through ethernet (tcp/ip) which leads to a networked control system. the bandwidth used by the control loop is reduced, compared with the one that needs a conventional control, by using a threshold-based communication. the values of the thresholds have been determined by means of simulation techniques. the results over the real plant show how this technique can reach a significant reduction of the bandwidth consumed with a negligible worsening of the performance. (c) 2016 isa. published by elsevier ltd. all rights reserved.
computer_programming	in this paper we introduce blockimpress, a visual, graphical block programming language for making web presentations by computer programming and we show some practical examples how to use it.
software_engineering	design defects are symptoms of design decay, which can lead to several maintenance problems. to detect these defects, most of existing research is based on the definition of rules that represent a combination of software metrics. these rules are sometimes not enough to detect design defects since it is difficult to find the best threshold values; the rules do not take into consideration the programming context, and it is challenging to find the best combination of metrics. as an alternative, we propose in this paper to identify design defects using a genetic algorithm based on the similarity/distance between the system under study and a set of defect examples without the need to define detection rules. we tested our approach on four open-source systems to identify three potential design defects. the results of our experiments confirm the effectiveness of the proposed approach.
analog_signal_processing	this paper deals with a model-based design of an autonomous biomechatronic device for sensing and analog signal processing of acoustic signals. the aim is to develop a biomechatronic artificial cochlear implant for people with hearing loss due to damage or disease of their cochlea. the unique artificial electronic cochlear implant is based on an array of microelectromechanical piezoelectric membranes. oscillations of membranes detect and filter acoustic signals in individual acoustic frequencies. the proposed biomechatronic device of the artificial cochlear implant consists of an active filters array, signal processing electronics, stimulation nerves electrodes and energy harvesting system for autonomous powering of the device. this solution differs from current cochlear implants solutions, which are bulky electronic systems limited by their high power consumption. the multidisciplinary models of the artificial cochlea implant concept are presented. the mechatronic approach based on model seems to be very useful for development of the full implantable cochlear implant which is designed for the sensing and processing of acoustic signals without external energy source. (c) 2015 elsevier ltd. all rights reserved.
distributed_computing	nowadays, it is more and more important to diagnose several kinds of pathologies at their early stage, in order to take the necessary countermeasures before having permanent consequences. unfortunately, though many pathologies are widespread, there does not exist a unique standardized reference or gold standard according to which it is possible to evaluate the patients, mainly when the pathology is in the early stages or is not very noticeable, and the doctor is not sufficiently expert in the problem domain. in this work, we deal with this problem, by envisioning new healthcare services supporting a collaborative clinical analysis of symptoms collected from the patients and forwarded to a group of experts, which are geographically distributed. the experts return back their assessment and diagnosis and the system combines these by means of the theory of the evidence, in order to provide a single response. the above services can be easily implemented on top of state-of-the-art distributed computing facilities such as grids or clouds, providing a connected environment for medical data distributed over different sites and allowing medical experts to collaborate without being co-located, thereby providing transparent access to data and computing resources. additionally, such services can provide feedbacks to each expert, in order to improve its own knowledge and experience in the case of divergence between the expert response and the global combined diagnosis in recognizing and classifying the received symptomatic indexes from the patient. we have considered the craniofacial pathologies in infant population as a practical example for better explaining the proposed solution. (c) 2016 elsevier b.v. all rights reserved.
symbolic_computation	in this article, we apply the singularity structure analysis to test an extended 2+1-dimensional fifth-order kdv equation for integrability. it is proven that the generalized equation passes the painleve test for integrability only in three distinct cases. two of those cases are in agreement with the known results, and a new integrable equation is first given. then, for the new integrable equation, we employ the bell polynomial method to construct its bilinear forms, bilinear backlund transformation, lax pair, and infinite conversation laws systematically. the n-soliton solutions of this new integrable equation are derived, and the propagations and collisions of multiple solitons are shown by graphs.
electrical_circuits	in this paper we consider the problem of synthesis of equivalent circuits containing nonlinear electrical circuits, in general, any number of non-linear elements. the system of differential equations describing the linear non autonomous multi-pole after quasiequivalence transformations allows to synthesize an equivalent circuit of the multi-pole consisting of two-pole linear, nonlinear resistors, controlled voltage sources, etc. the question of replacing the series-connected voltage sources controlled by the operational amplifier, the implementation of linear and nonlinear two-pole resistors.
signal-flow_graph	this paper proposes a static linear behavior (slb) analog fault model for switched-capacitor (sc) circuits. the sc circuits under test (cut) are divided into functional macros including the operational amplifiers, the capacitors, and the switches. each macro has specified design parameters from the design 's perspectives. these design parameters constitute a parameter set which determines the practical transfer function of the cut. the slb fault model defines that a cut is faulty if its parameter set results in transfer functions whose frequency responses are out of the design specification. we analyzed the fault effects of the macros and derived their faulty signal-flow graph models with which the faulty transfer function templates of the cut can be automatically generated. based on the templates, we proposed a test procedure that can estimate all the parameters in the parameter set so as to test the cut with multiple faults. different from conventional single fault assumption, the proposed slb fault model covers concurrent multiple parametric faults and catastrophic faults. in addition, it does not need to conduct fault simulations before test as conventional analog fault models do. as a result, it addresses the impractically long fault simulation time issue. a fully-differential low-pass sc biquad filter was adopted as an example to demonstrate how to design and use efficient multitone tests to test for the parameter set. the multitone test results acquired during the test procedure also reveal the distortion and noise performance of the cut though the slb fault model does not include them.
image_processing	varied spatial resolution of isochromatic fringes over the domain influences the accuracy of fringe order estimation using tfp/rgb photoelasticity. this has been brought out in the first part of the work. the existing scanning schemes do not take this into account, which leads to the propagation of noise from the low spatial resolution zones. in this paper, a method is proposed for creating a whole field map which represents the spatial resolution of the isochromatic fringe pattern. a novel scanning scheme is then proposed whose progression is guided by the spatial resolution of the fringes in the isochromatic image. the efficacy of the scanning scheme is demonstrated using three problems an inclined crack under biaxial loading, a thick ring subjected to internal pressure and a stress frozen specimen of an aerospace component. the proposed scheme has use in a range of applications. the scanning scheme is effective even if the model has random zones of noise which is demonstrated using a plate subjected to concentrated load. this aspect is well utilised to extract fringe data from thin slices cut from a stereo lithographic model that has characteristic random noise due to layered manufacturing. (c) 2016 elsevier ltd. all rights reserved.
electricity	an ultimate goal for those engaged in research to develop implantable medical devices is to develop mechatronic implantable artificial organs such as artificial pancreas. such devices would comprise at least a sensor module, an actuator module, and a controller module. for the development of optimal mechatronic implantable artificial organs, these modules should be self-powered and autonomously operated. in this study, we aimed to develop a microcontroller using the biocapacitor principle. a direct electron transfer type glucose dehydrogenase was immobilized onto mesoporous carbon, and then deposited on the surface of a miniaturized au electrode (7 mm(2)) to prepare a miniaturized enzyme anode. the enzyme fuel cell was connected with a 100 mu f capacitor and a power boost converter as a charge pump. the voltage of the enzyme fuel cell was increased in a stepwise manner by the charge pump from 330 mv to 3.1 v, and the generated electricity was charged into a 100 mu f capacitor. the charge pump circuit was connected to an ultra-low-power microcontroller. thus prepared biocapacitor based circuit was able to operate an ultra-low-power microcontroller continuously, by running a program for 17 h that turned on an led every 60 s. our success in operating a microcontroller using glucose as the sole energy source indicated the probability of realizing implantable self-powered autonomously operated artificial organs, such as artificial pancreas.
state_space_representation	this paper discusses the possibility of using observer-based approaches for cardiovascular anomalies detection and isolation. we consider a lumped parameter model of the cardiovascular system that can be written in a form of nonlinear state-space representation. we show that residuals that are sensitive to variations in some cardiovascular parameters and to abnormal opening and closure of the valves, can be generated. since the whole state is not easily available for measurement, we propose to associate the residual generator to a robust extended kalman filter. numerical results performed on synthetic data are provided.
pid_controller	this paper describes and proposes a modern solution for controlling the temperature of crude oil atmospheric distillation in which, a programmable logic controller (plc) was used instead of the classic proportional integral -derivative (pid) controller. the authors present in details the design of plc programme together with simulation diagrams that show how the designed control system works. programming the plc is done by using a function block diagrams method.
computer_programming	in this article we make a critical assessment of the relation between online and print design, focusing on the graphic language of newspaper infographics. a lot of the work done in this area consists in adapting print newspaper infographics to online versions. the problem with many of these adaptations is that there are losses in reading strategy and structure of their online versions, offering readers a mainly linear reading experience. to understand this fact, we compare print infographics and their digital versions through the analysis of layout and cognitive load. in a time when the knowledge of computer programming seems to be crucial to editorial design, we reflect on the importance of layout, which is the principle design structure to help readers access and understand information.
system_identification	in this paper, the problem of health monitoring and prognosis of aircraft gas turbine engines is considered by using computationally intelligent methodologies. two different dynamic neural networks, namely the nonlinear autoregressive with exogenous input neural networks and the elman neural networks, are developed and designed for this purpose. the proposed dynamic neural networks are designed to capture the dynamics of two main degradations in the gas turbine engine, namely the compressor fouling and the turbine erosion. the health status and condition of the engine in terms of the turbine output temperature (tt) are then predicted subject to occurrence of these deteriorations. various scenarios consisting of fouling and erosion separately as well as combined are considered. for each scenario, several neural networks are trained and their performance in predicting multiple flights ahead tts is evaluated. finally, the most suitable neural networks for achieving the best prediction are selected by using the normalized bayesian information criterion model selection. simulation results presented demonstrate and illustrate the effective performance of our proposed neural network-based prediction and prognosis strategies.
electricity	in this study, a proton conducting solid oxide fuel cell (layered h+-sofc) is prepared by introducing a la(2)nio(4)perovskite oxide with a ruddlesden-popper structure as a catalyst layer onto a conventional ni + bazr(0.4)ceo(0.4)y(0.2)o(3-delta) (nio + bzcy4) anode for in situ co2 dry reforming of methane. the roles of the la2nio4 catalyst layer on the reforming activity, coking tolerance, electrocatalytic activity and operational stability of the anodes are systematically studied. the la2nio4 catalyst layer exhibits greater catalytic performance than the nio + bzcy4 anode during the co2 dry reforming of methane. an outstanding coking resistance capability is also demonstrated. the layered h+-sofc consumes h-2 produced in situ at the anode and delivers a much higher power output than the conventional cell with the nio + bzcy4 anode. the improved coking resistance of the layered h+-sofc results in a steady output voltage of similar to 0.6 v under a constant current density of 200 ma cm(-2). in summary, the h+-sofc with la2nio4 perovskite oxide is a potential energy conversion device for co2 conversion and utilization with cogeneration of electricity and syngas. (c) 2017 elsevier b.v. all rights reserved.
cryptography	elliptic curve cryptosystems proved to be well suited for securing systems with constrained resources like embedded and portable devices. in a fault-based attack, errors are induced during the computation of a cryptographic primitive, and the results are collected to derive information about the secret key safely stored in the device. we introduce a novel attack methodology to recover the secret key employed in implementations of the elliptic curve digital signature algorithm. our attack exploits the information leakage induced when altering the execution of the modular arithmetic operations used in the signature primitive and does not rely on the underlying elliptic curve mathematical structure, thus being applicable to all standardized curves. we provide both a validation of the feasibility of the attack, even employing common off-the-shelf hardware to perform the required computations, and a low-cost countermeasure to counteract it.
signal-flow_graph	a novel configuration of current mirrors differentiators-based continuous-time current-mode low pass filter is proposed in this paper. the filter only consists of current mirrors differentiators and capacitors. the topology is really simple, the sensitivity is very low, so it suits full integration. the computer simulation of transistor is carried out and the results show that the proposed circuits are effective.
distributed_computing	this paper reports our research in developing a cyberinfrastructure platform to support multivariate visualization of data collected from distributed sensor network. three new techniques were introduced in this platform: (1) a hybrid data caching strategy that takes advantages of a scalable and distributed time series database, opentsdb, to realize efficient data retrieval; (2) a hyper-dimensional data cube is established to map and translate multivariate and heterogeneous sensor data into a common data structure to support location-aware visual analysis; and (3) a data-driven visualization module is implemented to support interactive and dynamic visualization on a simulated virtual globe. a series of experiments were conducted to demonstrate the good runtime performance of the proposed system. we expect this work to make a major contribution to both the visualization building block development in cyberinfrastructure research and the advancement of visual presentation and analysis of sensor data in domain sciences.
electricity	to response to the increasing demands for clean water, a large pressurized water reactor (pwr) with a desalination capability has been studied and demonstrated its potential so far. however, the electricity production of the large nuclear reactor decreases by 10% due to steam bypass for desalination. in this study, the authors evaluate the possibility of a large pwr with a capability of producing both electric power and clean water by using the supercritical co2 (s-co2) brayton cycle technology. the s-co2 power technology is adopted to minimize the decrease in the electricity production capacity due to desalination process. two concepts which replace the existing steam based power conversion system with a s-co2 brayton cycle were proposed. the first concept is that the low pressure steam turbine section of the power conversion system is replaced with the s-co2 brayton cycle. the second concept is that the whole steam based power conversion system is replaced with the s-co2 brayton cycle. several s -co2 cycle options were considered in terms of power production and the desalination capacity and conducted a comparative analysis of selected layouts and the optimal operating conditions of the suggested layouts were identified. (c) 2017 elsevier b.v. all rights reserved.
pid_controller	in this article, an optimized pid controller for a fuel cell is introduced. it should be noted that we did not compute the pid controller 's coefficients based on trial-and-error method; instead, imperialist competitive algorithms have been considered. at first, the problem will be formulated as an optimization problem and solved by the mentioned algorithm, and optimized results will be obtained for pid coefficients. then one of the important kinds of fuel cells, called proton exchange membrane fuel cell, is introduced. in order to control the voltage of this fuel cell during the changes in the charges, an optimal controller is introduced, based on the imperialist competitive algorithm. in order to apply this algorithm, the problem is written as an optimization problem which includes objectives and constraints. to achieve the most desirable controller, this algorithm is used for problem solving. simulations confirm the better performance of proposed pid controller.
computer_vision	discovering kinship relations from face images in the wild has become an interesting and important problem in multimedia and computer vision. despite the rapid advances in face analysis in unconstrained environment, kinship verification still remains a challenging problem as the subtle kinship relation is difficult to discover and changes in pose and lighting condition further complicate this task. in this paper, we propose a kinship verification approach based on multi-linear coherent space learning. local image patches at different scales are independently projected into their corresponding coherent spaces learned by robust canonical correlation analysis such that patch pairs with kinship relations have improved correlation. in addition, most discriminative patches for verification are selected via constrained linear programming. experimental results on two widely used kinship verification datasets show that the proposed method can effectively identify different kinship relations in image pairs. compared to state-of-the-art techniques, the proposed method achieves very competitive performance with the use of simple feature descriptors.
algorithm_design	wireless sensor networks (wsns) consists of large number of spatially distributed configurable sensors, to meet the requirements of industrial, military, precision agriculture and health monitoring applications with ease of implementation and maintenance cost. transmission of data requires both energy and quality of service (qos) aware routing to ensure efficient use of the sensors and effective access of the gathered information. design of wsns considering its issues is challenging task and leads to complex algorithm design which are difficult to analyze by analytical methods and by physical measurements. deploying test-beds supposes a huge effort. in deed computer aided simulation is the feasible approach for analysis of wsns. we addressed different types of simulators along with their key features and their applicability for simulation in numerous application areas.
computer_vision	in photogrammetry, remote sensing, computer vision and robotics, a topic of major interest is represented by the automatic analysis of 3d point cloud data. this task often relies on the use of geometric features amongst which particularly the ones derived from the eigenvalues of the 3d structure tensor (e.g. the three dimensionality features of linearity, planarity and sphericity) have proven to be descriptive and are therefore commonly involved for classification tasks. although these geometric features are meanwhile considered as standard, very little attention has been paid to their accuracy and robustness. in this paper, we hence focus on the influence of discretization and noise on the most commonly used geometric features. more specifically, we investigate the accuracy and robustness of the eigenvalues of the 3d structure tensor and also of the features derived from these eigenvalues. thereby, we provide both analytical and numerical considerations which clearly reveal that certain features are more susceptible to discretization and noise whereas others are more robust. (c) 2017 international society for photogrammetry and remote sensing, inc. (isprs). published by elsevier b.v. all rights reserved.
distributed_computing	we develop several parallel algorithms for shortest distance queries in planar graphs that use graph partitioning in the preprocessing phase to precompute and store distances between selected pairs of vertices. in the query phase, given a pair of arbitrary vertices v and w, the stored information is used to find the distance between v and w fast. the algorithms are implemented and tested on a high performance cluster with upto 256 16-core cpus and their performances are analyzed and compared.
state_space_representation	in order to adapt to a milling machines changing behavior while operating due to changing tool-workpiece contact conditions adaptive controllers are an advantageous approach to control the machines feed rate. otherwise inaccuracies can occur leading to poor quality. in this paper model predictive control (mpc) is used to control the feed rate of the machine. by applying a parameterized model to the current state of the milling process its future trend can be predicted. an n-th order system with delay time is used to model the behavior of the milling machines velocity control loop. by continually re-estimating the model parameters at run time, the controller adapts to the current machine behavior. we developed solutions of the maximum likelihood estimators of the models independent parameters for a state-space representation that can be numerically efficiently calculated. these estimators can be used to estimate the parameters of the n-th order system and the delay time iteratively based on the collected process data. two validation studies, one emulating an online estimation based on real data from the five-axis machining center mazak variaxis 630ii-t, and one simulation study with a simulated machine, were carried out to validate the iterative parameter estimation algorithm. in these studies, the time variant model, whose parameters are re-estimated on the basis of the developed estimators, is compared to a time invariant model, for which the controller does not adapt to changing machine behavior. (c) 2016, ifac (international federation of automatic control) hosting by elsevier ltd. all rights reserved.
electric_motor	this paper presents and analyses a phase shifter for diversity receivers, which modulates the i-/q-vector in the constellation diagram. the system consists of a three stage programmable gain amplifier (pga) chain in both branches. the design covers the full phase range of 360 degrees. each stage can be programmed to amplify the incoming signal between 19 db and 63 db with a centre frequency of 3 mhz. the radio frequency (rf) signal is down-converted to an intermediate frequency (if) of 5 mhz, where phase shifting is done. the circuit is intended for an automotive satellite radio receiver in sand l-band. thus, demand automotive requirements have to be fulfilled. the supply voltage is 1.8v. compared to other phase shifters, the power consumption of 2.7 mw is highly energy-efficient. this system includes a constant gm-source and a biasing circuit. all requirements are verified in post-layout corner and monte-carlo analysis using virtuoso and wicked. the design only takes 0.116 mm(2) of silicon area in a 150-nm cmos technology.
analog_signal_processing	this work falls into the category of linear cellular neural network (cnn) implementations. we detail the first investigative attempt on the cmos analog vlsi implementation of a recently proposed network formalism, which introduces time-derivative 'diffusion' between cnn cells for nonseparable spatiotemporal filtering applications-the temporal-derivative cnns (tdcnns). the reported circuit consists of an array of gm-c filters arranged in a regular pattern across space. we show that the state-space coupling between the gm-c-based array elements realizes stable and linear first-order (temporal) tdcnn dynamics. the implementation is based on linearized operational transconductance amplifiers and class-ab current mirrors. measured results from the investigative prototype chip that confirms the stability and linearity of the realized tdcnn are provided. the prototype chip has been built in the ams 0.35 mu m cmos technology and occupies a total area of 12.6mm sq, while consuming 1.2 mu w per processing cell. copyright (c) 2010 john wiley & sons, ltd.
microcontroller	this paper presents a comparison between the performances of different interleaving control methods for gallium nitride devices-based mhz critical conduction mode (crm) totem-pole power factor correction (pfc) circuit. both closed-loop interleaving and open-loop interleaving are good for the 70-khz crm pfc; but for a mhz frequency crm pfc with microcontroller (mcu) implementation, the open-loop interleaving outperforms the closed-loop interleaving with only a small and nonamplified phase error. after software optimization, the phase error of the open-loop interleaving is smaller than 3 degrees at 1 mhz, when the control is implemented by a 60-mhz low-cost mcu. significant ripple cancellation effect and differential-mode (dm) filter size reduction are achieved with good interleaving. for a 1.2-kw mhz totem-pole pfc, the dm filter size is reduced to one quarter when compared with the counterpart of a 100-khz pfc. last but not least, the stability of the open-loop interleaving is also analyzed indicating that the mhz crm totem-pole pfc with voltage-mode control, open-loop interleaving, and turn-on instant synchronization can maintain critical mode operation with better stability compared with the 70-khz crm pfc.
digital_control	a novel driving method implemented with high frequency electromagnetic isolation is proposed in this paper. and the hardware designing schematic diagram and the software configuration method are presented. then the corresponding operating principle is analyzed in detail based on digital control chip and analog circuits. the proposed driving method can be applied to real-time varying pulse width of the control signal and the duty-cycle ratio of this control pulse can be regulated in the range of 0-100 %. this novel driving method can achieve not only the advantages of high insulation and high common-mode suppression, but also the merits of low cost and fast dynamic response speed, and it is suitable for the isolation and amplification of high frequency switching control pulse signal. finally, the experimental results show that the proposed driving method in this paper is effective.
image_processing	the present work introduces a curvelet-like directional filter and discusses its application to edge detection in general images and fracture detection in gpr data. the filter is essentially a curvelet of adjustable anisotropy and orientation that can be tuned on any given (target) wavenumber; while retaining the properties of curvelets, it is not bound to the scaling rules of the curvelet frame but is individually steerable to any local trait of the data, hence it is dubbed ""curveletiform"". curveletiforms can be used in single-or multi-directional modes in a manner simple, computationally inexpensive and demonstrably efficient. gpr data generally contains straight or curved edge-like objects comprising reflections from planar interfaces and is notoriously susceptible to broadband noise. fractures are an important class of interfaces as they determine the health state of rocks or man-made structures and are primary targets of gpr surveys in geotechnical, engineering and environmental applications. as demonstrated with examples, curveletiforms can efficiently recover information of specific scale and geometry from straight or curved edges in general images. in gpr data they may distinguish reflections from small and large fractures, discriminate between groups of fractures, resolve fracture density and aid the assessment of damage in rocks and structures. (c) 2016 elsevier b.v. all rights reserved.
distributed_computing	software integration testing plays an increasingly important role as the software industry has experienced a major change from isolated applications to highly distributed computing environments. conducting integration testing is a challenging task because it is often very difficult to replicate a real enterprise environment. emulating testing environment is one of the key solutions to this problem. however, existing specification-based emulation techniques require manual coding of their message processing engines, therefore incurring high development cost. in this paper, we present a suite of domain-specific visual modeling languages to describe emulated testing environments at a high abstraction level. our solution allows domain experts to model a testing environment from abstract interface layers. these layer models are then transformed to runtime environment for application testing. our user study shows that our visual languages are easy to use, yet with sufficient expressive power to model complex testing applications.
microcontroller	timing abilities are often measured by having participants tap their finger along with a metronome and presenting tap-triggered auditory feedback. these experiments predominantly use electronic percussion pads combined with software (e.g., ftap or max/msp) that records responses and delivers auditory feedback. however, these setups involve unknown latencies between tap onset and auditory feedback and can sometimes miss responses or record multiple, superfluous responses for a single tap. these issues may distort measurements of tapping performance or affect the performance of the individual. we present an alternative setup using an arduino microcontroller that addresses these issues and delivers low-latency auditory feedback. we validated our setup by having participants (n = 6) tap on a force-sensitive resistor pad connected to the arduino and on an electronic percussion pad with various levels of force and tempi. the arduino delivered auditory feedback through a pulse-width modulation (pwm) pin connected to a headphone jack or a wave shield component. the arduino 's pwm (m = 0.6 ms, sd = 0.3) and wave shield (m = 2.6 ms, sd = 0.3) demonstrated significantly lower auditory feedback latencies than the percussion pad (m = 9.1 ms, sd = 2.0), ftap (m = 14.6ms, sd = 2.8), and max/msp (m = 15.8 ms, sd = 3.4). the pwm and wave shield latencies were also significantly less variable than those from ftap and max/msp. the arduino missed significantly fewer taps, and recorded fewer superfluous responses, than the percussion pad. the arduino captured all responses, whereas at lower tapping forces, the percussion pad missed more taps. regardless of tapping force, the arduino outperformed the percussion pad. overall, the arduino is a high-precision, low-latency, portable, and affordable tool for auditory experiments.
pid_controller	to assess the influence of ship-bank interactions on the course keeping ability of ships, planar motion mechanism (pmm) tests on a scale model of the kvlcc2 tanker were conducted in a circulating water channel (cwc) at different ship-bank distances and speeds. to characterize the asymmetric hydrodynamic features, the asymmetric hydrodynamic derivatives are defined and are measured by the straight towing test with off-centerline displacements. the change in the linear hydrodynamic derivatives due to ship-bank interactions is discussed. the state-space equations are derived from the linear equations of maneuvering motion, which include the asymmetric hydrodynamic derivatives. the linear quadratic regulator (lqr) is adopted to provide the rudder angle and the variation in forward speed during the course keeping process. the simulation results with varying ship-bank separations show that the lqr is more suitable than the classical proportional-integral-derivative (pid) controller for the course keeping of the kvlcc2 in the scenario discussed.
image_processing	a look back at skeletal radiology in 2016 reveals a sizable number of publications that significantly advanced the state of knowledge about diseases of the musculoskeletal system. this review summarizes the content of some of the most intriguing papers of the year.
signal-flow_graph	we propose a novel design of optical buffer to generate slow light based on delay time. in the framework of the nonlinear waveguide, we investigate propagation of solitons through microring resonators. dynamical control over slow-light solitons is realized via controlling fields generated by bright soliton and gaussian pulse. the nonlinear dependence of the velocity of the signal on the controlling field is analytically described. the buffering effect is achieved by slowing the optical signal using an external control light source to vary the dispersion characteristic of the medium via microring resonators. a graphical approach with a signal flow graph method is used to derive the optical transfer functions in z-domain of filters. the characteristics of the optical buffer devices including the transmittance and time delay of the through and drop port are simulated. simulated results show the criteria of achieving slow light in semiconductor microring resonators. finally, output signal shows the delay time rate by propagation through the semiconductor microring resonators. (c) 2012 society of photo-optical instrumentation engineers (spie). [doi: 10.1117/1.oe.51.4.044601]
structured_storage	many large-scale online services use structured storage to persist metadata and sometimes data. the structured storage is typically provided by standard database servers such as microsoft 's sql server. it is important to understand the workloads seen by these servers, both for provisioning server hardware as well as to exploit opportunities for energy savings and server consolidation. in this paper we analyze disk i/o traces from production servers in four internet services as well as servers running tpc benchmarks. we show using a range of load metrics that the services differ substantially from each other and from standard tpc benchmarks. online services also show significant diurnal patterns in load that can be exploited for energy savings or consolidation. we argue that tpc benchmarks do not capture these important characteristics and argue for developing benchmarks that can be parameterized with workload features extracted from live production workload traces.
machine_learning	most diseases, including those of genetic origin, express a continuum of severity. clinical interventions for numerous diseases are based on the severity of the phenotype. predicting severity due to genetic variants could facilitate diagnosis and choice of therapy. although computational predictions have been used as evidence for classifying the disease relevance of genetic variants, special tools for predicting disease severity in large scale are missing. here, we manually curated a dataset containing variants leading to severe and less severe phenotypes and studied the abilities of variation impact predictors to distinguish between them. we found that these tools cannot separate the two groups of variants. then, we developed a novel machine-learning-based method, pon-ps (), for the classification of amino acid substitutions associated with benign, severe, and less severe phenotypes. we tested the method using an independent test dataset and variants in four additional proteins. for distinguishing severe and nonsevere variants, pon-ps showed an accuracy of 61% in the test dataset, which is higher than for existing tolerance prediction methods. pon-ps is the first generic tool developed for this task. the tool can be used together with other evidence for improving diagnosis and prognosis and for prioritization of preventive interventions, clinical monitoring, and molecular tests. (c) 2017 wiley periodicals, inc.
relational_databases	the dynamics of belief and knowledge is one of the major components of any autonomous system that should be able to incorporate new pieces of information. in order to apply the rationality result of belief dynamics theory to various practical problems, it should be generalized in two respects: first it should allow a certain part of belief to be declared as immutable; and second, the belief state need not be deductively closed. such a generalization of belief dynamics, referred to as base dynamics, is presented in this paper, along with the concept of a generalized revision algorithm for knowledge bases (horn or horn logic with stratified negation). we show that knowledge base dynamics has an interesting connection with kernel change via hitting set and abduction. in this paper, we show how techniques from disjunctive logic programming can be used for efficient (deductive) database updates. the key idea is to transform the given database together with the update request into a disjunctive (datalog) logic program and apply disjunctive techniques (such as minimal model reasoning) to solve the original update problem. the approach extends and integrates standard techniques for efficient query answering and integrity checking. the generation of a hitting set is carried out through a hyper tableaux calculus and magic set that is focused on the goal of minimality.
image_processing	the deficiency in rapid and in-field detection methods and portable devices that are reliable, easy-to-use, and low cost, results in the difficulties to uphold the high safety standards in china. in this study, we introduce a rapid and cost-effective smartphone-based method for point-of-need food safety inspection, which employs aptamer-conjugated aunps as the colorimetric indicator, and a battery-powered optosensing accessory attached to the camera of a smartphone for transmission images capture. a userfriendly and easy-to-use android application is developed for automatic digital image processing and result reporting. streptomycin (str) is selected as the proof-of-concept target, and its specific quantitation can be realized with a lod of 12.3 nm (8.97 mg kg(-1)) using the reported smartphone- based method. the quantitation of str in honey, milk and tap water confirm the reliability and applicability of the reported method. the extremely high acceptance of smartphone in remote and metropolitan areas of china and ease-of-use of the reported method facilitate active food contaminant and toxicant screening, thus making the implementation of the whole food supply chain monitoring and surveillance possible and hence significantly improving the current chinese food safety control system. (c) 2017 elsevier b.v. all rights reserved.
machine_learning	we evaluated the underlying causes of differences between latent heat (le) fluxes measured with two enclosed-path eddy covariance systems (ec) at two measurement levels and independent estimates in an open oak-tree grass savannah over almost one year. estimates of le of the well-stablished underlying grass by replicated weighable tension-controlled lysimiters (lelye) provided a robust baseline against which to compare ec le measured at 1.6 m above ground (le_1.6). similarly and at the ecosystem level, le up-scaled using independent measurements (leupscaled =sap flow+ lysimeter) was benchmarked with 3 ec-derived le estimates: 1) le measured by a ec tower at 15 m above ground (le-1.6), 2) le-1.5 adjusted to close the energy balance by using the bowen ratio method (lebowen = (rn - g)/(1 + beta)) and 3) le derived from the energy budget residual (leresidual = r-n - g - h-1.5). the sensitivity of ec le to the correction method applied (i.e. corrections for low-pass filtering effects on water vapor fluctuations and the so-called angle-of-attack correction) and its impact on the energy balance closure (ebc) were also evaluated. comparison of ec le between 1.6 m- and 15m-heights showed that grass dominated annual evaporative loss from 69 to 87% depending upon the spectral correction method applied. results revealed substantial underestimation of le-1.6 (up to 35%) compared to lelys, which mostly occurred during the growing season. however those differences were remarkably lower when likening le-1.5 versus leupscaled (14%) suggesting that the dampening of the water vapor fluctuations due to low-pass filtering effects is more pronounced near the surface. interestingly, a diagnostic evaluation of the errors with a random forest model showed that differences followed quite structured patterns and were associated with certain atmospheric conditions: turbulent mixing deficiencies and or stable atmospheric stratification. in addition, the model showed that differences increased with increasing relative humidity (rh) and soil moisture. our results revealed that the degree of ebc is highly sensitive to the flux correction method applied, in particular when correcting for flow distortion effects. typically, turbulent fluxes fell below the measured available energy (slope 0.92) but the slope switched abruptly when the angle-of-attack correction was applied (slope 1.07). consistent with the ebc, independent le estimates matched well with lebowen and the ebc gap decreased when leupscaied was used (slope 0.96). the use of independent estimates of le together with machine learning methods are proposed as a powerful means to diagnose the complexity behind le errors and give insights into the energy imbalance problem. in addition to inherent randomness of ec le data, accounting for uncertainties associated with the appropriateness of the correction method applied is highly recommended. 2017 elsevier b.v. all rights reserved.
distributed_computing	we present jump, a practical system for capturing high resolution, omnidirectional stereo (ods) video suitable for wide scale consumption in currently available virtual reality (vr) headsets. our system consists of a video camera built using off-the-shelf components and a fully automatic stitching pipeline capable of capturing video content in the ods format. we have discovered and analyzed the distortions inherent to ods when used for vr display as well as those introduced by our capture method and show that they are small enough to make this approach suitable for capturing a wide variety of scenes. our stitching algorithm produces robust results by reducing the problem to one of pairwise image interpolation followed by compositing. we introduce novel optical flow and compositing methods designed specifically for this task. our algorithm is temporally coherent and efficient, is currently running at scale on a distributed computing platform, and is capable of processing hours of footage each day.
relational_databases	data conversion has become an emerging topic in bigdata era. to face the challenge of rapid data growth, legacy or existing relational databases have the need to convert into nosql column-family database in order to achieve better scalability. the conversion from sql to nosql databases requires combining small, normalized sql data tables into larger nosql data tables; a process called denormalization. a challenging issues in data conversion is how to group the denormalized columns in a large data table into ""families"" in order to ensure the performance of query processing. in this paper, we propose an efficient heuristic algorithm, gpa (graph-based partition algorithm), to address this problem. we use tpc-c and tpc-h benchmarks to demonstrate that, the column-families produced by gpa is very efficient for large scale data processing.
pid_controller	the class of vehicles that can move both in the air and underwater has been of great interest for decades. a novel water-air unmanned vehicle with double quadrotor structure is designed in this study. the air power mechanism works when the vehicle flies in the air, whereas the water power mechanism works when it moves underwater. the water entry process of water-air unmanned vehicle requires accurate attitude and height control, or the vehicle may bounce off or overturn. however, a force resisting its descent known as in-ground effect will affect its stability. the in-ground effect formula of the water entry process is derived by experiments, and the water entry dynamic model is improved at the same time. an active disturbance rejection controller (adrc) is designed for the control of water entry attitude and height. experimental results obtained from the comparison of the adrc and a proportional-integral-derivative (pid) controller show that the adrc designed in this study is more robust than the pid controller for the internal coupling and external disturbance on the vehicle. moreover, the adrc can meet the requirements of rapid attitude adjustment and accurate height control.
distributed_computing	this paper presents a novel two-step method for automated design of self-stabilization. the first step enables the specification of legitimate states and an intuitive (but imprecise) specification of the desired functional behaviors in the set of legitimate states (hence the term ""shadow""). after creating the shadow specifications, we systematically introduce the main variables and the topology of the desired self-stabilizing system. subsequently, we devise a parallel and complete backtracking search towards finding a self-stabilizing solution that implements a precise version of the shadow behaviors, and guarantees recovery to legitimate states from any state. to the best of our knowledge, the shadow/puppet synthesis is the first sound and complete method that exploits parallelism and randomization along with the expansion of the state space towards generating self-stabilizing systems that cannot be synthesized with existing methods. we have validated the proposed method by creating both a sequential and a parallel implementation in the context of a software tool, called protocon. moreover, we have used protocon to automatically design three new self-stabilizing protocols that we conjecture to require the minimal number of states per process to achieve stabilization (when processes are deterministic): 2-state maximal matching on bidirectional rings, 5-state token passing on unidirectional rings, and 3-state token passing on bidirectional chains.
microcontroller	an insect-like tailless flapping wing micro air vehicle (fw-mav) without feedback control eventually becomes unstable after takeoff. flying an insect-like tailless fw-mav is more challenging than flying a bird-like tailed fw-mav, due to the difference in control principles. this work introduces the design and controlled flight of an insect-like tailless fw-mav, named kubeetle. a combination of four-bar linkage and pulley-string mechanisms was used to develop a lightweight flapping mechanism that could achieve a high flapping amplitude of approximately 190 degrees. clap-and-flings at dorsal and ventral stroke reversals were implemented to enhance vertical force. in the absence of a control surface at the tail, adjustment of the location of the trailing edges at the wing roots to modulate the rotational angle of the wings was used to generate control moments for the attitude control. measurements by a 6-axis load cell showed that the control mechanism produced reasonable pitch, roll and yaw moments according to the corresponding control inputs. the control mechanism was integrated with three sub-micro servos to realize the pitch, roll and yaw controls. a simple pd feedback controller was implemented for flight stability with an onboard microcontroller and a gyroscope that sensed the pitch, roll and yaw rates. several flight tests demonstrated that the tailless kubeetle could successfully perform a vertical climb, then hover and loiter within a 0.3 m ground radius with small variations in pitch and roll body angles.
electric_motor	single-phase induction motors are used in the industry commonly. induction motors are not expensive, so it is a reason to use them. diagnostics of faults is very important. it prevents financial loss and unplanned downtimes causes by faults. in this paper the authors described fault diagnostic techniques of the single-phase induction motor. presented techniques were based on the analysis of thermal images of electric motor. the authors measured and analysed 3 states of the single-phase induction motor. in this paper an original method of the feature extraction of thermal images called moasos (method of area selection of states) was presented. the proposed method - moasos and an image histogram were used to form feature vectors. classification of the obtained vectors was performed by nn (nearest neighbour classifier) and gaussian mixture models (gmm). the described fault diagnostic techniques are useful for reliability of the single-phase induction motors and other rotating electrical machines such as: three-phase induction motors, synchronous motors, dc motors. (c) 2016 elsevier ltd. all rights reserved.
electrical_network	this work presents a new control method to track the maximum power point of a grid-connected photovoltaic (pv) system. a backstepping controller is designed to be applied to a buck-boost dc-dc converter in order to achieve an optimal pv array output voltage. this nonlinear control is based on lyapunov functions assuring the local stability of the system. control reference voltages are initially estimated by a regression plane, avoiding local maximum and adjusted with a modified perturb and observe method (p&o). thus, the maximum power extraction of the generating system is guaranteed. finally, a dc-ac converter is controlled to supply ac current in the point of common coupling (pcc) of the electrical network. the performance of the developed system has been analyzed by means a simulation platform in matlab/simulink helped by sympowersystem blockset. results testify the validity of the designed control method.
electrical_circuits	the main objective of this paper is to present an academic example of a pd controller applied to teach position control design of a dc-motor to automatically adjust a potentiometer. this adjustment is focused on to solve the maximum power transfer objective in a linear electrical circuit. this design involves the use of the extremum seeking algorithm. to support our proposal, numerical simulations and mathematical modelling of the main problem statement are programmed. (c) 2016, ifac (international federation of automatic control) hosting by elsevier ltd. all rights reserved.
analog_signal_processing	a cmos current-mode analog multiplier/divider circuit is presented. it is suited to standard cmos fabrication and can be successfully employed in a wide range of analog signal processing applications. measurement results for a 0.5 mu m cmos test chip prototype verify the approach employed. the circuit consumes 120 mu w using a single supply voltage of 1.5 v and requires a silicon area of 150 x 140 mu m.
cryptography	while performing cryptanalysis, it is of interest to approximate a boolean function in n variables f : f-2(n) ->f-2 by affine functions. usually, it is assumed that all the input vectors to a boolean function are equiprobable while mounting affine approximation attack or fast correlation attacks. in this paper we consider a more general case when each component of the input vector to f is independent and identically distributed bernoulli variates with the parameter p. since our scope is within the area of cryptography, we initiate an analysis of cryptographic boolean functions under the previous considerations and derive expression of the analogue of walsh-hadamard transform and nonlinearity in the case under consideration. we observe that if we allow p to take up complex values then a framework involving quantum boolean functions can be introduced, which provides a connection between walsh-hadamard transform, nega-hadamard transform and boolean functions with biased inputs.
control_engineering	the implementation of anticipating driving styles in adaptive cruise control systems promises to considerably reduce fuel consumption of vehicles. as drivers have to accept the optimised driving styles of such systems, which implement longitudinally automated driving, the optimisation results should not deviate strongly from the average driving behaviour. this work presents an approach to the optimisation of the vehicle 's longitudinal dynamics, which is based on a predicted average driving profile. the proposed approach ensures that the optimisation results meet the expectations of drivers by directly accounting for driver 's preferences on weighting up travel time against fuel consumption relative to the average driving profile. based on human decision finding, rational and intuitive planning decisions are modelled in a cost function and represent optimisation constraints. the approach generally includes information from vehicle-to-vehicle and vehicle-to-infrastructure communication (v2x), which is an extension to the state-of-the-art. this study describes the optimisation approach and presents a method to determine suitable optimisation parameters in order to consider driver 's preferences. the optimisation approach is applied in a simulated test drive and improvements in fuel economy are analysed. finally, the authors sketch a reference system architecture to prove the feasibility of the presented approach.
image_processing	three-dimensional (3d) vision based scanning for metrology and inspection applications is an area that has attracted increasing interest in the industry. this interest is driven by the recent advances in 3d technologies, which enable high precision measurements at an affordable cost. 3d vision allows for the modelling and inspection of the visible surface of objects. when it is necessary to detect subsurface defects, active infrared (ir) thermography is one of the most commonly used tools today for the non-destructive testing and evaluation (ndt&e) of materials. fusion of these two modalities allows the simultaneous detection of surface and subsurface defects and the visualisation of these defects overlaid on the 3d model of the scanned and modelled parts or their 3d computer-aided design (cad). in this work, we present a framework for automatically fusing 3d data (scanned or cad) with the infrared thermal images for an ndt&e process in 3d space. the captured 3d images and their thermal infrared counterparts are aligned and fused using automatically detected features. this fusion is undergone on 3d space, thus allowing 3d visualisation of subsurface defects on a 3d model (or cad). additionally, the defects are extracted using image processing techniques and overlaid over their virtual position in 3d space. their positioning at a certain distance from the part 's 3d surface is proportional to the computed depth using phase image analysis in the fourier domain. this depth represents the real position of the detected subsurface defect and is extracted using thermograms (temporal sequence of thermal images). the results obtained are promising and show how this new technology can be used efficiently in a combined ndt&e-metrology analysis of manufactured parts, in areas such as aerospace and automotive, among others.
electricity	this paper analyzes the impacts of flexible demands on day-ahead market outcomes in a system with significant wind power production. we use a two-stage stochastic market-clearing model, where the first stage represents the day-ahead market and the second stage represents the real-time operation. on one hand, flexibility of demands is beneficial to the system as a whole since such flexibility reduces the operation cost, but on the other hand, shifts in demands from peak periods to off-peak periods may influence prices in such a way that demands may not be willing to provide flexibility. specifically, we investigate the impacts of different degree of demand flexibility on day-ahead prices. a number of scenarios modeling the uncertainty associated with wind production at the operation stage, and nonconvexities due to start-up costs of generators and their minimum power outputs are taken into account.
electric_motor	in recent years, measurements of total electron content (tec) have gained importance with increasing demand for the gps-based navigation applications in trans-ionospheric communications. to study the variation in ionospheric tec, we used the data obtained from gps ionospheric scintillation and tec monitoring (gistm) system which is in operation at svnit, surat, india (21.16 degrees n, 72.78 degrees e) located at the northern crest of equatorial anomaly region. the data collected (for the low sunspot activity period from august 2008-december 2009) were used to study the diurnal, monthly, seasonal semi-annual and annual variations of tec at surat. it was observed that the diurnal variation at the region reaches its maximum value between 13:00 and 16:00 ist. the monthly average diurnal variations showed that the tec maximizes during the equinox months followed by the winter months, and are lowest during the summer months. the ionospheric range delay to tec for the primary gps signal is 0.162 m per tecu. the diurnal variation in tec shows a minimum to maximum variation of about 5 to 50 tecu (in current low sunspot activity periods). these tec values correspond to range delay variations of about 1 to 9 m at surat. these variations in the range delay will certainly increase in high sunspot activity periods. detected tec variations are also closely related to space weather characterizing quantities such as solar wind and geomagnetic activity indices.
computer_programming	we extended the current density convolution finite-difference time-domain (jec-fdtd) method to plasma photonic crystals using the crank-nicolson -difference scheme and derived the one-dimensional jec-crank-nicolson (cn)-fdtd iterative equation of plasma photonic crystals. the method eliminated the courant-friedrich-levy (cfl) stability constraint and became completely unconditional stable form. the incomplete cholesky conjugate gradient (iccg) algorithm is proposed to solve the equation with a large sparse matrix in the cn-fdtd method as the iccg method improves the speed of convergence, enhances stability, and reduces memory consumption. the jec-cn-fdtd method is applied to study the characteristics of time domain and frequency domain in the plasma photonic crystal objects. the high accuracy and efficiency of the jec-cn-fdtd method are confirmed by computing the characteristic parameters of plasma photonic crystals under different conditions such as the electric field distribution of electromagnetic wave, reflection coefficients, and transmission coefficients. simulation study showed that the algorithm performed stably and could reduce memory consumption and facilitate computer programming.
algorithm_design	to improve the energy conversion ability and well utilize renewable resources, j. rifkin first put forward the concept of internet of energy ioe). although a peer-to-peer energy sharing mechanism is achieved through bi-directional energy transportation, the approach to solving cooperative energy transportation and storage still needs improving. traditionally, the redundant energy will be wasted if it cannot be consumed by power load. in fact, the redundant energy can be stored to supply power loads in the future. for this end, we investigate cooperative energy transportation and storage for ioes in terms of problem analysis, algorithm design, and platform development. after demonstrating the feasibility condition and proving the np-hard of our problem, we derive the optimal solution by the reduction from a classic knapsack problem. we also design novel heuristics followed by different energy storage strategies. in addition, based on software-defined networking (sdn), a complementary platform is developed to make an effective decision for cooperative energy transportation and storage using heuristics above. both simulation and experimental results demonstrate the effectiveness of our solutions.
network_security	with continuous development of science and technology, actual data integration and operating path also change greatly. to better improve transmission accuracy of overall data information, and guarantee optimal establishment of computer network security system, accuracy of overall system can improve fundamentally and more efficient computer security treatment measures can be established only when efficient network model operates. this paper simply analyzes the connotation of computer network security risk assessment model, intensively interprets the principle of fuzzy theory and composition of neural network model and finally discusses neural network model of fuzzy theory and fusion system of computer network security. this paper aims to verify system security performance through effective data analysis.
analog_signal_processing	this paper presents a full and partial load exergy analysis of a hybrid sofc-gt power plant. the plant basically consists of: an air compressor, a fuel compressor, several heat exchangers, a radial gas turbine, mixers, a catalytic burner, an internal reforming tubular solid oxide fuel cell stack, bypass valves, an electrical generator and an inverter. the model is accurately described. special attention is paid at the calculation of sofc overpotentials. maps are introduced, and properly scaled, in order to evaluate the partial load performance of turbomachineries. the plant is simulated at full-load and part-load operation, showing energy and exergy flows trough all its components and thermodynamic properties at each key-point. at full-load operation a maximum value of 65.4% of electrical efficiency is achieved. three different part-load strategies are introduced. the off-design operation is achieved handling the following parameters: air mass flow rate, fuel mass flow rate, combustor bypass, gas turbine bypass, avoiding the use of a variable speed control system. results showed that the most efficient part-load strategy corresponded to a constant value of the fuel to air ratio. on the other hand, a lower value of net electrical power (34% of nominal load) could be achieved reducing fuel flow rate, at constant air flow rate. this strategy produces an electrical efficiency drop that becomes 45%. (c) 2005 elsevier b.v. all rights reserved.
electric_motor	compared with the position sensor control, sensorless control avoids a lot of defects caused by the position sensor, at the same time makes the system more stability and stronger anti-interference performance, it has more advantages and meets control field 's requirements better in the future, it has gradually become a hotspot in the brushless dc motor control field. the rotor position detection has been a very critical research in the brush less dc motor sensorless control. in this paper, a new type of rotor position detection method is proposed, which is based on the principle and mathematical model of a brush less dc motor after the analysis of advantages and disadvantages of the back emf principle of zero-detection and the method of the back-emf superposition, which means a combination of the method of the two rotor position detection, as above. this method neither need a delay of 30 degrees nor require a depth filter, the hardware circuit is also simple and there is no need to compensate for the phase shift. then, the frequency of the detection signal is three times of fundamental wave frequency in this method and the detection signal is easier to detect when the motor running at low speed, which expand the applicable speed range of the electric motor. this paper analyzes the principle and commutation logic of the rotor position detection method, it come up with a conclusion that the stagnation point of the three bemf superposition derivative is the commutation points of the stator windings, and it uses the method of the back-emf zero crossings to determine the current conduction state. the simulation model of the brushless dc motor 's control system is established in matlab /simulink, it uses speed and current double close loop pi control. the result shows that the method is correct and feasible, it can get the right rotor position signal and control motor commutation correctly, the method can achieve the control of brush less dc motor without position sensor, and it can provide a reference for further research.
electric_motor	in traction application, the electric motor design methodology is not trivial. this paper presents a design approach using rated point. based on a 2d finite element model, design optimization of a double-sided linear induction motor is achieved using an efficient global optimization algorithm.
cryptography	the key escrow problem and high computational cost are the two major problems that hinder the wider adoption of hierarchical identity-based signature (hibs) scheme. hibs schemes with either escrow-free (ef) or online/offline (oo) model have been proved secure in our previous work. however, there is no much ef or oo scheme that has been evaluated experimentally. in this letter, several ef/oo hibs schemes are considered. we study the algorithmic complexity of the schemes both theoretically and experimentally. scheme performance and practicability of ef and oo models are discussed.
machine_learning	feature selection problem in data mining is addressed here by proposing a bi-objective genetic algorithm based feature selection method. boundary region analysis of rough set theory and multivariate mutual information of information theory are used as two objective functions in the proposed work, to select only precise and informative data from the data set. data set is sampled with replacement strategy and the method is applied to determine non-dominated feature subsets from each sampled data set. finally, ensemble of such bi-objective genetic algorithm based feature selectors is developed with the help of parallel implementations to produce much generalized feature subset. in fact, individual feature selector outputs are aggregated using a novel dominance based principle to produce final feature subset. proposed work is validated using repository especially for feature selection datasets as well as on uci machine learning repository datasets and the experimental results are compared with related state of art feature selection methods to show effectiveness of the proposed ensemble feature selection method. (c) 2017 elsevier b.v. all rights reserved.
computer_graphics	this paper presents a virtual try-on system to correctly visualize 3d objects (e.g., glasses) in the face of a given user. by capturing the image and depth information of a user through a low-cost rgb-d camera, we apply a face tracking technique to detect specific landmarks in the facial image. these landmarks and the point cloud reconstructed from the depth information are combined to optimize a 3d facial morphable model that fits as good as possible to the user 's head and face. at the end, we deform the chosen 3d objects from its rest shape to a deformed shape matching the specific facial shape of the user. the last step projects and renders the 3d object into the original image, with enhanced precision and in proper scale, showing the selected object in the user 's face. we validate the performance of our system on eight different subjects (four male and four female) and show results numerically and visually. our results demonstrate that, by fitting a facial model to the user 's face, the rendered virtual 3d objects look more realistic.
microcontroller	most automatic steering systems for large tractors are designed with hydraulic systems that run on either constant flow or constant pressure. such designs are limited in adaptability and applicability. moreover, their control valves can unload in the neutral position and eventually lead to serious hydraulic leakage over long operation periods. in response to the problems noted above, a multifunctional automatic hydraulic steering circuit is presented. the system design is composed of a 5-way-3-position proportional directional valve, two pilot-controlled check valves, a pressure-compensated directional valve, a pressure-compensated flow regulator valve, a load shuttle valve, and a check valve, among other components. it is adaptable to most open-center systems with constant flow supply and closed-center systems with load feedback. the design maintains the lowest pressure under load feedback and stays at the neutral position during unloading, thus meeting the requirements for steering. the steering controller is based on proportional-integral-derivative (pid) running on a 51-microcontroller-unit master control chip. an experimental platform is developed to establish the basic characteristics of the system subject to stepwise inputs and sinusoidal tracking. test results show that the system design demonstrates excellent control accuracy, fast response, and negligible leak during long operation periods.
computer_vision	the estimation of nutrient content of plants is considerably important in agricultural practices, especially in enabling the application of precision farming. a plethora of methods has been used to estimate nitrogen amount in plants, including the utilization of computer vision. however, most of the image-based nitrogen estimation methods are conducted in controlled environments. these methods are not so practical, time consuming, and require many equipment. therefore, there is a crucial need to develop a method to estimate nitrogen content of plants based on leaves images captured on field. it is a very challenging task since the intensity of sunlight is always changing and this leads to an inconsistent image capturing problem. in this paper, we develop a low-cost, simple, and accurate approach image-based nitrogen amount estimation. plant images are captured directly under sunlight by using a conventional digital camera and are subject to a variation in lighting conditions. we propose a color constancy method using neural networks fusion and a genetic algorithm to normalize various plant images due to different sunlight intensities. a macbeth color checker is utilized as the reference to normalize the color of the images. we also develop a combination of neural networks using a committee machine to estimate the nitrogen content in wheat leaves. twelve statistical rgb color features are used as the input parameters for the nutrient estimation. the obtained result shows considerable better performance than the conventional gray-world and scale-by-max approaches, as well as linear model and single neural network methods. finally, we show that our nutrient estimation approach is superior to the commonly used soil-plant analysis development meter based prediction.
digital_control	an indirect hysteresis voltage digital control is proposed for single-phase half-bridge inverters. because of the slow response to the switching modulation, it is difficult to control the voltage by hysteresis method directly. in this study, the output voltage is controlled indirectly by using the adaptive band hysteresis current control, which is fast response, robustness, and independent on the system parameters. the reference current is computed based on the desired reference output voltage, and the hysteresis band is controlled to maintain the switching frequency at a constant value. simulation results show good performances of the proposed control method in both cases: ac and dc reference output voltage.
computer_programming	terrestrial laser scanners are frequently used in most of measurement application, particularly in documentation and restoration studies of indoor historical structures, and in acquiring facade reliefs. when compared to a photogrammetric method, terrestrial laser scanners have the ability to give three dimensional point cloud data directly in a fast and detailed way. high data density of point cloud data is a challenging factor in texture-map operations during documentation and restoration of historical artifacts with more indoor spaces. when coordinate information for terrestrial laser scanner point cloud data is documented, it is seen that there is no regular order and classification for the data. the aim of this study is to suggest the mathematical filtering algorithm for segmentation work towards separation of planar surfaces which have different depths and parallel to each other and which can be frequently encountered in the indoor spaces from the data of terrestrial laser scanner. filtering function for segmentation used, is based on the distance of a point to the plane. this algorithm has been chosen for the advantage of the rapid and easy results for extracting 3d coordinate data in texture mapping process. the matlab interface has been developed for using this method and analyzing the results for application which is detected how many different surfaces exist according to the statistical deviation amount. in the application, test data with 21932 points was segmented by separating it into 16 points in total with four different planes and four corner points per plane. surfaces with four different depths were obtained as the result of the research. each of them included four points. these segmented surfaces consisting of four points will facilitate integrated data production by integrating vectorial terrestrial laser scanner data into raster camera data, without the need to conventional measurements that accelerate particularly documentation and modeling in the fields of historical indoor areas. (c) 2014 elsevier ltd. all rights reserved.
state_space_representation	this article addresses the problem of active structural vibration control by means of embedded piezoelectric actuators. the topology optimization method using the solid isotropic material with penalization (simp) approach is employed in this work to find the optimum design of actuators taken into account the control spillover effects. a coupled finite element model of the structure is derived assuming a two-phase material and this structural model is written into the state-space representation. the proposed optimization formulation aims to determine the distribution of piezoelectric material which maximizes the controllability for a given vibration mode. the undesirable effects of the feedback control on the residual modes are limited by including a spillover constraint term containing the residual controllability gramian eigenvalues. the optimization of the shape and placement of the conventionally embedded piezoelectric actuators are performed using a sequential linear programming (slp) algorithm. numerical examples are presented considering the control of the bending vibration modes for a cantilever and a fixed beam. a linear-quadratic regulator (lqr) is synthesized for each case of controlled structure in order to compare the influence of the additional constraint. (c) 2016 elsevier ltd. all rights reserved.
electrical_circuits	it was investigated the physical processes in the molecules, which have properties required in case of using as molecular switches, transistors, or other electronic elements of future computers. studies show that in the molecules of biphenyl substituents the angle between the planes of the phenyl rings depends on the magnitude of the applied external electric field. so, the ratio of squares of cosines of the angles between the phenyl groups in the field 0.01 a.u. and without field reaches 18. it significantly changes the ability of electrons to move along the long axis of the molecule. by varying the nature of the substituents, we can obtain the molecule characteristics that make these molecules promising for future using. this effect provides the use of biphenyl substitutes as transistors in electrical circuits constructed on separate molecules.
control_engineering	pid controller structure is regarded as a standard in the control-engineering community and is supported by a vast range of automation hardware. therefore, pid controllers are widely used in industrial practice. however, the problem of tuning the controller parameters has to be tackled by the control engineer and this is often not dealt with in an optimal way, resulting in poor control performance and even compromised safety. the paper proposes a framework, which involves using an interval model for describing the uncertain or variable dynamics of the process. the framework employs a particle swarm optimization algorithm for obtaining the best performing pid controller with regard to several possible criteria, but at the same time taking into account the complementary sensitivity function constraints, which ensure robustness within the bounds of the uncertain parameters' intervals. hence, the presented approach enables a simple, computationally tractable and efficient constrained optimization solution for tuning the parameters of the controller, while considering the eventual gain, pole, zero and time-delay uncertainties defined using an interval model of the controlled process. the results provide good control performance while assuring stability within the prescribed uncertainty constraints. furthermore, the controller performance is adequate only if the relative system perturbations are considered, as proposed in the paper. the proposed approach has been tested on various examples. the results suggest that it is a useful framework for obtaining adequate controller parameters, which ensure robust stability and favorable control performance of the closed-loop, even when considerable process uncertainties are expected. (c) 2015 elsevier b.v. all rights reserved.
cryptography	the notion internet of things (iot) means all things in the global network can be interconnected and accessed. wireless sensor network (wsn) is one of the most important applications of the notion and is widely used in nearly all scopes. in 2014, hsieh et al. presented an improved authentication scheme for wsns. but it has several weaknesses, including no session key, lack of mutual authentication and under the insider attack, the off-line guessing attack, the user forgery attack and the sensor capture attack. to avoid the weaknesses, we present a new authentication scheme which is also for wsns. then we employ the random oracle model to show the formal proof, and use the protocol analyzing tool proverif to list the formal verification process. compared with some recent schemes for wsns via the aspects of security properties, the proposed scheme overcomes the common problems and fits for the security properties of iot.
signal-flow_graph	in this paper, a general synthesis procedure of using the signal flow graph technique to realize an nth-order allpole lowpass current transfer function with current follower transconductance amplifiers (cftas) has been presented. the proposed circuit, in general, contains at most n cftas and n grounded capacitors, without needing external passive resistors. it has been also shown that the design procedure given here is simple structure, convenient tunability, and suitable for integration. furthermore, the circuit has low sensitivity. pspice simulation results which agree very well with the theoretical analysis are also included.
digital_control	lcl filters have been widely used for grid-connected inverters. however, the problem that how time delay affects the stability of digitally controlled grid-connected inverters with lcl filters has not been fully studied. in this paper, a systematic study is carried out on the relationship between the time delay and stability of single-loop controlled grid-connected inverters that employ inverter current feedback (icf) or grid current feedback (gcf). the ranges of time delay for system stability are analyzed and deduced in the continuous s-domain and discrete z-domain. it is shown that in the optimal range, the existence of time delay weakens the stability of the icf loop, whereas a proper time delay is required for the gcf loop. the present work explains, for the first time, why different conclusions on the stability of icf loop and gcf loop have been drawn in previous studies. to improve system stability, a linear predictor-based time delay reduction method is proposed for icf, while a time delay addition method is used for gcf. a controller design method is then presented that guarantees adequate stability margins. the delay-dependent stability study is verified by simulation and experiment.
electric_motor	rotational speed measurement is a key issue in most industries, either for process control, characterization or fault diagnosis. in electric motor driven systems it can be used, for example, to estimate the motor load or pulley-belt transmission slip. encoders and resolvers are typically used for continuous speed monitoring, requiring mechanical coupling with the rotating shaft/part. if the speed is to be measured at a given instant or during a few moments, noninvasive contactless optical tachometers can be used, using optical reflection or stroboscopic principles. in most cases, stroboscopic tachometers require no reflective elements/strips in the rotating part. however, if the user wants to continuously measure the speed of a given rotating part during the audit/characterization period, with real-time data logging and without sticking reflective strips or introducing shaft-coupled encoders/resolvers, there is no low-cost commercial solution to perform such task. for example, if the user 's aim is to continuously estimate the load variation of an induction motor over a day or week, on the basis of the slip/speed value, it is not possible with conventional commercial low-cost contactless equipment, unless the user uses expensive online-operation equipment estimating the speed by means of input voltage/current. moreover, in some rotating systems/parts not directly driven by an electric motor, the online equipment cannot be used and it is not practical, and in some cases even impossible, to couple an encoder/resolver or stick some reflective strips. in this paper, an innovative nonintrusive low-cost webcam-based tachometer is proposed, developed and experimentally tested. it can be used to easily estimate and record the speed over time in, for example, electrical motors, pulleys, shafts and wind turbines.
symbolic_computation	the multiple exp-function method is a new approach to obtain multiple-wave solutions of nonlinear partial differential equations (nlpdes). by this method, one can obtain multi-soliton solutions of nlpdes. hence, in this paper, using symbolic computation, we apply the multiple exp-function method to construct the exact multiple-wave solutions of a (3 + 1)-dimensional soliton equation. based on this application, we obtain mobile single-wave, double-wave and multi-wave solutions for this equation. in addition, we employ the straightforward and algebraic hirota bilinearization method to construct the multi-soliton solutions of nlpdes, and we reveal the remarkable property of soliton-soliton collision through this approach. further, we investigate the one- and two-soliton solutions of a (3 + 1)-dimensional soliton equation using the hirota 's method. we explore the particle-like behavior or elastic interaction of solitons, which has potential application in optical communication systems and switching devices.
bioinformatics	background: aberrant activation of fibroblast growth factor receptor 3 (fgfr3) is frequently observed in bladder cancer, but how it involved in carcinogenesis is not well understood. the current study was aimed to investigate the underlying mechanism on the progression of bladder cancer. methods: the gse41035 dataset downloaded from gene expression omnibus was used to identify the differentially expressed genes (degs) between bladder cancer cell line rt112 with or without depletion of fgfr3, and gene ontology enrichment analysis was performed. then, fgfr3-centered protein-protein interaction (ppi) and regulatory networks were constructed. combined with the data retrieved from gse31684, prognostic makers for bladder cancer were predicted. results: we identified a total of 2855 degs, and most of them were associated with blood vessel morphogenesis and cell division. in addition, kiaa1377, pola2, fgfr3, and epha4 were the hub genes with high degree in the fgfr3-centered ppi network. besides, 17 micrornas (mirnas) and 6 transcriptional factors (tfs) were predicted to be the regulators of the nodes in ppi network. moreover, cstf2, pola1, hmox2, and efnb2 may be associated with the prognosis of bladder cancer patient. conclusions: the current study may provide some insights into the molecular mechanism of fgfr3 as a mediator in bladder cancer.
electricity	one of the possible research lines for improving the concentrated solar power (csp) technology is the enhancement of the thermophysical properties of the heat transfer fluids (htf) used. this enhancement leads to reduce costs for producing electricity using this technology. so, this study presents the preparation of nanofluids in which ag nanoparticles were added to a base fluid composed of a eutectic mixture of diphenyl oxide and biphenyl. the base fluid is a heat transfer fluid commonly used in concentrating solar power plants. the nanofluids were shown to have improved thermal properties, the heat transfer coefficient increasing by up to 6% compared with the base fluid. thus, their use could lead to enhancements in the overall efficiency of csp plants. accordingly, nanofluids were prepared with varying nanoparticle concentrations and their properties were characterized, including their physical and chemical stability, viscosity, isobaric specific heat and thermal conductivity. in addition, molecular dynamic calculations were performed to reach a better understanding of the nanofluid system at a molecular level. the isobaric specific heat and thermal conductivity values followed the same experimental tendency. an analysis of the radial distribution functions (rdfs) and spatial distribution functions (sdfs) shows that there is a first layer of base fluid molecules around the metal in which the oxygen atoms play an important role. this first layer encourages the directionality of the movement in the heart of the nanofluid, which leads to enhanced thermal properties. (c) 2017 elsevier ltd. all rights reserved.
system_identification	in this study, the author uses parametric models to predict the track geometry-induced dynamic behavior of a vehicle. the characteristics of vehicle dynamics in these models are directly identified through the spatial as opposed to the frequency domain. one of the former 's merits is that we can identify the characteristics of vehicle dynamics with fewer observed points than when we use spectral analysis, making it easier to obtain fewer data set for identification. another is that we can determine the parameters to represent dynamic behavior of a vehicle using statistical criteria. with these models, we can predict vertical acceleration of a vehicle and its wheel load as well as estimate track conditions by taking into account both ride comfort and operating safety.
system_identification	a novel variational bayesian mixture of experts model for robust regression of bifurcating and piece-wise continuous processes is introduced. the mixture of experts model is a powerful model which probabilistically splits the input space allowing different models to operate in the separate regions. however, current methods have no fail-safe against outliers. in this paper, a robust mixture of experts model is proposed which consists of student-t mixture models at the gates and student-t distributed experts, trained via bayesian inference. the student-t distribution has heavier tails than the gaussian distribution, and so it is more robust to outliers, noise and non normality in the data. using both simulated data and real data obtained from the z24 bridge this robust mixture of experts performs better than its gaussian counterpart when outliers are present. in particular, it provides robustness to outliers in two forms: unbiased parameter regression models, and robustness to overfitting/complex models.
computer_programming	in today 's industrial environment, it is common to see the use of pipes or vessels to transfer mixtures of materials or products along them. however, the measurement of the amount delivered can only be done in one way: isolate the components first; then meter, weigh or measure the volume for each individual component. this measuring procedure often stalls the production rate. this work implements a noninvasive, real time monitoring system to measure the flow concentration and velocity distributions of a two-phase (liquid-gas) flow. the system uses the combination of a specially designed twin-plane segmented electrical capacitance tomography (ect) sensor with 16 portable electrodes and the cross-correlation method as the velocity measurement technique. the measured values or data from the ect sensor will be manipulated to reconstruct the cross sectional image of the pipeline by computer programming. these images are then cross-correlated to obtain the velocity profile of the multiphase flow. the visualization results deliver information regarding the flow regime, superficial velocity and concentration distribution in two-phase flow rate measurement system. the information obtained is able to improve: the process equipment 's design, verification of existing computational modeling and simulation techniques. this technique has the possibility to promote an excellent opportunity to build methods for measuring the velocity field in multiphase flow by using noninvasive technique and cross-correlating.
analog_signal_processing	this paper presents design of an active building block for analog signal processing, named as current-controlled differential difference current conveyor (ccddcc). its parasitic resistances at x-terminal can be controlled by an input bias current. the proposed element is realized in a cmos technology. it displays usability of the new active element, where the maximum bandwidth of voltage and current followers are around 1ghz, 100mhz, respectively. the thd is obtained around 0.8% within 0.6vpp input range. the power dissipation of a ccddcc at 10 mu a biased current is obtained around 1.35mw with +/- 1.25v power supplies. in addition, current-mode multiple-input single output (miso) second-order universal analog filter is included as the applications. the filter offers the realization of simultaneous five type standard filter responses. the quality factor and the frequency response parameters can be independently tuned. spice simulation results of proposed ccddcc and its applications are also presented.
signal-flow_graph	a novel approach using microresonating system with low power consumption is proposed for determining young 's modulus of mirco and nano-sized waveguide material. based on the mason rule with signal flow graph (sfg) method in the z-domain, the optical transfer function is derived for resonating layout consists of two single microring resonators which are indirectly coupled to an add-drop micro resonator. a mathematical function is determined for critical coupling coefficient and the optimum optical transmission of proposed system. for the resonant mode numbers of 5;3;3, the free spectral range (fsr) is extended to 182 nm with the out of band rejection ratio(obrr) of 50 db and the q factor is 8593. the young 's modulus is determined based on a change in the sensing ring radius due to the applied external force on the waveguide that causes the wavelength shift in resonant peaks. the young 's modulus for the lateral surface of the soi waveguide with 250 nm height and 1.5 mu m radius is determined to be 147.72 gpa and for the upper surface of the soi waveguide with 440 nm average width and 1.5 mu m radius is determined to be 83.93 gpa. the proposed resonating system is a potential candidate for measuring young 's modulus of materials in mirco and nano size with high resolution and has the advantages of the low power consumption due to the low intensity source.
analog_signal_processing	this paper 's domain is the application of well-known modern applied mathematical methods in a control structure of oil industry. electrical submersible pumps (esp) telemetry system allows for the obtaining of information in the neighborhood of different heavy electromagnetic noises. the telemetry system needs to receive accurate information on the pump unit 's intake pressure, temperature and most importantly for the submersible electric motor, the stator cooling oil insulation resistance, for the successful exploitation of the esp. but increasing disturbance levels with the corrupted analog telemetry signal are resulting in increasing noise levels; however, often it is still audible or the control is still reliable. though, beyond a certain disturbance level, the so-called digital cliff, the digital telemetry signal and control may stop abruptly (fig. 1). in this paper, an analog signal processing implementation was researched for the detection of the most efficient adaptive noise-cancelling filters among dozens of recognized ones for oil industry esp telemetry systems of under severely noisy conditions. from ten applied adaptive filter algorithms, only three have shown successfully good results in the early prediction of the esp electric motor real insulation disruption.
microcontroller	sea-level rise is expected to cause saltwater intrusion into tidal freshwater wetlands. the resulting changes in the soil environment would likely cause shifts in plant and microbial communities and alter ecosystem functions. to simulate saltwater intrusion, we constructed a solar-powered automated irrigation system. the system consisted of holding tanks that were filled with freshwater or artificial brackish water during high tide. during low tide, the water was gravity-fed through solenoid valves and metered out to each plot. this system was controlled by an open-source microcontroller platform and built from off-the-shelf electronics at a cost of $1800. porewater salinity in near-surface soils of the plots receiving brackish water was increased from freshwater to oligohaline levels within one month of operation and was maintained throughout the first summer of operation. this porewater manipulation led to changes in the plant community and in exchanges of carbon dioxide and methane between the marsh and atmosphere. the system has proven to be a reliable way of manipulating wetland salinity for studying changes in the physicochemical environment. with modifications, it could be used to manipulate nutrient loads, hydrology, and sediment supply in other wetland systems.
computer_programming	due to that conventional teaching method mainly focus on the impartment and the memorization of knowledge points, the initiative of student cannot be activated and there is still substantial room for improving the professional abilities, including independent learning ability and problem solving capability, hands-on practical ability, etc. aiming at improving the teaching results of computer programming courses, a practical mode of classroom instruction with diverse collaboration is proposed in this paper. in this teaching mode, the theoretical teaching and learning is closely integrated with professional practice, opening lab problems and scientific research project. the course assessment emphasizes the project evaluation instead of paper test for proper evaluation of actual practice level of students.
state_space_representation	long horizon lengths in moving horizon estimation are desirable to reach the performance limits of the full information estimator. however, the conventional mhe technique suffers from a number of deficiencies in this respect. first, the problem complexity scales at least linearly with the horizon length selected, which restrains from selecting long horizons if computational limitations are present. second, there is no monitoring of constraint activity/inactivity which results in conducting redundant constrained minimizations even when no constraints are active. in this study we develop a multiple-window moving horizon estimation strategy (mw-mhe) that exploits constraint inactivity to reduce the problem size in long horizon estimation problems. the arrival cost is approximated using the unconstrained full information estimator arrival cost to guarantee stability of the technique. a new horizon length selection criterion is developed based on the sensitivity between remote states in time. the development will be in terms of general causal descriptor systems, which includes the standard state space representation as a special case. the potential of the new estimation algorithm will be demonstrated with an example showing a significant reduction in both computation time and numerical errors compared to conventional mhe. (c) 2014 elsevier ltd. all rights reserved.
control_engineering	on this work, a device was made in order to help the visualization by the student of a pid temperature control and thus fix the concepts learned in the classroom. this device was built primarily with a pic18f4550 microcontroller, a mini cooler from a pc, a heat resistor, lm35 temperature sensors, liquid crystal display, usb connector, transistors, leds, potentiometers, resistors and capacitors. the usb connection is responsible for recording the microcontroller firmware (bootloader mode), for interfacing with a supervisory software, and to supply the system. the heat resistor provides heat to the system. on the other hand, the cooler has the function of removing heat from the system. the liquid crystal display helps the student to check the temperature, the constants of the controller (kp, ki and kd) and the set point temperature or the cooler voltage. the potentiometers provide the option to run the system in open loop, that is, they serve to make the control of the heat supplied by the heat resistor and the cooler voltage manually. both the heat resistor and the cooler are controlled via transistors switched by pwms (pulse wide modulation). a computer program was developed in c sharp language to display the temperature over time measured by the sensors. the program also is used to adjust the constants kp, ki and kd of the controller and the temperature set point. the microcontroller firmware allows the system to operate in both open and closed loop modes. this work allows the student to learn in practice the control actions when the controller parameters are changed, contributing to improve the acknowledgment of control engineering.
electrical_network	this paper presents an algorithm for economic optimization of a laboratory microgrid. the microgrid incorporates a hybrid storage system composed of a battery bank and a hydrogen storage and it has a connection with the external electrical network and a charging station for electric vehicles. to study the impact of use of renewable energy power systems, the microgrid has a programmable power supply that can emulate the dynamic behavior of a wind turbine and/or a photovoltaic field. the system modeling was carried out using the energy hubs methodology. a hierarchical control structure is proposed based on model predictive control and acting in different time scales, where the first level is responsible for maintaining the microgrid stability and the second level has the task of performing the management of electricity purchase and sale to the power grid, maximize the use of renewable energy sources, manage the use of energy storages and perform the charge of the parked vehicles. practical experiments were performed with different weather conditions of solar irradiation and wind. the results show a reliable operation of the proposed control system. (c) 2016 elsevier b.v. all rights reserved.
symbolic_computation	a family of conservative, truly nonlinear, oscillators with integer or non-integer order nonlinearity is considered. these oscillators have only one odd power-form elastic-term and exact expressions for their period and solution were found in terms of gamma functions and a cosine-ateb function, respectively. only for a few values of the order of nonlinearity, is it possible to obtain the periodic solution in terms of more common functions. however, for this family of conservative truly nonlinear oscillators we show in this paper that it is possible to obtain the fourier series expansion of the exact solution, even though this exact solution is unknown. the coefficients of the fourier series expansion of the exact solution are obtained as an integral expression in which a regularized incomplete beta function appears. these coefficients are a function of the order of nonlinearity only and are computed numerically. one application of this technique is to compare the amplitudes for the different harmonics of the solution obtained using approximate methods with the exact ones computed numerically as shown in this paper. as an example, the approximate amplitudes obtained via a modified ritz method are compared with the exact ones computed numerically. (c) 2014 elsevier b.v. all rights reserved.
microcontroller	this article presents a new optical, multi-functional, high-resolution 3-axis sensor which serves to navigate and can, for example, replace standard joysticks in medical devices such as electric wheelchairs, surgical robots or medical diagnosis devices. a light source, e.g., a laser diode, is affixed to a movable axis and projects a random geometric shape on an image sensor (cmos or ccd). the downstream microcontroller 's software identifies the geometric shape 's center, distortion and size, and then calculates x, y, and z coordinates, which can be processed in attached devices. depending on the image sensor in use (e.g., 6.41 megapixels), the 3-axis sensor features a resolution of 1544 digits from right to left and 1038 digits up and down. through interpolation, these values rise by a factor of 100. a unique feature is the exact reproducibility (deflection to coordinates) and its precise ability to return to its neutral position. moreover, optical signal processing provides a high level of protection against electromagnetic and radio frequency interference. the sensor is adaptive and adjustable to fit a user 's range of motion (stroke and force). this recommendation aims to optimize sensor systems such as joysticks in medical devices in terms of safety, ease of use, and adaptability.
pid_controller	this article presents the automatic generation control of an unequal three area thermal system. single stage reheat turbines and generation rate constraints of 3%/min are considered in each control area. controllers such as integral (i), proportional - integral (pi), proportional - integral- derivative (pid), and proportional - integral - derivative plus second order derivative.(pid + dd) are treated as secondary controllers separately. a nature inspired optimization technique called ant lion optimizer (alo) algorithm is used for simultaneous optimization of the controller gains. comparison of dynamic responses of frequencies and tie line powers corresponding to alo optimized i, pi, pid and pid + dd controller reveal the better performance of pid + dd controller in terms of lesser settling time, peak overshoots as well as reduced oscillations. robustness of the optimum gains of best controller obtained at nominal conditions is evaluated using sensitivity analysis. analysis exposed that the optimum pid + dd controller gains obtained at nominal are robust and not necessary to reset again for changes in loading, parameter like inertia constant (h), size and position of disturbance. furthermore, the performance of pid + dd controller is found better as compared to pid controller against random loading pattern condition. (c) 2016 elsevier ltd. all rights reserved.
electricity	countries are implementing policies to develop greener energy markets worldwide. in europe, the ""2030 energy and climate package"" asks for further reductions of green house gases, renewable sources integration, and energy efficiency targets. but the polluting intensity of electricity may be different in average than when considering market inefficiencies, in particular losses, and therefore the implemented policy must take those differences into account. precisely, herein we study the importance in terms of co2 emissions the extra amount of energy necessary to cover losses. with this purpose we use spanish market and system data with hourly frequency from 2011 to 2013. our results show that indeed electricity losses significantly explain co2 emissions, with a higher co2 emissions rate when covering losses than the average rate of the system. additionally, we find that the market closing technologies used to cover losses have a positive and significant impact on co2 emissions: when polluting technologies (coal or combined cycle) close the market, the impact of losses on co2 emissions is high compared to the rest of technologies (combined heat and power, renewables or hydropower). to the light of these results we make some policy recommendations to reduce the impact of losses on co2 emissions.
network_security	wireless sensor networks are installed in hostile areas. the security issues in wireless sensor networks are very important. getting secure links between nodes is a challenging problem in wsns. they are more vulnerable to security attacks than wired networks. in order to protect the sensitive data in wsn can be protected using secret keys to encrypt the exchanged messages between communicating nodes. key management is essential for many security services such as confidentiality and authentication. the symmetric or asymmetric key cryptography or trusted-server schemes are used to solve this problem. asymmetric key cryptography increases network security but it increases computational, memory, and energy overhead. symmetric key cryptography provides less security and it is efficient key management scheme. trusted server schemes use key management server. because there is usually no trusted infrastructure it is not very suitable for sensor networks. in this paper, we have proposed mobile agent (ma) based key distribution (makd). in makd, mobile agents are used for dissemination of public keys and update of shared keys. each sensor node constructs different symmetric keys with its neighbors, and communication security is achieved by data encryption and mutual authentication with these keys. simulation results show that makd is scalable and with less memory overhead.
electrical_circuits	the current state of art in the literature indicates that linear visual receptive fields are gaussian or formed based on gaussian kernels in biological visual systems. in this paper, by employing hypotheses based on the anatomy and physiology of vertebrate biological vision, we propose a neural circuitry possessing gaussian-related visual receptive fields. here, we present a plausible circuitry system matching the characteristic properties of an ideal visual front end of biological visual systems and then present a condition under which this circuit demonstrates a linear behaviour to model the linear receptive fields observed in the biological experimental data. the objective of this study is to understand the hardware circuitry from which various visual receptive fields in biological visual system can be deduced. in our model, a nonlinear neural network communicating with spikes is considered. the condition under which this neural network behaves linearly is discussed. the equivalent linear circuit proposed here employs some anatomical and physiological properties of the early biological visual pathway to derive the visual receptive field profiles for linear cells such as neurons with isotropic separable, non-isotropic separable and non-separable (velocity-adapted) gaussian receptive fields in the lgn and striate cortex. in the model presented here, the theory of transmission lines for linear distributed electrical circuits is employed for two-dimensional transmission grids to model cell connectivities in a neural layer. the model presented here leads to a formulation similar to the gaussian scale-space theory for the transmission of visual signals through various layers of neurons. our model therefore presents a new insight on how the convolution process with gaussian kernels can be implemented in vertebrate visual systems. the comparison of the numerical simulations of our model presented in this paper with the data analysis of receptive field profiles recorded in the biological literature demonstrates a complete agreement between our theoretical model and experimental data. our model is also in good agreement with the numerical results of the gaussian scale-space theory for the visual receptive fields.
electricity	limiting global warming to well below 2 degrees c requires the transformation of the global energy system at a scale unprecedented since the industrial revolution. to meet this 2 degrees c goal, 87% of integrated assessment models opt for using bioenergy with carbon capture and storage (beccs). without beccs, the models predict that the goal will be either unachievable or substantially more costly to meet. while the modeling literature is extensive, studies of how key climate policy actors perceive and prioritize beccs are sparse. this article provides a unique intercontinental mapping of the prioritization of beccs for the long term transition of the electricity supply sector. based on survey responses from 711 un climate change conference delegates, the article reports the low prioritization of beccs relative to alternative technologies, indicating an urgent need for studies of the sociopolitical preconditions for large-scale beccs deployment.
digital_control	the article describes some of the features of the servo amplifier, developed in the nru ""mpei"" for use in multi-axis high-precision materials processing. simplified structure of servo amplifier and some of the key components of servo drive digital control system are presented. two ways of multi-axes control are compared: using the rs-232 interface and digital inputs/outputs, and using the canopen standard based digital can protocol. the benefits of multi-axis control with the canopen protocol are high-speed exchanges, reliability of data transmission, standardization and simple communication topology.
relational_databases	functional dependencies (fds) represent potentially novel and interesting patterns existent in relational databases. the discovery of functional dependencies has a wide range of applications such as database design, knowledge discovery, data quality assessment, etc. there has been growing interest in the problem of functional dependencies discovery in the last ten years. however, existing functional dependencies discovery algorithms are mainly applied to centralized small data. it is far more challenging to discover functional dependencies from big data. in this paper, we propose an efficient functional dependencies discovery algorithm, for mining functional dependencies from distributed big data. we prune candidate fds at each node by local fragmented data and batch verify candidate fds in parallel. load balance is taken into account when discovering functional dependencies. experiments show that the proposed algorithm is effective on real dataset and synthetic dataset.
electricity	energy storage is unique in that it can provide multiple services. this feature raises cost-recovery issues for storage, due to the combination of competitive markets and ratebased cost recovery used in many power systems today. this hybrid regulatory paradigm relies on classifying assets as providing competitively prices or unpriced services and handling cost recovery based on that classification. some recent regulatory precedents suggest that storage developers must choose between classifying their assets as providing competitively priced or unpriced services. in the former case, storage costs must be recovered through the market. if an asset is classified as providing only unpriced services, costs can be recovered through the ratebase. this regulatory design can hamper cost recovery for storage and may lead to inefficient storage investment and use. we propose an alternate solution whereby storage-capacity rights are auctioned to third parties that use their rights for priced or unpriced services. storage-capacity rights disentangle storage cost recovery from the regulatory treatment of its end use. we formulate the storage-capacity auction model and demonstrate how to efficiently price storage-capacity rights. we show that the revenues earned by the storage owner through the auction equals the imputed marginal value of storage capacity, as revealed by the market bids.
computer_programming	since the introduction of spice non-linear controlled voltage and current sources, they have become a central feature in the interactive development of behavioural device models and circuit macromodels. the current generation of spice-based open source general public license circuit simulators, including qucs, ngspice and xyce (c), implements a range of mathematical operators and functions for modelling physical phenomena and system performance. the qucs equation-defined device is an extension of the spice style non-linear b type controlled source which adds dynamic charge properties to behavioural sources, allowing for example, voltage and current dependent capacitance to be easily modelled. following, the standardization of verilog-a, it has become a preferred hardware description language where analogue models are written in a netlist format combined with more general computer programming features for sequencing and controlling model operation. in traditional circuit simulation, the generation of a verilog-a model from a schematic, with embedded non-linear behavioural sources, is not automatic but is normally undertaken manually. this paper introduces a new approach to the generation of verilog-a compact device models from qucs circuit schematics using a purpose built analogue module synthesizer. to illustrate the properties and use of the qucs verilog-a module synthesiser, the text includes a number of semiconductor device modelling examples and in some cases compares their simulation performance with conventional behavioural device models. copyright (c) 2016 john wiley & sons, ltd.
bioinformatics	background: next generation sequencing (ngs) technologies provide exciting possibilities for whole genome sequencing of a plethora of organisms including bacterial strains and phages, with many possible applications in research and diagnostics. no streptomyces flavovirens phages have been sequenced to date; there is therefore a lack in available information about s. flavovirens phage genomics. we report biological and physiochemical features and use ngs to provide the complete annotated genomes for two new strains (sf1 and sf3) of the virulent phage streptomyces flavovirens, isolated from egyptian soil samples. results: the s. flavovirens phages (sf1 and sf3) examined in this study show higher adsorption rates (82 and 85%, respectively) than other actinophages, indicating a strong specificity to their host, and latent periods (15 and 30 min.), followed by rise periods of 45 and 30 min. as expected for actinophages, their burst sizes were 1.95 and 2.49 virions per ml. both phages were stable and, as reported in previous experiments, showed a significant increase in their activity after sodium chloride (nacl) and magnesium chloride (mgcl2.6h(2)o) treatments, whereas after zinc chloride (zncl2) application both phages showed a significant decrease in infection. the sequenced phage genomes are parts of a singleton cluster with sizes of 43,150 bp and 60,934 bp, respectively. bioinformatics analyses and functional characterizations enabled the assignment of possible functions to 19 and 28 putative identified orfs, which included phage structural proteins, lysis components and metabolic proteins. thirty phams were identified in both phages, 10 (33.3%) of them with known function, which can be used in cluster prediction. comparative genomic analysis revealed significant homology between the two phages, showing the highest hits among sf1, sf3 and the closest streptomyces phage (vwb phages) in a specific 13kb region. however, the phylogenetic analysis using the major capsid protein (mcp) sequences highlighted that the isolated phages belong to the bg streptomyces phage group but are clearly separated, representing a novel sub-cluster. conclusion: the results of this study provide the first physiological and genomic information for s. flavovirens phages and will be useful for pharmaceutical industries based on s. flavovirens and future phage evolution studies.
software_engineering	in this paper an analysis of a technical support data with the goal of identifying process improvement actions for reducing interrupts is presented. a technical support chat is established and used to provide internal developer support to other development teams, which use the software code developed by a core team. the paper shows how data analysis of a 6-month support time helped to identify gaps and action items for improving the technical support process to minimize interrupts from other developer teams. we show that developers are interrupted through the investigated technical support chat multiple times a day and the interruptions come during the peak working hours. we also show that these interruptions can be prevented with the introduction of multiple tools such as a dispatcher service policy, a dispatcher role, and an faq page among others. the paper also shows effects (advantages and drawbacks) of the technical support refactor actions taken on the basis of this analysis.
microcontroller	in the past, human-machine interfacing ( hmi) motivated many studies to develop systems and devices that were able to transfer analog commands from the user 's body to machines. however, many design solutions are still affected by comfort and performance limitations due to wire communications, long calibration procedures, resistance to hand motions, and power supplies requiring cables or batteries. goldfinger, the hmi glove introduced in this paper, has the potential to overcome some of these limitations thanks to the integration of advanced materials, miniaturization of components and electronics, and power generation through biomechanical energy harvesting. hand motions are used to communicate with the machine via a led tracking system. then, information is digitalized with dedicated software that also provides the machine microcontroller programming in the c language. additionally, the battery discharge time is reduced due to the power harvested from integrated piezoelectric transducers, which generate power from finger motions.
microcontroller	the drive control system of modulated grating y branch (mg-y) laser is designedin order to meet the applications and test requirements of mg-ytunable laser. the computer system was implemented by labview graphical programming language developed by ni company. the hardware with 64 k high-speed microcontroller as control core, combining with multiple voltage controlled current source module and serial communication module, realize fully programmable and real-time control of the laser drive current. the stability of constant current source part of the designed module is 0.05% in 2 hours at room temperature. for theadjustablecurrent source part, the error range is 3.45 mu a, bandwidth of the input driving signal is 200 hz, and current tuning rate can reach 3.409 a/s, with maximum signal delay 0.15 ms.
analog_signal_processing	a cmos charge amplifier, due to its very low power consumption and good noise performance, has great interest for analog signal processing in the fields of particle physics, nuclear physics and x-or beta-ray detection. the simulation environment of eldo (tm) using ami05 (american microsystems inc.) technology provided by mentor graphics corporation is used for noise optimization of a low power cmos charge amplifier. using simulation tools we have designed and simulated the output of the charge amplifier and have calculated the power consumption, band width, gain and equivalent noise charge (enc) of the circuit. we have also studied the factors on which noise of amplifier depends. this has resulted in a noise performance of enc = 116 electrons at 0 pf detector capacitance with a power consumption of 80 mu w per channel. due to its very low noise and low power consumption, this kind of new charge amplifier can be widely used in research in the fields of particle physics, nuclear physics and x-ray detection.
algorithm_design	games became popular, within the formal verification community, after their application to automatic synthesis of circuits from specifications, and they have been receiving more and more attention since then. this paper focuses on coding the ""sokoban"" puzzle, i.e., a very complex single-player strategy game. we show how its solution can be encoded and represented as a bounded model checking problem, and then solved with a sat solver. after that, to cope with very complex instances of the game, we propose two different ad-hoc divide-and-conquer strategies. those strategies, somehow similar to state-of-the-art abstraction-and-refinement schemes, are able to decompose deep bounded model checking instances into easier subtasks, trading-off between efficiency and completeness. we analyze a vast set of difficult hard-to-solve benchmark games, trying to push forward the applicability of state-of-the-art sat solvers in the field. those results show that games may provide one of the next frontier for the sat community.
electricity	the current increase in the deployment of new renewable electricity generation systems is creating new challenges in balancing electric grids. solutions including energy storage at small and large scales are becoming of paramount importance to guarantee and secure a stable supply of electricity. this paper presents a study about a hybrid solution including a large scale energy storage system coupled with power generation and fast responding energy storage systems. the hybrid plant is able to deliver the energy previously stored by using an air liquefaction process either with or without the contribution of additional energy from combustion. the paper also highlights how such hybrid plants may offer the chance of providing the grid with fast control services. an ideal energy storage technology should have a high power rating, a large storage capacity, high efficiency, low costs and no geographic constraints. the use of air as energy carrier has been studied since the 20th century with the first compressed air energy storage (caes) systems. this technology is still considered to have a potential but it is geographically constrained, where suitable geological reservoirs are available, unless compressed air is stored in pressurized tanks with significant costs. liquid air energy storage (laes) represents an interesting solution due to its relatively large volumetric energy density and ease of storage. different process schemes for hybrid plants were modeled in this study with aspen hysys (r) simulation software and the results were compared in terms of equivalent round-trip and fuel efficiencies. equivalent round-trip efficiencies, higher than 80%, have been calculated showing that the proposed configurations might play an important role for power systems balancing in the near future. (c) 2016 elsevier ltd. all rights reserved.
electrical_network	this paper describes the approach developed to model the current return networks installed aboard aircrafts having parts made in composite materials. the surface partial element equivalent circuit (peec) method is adopted for its high-fidelity modeling capabilities, and its accuracy in the low-frequency region, which is of interest for the characterization of the return networks. state of the art of peec modeling is implemented in order to allow real-life aircrafts to be modeled. a special complex mock-up has been realized and measured. the numerical results are compared with measurements to assess their adequacy.
analog_signal_processing	the world is presently confronted with the twin crisis of fossil fuel depletion and environmental degradation. indiscriminate extraction and lavish consumption of fossil fuels have led to reduction in underground based carbon resources. the search for an alternative fuel, which promises a harmonious correlation with sustainable development, energy conservation, management, efficiency, and environmental preservation, has become highly pronounced in the present context. for the developing countries of the world, fuels of bio-origin can provide a feasible solution to the crisis. in the present investigation, hydrogen-enriched air was used as intake charge in a cl (compression ignition) engine. experiments were conducted in a single-cylinder, four-stroke, air-cooled, stationary direct-injection diesel engine kirlosker taf1 with 1500 rpm and 4.4 kw capacity coupled to an electrical generator. the injection timings (18.5, 20, 21.5, 24.5, 27.5 degrees ca) and flow rates of hydrogen were varied (80, 120, 150 g/hr) to find out the optimum condition for hydrogen enrichment to meet the best performance. experiment results showed that hydrogen enriched engine gave maximum brake thermal efficiency and minimum brake specific energy consumption at 16.4% h-2 or 120 g/h flow rate with 20 ca injection timing. (c) 2013 elsevier ltd. all rights reserved.
signal-flow_graph	in this work, new kerwin-huelsman-newcomb (khn) biquads employing current-controlled current conveyors (ccciis) in voltage-mode (vm) as well as in current-mode (cm) are presented. the parameters of the proposed circuits can be electronically controlled thanks to the tunability properties of the ccciis. the vm circuit is derived from a previously reported one by modifying its summing circuit and replacing the current conveyors (cciis) and resistors at their x-input terminals with ccciis. on the other band, the cm circuit is derived from the adjoint graph of the signal-flow graph corresponding to the classical khn circuit. this circuit is a multi-input single-output cm universal filter, which offers all the main advantages of the cm circuits as well as those of the classical khn circuit. in addition to the three basic filter responses, they also allow the realization of the notch and the allpass responses.
symbolic_computation	we investigate the resonant davey-stewartson (ds) system. the resonant ds system is a natural (2 +1)-dimensional version of the resonant nonlinear schrodinger equation. traveling wave solutions were found. in this paper, we demonstrate the effectiveness of the analytical methods, namely, improved tan(phi/2)-expansion method (item) and generalized (g'/g)-expansion method for seeking more exact solutions via the resonant davey-stewartson system. these methods are direct, concise and simple to implement compared to other existing methods. the exact particular solutions containing four types of solutions, i.e., hyperbolic function, trigonometric function, exponential and solutions. we obtained further solutions comparing these methods with other methods. the results demonstrate that the aforementioned methods are more efficient than the multilinear variable separation method applied by tang et al. (chaos solitons fractals 42: 2707-2712, 2009). recently the item was developed for searching exact traveling wave solutions of nonlinear partial differential equations. abundant exact traveling wave solutions including solitons, kink, periodic and rational solutions have been found. these solutions might play important role in engineering and physics fields. it is shown that these methods, with the help of symbolic computation, provide a straightforward and powerful mathematical tool for solving the nonlinear problems.
network_security	nowadays, a significant part of all network accesses comes from embedded and battery-powered devices, which must be energy efficient. this paper demonstrates that a hardware (hw) implementation of network security algorithms can significantly reduce their energy consumption compared to an equivalent software (sw) version. the paper has four main contributions: (i) a new feature extraction algorithm, with low processing demands and suitable for hardware implementation; (ii) a feature selection method with two objectives-accuracy and energy consumption; (iii) detailed energy measurements of the feature extraction engine and three machine learning (ml) classifiers implemented in sw and hw-decision tree (dt), naive-bayes (nb), and k-nearest neighbors (knn); and (iv) a detailed analysis of the tradeoffs in implementing the feature extractor and ml classifiers in sw and hw. the new feature extractor demands significantly less computational power, memory, and energy. its sw implementation consumes only 22 percent of the energy used by a commercial product and its hw implementation only 12 percent. the dual-objective feature selection enabled an energy saving of up to 93 percent. comparing the most energy-efficient sw implementation (new extractor and dt classifier) with an equivalent hw implementation, the hw version consumes only 5.7 percent of the energy used by the sw version.
symbolic_computation	lie symmetry analysis is performed on a two-dimensional generalized sawada-kotera equation, which arises in various problems in mathematical physics. exact solutions are obtained using the lie point symmetries method and the simplest equation method.
network_security	software defined networking (sdn) has recently emerged to become one of the promising solutions for the future internet. with the logical centralization of controllers and a global network overview, sdn brings us a chance to strengthen our network security. however, sdn also brings us a dangerous increase in potential threats. in this paper, we apply a deep learning approach for flow-based anomaly detection in an sdn environment. we build a deep neural network (dnn) model for an intrusion detection system and train the model with the nsl-kdd dataset. in this work, we just use six basic features (that can be easily obtained in an sdn environment) taken from the fortyone features of nsl-kdd dataset. through experiments, we confirm that the deep learning approach shows strong potential to be used for flow-based anomaly detection in sdn environments.
cryptography	in last years, low-dimensional and high-dimensional chaotic systems have been implemented in cryptography. the efficiency and performance of these nonlinear systems play an important role in limited hardware implementations. in this context, low-dimensional chaotic systems are more attractive than high-dimensional chaotic systems to produce the pseudorandom key stream used for encryption purposes. although low-dimensional chaotic maps present some security disadvantages when they are used in cryptography, they are highly attractive due its simple structure, discrete nature, less arithmetic operations, high output processing, and relatively easy to implement in a digital system. in this paper, we proposed both a pseudorandomly enhanced logistic map (pelm) and its application in a novel pseudorandom number generator (prng) algorithm, which produces pseudorandom stream with excellent statistical properties. the proposed pelm is compared with logistic map by using histograms and lyapunov exponents to show its higher benefits in pseudorandom number generator. in contrast to recent schemes in the literature, we present a comprehensive security analysis over the proposed pseudorandom number generator based on pseudorandomly enhanced logistic map (prng-pelm) from a cryptographic point of view to show its potential use in secure communications. in addition, the randomness of the prng-pelm is verified with the most complete random test suit of national institute of standards and technology (nist 800-22) and with testu01. based on security results, few arithmetic operations required, and high output rate, the proposed prng-pelm scheme can be implemented in secure encryption applications, even in embedded systems with limited hardware resources.
operating_systems	information leakage and memory disclosures are significant threats to the security of modern operating systems. if an attacker is able to obtain the binary-code of a program, it is then possible to reverse engineer its source code, uncover vulnerabilities, craft exploits, and subsequently patch together code-segments to form code-reuse attacks. these activities are particularly concerning when the program is a device driver or the operating system kernel, since these facilitate privilege-escalation and the ability to persist and hide. while execute-only code is a way to inhibit memory disclosures, the current x86-64 bit virtual memory implementation does not provide the capability to enforce execute only access permissions. the authors present their implementation of exoshim: a novel, 325-line, lightweight shim hypervisor layer employing intel 's commodity virtualization features that can be dynamically inserted beneath a running kernel to prevent memory disclosures by marking its code execute-only. unlike alternative approaches that operate only on user level applications, exoshim utilizes self-protection and hiding techniques that guarantee its integrity even in the event that the attacker is able to gain root-level access. the technology can be combined with fine grained compile- and load-time diversity to mitigate the additional threat of indirect memory disclosures. these concepts have been integrated within an experimental minix-like 64-bit microkernel. while the concepts are general and could be applied to other operating systems, their implementation is subtle and requires a detailed understanding of the kernels interaction with its virtual memory layer and consideration at boot -time to load kernel code and kernel data on distinct pages of memory. early evaluations quantify exoshim 's code size and complexity, run time performance cost, and effectiveness in thwarting information leakage. exoshim provides complete multic-like execute only protection for kernel code at a runtime- performance overhead of only 0.86% due to the advanced modern caching techniques in the x86 architecture. overall, this paper contributes the presentation, implementation, and evaluation of a lightweight tool for enforcing execute only access control permissions on kernel code using the virtualization features of the modern x86-64 architecture.
symbolic_computation	the auxiliary equation method presents wide applicability to handling nonlinear wave equations. in this article, we establish new exact travelling wave solutions of the nonlinear zoomeron equation, coupled higgs equation, and equal width wave equation. the travelling wave solutions are expressed by the hyperbolic functions, trigonometric functions, and rational functions. it is shown that the proposed method provides a powerful mathematical tool for solving nonlinear wave equations in mathematical physics and engineering. throughout the article, all calculations are made with the aid of the maple packet program.
computer_vision	in viticulture, there are several applications where bud detection in vineyard images is a necessary task, susceptible of being automated through the use of computer vision methods. a common and effective family of visual detection algorithms are the scanning-window type, that slide a (usually) fixed size window along the original image, classifying each resulting windowed-patch as containing or not containing the target object. the simplicity of these algorithms finds its most challenging aspect in the classification stage. interested in grapevine buds detection in natural field conditions, this paper presents a classification method for images of grapevine buds ranging 100-1600 pixels in diameter, captured in outdoor, under natural field conditions, in winter (i.e., no grape bunches, very few leaves, and dormant buds), without artificial background, and with minimum equipment requirements. the proposed method uses well-known computer vision technologies: scale-invariant feature transform for calculating low-level features, bag of features for building an image descriptor, and support vector machines for training a classifier. when evaluated over images containing buds of at least 100 pixels in diameter, the approach achieves a recall higher than 0.9 and a precision of 0.86 over all windowed-patches covering the whole bud and down to 60% of it, and scaled up to window patches containing a proportion of 20-80% of bud versus background pixels. this robustness on the position and size of the window demonstrates its viability for use as the classification stage in a scanning-window detection algorithms. (c) 2017 elsevier b.v. all rights reserved.
electrical_network	with the growing use of renewable energy sources, distributed generation (dg) systems are rapidly spreading. embedding dg to the distribution network may be costly due to the grid reinforcements and control adjustments required in order to maintain the electrical network reliability. deterministic load flow calculations are usually employed to assess the allowed dg penetration in a distribution network in order to ensure that current or voltage limits are not exceeded. however, these calculations may overlook the risk of limit violations due to uncertainties in the operating conditions of the networks. to overcome this limitation, related to both injection and demand profiles, the present paper addresses the problem of dg penetration with a monte carlo technique that accounts for the intrinsic variability of electric power consumption. the power absorbed by each load of a medium voltage network is characterized by a load variation curve; a probabilistic load flow is then used for computing the maximum dg power that can be connected to each bus without determining a violation of electric constraints. a distribution network is studied and a comparison is provided between the results of the deterministic load flow and probabilistic load flow analyses. (c) 2014 elsevier ltd. all rights reserved.
computer_programming	this paper introduces a system for automatic evaluation of correctness and originality of source codes submitted by students enrolled in courses dealing with computer programming. automatic correctness checking consists of searching for plagiarisms in assignments submitted earlier and checking the correct implementation of algorithms. user interface is implemented as a moodle module using its plagiarism api. the complete system is published with gplv3 license; therefore other learning institutions can use it as well.
data_structures	shk toxin is a cysteine-rich 35-residue protein ion-channel ligand isolated from the sea anemone stichodactyla helianthus. in this work, we studied the effect of inverting the side chain stereochemistry of individual thr or ile residues on the properties of the shk protein. molecular dynamics simulations were used to calculate the free energy cost of inverting the side-chain stereochemistry of individual thr or ile residues. guided by the computational results, we used chemical protein synthesis to prepare three shk polypeptide chain analogues, each containing either an allo-thr or an alloile residue. the three allo-thr or allo-ile-containing shk polypeptides were able to fold into defined protein products, but with different folding propensities. their relative thermal stabilities were measured and were consistent with the md simulation data. structures of the three shk analogue proteins were determined by quasi-racemic x-ray crystallography and were similar to wild-type shk. all three shk analogues retained ion-channel blocking activity.
operating_systems	the complexity increase in the software and hardware necessary to support more and more advanced applications for wireless sensor networks conspicuously contribute to render them susceptible to security attacks. the nodes of most complex wsn applications sport desktop-level operating systems and this reliance on software make them ideal prey for traditional threats, like viruses and general malware. to address these problems, in this paper we devise a system for a dedicated mobile node to locate, track, access and cure the infected elements of a wsn, threatened by a proximity malware infection. in parallel, we provide a mathematical formulation for the aforementioned operations. we perform extended simulations, comparing our proposal against classic solutions in different network scenarios and we use the results of the mathematical formulation as a benchmark. furthermore, we introduce a variation of our proposal, capable to support the concurrent operation of multiple mobile nodes and implement cooperation. (c) 2016 elsevier b.v. all rights reserved.
parallel_computing	the spiking neural p (sn p) system is defined as a type of parallel computing mechanism bio-inspired by the behavior of the soma. several authors have been employing these systems in order to create efficient arithmetic divisor circuits exploiting at maximum their intrinsic parallel processing. however, the current neural divisors expend a large amount of neurons with complex spiking rules to synchronize the input information to be processed by the soma. this work proposes a compact neural divisor that uses eight neurons and two type spiking rules per neuron. in addition, the proposed circuit includes the dendrite 's behavior as feedback connections, dendritic delays, reduction in the dendrite length and dendritic pruning into the conventional sn p systems in order to simplify the synchronization of the neural processing carried out by the soma. the results show that the proposed neural divisor can be implemented in embedded neuromorphic circuits. this, potentially allows its use in portable applications such as vision processing systems for mobile robots and cryptographic systems for mobile communication devices. (c) 2017 elsevier b.v. all rights reserved.
data_structures	this paper presents a concurrent garbage collection method for functional programs running on a multicore processor. it is a concurrent extension of our bitmap-marking non-moving collector with yuasa 's snapshot-at-the-beginning strategy. our collector is unobtrusive in the sense of the doligez-leroy-gonthier collector; the collector does not stop any mutator thread nor does it force them to synchronize globally. the only critical sections between a mutator and the collector are the code to enqueue/dequeue a 32 kb allocation segment to/from a global segment list and the write barrier code to push an object pointer onto the collector 's stack. most of these data structures can be implemented in standard lock-free data structures. this achieves both efficient allocation and unobtrusive collection in a multicore system. the proposed method has been implemented in sml#, a full-scale standard ml compiler supporting multiple native threads on multicore cpus. our benchmark tests show a drastically short pause time with reasonably low overhead compared to the sequential bitmap-marking collector.
distributed_computing	one of the challenging issues in a distributed computing system is to reach on a decision with the presence of so many faulty nodes. these faulty nodes may update the wrong information, provide misleading results and may be nodes with the depleted battery power. consensus algorithms help to reach on a decision even with the faulty nodes. every correct node decides some values by a consensus algorithm. if all correct nodes propose the same value, then all the nodes decide on that. every correct node must agree on the same value. faulty nodes do not reach on the decision that correct nodes agreed on. binary consensus algorithm and average consensus algorithm are the most widely used consensus algorithm in a distributed system. we apply binary consensus and average consensus algorithm in a distributed sensor network with the presence of some faulty nodes. we evaluate these algorithms for better convergence rate and error rate.
state_space_representation	beside the major objective of providing congestion control, achieving predictable queuing delay, maximizing link utilization, and robustness are the main objectives of an active queue management (aqm) controller. this paper proposes an improved queue dynamic model while incorporating the packet drop probability as well. by applying the improved model, a new compensated pid aqm controller is developed for transmission control protocol/internet protocol (tcp/ip) networks. the non-minimum phase characteristic caused by pade approximation of the network delay restricts the direct application of control methods because of the unstable internal dynamics. in this paper, a parameter-varying dynamic compensator, which operates on tracking error and internal dynamics, is proposed to not only capture the unstable internal dynamics but also reduce the effect of uncertainties by unresponsive flows. the proposed dynamic compensator is then used to design a pid aqm controller whose gains are obtained directly from the state-space representation of the system with no further gain tuning requirements. the packet-level simulations using network simulator (ns2) show the outperformance of the developed controller for both queuing delay stability and resource utilization. the improved underlying model leads also to the faster response of the controller. copyright (c) 2013 john wiley & sons, ltd.
control_engineering	the aim of this paper is to present experimental validation results to show the design simplicity of single input interval type-2 (it2) fuzzy pid (fpid) controllers by evaluating their performance on a real-time 3 dof helicopter testbed. in this study, we briefly show that the presented analytical design approach gives the opportunity to construct the it2 fuzzy mappings by tuning a single parameter which constructs the footprint of uncertainty (fou) of the it2 fuzzy sets. then, by employing these theoretical analyses, various single input it2 fpid (sit2-fpid) controllers are designed to solve the control problem of the 3 dof helicopter. through extensive and comparative experimental analysis, we analyze the it2 fuzzy control system performances and validate the effect of the fou parameter on the controller characteristics. the experimental results show that, having neither a priori knowledge about the mathematical model of the system nor its parameters, the sit2-fpid is able to achieve a satisfactory control performance over nonlinear working regions in the presence of noise and unmodelled disturbance dynamics. we believe that the experimental validation of the sit2-fpid controllers' theoretical analyses will open the door to a wider deployment of sit2-fpids to real world control engineering applications.
system_identification	accurate evaluation of soil dynamic properties is essential for seismic response analyses of sites. in a number of studies, site properties have been identified using one-dimensional analyses. such analyses uncouple the two-dimensional (horizontal) response of soil deposits, which is inherently coupled. this paper presents a system identification technique that takes into account the coupled two-directional response of soil deposits. the technique employs non-parametric estimates of the shear stresses derived from acceleration records provided by a vertical (downhole) array. a multi-yield surface plasticity approach is used to model the multi-dimensional stress-strain relation. the identification technique is first verified using finite elements computational simulations. this technique was then used to assess the coupled response of the wildlife liquefaction research site (imperial valley, california). the identified shear moduli and shear wave velocities were found to be in a very good agreement with those measured in the field using crosshole seismic testing.
electricity	under increasing penetration of distributed resources, regulators and electricity distribution utilities face greater uncertainty regarding the evolution of network uses and efficient system costs. this uncertainty can threaten revenue adequacy and challenges both cost of service/rate of return and incentive/performance-based approaches to the remuneration of distribution utilities. to address these challenges, this paper proposes a novel methodology to establish allowed utility revenues over a multi-year regulatory period. this method combines several ""state of the art"" regulatory tools designed to overcome information asymmetries, manage uncertainty, and align incentives for utilities to cost-effectively integrate distributed energy resources while taking advantage of opportunities to reduce system costs and improve performance. we use a reference network model to simulate a large-scale urban distribution network, demonstrate the practical application of this regulatory method, and illustrate its performance in the face of both benchmark and forecast errors.
pid_controller	pid control schemes have been widely used in most industrial control systems. however, it is difficult to determine a suitable set of pid parameters because most industrial systems have nonlinearity. in order to overcome such a problem, a data-driven pid (dd-pid) control scheme based on utilizing a database has been proposed and its effectiveness has been investigated. however, the dd-pid controller has two problems. one is that training of the database in an on-line manner takes a long time. the other is that a database requires large amount of memory and high computational cost for some micro-controllers. in order to train a database in an off-line manner, the dd-frit scheme which is a combination of a database and the fictitious reference iterative tuning (frit) scheme has been proposed in a previous research. according to the dd-frit scheme, a dd-pid controller can be trained in an off-line manner by using a set of operating data. in this paper, to address the problem of required memory and computational cost, a method that expresses a dd-pid controller as a simple nonlinear function by using the group method of data handling (gmdh) is proposed. according to the proposed method, a dd-pid controller which is trained in advance by using a set of operating data is replaced by a network constructed in n-adalines (units expressed by a simple nonlinear function). the proposed method is first explained and the effectiveness of the proposed method is numerically evaluated by a simulation example.
parallel_computing	as the need for faster power system dynamic simulations increases, it is essential to develop new algorithms that exploit parallel computing to accelerate those simulations. this paper proposes a parallel algorithm based on a two-level, schur-complement-based, domain decomposition method. the two-level partitioning provides high parallelization potential (coarse- and fine-grained). in addition, due to the schur-complement approach used to update the sub-domain interface variables, the algorithm exhibits high global convergence rate. finally, it provides significant numerical and computational acceleration. the algorithm is implemented using the shared-memory parallel programming model, targeting inexpensive multi-core machines. its performance is reported on a real system as well as on a large test system combining transmission and distribution networks.
image_processing	this paper proposed an energy efficient adder employing multistage latency and approximate computing technology. the delay of the adder decreases after the critical path of the adder is divided into multiple short stages with series of predictors, then the approximate computing technology is exploited to make a tradeoff between output quality and energy efficiency. the proposed design is applied into discrete cosine transformation (dct) in image processing and support vector machine (svm) algorithm in machine learning to verify its availability, the simulation results demonstrate that the proposed approximate adder provides 25.6% power delay-product (pdp) reduction and 2 orders of magnitude reduction in output error than the recent counterpart designs. compared with the conventional accurate ripple carry adder (rca) and kogge stone adde (ksa), the proposed design presents 66.5% to 37.6% pdp reduction, at the cost of negligible output quality reduction, which are qualified as peak signal-to-noise ratio (psnr) for dct (decreases from 33.88 db to 33.84 db) and classification accuracy for svm (decreases from 80.46% to 79.19%).
microcontroller	single-inductor multiple-output (simo) switching dc-dc power converter architecture is a cost-effective alternative to multiple individual switching power converters solution in many power distribution system applications where multiple voltage rails are required at reduced cost. however, with multiple output voltage rails coupled to the same switching node, the simo power converters suffer from cross regulation between the multiple outputs, which complicates the closed-loop controller design of the simo converter and degrades regulation performance. in this paper, a power-multiplexed (pm) control scheme is proposed aiming to completely decouple the operations of multiple outputs from one another. the proposed pm control scheme results in eliminating the cross regulation among the multiple outputs while maintaining desired voltage regulation performance for each output under both steady-state and dynamic operations. low-cost microcontroller or analog circuitries can be used to implement the proposed controller. experimental proof of concept prototype results verify the feasibility and advantages of the proposed controller.
symbolic_computation	this paper deals with a (2+1)-dimensional nonlinear evolution equation (nlee) generated by the jaulent-miodek hierarchy for nonlinear water waves via the hirota 's bilinear method and pfaffian. first, we construct rational solutions for general bilinear equations, and then convert the target bilinear equations to the general ones to obtain their rational solutions. the pfaffian plays a role to simplifying the computations compared with the determinant way in the existing literatures. once the first-and second-order rational solutions have been obtained, the higher-order solutions can be derived by the same token. figures for the first-and second-order rational solutions are plotted and analyzed. as an application, the rational solutions for the modified kadomtsev-petviashvili equation have also been constructed. the method might be used for some other nlees to construct their rational solutions. (c) 2016 elsevier ltd. all rights reserved.
digital_control	the main goal of radiotherapy is to destroy the tumor while minimizing harm to nearby healthy tissue. advances in the digital control have enabled planning and performing accurate treatments. however, todays technology is unable to compensate respiration induced motion, and therefore, ensure sufficient precision. one of the tasks in compensating respiratory motion is predicting position of the functional target ( tumor) from an external marker during fraction. performance of techniques, such as pearson correlation, gaussian filters, fourries transformation, cross correlation, linear interpolation and partial-least squares, still leave plenty space for the improvement. we reports results of work in progress, i.e. experiments of applying different types of regressions to predict motion of functional target from different external markers. results seem to be promising in most of the cases.
distributed_computing	we introduce an architecture for undertaking data processing across multiple layers of a distributed computing infrastructure, composed of edge devices (making use of internet-of-things (iot) based protocols), intermediate gateway nodes and large scale data centres. in this way, data processing that is intended to be carried out in the data centre can be pushed to the edges of the network - enabling more efficient use of data centre and in-network resources. we suggest the need for specialist data analysis and management algorithms that are resource-aware, and are able to split computation across these different layers. we propose a coordination mechanism that is able to combine different types of data processing capability, such as in-transit and in-situ. an application scenario is used to illustrate the concepts, subsequently evaluated through a multi-site deployment.
electric_motor	this simulation study discusses the application of a multimode combustion engine in a mild hybrid electric vehicle (hev) with three-way catalytic converter (twc). operation in the lean combustion mode homogeneous charge compression ignition (hcci) results in oxidation of the oxygen storage capacity (osc) of the twc. thereby, the twc 's ability to convert, nox under lean conditions is removed. succeeding depletion of the osc under rich spark-ignition (si) conditions is required, winch results in significant fuel efficiency penalties. in case of a mild hev the torque assist from the electric motor is able to extend the residence time in hcci, thereby reducing the number osc depletion events. the applied supervisory controller, which decides when to switch between si and hcci, is based on the equivalent consumption minimization strategy (ecms) and incorporates the fuel penalties associated with mode switching and osc depletion. it is shown that, while the impact of the osc depletion on drive cycle fuel economy of the mild hev is still significant, it is much smaller than in case of the vehicle without electric motor. the prolonged operation in lean hcci mode leads to substantial amounts of tailpipe nox for all drive cycles tested. in a case study two modifications to the system hardware are introduced with counterintuitive results. first, the hcci regime is further constrained to conditions where engine-out nox levels are extremely low. second, the size of the osc is significantly reduced, allowing a much faster and less inefficient depletion. associated drive cycle results show a substantial reduction in tailpipe nox while fuel economy benefits can be maintained. (c) 2016, ifac (international federation of automatic control) hosting by elsevier ltd. all rights reserved.
electricity	biogas has been earmarked as an efficient way to promote economic development and mitigate environmental emissions, and it requires a better accounting framework to evaluate its performance. in this study, we aim to develop an emergy-based accounting framework to assess and report the sustainability performance of biogas projects. first, the existing financial accounting and environmental accounting methodologies are combined to measure and report the economic events and environmental characteristics of a biogas project. then, using the new metric of emdollar value, the cost and revenue flows within the system boundary are unified and quantified by multiplying specific emergy transformity to reflect their embodiment and hierarchical characteristics. an integrated accounting framework covering economic aspects (economic profitability, economic efficiency, operation risk), environmental aspects (environmental resource utilization, load, emissions) and environmental-economic composited characteristics (emissions reduction efficiency, emdollar intensity of emission reduction, emission intensity of profit) is set up accordingly. results show that the biogas project has a positive net present value of 1.64e+04 emdollars. the total cost can be returned after 5 years. the renewability ratio, environmental load ratio (elr), and composite sustainability indicator (csi) reflecting environmental load are 9%, 10.1, and 0.76, respectively. the proposed sustainability accounting framework may unveil the real environmental support and assess the ecological economic performance of a biogas project. (c) 2016 elsevier ltd. all rights reserved.
network_security	both network security and quality of service (qos) consume computational resource of it system and thus may evidently affect the application services. in the case of limited computational resource, it is important to model the mutual influence between network security and qos, which can be concurrently optimized in order to provide a better performance under the available computational resource. in this paper, an evaluation model is accordingly presented to describe the mutual influence of network security and qos, and then a multi-objective genetic algorithm nsga-ii is revised to optimize the multi-objective model. using the intrinsic information from the target problem, a new crossover approach is designed to further enhance the optimization performance. simulation results validate that our algorithm can find a set of pareto-optimal security policies under different network workloads, which can be provided to the potential users as the differentiated security preferences. these obtained pareto-optimal security policies not only meet the security requirement of the user, but also provide the optimal qos under the available computational resource. (c) 2016 elsevier ltd. all rights reserved.
electrical_network	the aim of the article is to determine, by experiment on large-scale models, the probability of direct lightning strikes in overhead lines with protected wires for different model configurations. the experimental results have allowed to refute the hypothesis of the absence of direct impacts in protected wires of overhead lines. the studies conducted suggest that lightning defeat of overhead lines with protected wires is substantially lower than that traditional lines.
computer_programming	libraries are a collection of implementations of behavior written in a computer programming language providing a well-defined interface by which the behavior can be invoked. although a majority of the code in numerous applications comes from libraries, the risk of security vulnerabilities that comes with these libraries is often overlooked. in this regard, we seek to assess the threat landscape associated with software libraries and discuss mitigation strategies via security development lifecycle (sdl).
machine_learning	among the population of known galactic black hole x-ray binaries, grs 1915+105 stands out in multiple ways. it has been in continuous outburst since 1992, and has shown a wide range of different states that can be distinguished by their timing and spectral properties. these states, also observed in igr j17091-3624, have in the past been linked to accretion dynamics. here, we present the first comprehensive study into the long-term evolution of grs 1915+105, using the entire data set observed with rossi x-ray timing explorer over its 16-yr lifetime. we develop a set of descriptive features allowing for automatic separation of states, and show that supervised machine learning in the form of logistic regression and random forests can be used to efficiently classify the entire data set. for the first time, we explore the duty cycle and time evolution of states over the entire 16-yr time span, and find that the temporal distribution of states has likely changed over the span of the observations. we connect the machine classification with physical interpretations of the phenomenology in terms of chaotic and stochastic processes.
electricity	this paper describes the main characteristics and the performance of a saturated core type fault current limiter (fcl) rated 45mva(33 kv-800 a) to be provided by asg power systems. the fcl, which has been submitted to preliminary laboratory testing, will be installed at a 275/33 kv substation in the u.k. and will reduce the fault current by 38%. the device is based on an open geometry of the magnetic cores which allows reduced size and the weight. magnetic saturation of the cores is obtained by means of two magnesium diboride (mgb2) magnets. a numerical model of the fcl has been developed and validated and the interaction of the device with the power grid has been investigated. details and results of the model are also discussed in the paper.
computer_programming	during an actual drilling process, the wellbore pressure might be below the critical pressure under which the rock surrounding the wellbore begins to fail. therefore, optimizing the wellbore trajectory based on the critical pressure to improve wellbore stability may be unreasonable, because the critical pressure can only reflect the degree of difficulty for the initial damage to occur at the wellbore rather than the extent of the wellbore damage. in accordance with the linear poroelastic rock mechanics theory, combined with the mogi-coulomb criterion, the shape of the initial shear failure zone of arbitrary wellbores is simulated. in order to predict the degree of the wellbore damage, the initial shear failure location, failure width, and failure depth of arbitrary wellbores are determined, and then a new model for calculating the initial collapse volume of a directional wellbore is derived in this paper. with the help of computer programming, the failure position, critical pressure, failure depth, failure width, and the initial collapse volume of arbitrary wellbores under different in-situ stresses are analysed. the results show that the wellbore trajectory optimized according to the critical pressure is significantly different to that optimized according to the degree of wellbore damage, and these trajectories can be completely opposite. a case from southwest sichuan shows that, when the wellbore pressure has to be below the critical pressure during a drilling process, the new model provided in this paper can be used for optimizing the wellbore trajectory to ensure the safety of the drilling operation. (c) 2016 elsevier b.v. all rights reserved.
electrical_circuits	a simple optoelectronic regenerator for differential quadrature phase-shift keying (qpsk) signals is demonstrated. the regenerator consists of two parallel delay interferometers followed by balanced detectors, limiting and driving amplifiers, and a dual-parallel mach-zehnder modulator that regenerates noise-suppressed optical qpsk signals. we experimentally show that the regenerator improves the receiver sensitivity by about 8 db at an input optical signal-to-noise ratio (osnr) of 19 db at a signal speed of 10 gbaud. numerical simulation is conducted for higher speed operation at 56 gbaud to study the impact of the bandwidth of electrical circuits inside the regenerator on the regenerator performance. electrical power consumption of the regenerator is assessed, and it is shown that the optoelectronic regenerator consumes a similar amount of electrical power as that consumed by an all-optical version of the regenerator using semiconductor optical amplifiers as a nonlinear element.
algorithm_design	there is an increasing interest in the field of parallel and distributed data mining in grid environment over the past decade. as an important branch of spatial data mining, spatial outlier mining can be used to find out some interesting and unexpected spatial patterns in many applications. in this paper, a new parallel & distributed spatial outlier mining algorithm (pd-som) is proposed to simultaneously detect global and local outliers in a grid environment. pd-som is a delaunay triangulation (d-tin) based approach, which was encapsulated and deployed in a distributed platform to provide parallel and distributed spatial outlier mining service. subsequently, a distributed system framework for pd-som is designed on top of a geographical knowledge service grid (geoksgrid) developed by our research group, a two-step strategy for spatial outlier detection is put forward to support the encapsulation and distributed deployment of the geographical knowledge service, and two key techniques of the geographical knowledge service: parallel and distributed computing of delaunay triangulation and the implementation of pd-som algorithm are discussed. finally, the efficiency of the spatial outlier mining service is analyzed in theory, the practicality is confirmed by a demonstrative application on the abnormality analyzing of soil geochemical investigation samples from fujian eastern coastal zone area in china, and the effectiveness and superiority of pd-som in a balanced, scalable grid environment are verified through the comparison with the popular spatial outlier mining algorithm slom, for the involvement of large amount of computing cores.
pid_controller	a systematic data-based design method for tuning proportional-integral-derivative (pid) controllers for disturbance attenuation is proposed. in this method, a set of closed-loop plant data are directly exploited without using a process model. pid controller parameters for a control system that behaves as closely as possible to the reference model for disturbance rejection are derived. two algorithms are developed to calculate the pid parameters. one algorithm determines the optimal time delay in the reference model by solving an optimization problem, whereas the other algorithm avoids the nonlinear optimization by using a simple approximation for the time delay term, enabling derivation of analytical pid tuning formulas. because plant data integrals are used in the regression equations for calculating pid parameters, the two proposed algorithms are robust against measurement noises. moreover, the controller tuning involves an adjustable design parameter that enables the user to achieve a trade-off between performance and robustness. because of its closed-loop tuning capability, the proposed method can be applied online to improve (retune) existing underperforming controllers for stable, integrating, and unstable plants. simulation examples covering a wide variety of process dynamics, including two examples related to reactor systems, are presented to demonstrate the effectiveness of the proposed tuning method. (c) 2016 isa. published by elsevier ltd. all rights reserved.
algorithm_design	with the increasingly growing amount of service requests from the world-wide customers, the cloud systems are capable of providing services while meeting the customers' satisfaction. recently, to achieve the better reliability and performance, the cloud systems have been largely depending on the geographically distributed data centers. nevertheless, the dollar cost of service placement by service providers (sp) differ from the multiple regions. accordingly, it is crucial to design a request dispatching and resource allocation algorithm to maximize net profit. the existing algorithms are either built upon energy-efficient schemes alone, or multi-type requests and customer satisfaction oblivious. they cannot be applied to multi-type requests and customer satisfaction-aware algorithm design with the objective of maximizing net profit. this paper proposes an ant-colony optimization-based algorithm for maximizing sp 's net profit (amp) on geographically distributed data centers with the consideration of customer satisfaction. first, using model of customer satisfaction, we formulate the utility (or net profit) maximization issue as an optimization problem under the constraints of customer satisfaction and data centers. second, we analyze the complexity of the optimal requests dispatchment problem and rigidly prove that it is an np-complete problem. third, to evaluate the proposed algorithm, we have conducted the comprehensive simulation and compared with the other state-of-the-art algorithms. also, we extend our work to consider the data center 's power usage effectiveness. it has been shown that amp maximizes sp net profit by dispatching service requests to the proper data centers and generating the appropriate amount of virtual machines to meet customer satisfaction. moreover, we also demonstrate the effectiveness of our approach when it accommodates the impacts of dynamically arrived heavy workload, various evaporation rate and consideration of power usage effectiveness. copyright (c) 2014 john wiley & sons, ltd.
system_identification	l-band digital aeronautical communication system 1 (l-dacs1) is a promising candidate data-link for future air-ground communication, but it is severely interfered by the pulse pairs (pps) generated by distance measure equipment. a novel pp mitigation approach is proposed in this paper. firstly, a deformed pp detection (dppd) method that combines a filter bank, correlation detection, and rescanning is proposed to detect the deformed pps (dpps) which are caused by multiple filters in the receiver. secondly, a finite impulse response (fir) model is used to approximate the overall characteristic of filters, and then the waveform of dpp can be acquired by the original waveform of pp and the fir model. finally, sparse representation is used to estimate the position and amplitude of each dpp, and then reconstruct each dpp. the reconstructed dpps will be subtracted from the contaminated signal to mitigate interference. numerical experiments show that the bit error rate performance of our approach is about 5 db better than that of recent works and is closer to interference-free environment. (c) 2016 chinese society of aeronautics and astronautics. production and hosting by elsevier ltd.
state_space_representation	nonlinearity can be used to enhance broadband rotating piezoelectric vibration energy harvesting, but how to construct a proper nonlinear rotating harvester is a challenging problem in engineering applications. this article presents a melnikov-theory-based method to explore broadband mechanism and necessary conditions of nonlinear rotating piezoelectric vibration energy harvesting system. first, a perturbed state-space representation of nonlinear rotating energy harvesting system is built based on its dynamic model. it can be seen that bi-stability of the unperturbed nonlinear system is the physical basis of achieving broadband and low-frequency rotating energy harvesting. second, the melnikov function is defined to derive two necessary conditions of homoclinic bifurcation and chaotic motions. then simulations are performed to identify the key parameters and their effects on the melnikov conditions, including distance, rotating frequency, and excitations. it can be seen that homoclinic bifurcation and chaotic motions can occur in nonlinear rotating energy harvesting systems under single-frequency and broadband excitations. finally, the experiments are carried out to validate the two necessary conditions. the results demonstrate that the proposed method can provide important guidelines for optimally designing nonlinear rotating piezoelectric energy harvesters in practice.
digital_control	the time delay caused by the calculation time is unavoidable for the implementation of digital controller and also degrades the control performance. in order to cope with the time delay for the control of single-phase uninterruptible power supply (ups), this paper proposes the time delay compensator based on the smith-predictor for both voltage and current controller and also evaluates the usefulness of the compensator by analytic analysis and experimental results. theoretically the compensator alleviates the effect of time delay for both voltage and current controller, but the compensation for the fast current control is usually sufficient from the practical point of view. the experimental results are presented to show the validity of the proposed design and analysis of the time delay compensator for single-phase ups.
algorithm_design	multicast routing that meets multiple quality of service constraints is important for supporting multimedia com-munications in the internet of things (iot). existing multicast routing technologies for iot mainly focus on ad hoc sensor net-working scenarios; thus, are not responsive and robust enough for supporting multimedia applications in an iot environment. in order to tackle the challenging problem of multicast routing for multimedia communications in iot, in this paper, we pro-pose two algorithms for the establishing multicast routing tree for multimedia data transmissions. the proposed algorithms leverage an entropy-based process to aggregate all weights into a comprehensive metric, and then uses it to search a multicast tree on the basis of the spanning tree and shortest path tree algorithms. we conduct theoretical analysis and extensive simulations for evaluating the proposed algorithms. both analytical and experimental results demonstrate that one of the proposed algorithms is more efficient than a representative multiconstrained multicast routing algorithm in terms of both speed and accuracy; thus, is able to support multimedia communications in an iot environ-ment. we believe that our results are able to provide in-depth insight into the multicast routing algorithm design for multimedia communications in iot.
computer_programming	pedagogical agents are animated avatars that stimulate cognitive and socio-emotive aspects of instructional activity in virtual learning environment. in the context of visual design, a pedagogical agent simulating human tutor can either be realistic (3d-rendered and naturalistic) or unrealistic (2d-rendered and stylized/cartoon). though design factors such as agent stereotypes, aesthetics, roles and gender has been studied extensively, the issue of pedagogical agent 's realism has not receive sufficient attention from the research community. this is unfortunate, as decision regarding agent 's visual realism must be faced by instructional designers when implementing pedagogical agent in virtual learning environment. hence, the objective of this study is to investigate the relationship among agent 's visual realism, learners' cognition and learner 's socio-emotive behaviours in a virtual learning environment. one hundred forty-four university sophomores at an asian university interacted with either a realistic agent (3d-rendered and naturalistic) or an unrealistic agent (2d-rendered and stylized/cartoon) in a virtual learning system that delivers a lesson on basic computer programming. results showed that the unrealistic (cartoonish) agent imposed extraneous cognitive load and hindered learning transfer, particularly for male learners. mediation analysis demonstrated that the effects of agent 's design (realistic versus cartoonish) on learning transfer among males were fully mediated by learner 's extraneous load. the hypothesis that a cartoonish agent will elicit higher socio-emotive responses from learners was not supported. on the contrary, the realistic agent induced a higher level of positive affect in learners than the unrealistic agent theoretical and design considerations regarding agents' visual realism are discussed in this paper.
electrical_circuits	in2s3 films have been grown on preheated glass substrate by spray pyrolysis. indium chloride and thiourea in the molar ratio s:in = 2 were used as reagents. substrate temperature was fixed at 613 k. these films adhered well to the substrate and were approximately 2 mu m thick. structural, morphological, optical, and electrical properties of the as-grown in2s3 films were studied by use of x-ray diffraction (xrd) analysis, energy-dispersive spectroscopy, atomic force microscopy (afm), optical absorption spectroscopy, and impedance spectroscopy. xrd revealed well crystallized films oriented in the (400) direction corresponding to the cubic beta-in2s3 phase. the surface of the films was smooth; average roughness was 5 nm. the afm image revealed that the films were nanopolycrystalline and contained grains in the range 20-30 nm. optical transmission in the visible and near-infrared regions was 80%. the direct band-gap energy was 2.62 ev. the electrical data were analyzed on the basis of the impedance cole-cole plots in the frequency range 0.1 hz to 100 khz at room temperature. constant-phase elements were used in equivalent electrical circuits for fitting of experimental impedance data. the experimental results were fitted to the equivalent electrical circuit by use of z-view software. the conductivity of grains and grain boundaries was estimated. the gas-sensing properties of the sample were investigated on the basis of the change in conductance as a result of adsorption and desorption of atmospheric oxygen.
distributed_computing	mobile cloud computing (mcc) is the state-of-the-art mobile distributed computing model that incorporates multitude of heterogeneous cloud-based resources to augment computational capabilities of the plethora of resource-constraint mobile devices. in mcc, execution time and energy consumption are significantly improved by transferring execution of resource-intensive tasks such as image processing, 3d rendering, and voice recognition from the hosting mobile to the cloud-based resources. however, accessing and exploiting remote cloud-based resources is associated with numerous security and privacy implications, including user authentication and authorization. user authentication in mcc is a critical requirement in securing cloud-based computations and communications. despite its critical role, there is a gap for a comprehensive study of the authentication approaches in mcc which can provide a deep insight into the state-of-the-art research. this paper presents a comprehensive study of authentication methods in mcc to describe mcc authentication and compare it with that of cloud computing. the taxonomy of the state-of-the-art authentication methods is devised and the most credible efforts are critically reviewed. moreover, we present a comparison of the state-of-the-art mcc authentication methods considering five evaluation metrics. the results suggest the need for futuristic authentication methods that are designed based on capabilities and limitations of mcc environment. finally, the design factors deemed could lead to effective authentication mechanisms are presented, and open challenges are highlighted based on the weaknesses and strengths of existing authentication methods. (c) 2015 elsevier ltd. all rights reserved.
electrical_circuits	in the paper, the wide-spread mathematical models of the deterministic chaos transistor oscillators are considered. these models describe dynamic processes to take place in transistor colpitts oscillators. variations of the deterministic chaos transistor oscillator 's schemes are presented. phase portraits, time and spectral diagrams of chaotic oscillation were obtained.
computer_vision	supermarkets nowadays are equipped with barcode scanners to speed up the checkout process. nevertheless, most of the agricultural products cannot be pre-packaged and thus must be weighted. the development of produce recognition system based on computer vision could help the cashiers in the supermarkets with the pricing of these weighted products. this work proposes a hybrid approach of object classification and attribute classification for the produce recognition system which involves the cooperation and integration of statistical approaches and semantic models. the integration of attribute learning into the produce recognition system was proposed due to the fact that attribute learning has emerged as a promising paradigm for bridging the semantic gap and assisting in object recognition in many fields of study. this could tackle problems occurred when less training data are available, i.e. less than 10 samples per class. the experiments show that the correct classification rate of the hybrid approach were 60.55, 75.37 and 86.42% with 2, 4 and 8 training examples, respectively, which were higher than other individual classifiers. a well-balanced specificity, sensitivity and f-1 score were achieved by the hybrid approach for each produce type.
computer_programming	this article contains a description of the structure, the software and functional capabilities, and the scope and purposes of application of the group profile (gp) computer technique. this technique rests on a conceptual basis (the microgroup theory), includes 16 new and modified questionnaires, and a unique algorithm, tied to the questionnaires, for identification of informal groups. the gp yields a wide range of data about the group as a whole (47 indices), each informal group (43 indices), and each group member (16 indices). the gp technique can be used to study different types of groups: production (work groups, design teams, military units, etc.), academic (school classes, student groups), and sports.
computer_graphics	this contribution presents the functionalities and multimedia contents of the e-learning module on virtual prototyping of garments within the erasmus+ project entitled e-learning course for innovative textile fields - advan2tex. use of advanced information technologies and systems can assure the textile and garment manufacturing companies the competitive advantages, such as high and constant quality of products, productivity, flexibility, and quick response to the requirements of fashion and market. a wide range of new technologies, above all those using fascinating possibilities of computer graphics, together with a new generation of computer-based systems, assure the textile companies the ability to react extremely fast to the customer demands offering quality and future-oriented services. this enables greater commercial presence and contributes to company 's better marketing position. the universities, research institutions and software producers apply nowadays a whole range of new technologies to create the advanced computer solutions that will in the future support the whole cycle starting from the virtual design of fabric and garments through automated production up to virtual merchandising. therefore, the students and textile professionals, already working in textile industries, should be given the knowledge needed for successful work with the new technologies, which will contribute to developing the textile information society of the future. this module of the e-learning course for innovative textile field informs the readers and course participants about new emerging technologies, which have a great potential for the textile-related industries: virtual prototyping of garments and 3d scanning.
relational_databases	in this paper, we have discussed the challenges in handling real-time medical big data collection and storage in health information system (his). based on challenges, we have proposed a model for real-time analysis of medical big data. we exemplify the approach through spark streaming and apache kafka using the processing of health big data stream. apache kafka works very well in transporting data among different systems such as relational databases, apache hadoop and non-relational databases. however, apache kafka lacks analyzing the stream, spark streaming framework has the capability to perform some operations on the stream. we have identified the challenges in current real-time systems and proposed our solution to cope with the medical big data streams.
image_processing	microalgae are one of the most suitable subjects for testing the potentiality of light microscopy and image analysis, because of the size of single cells, their endogenous chromaticity, and their metabolic and physiological characteristics. microscope observations and image analysis can use microalgal cells from lab cultures or collected from water bodies as model to investigate metabolic processes, behavior/reaction of cells under chemical or photic stimuli, and dynamics of population in the natural environment in response to changing conditions. in this paper we will describe the original microscope we set up together with the image processing techniques we improved to deal with these topics. our system detects and recognizes in-focus cells, extracts their features, measures cell concentration in multi-algal samples, reconstructs swimming cell tracks, monitors metabolic processes, and measure absorption and fluorescent spectra of subcellular compartments. it can be used as digital microscopy station for algal cell biology and behavioral studies, and field analysis applications.
analog_signal_processing	in developing country like bangladesh, the demand of electrical energy is very higher than the available production. at present, the electricity supply deficiency is about 1500 to 2000 mw /day i.e. the total supply is 4000 to 4500 mw/day within the demand of 6000mw/day for this reason power failure has become an acute problem in our country. to solve this energy crisis, it is important to found alternative approaches. recently tidal power becomes most important and researchable topic in the world, especially the countries which are placed near sea or ocean. bangladesh is situated between 20 degrees 34' and 26 degrees 38' north latitude, 88 degrees 01' & 92 degrees 41' east longitude with an area of 147570 sq.km. it has a 710 km of coastal line along the bay of bengal [1-3]. as bangladesh has a long coastal line along the bay of bengal, so tidal energy technology can be used as one of the major reliable energy resource. in this paper an efficient tidal energy site is proposed based on analysis of technical as well as market data and the data is collected from bangladesh navy and different tidal current data chart. finally based on tidal current condition of one of the efficient site, a matlab simulink simulation result is shown by proposed a suitable electrical generator.
analog_signal_processing	the paper presents an original approach of designing analog signal processing circuits, based on the re-using of the same functional core for implementing two circuit functions: signal gain with theoretical null distortions and signal squaring. the advantages of the increased modularity and controllability and of the reduced design costs represent an immediate consequence of the double function realized by the proposed structures. because the most important circuit complexity is concentrated for implementing the core of the structure, both circuit area and power consumption per each realized function can be strongly reduced using this method. the overall error of the transconductance amplifier is 0.4% and the approximation error for the squaring circuit is 0.27%, in the condition of a low-voltage low-power operation (a supply voltage of 1.5v and a medium current consumption of 50 mu a for each implemented circuit function).
relational_databases	information sources such as relational databases, spreadsheets, xml, json, and web apis contain a tremendous amount of structured data that can be leveraged to build and augment knowledge graphs. however, they rarely provide a semantic model to describe their contents. semantic models of data sources represent the implicit meaning of the data by specifying the concepts and the relationships within the data. such models are the key ingredients to automatically publish the data into knowledge graphs. manually modeling the semantics of data sources requires significant effort and expertise, and although desirable, building these models automatically is a challenging problem. most of the related work focuses on semantic annotation of the data fields (source attributes). however, constructing a semantic model that explicitly describes the relationships between the attributes in addition to their semantic types is critical. we present a novel approach that exploits the knowledge from a domain ontology and the semantic models of previously modeled sources to automatically learn a rich semantic model for a new source. this model represents the semantics of the new source in terms of the concepts and relationships defined by the domain ontology. given some sample data from the new source, we leverage the knowledge in the domain ontology and the known semantic models to construct a weighted graph that represents the space of plausible semantic models for the new source. then, we compute the top k candidate semantic models and suggest to the user a ranked list of the semantic models for the new source. the approach takes into account user corrections to learn more accurate semantic models on future data sources. our evaluation shows that our method generates expressive semantic models for data sources and services with minimal user input. these precise models make it possible to automatically integrate the data across sources and provide rich support for source discovery and service composition. they also make it possible to automatically publish semantic data into knowledge graphs. (c) 2015 elsevier b.v. all rights reserved.
state_space_representation	this paper presents a dynamic model of a once-through-to-superheat solar steam receiver for electricity generation. the receiver is a mono-tube cavity boiler mounted at the focal point of a 500 m(2) paraboloidal dish concentrator at the australian national university. the dynamic model is derived from physical principles of mass and energy conservation, and uses a moving boundary formulation, coupled with a switching approach, to represent outlet flow, ranging from sub-cooled liquid to superheated steam. a method to compute outlet mass flow rate for all three receiver outlet flow conditions is included. this modelling approach results in a compact state-space representation of the receiver which is useful in the development of model-based control strategies for the operation of the receiver in a concentrator plant. the model is implemented in trnsys 16 and validated with experimental data from the australian national university 500 m(2) dish system. (c) 2013 elsevier ltd. all rights reserved.
operational_amplifier	this paper presents a digital testing strategy for characterizing an analog circuit block. the operational amplifier (op amp) is evaluated due to its wide application in electronic circuits and systems. in the proposed strategy, the op amp device under test (dut) is configured to respond to a testing pulse, and the associated output is digitized by a digital buffer to reduce the high cost of generating a high-frequency clock. the testing procedure is divided into two modes to estimate the reference slew rate and then to evaluate the practical slew rate to moderate the difficulty of designing a digital buffer that has a highly precise delay time. the testing concept, accuracy, time, and hardware are also comprehensively investigated to describe the proposed testing strategy. the digital compatibility, the simplicity, and the testing capability of the high-performance op amp are the main advantages of the proposed testing strategy. easily available discrete devices were experimentally employed to verify the functionality of the proposed testing strategy. an integrated application to test the op amp dut embedded in a second-order sallen-key low-pass filter was simulated with the hspice tool to verify the testing feasibility and the effectiveness of the proposed strategy.
pid_controller	the effect of spatial variations in mean radiant temperature and occupancy on hvac energy and occupant thermal comfort is studied in an operi-plan office space with multiple ahus. a predictive control method is proposed that arrives at optimum temperature set-point vector by solving an optimization problem, which minimizes hvac energy consumption subject to acceptable thermal comfort and adequate outside air intake. the optimum temperature set-point vector is used in a pid controller that modulates the ahu fan speed. the proposed control is evaluated on occupancy traces observed in an open-plan space and compared with static set-points based pid control strategies. normally pid control operates with a dead band around the static set-point and the ahu fan speed is adjusted only when return air temperature is outside the dead-band. the proposed control has a dynamic set-point and hence the ahu speeds are adjusted at much finer time steps than the normal control. the occupancy traces are classified into densely and sparsely occupied days. across all days, the proposed control achieves an average additional savings of 15% over a pid control that assumes uniform spatial occupancy distribution in ahu control and 12% over a pid based strategy that uses actual spatial occupancy information. (c) 2017 elsevier b.v. all rights reserved.
machine_learning	machine learning-based computational intelligence methods are widely used to analyze large-scale data sets in this age of big data. extracting useful predictive modeling from these types of data sets is a challenging problem due to their high complexity. analyzing large amount of streaming data that can be leveraged to derive business value is another complex problem to solve. with high levels of data availability (i.e., big data), automatic classification of them has become an important and complex task. hence, we explore the power of applying mapreduce-based distributed adaboosting of extreme learning machine (elm) to build a predictive bag of classification models. accordingly, (1) data set ensembles are created; (2) elm algorithm is used to build weak learners (classifier functions); and (3) builds a strong learner from a set of weak learners. we applied this training model to the benchmark knowledge discovery and data mining data sets.
bioinformatics	purpose: ketamine-induced cystitis (kc) among chronic ketamine young abusers has increased dramatically and it has brought attention for urologists. the underlying pathophysiological mechanism(s) of kc is still unclear. therefore, the purpose of this study is to elucidate the possible pathophysiological mechanism(s) of kc through proteomic techniques. experimental design: bladder tissues are obtained from seven patients with kc, seven patients with interstitial cystitis/bladder pain syndrome, and five control subjects who underwent videourodynamic study followed by augmentation enterocystoplasty to increase bladder capacity. 2de/ms/ms-based approach, functional classifications, and network analyses are used for proteomic and bioinformatics analyses and protein validation is carried out by western blot analysis. results: among the proteins identified, bioinformatics analyses revealed that several actin binding related proteins such as cofilin-1, myosin light polypeptide 9, filamin a, gelsolin, lamin a are involved in the apoptosis. besides, the contractile proteins and cytoskeleton proteins such as myosin light polypeptide 9, filamin a, and calponin are found downregulated in kc bladders. conclusions and clinical relevance: increased apoptosis in kc might be mediated by actinbinding proteins and a ca2+ -activated protease. rapid detrusor contraction in kc might be induced by contractile proteins and cytoskeleton proteins.
pid_controller	different educational and didactic papers that allow students to experimentally validate linear controllers have been reported. however, generally, in those papers, procedure followed to select controller gains is not discussed. this lack of information renders difficult experimental implementation of controllers by students who, in general, do not have enough experience on controller tuning. motivated by this situation, this paper introduces a methodology that provides important information on how to select controller gains for regulation in a furuta pendulum. this methodology allows improving closed-loop system performance in a desired direction. differential flatness is the furuta pendulum property that is exploited. the main idea is to translate a linear state feedback control design problem into a scenario, where classical tools such as root locus can be used. as an example, controller design is directed toward reduction or even elimination of limit cycle effects. the proposal is experimentally tested on a built furuta pendulum. these experimental results show that the closed-loop system performance is improved, and hence, the proposed methodology is successfully validated.
state_space_representation	this contribution addresses the development of a linear quadratic (lq) regulator in order to control the concentration profiles along a catalytic distillation column, which is modelled by a set of coupled hyperbolic partial differential and algebraic equations (pdaes). the proposed method is based on an infinite-dimensional state-space representation of the pdae system which is generated by a transport operator. the presence of the algebraic equations, makes the velocity matrix in the transport operator, spatially varying, non-diagonal, and not necessarily negative through of the domain. the optimal control problem is treated using operator riccati equation (ore) approach. the existence and uniqueness of the non-negative solution to the ore are shown and the ore is converted into a matrix riccati differential equation which allows the use of a numerical scheme to solve the control problem. the result is then extended to design an optimal proportional plus integral controller which can reject the effect of load losses. the performance of the designed control policy is assessed through a numerical study. (c) 2012 elsevier ltd. all rights reserved.
bioinformatics	background: hepatocellular carcinoma (hcc) is the most common liver malignancy worldwide. however, present studies of its multiple gene interaction and cellular pathways still could not explain the initiation and development of hcc perfectly. to find the key genes and mirnas as well as their potential molecular mechanisms in hcc, microarray data gse22058, gse25097, and gse57958 were analyzed. methods: the microarray datasets gse22058, gse25097, and gse57958, including mrna and mirna profiles, were downloaded from the geo database and were analyzed using geo2r. functional and pathway enrichment analyses were performed using the david database, and the protein-protein interaction (ppi) network was constructed using the cytoscape software. finally, mirdb was applied to predict the targets of the differentially expressed mirnas (dems). results: a total of 115 differentially expressed genes (degs) were found in hcc, including 52 up-regulated genes and 63 down-regulated genes. the gene ontology (go) and kyoto encyclopedia of genes and genomes (kegg) pathway enrichment analyses from david showed that up-regulated genes were significantly enriched in chromosome segregation and cell division, while the down-regulated genes were mainly involved in complement activation, protein activation cascades, carboxylic acid metabolic processes, oxoacid metabolic processes, and the immune response. from the ppi network, the 18 nodes with the highest degree were screened as hub genes. among them, esr1 was found to have close interactions with foxo1, cxcl12, and gnao1. in addition, a total of 64 dems were identified, which included 58 up-regulated mirnas and 6 down-regulated mirnas. esr1 was potentially targeted by five mirnas, including hsa-mir-18a and hsa-mir-221. conclusions: the roles of dems like hsa-mir-221 in hcc through interactions with degs such as esr1 and cxcl12 may provide new clues for the diagnosis and treatment of hcc patients.
electrical_network	a new directional solidification technique has been presented. this technique employs the pyrolytic graphite for heat dissipation by conduction and does not withdraw the cast. the furnace design was presented for this static solid cooling (ssc) method. a heat dissipation model was put forward for evaluating the cooling efficiency by calculating the total thermal resistance in directional solidification. the total thermal resistance in the ssc method is the minimum compared with other methods. the solidification process is simulated and the results show that the axial temperature gradient increases to 130 degrees c/cm from 52 degrees c/cm (bridgman method) and the growth rate is improved to 10.84 mm/min from 3.86 mm/min (bridgman method). the solidification time is reduced by 64.4%. the cooling rate increases dramatically as well. additionally, the heat insulation of the hot and cool zones is improved substantially in the ssc method. the thermal resistance of the mould is reduced as well due to the thin mould. besides, the ssc method employs the electrical network to control the growth rate. the solidification condition is much uniform due to the position control by the electrical network. (c) 2016 elsevier b.v. all rights reserved.
digital_control	an approach to mass measurement for the electronic balance based on continuous-time sigma-delta (ct sigma-delta) modulator is described in this paper. as an effect of multifarious interfering noises, the accuracy of the electronic balance is restricted. the general idea of this proposed approach is to apply an electromagnetic-force-compensated load cell (emcc), a related signal processing circuit, and a composite filter. the circuit mainly consists of a proportional-integral-differential controller and a pulsewidth modulator, which combine with the emcc to form a ct sigma-delta modulator. as the ct sigma-delta modulator possesses inherent antialiasing filtering, oversampling, and noise-shaping characteristics, the interfering noises can be effectively removed by the composite filter that is composed of two sinc(n) filters. the simulations for both of the electronic balance models adopting the proposed approach and working in conventional pulse current mode are analyzed by adding the white gaussian noise in simulink. the simulation results demonstrate the effectiveness of this proposed approach, the proposed electronic balance in the field can improve its signal-to-noise ratio, and the testing results meet the requirement for the weighing accuracy of the special-class scale defined by organisation internationale de metrologie legale r76 nonautomatic weighing instruments.
electricity	we propose a two-stage mixed-integer linear stochastic optimization model to analyze the scheduling of electricity-production units under natural gas-supply uncertainty due to pipeline congestion and natural gas-price variability. the first stage of this stochastic optimization model represents the day-ahead scheduling (i.e., unit commitment) stage, while the second stage represents actual real-time operations through a number of scenarios. we use this model to analyze the effect on unit commitment and dispatch of two types of natural gas-supply conditions. first, we analyze a case involving low-cost natural gas supply with natural gas-transmission issues related to potential gas-pipeline congestion. we then examine a case involving higher-cost natural gas, which is used solely to attain feasibility with fast-ramping events. the first case mimics situations in the iso new england system, in which relatively low-cost natural gas supply is uncertain in cold-weather conditions due to natural gas-transmission bottlenecks. the second case is reminiscent of situations in the california iso system, in which relatively expensive but flexible natural gas-fired units need to be used to handle rapid changes in net demand in the early mornings and late afternoons.
symbolic_computation	studied in this paper are the bright-dark vector soliton solutions for a generalized coupled hirota system which describes the propagation for the high-intensity ultrashort pulses in the optical glass fiber. beyond the existing bilinear forms, using an auxiliary function, we obtain the improved bilinear forms and bright-dark soliton solutions under two integrable constraints through the hirota method and symbolic computation. with the help the analytic and graphic analysis, we study the soliton properties including the amplitudes, velocities and phase shifts, and show that the interactions for the bright-dark two solitons are elastic. for the bright-dark one soliton, parametric conditions that the dark component is ""black"" or ""gray"" are obtained. for the bright-dark two solitons, we find that the bright component is affected by the dark component background parameters during such an interaction, while the dark component is not affected by the bright component background parameters. velocities for the bright-dark two solitons are inversely proportional to the higher-order effect parameter, but amplitudes and phase shifts are independent of it. besides, the bound-state bright-dark two solitons are also presented. (c) 2016 elsevier b.v. all rights reserved.
parallel_computing	in the course of the last decade, fast and qualitative computing power developments have undoubtedly permitted for a better and more realistic modeling of complex physiological processes. due to this favorable environment, a fast, generic and reliable model for high density surface electromyographic (hd-semg) signal generation with a multilayered cylindrical description of the volume conductor is presented in this study. its main peculiarity lies in the generation of a high resolution potential map over the skin related to active motor units (mus). indeed, the analytical calculus is fully performed in the frequency domain. hd-semg signals are obtained by surfacic numerical integration of the generated high resolution potential map following a variety of electrode shapes. the suggested model is implemented using parallel computing techniques as well as by using an object-oriented approach which is comprehensive enough to be fairly quickly understood, used and potentially upgraded. to illustrate the model abilities, several simulation analyses are put forward in the results section. these simulations have been performed on the same muscle anatomy while varying the number of processes in order to show significant speed improvement. accuracy of the numerical integration method, illustrating electrode shape diversity, is also investigated in comparison to analytical transfer functions definition. an additional section provides an insight on the volume detection of a circular electrode according to its radius. furthermore, a large scale simulation is introduced with 300 mus in the muscle and a hd-semg electrode grid composed of 16 x 16 electrodes for three constant isometric contractions in 12 s. finally, advantages and limitations of the proposed model are discussed with a focus on perspective works. (c) 2016 elsevier ltd. all rights reserved.
software_engineering	the inherent uncertainty to factors such as technology and creativity in evolving software development is a major challenge for the management of software projects. to address these challenges the project manager, in addition to examining the project progress, may cope with problems such as increased operating costs, lack of resources, and lack of implementation of key activities to better plan the project. software cost estimation (sce) models do not fully cover new approaches. and this lack of coverage is causing problems in the consumer and producer ends. in order to avoid these problems, many methods have already been proposed. model-based methods are the most familiar solving technique. but it should be noted that model-based methods use a single formula and constant values, and these methods are not responsive to the increasing developments in the field of software engineering. accordingly, researchers have tried to solve the problem of sce using machine learning algorithms, data mining algorithms, and artificial neural networks. in this paper, a hybrid algorithm that combines coa-cuckoo optimization and k-nearest neighbors (knn) algorithms is used. the so-called composition algorithm runs on six different data sets and is evaluated based on eight evaluation criteria. the results show an improved accuracy of estimated cost.
computer_programming	algorithmic thinking development is a difficulty that students have to confront when they learn programming the right use of selection and control structures is a big challenge. in this research were used generative learning objects for algorithmic thinking development in the programming foundations course that is offered to new students of computer systems career. research methodological approach, was quantitative, quasi-experimental design and were applied pretest and posttest. the obtained results determined that the use of generative learning objects was relevant.
software_engineering	smart farming is a management style that includes smart monitoring, planning and control of agricultural processes. this management style requires the use of a wide variety of software and hardware systems from multiple vendors. adoption of smart farming is hampered because of a poor interoperability and data exchange between ict components hindering integration. software ecosystems is a recent emerging concept in software engineering that addresses these integration challenges. currently, several software ecosystems for farming are emerging. to guide and accelerate these developments, this paper provides a reference architecture for farm software ecosystems. this reference architecture should be used to map, assess design and implement farm software ecosystems. a key feature of this architecture is a particular configuration approach to connect ict components developed by multiple vendors in a meaningful, feasible and coherent way. the reference architecture is evaluated by verification of the design with the requirements and by mapping two existing farm software ecosystems using the farm software ecosystem reference architecture. this mapping showed that the reference architecture provides insight into farm software ecosystems as it can describe similarities and differences. a main conclusion is that the two existing farm software ecosystems cad improve configuration of different ict components. future research is needed to enhance configuration in farm software ecosystems. (c) 2016 the authors. published by elsevier b.v.
digital_control	this paper presents a nonlinear power system stabilizer based on a pointwise min-norm control law and a third order state space mathematical model of the synchronous generator connected through transmission lines to the power system. commonly, the mathematical model includes transient electromotive force as a state variable that cannot be measured. therefore, the mathematical model is transformed in a form containing all measurable variables. furthermore, the control law for the proposed stabilizer also considers voltage regulation. the proposed algorithm has been implemented in a digital control system and its performance experimentally verified on a 83 kva synchronous generator connected to the power system. experimental results referring to the change in voltage and mechanical power reference, for disconnection of the transmission line, three phase and two phase short circuit, and forced oscillations are presented and compared to a pss2a stabilizer. the experimental results show better performance of the excitation system with the proposed stabilizer compared to the system with a conventional pi voltage controller and pss2a stabilizer. furthermore, the results show that the proposed stabilizer is robust to system changes in the case of small and large disturbances, as well as near the generator stability limit. (c) 2016 elsevier b.v. all rights reserved.
system_identification	this paper proposes a cascaded control structure and a method of practical application for attitude control of a multi-rotor unmanned aerial vehicle (uav). the cascade control, which has tighter control capability than a single-loop control, is rarely used in attitude control of a multi-rotor uav due to the input-output relation, which is no longer simply a set-point to euler angle response transfer function of a single-loop pid control, but there are multiply measured signals and interactive control loops that increase the complexity of evaluation in conventional way of design. however, it is proposed in this research a method that can optimize a cascade control with a primary and secondary loops and a pid controller for each loop. an investigation of currently available pid-tuning methods lead to selection of the simple internal model control (simc) method, which is based on the internal model control (imc) and direct-synthesis method. through the analysis and experiments, this research proposes a systematic procedure to implement a cascaded attitude controller, which includes the flight test, system identification and simc-based pid-tuning. the proposed method was validated successfully from multiple applications where the application to roll axis lead to a pid-pid cascade control, but the application to yaw axis lead to that of pid-pi.
symbolic_computation	as a result of the application of a technique of multistep processes stochastic models construction the range of models, implemented as a self-consistent differential equations, was obtained. these are partial differential equations (master equation, the fokker-planck equation) and stochastic differential equations (langevin equation). however, analytical methods do not always allow to research these equations adequately. it is proposed to use the combined analytical and numerical approach studying these equations. for this purpose the numerical part is realized within the framework of symbolic computation. it is recommended to apply stochastic runge-kutta methods for numerical study of stochastic differential equations in the form of the langevin. under this approach, a program complex on the basis of analytical calculations metasystem sage is developed. for model verification logarithmic walks and black-scholes two-dimensional model are used. to illustrate the stochastic ""predator-prey"" type model is used. the utility of the combined numerical-analytical approach is demonstrated.
pid_controller	for a flexible manipulator system, the unwanted vibrations deteriorate usually the performance of the system due to the coupling of large overall motion and elastic vibration. this paper focuses on the active vibration control of a two-link flexible manipulator with piezoelectric materials. the multi flexible body dynamics (mfbd) model of the two-link flexible manipulator attached with piezoelectric sensors and actuators is established firstly. based on the absolute nodal coordinate formulation (ancf), the motion equations of the manipulator system are derived and motion process and dynamic responses of the system are simulated. according to the time varying feature of system, a fuzzy pid controller is developed to depress the vibration. this controller can tune control gains online accommodating to the variation of the system. control results obtained by the fuzzy pid control and the conventional pid control indicate that the fuzzy pid controller can effectively suppress the elastic vibration of the manipulator system and performs better than the conventional pid controller.
electricity	when talking about energy conservation, ""rebound effect"" (re) is always concerned, which defined as the increasing energy consumption relative to the counterfactual predicted by technological progress because of efficiency induced decrease in the real price of energy services. in this paper, we try to find a way to figure out the re through calculating the substitution relations accord with the definition. based on the trans-log cost function and considering the asymmetric impact on energy-cost share equation, the paper applies allen-uzawa substitution elasticity to establish the price-oriented analysis diagram of fossil-energy consumption re. 'using time series data, applying the joint method of the dynamic ols (dols) and the seemingly unrelated regressions (sur), the re in china 's electricity generation sector is estimated. the results showed that the re is 11.6% in china 's electricity generation sector if allowing for asymmetric price effects, which indicates that china 's power generation sector generally displays a feature of energy saving.
digital_control	fuel cell (fc)/lithium-ion battery hybrid power system (hps) gradually becomes a powerful energy source in the future. this paper presents a digital boost converter for fc current regulation in the hps with a dual-battery energy storage unit (esu). the digital boost converter regulates the fc current in order to control the fc power generation. simulations have been conducted in psim environment, and the digital controller is implemented with a microchip dspic33fj06gs202 16-bit microcontroller. experimental results show that the efficiency of power conversion can reach to 85%.
electricity	the paper aims to determine the day-ahead market bidding strategies for retailers with flexible demands to maximize the short-term profit. it proposes a short-term planning framework to forecast the load under dynamic tariffs and construct biding curves. stochastic programming is applied to manage the uncertainties of spot price, regulating price, consumption behaviors, and responsiveness to dynamic tariffs. a case study based on data from sweden is carried out. it demonstrates that a real-time selling price can affect the aggregate load of a residential consumer group and lead to load shift toward low-price periods. the optimal bidding curves for specific trading periods are illustrated. through comparing the bidding strategies under different risk factors, the case study shows that a risk-averse retailer tends to adopt the strategies with larger imbalances. the benefit lies in the reduction of low-profit risk. however, the aversion to risk can only be kept in a certain level. a larger imbalance may lead to a quick reduction of profit in all scenarios.
distributed_computing	we present fabsim, a toolkit developed to simplify a range of computational tasks for researchers in diverse disciplines. fabsim is flexible, adaptable, and allows users to perform a wide range of tasks with ease. it also provides a systematic way to automate the use of resources, including hpc and distributed machines, and to make tasks easier to repeat by recording contextual information. to demonstrate this, we present three use cases where fabsim has enhanced our research productivity. these include simulating cerebrovascular bloodflow, modelling clay-polymer nanocomposites across multiple scales, and calculating ligand-protein binding affinities.
analog_signal_processing	this paper reports a suspended coil, electromagnetic acoustic energy harvester (aeh) for extracting acoustical energy. the developed aeh comprises helmholtz resonator (hr), a wound coil bonded to a flexible membrane and a permanent magnet placed in a magnet holder. the harvester 's performance is analyzed under different sound pressure levels (spls) both in laboratory and in real environment. in laboratory, when connected to 50 omega load resistance and subjected to an spl of 100 db, the aeh generated a peak load voltage of 198.7 mv at the resonant frequency of 319 hz. when working under the optimum load resistance, the aeh generated an optimum load power of 789.65 mu w. in real environment, the developed aeh produced a maximum voltage of 25 mv when exposed to the acoustic noise of a motorcycle and generated an optimum voltage of 60 mv when it is placed in the surroundings of a domestic electrical generator.
operational_amplifier	radiation hardness of different samples of the same ics can vary greatly from lot to lot, depending on the year or the country of production. however, it is assumed that radiation hardness of the samples from the same lot is the same too. the new chip uniformity test method based on ionization response comparison is offered.
machine_learning	gene regulation modulates rna expression via transcription factors. posttranscriptional gene regulation in turn influences the amount of protein product through, for example, micrornas (mirnas). experimental establishment of mirnas and their effects is complicated and even futile when aiming to establish the entirety of mirna target interactions. therefore, computational approaches have been proposed. many such tools rely on machine learning (ml) which involves example selection, feature extraction, model training, algorithm selection, and parameter optimization. different ml algorithms have been used for model training on various example sets, more than 1,000 features describing pre-mirnas have been proposed and different training and testing schemes have been used for model establishment. for pre-mirna detection, negative examples cannot easily be established causing a problem for two class classification algorithms. there is also no consensus on what ml approach works best and, therefore, we set forth and established the impact of the different parts involved in ml on model performance. furthermore, we established two new negative datasets and analyzed the impact of using them for training and testing. it was our aim to attach an order of importance to the parts involved in ml for pre-mirna detection, but instead we found that all parts are intricately connected and their contributions cannot be easily untangled leading us to suggest that when attempting ml-based pre-mirna detection many scenarios need to be explored.
electric_motor	swimming exercise at optimal speed may optimize growth performance of yellowtail kingfish in a recirculating aquaculture system. therefore, optimal swimming speeds (u-opt in m s(-1) or body lengths s(-1), bl s(-1)) were assessed and then applied to determine the effects of long-term forced and sustained swimming at u-opt on growth performance of juvenile yellowtail kingfish. uopt was quantified in blazka-type swim-tunnels for 145, 206, and 311 mm juveniles resulting in values of: (1) 0.70 m s(-1) or 4.83 bl s(-1), (2) 0.82 m s(-1) or 3.25 bl s(-1), and (3) 0.85 m s(-1) or 2.73 bl s(-1). combined with literature data from larger fish, a relation of u-opt (bl s(-1)) = 234.07(bl)(-0.779) (r-2 = 0.9909) was established for this species. yellowtail kingfish, either forced to perform sustained swimming exercise at an optimal speed of 2.46 bl s(-1) (""swimmers"") or allowed to perform spontaneous activity at low water flow (""resters"") in a newly designed 3600 l oval flume (with flow created by an impeller driven by an electric motor), were then compared. at the start of the experiment, ten fish were sampled representing the initial condition. after 18 days, swimmers (n = 23) showed a 92% greater increase in bl and 46% greater increase in bvv as compared to resters (n = 23). as both groups were fed equal rations, feed conversion ratio (fcr) for swimmers was 1.21 vs. 1.74 for resters. doppler ultrasound imaging showed a statistically significant higher blood flow (31%) in the ventral aorta of swimmers vs. resters (44 +/- 3 vs. 34 +/- 3 ml min(-1), respectively, under anesthesia). thus, growth performance can be rapidly improved by optimal swimming, without larger feed investments.
bioinformatics	although many changes have been discovered during heart maturation, the genetic mechanisms involved in the changes between immature and mature myocardium have only been partially elucidated. here, gene expression profile changed between the human fetal and adult heart was characterized. a human microarray was applied to define the gene expression signatures of the fetal (13-17 weeks of gestation, n = 4) and adult hearts (30-40 years old, n = 4). gene ontology analyses, pathway analyses, gene set enrichment analyses, and signal transduction network were performed to predict the function of the differentially expressed genes. ten mrnas were confirmed by quantificational real-time polymerase chain reaction. 5547 mrnas were found to be significantly differentially expressed. ""cell cycle"" was the most enriched pathway in the down-regulated genes. efgr, igf1r, and itgb1 play a central role in the regulation of heart development. egfr, igf1r, and fgfr2 were the core genes regulating cardiac cell proliferation. the quantificational real-time polymerase chain reaction results were concordant with the microarray data. our data identified the transcriptional regulation of heart development in the second trimester and the potential regulators that play a prominent role in the regulation of heart development and cardiac cells proliferation.
signal-flow_graph	this paper presents new cmos current-mode ladder chebyshev and elliptic band-pass filters (bpfs). the signal flow graph and the network transformation methods are used to synthesize the proposed bpfs by using chebyshev and elliptic rlc low-pass prototypes. cmos-based lossy and lossless integrators with grounded capacitors are used to synthesize the proposed bpfs. the proposed filters can be electronically tuned between 10 khz and 100 mhz by adjusting the bias current from 0.02 mu a to 200 mu a. both filters use a 1.5 v dc power supply, which leads to low dynamic power consumption. both filters enjoy total harmonic distortion of less than 1.5% along the range of the tuning bias currents. simulation results are included to illustrate the functionality of the proposed filters.
pid_controller	the grey wolf optimization algorithm is proposed to design proportional, integrative and derivative controllers using a two degrees of freedom control configuration. the control system is designed in order to achieve good set-point tracking and disturbance rejection performance. the design is accomplished by minimizing an aggregated cost function based on the time-weighted absolute error integral, subjected to robustness constraints. the control system robustness levels are prescribed in terms of the vector margin and maximum complementary sensitivity function values. simulation results are presented for several common systems dynamics and compared with the ones obtained with a particle swarm optimization algorithm.
operational_amplifier	this paper proposes a novel analog circuit verification approach using causal reasoning. to verify analog circuits, the flow begins with mining the causal reasoning steps (design plan) that produced the circuit, including starting ideas, design step sequence, and their justification [1]. then, topological structures corresponding to the starting ideas and design step sequences are verified individually by replacing the related devices with ideal amplifier model. circuit performance is evaluated through spectre simulation. comparing simulation results reveals incorrect functional issues and/or performance drawbacks (negative causes) of certain starting ideas or design steps, which might have been omitted during the design process. the paper discusses three operational amplifier designs realized in 0.2-mu m cmos technology to illustrate the verification approach.
system_identification	the electromagnetic actuators are widely used in the industry due to their simple structure, force characteristics, and low manufacturing costs. however, from control point of view, they are nonlinear systems. in this brief, clustering-based system identification experiments as well as a piecewise mathematical model are described. furthermore, a model-based fault detection and isolation of the actuator is presented, when the armature movement is sensed indirectly, by sensing only the armature current.
signal-flow_graph	we derive a unified graph-theoretic approach to continuous and discrete phase-type distributions. the algorithms are given to obtain the signal-flow graph directly from either the matrix representation of the distribution or from the transition diagram of the underlying markov chain. the transfer function of the signal-flow graph, easily computable using mason 's rule, gives the characteristic function of the phase-type distribution in a symbolic form. the proposed approach intrinsically includes non-trivial initial probabilities of the states. moreover, in the continuous case, it results in graphs that are simpler to obtain than those found in the literature. finally, we show that the approximate discrete counterpart of the continuous phase-type distribution can be viewed as the forward difference (euler) mapping between continuous and discrete time domains. (c) 2006 elsevier b.v. all rights reserved.
state_space_representation	this paper presents a cost effective control algorithm for standalone batteryless photovoltaic (pv) systems. the control is driven by a fuzzy-based maximum power point tracker which has the capabilities to maintain high-energy conversion efficiency under different weather and load conditions. general design considerations are presented based on the linearization of the dynamic model of the entire system which consists of pv panel, cuk converter, and motor load. for our particular fuzzy-mppt controller, these design considerations are combined with an artificial intelligent technique to achieve the optimum control design. furthermore, the developed control algorithm has voltage regulation capability to protect the load from overvoltage during light load conditions and a fast digital overload protection. the transient and steady-state performance of the entire system was modeled by a nonlinear state-space representation. the proposed control is simulated in matlab and experimentally tested under the fast variation of climatic conditions for verification purposes a very good agreement has been shown between theoretical, simulations, and experimental results
electrical_network	in order to take full advantage of distributed generators, an evolution of the classical power system organization and management is also necessary. an aggregator of a residential urban electrical network can be considered by the distribution system operator as a stakeholder, which is able to control a cluster of local generators and loads with technical constraints for the connection with the remaining distribution grid and commercial contracts with outer electrical producers. this paper is focused on the design of the microgrid central energy management system which relies on a day-ahead operational planning and an online adjustment procedure during the operation. a dynamic programming-based algorithm is derived to solve the unit commitment problem with a multiobjective function in order to reduce the economic cost and co2 equivalent emissions. the proposed energy management system is implemented into a supervisory control and data acquisition (scada) and tested by using a hardware-in-the-loop simulation of the urban network. economic and environmental gains are evaluated.
signal-flow_graph	we describe a complete, fast implementation to compute a 2d discrete cosine transform. we briefly discuss the hardware model for which we are developing a toolkit. we employ an 11 x 8 array of common processors handling data at the level of words with automatic data flow synchronization. we present a general software solution as opposed to a custom-built hardware description. the solution is a unique composition of two, algorithms, yielding a systolic (highly parallel with regular data flow) implementation. it is efficient as utilization of resources is high. although the solution is computationally intensive, it is suitable for real-time applications as the input data, which is an infinite sequence of 8 x 8 matrices, is input one row at a time continuously. finally, we discuss programming tools which are needed to ease the programming effort. we hope this work demonstrates the importance of such tools.
cryptography	with the rapid advancement of wireless technologies, distinct futuristic applications of wireless sensor networks (wsns) are evolving for both public and private domains. however, wireless sensor nodes experience the major challenges in terms of power supply, computing capabilities and bandwidth requirements during the data communication. apart from these, data confidentiality and integrity suffer due to various transmission errors caused by channel noise, channel bandwidth limitation, weak signals, limitation of transmitting and receiving devices as well as different security attacks. various researches have been conducted to resolve these issues in an integrated way. nevertheless, existing literature does not offer any effective solution to resolve these issues. hence, this paper proposes a unique elliptic curve based cryptography along with the diffie-hellman key exchange technique to address these issues. the experimental results show that the proposed technique consumes low power and utilizes cpu time effectively by offering better throughput and low cyclomatic complexity. it enhances confidentiality by producing higher avalanche effect and entropy value than the existing techniques. the capacity of generating higher signal to noise ratio and lower percentage of information loss justify its efficiency to produce higher data integrity as compared to the existing schemes in the literature.
machine_learning	autism spectrum disorder (asd) is a complex neurodevelopmental disorder mainly showed atypical social interaction, communication, and restricted, repetitive patterns of behavior, interests and activities. now clinic diagnosis of asd is mostly based on psychological evaluation, clinical observation and medical history. all these behavioral indexes could not avoid defects such as subjectivity and reporter-dependency. therefore researchers devoted themselves to seek relatively stable biomarkers of asd as supplementary diagnostic evidence. the goal of present study is to generate relatively stable predictive model based on anatomical brain features by using machine learning technique. forty-six asd children and thirty-nine development delay children aged from 18 to 37 months were evolved in. as a result, the predictive model generated by regional average cortical thickness of regions with top 20 highest importance of random forest classifier showed best diagnostic performance. and random forest was proved to be the optimal approach for neuroimaging data mining in small size set and thickness-based classification outperformed volume-based classification and surface area-based classification in asd. the brain regions selected by the models might attract attention and the idea of considering biomarkers as a supplementary evidence of asd diagnosis worth exploring. autism res2017, 0: 000-000. (c) 2016 international society for autism research, wiley periodicals, inc. autism res 2017, 10: 620-630. (c) 2016 international society for autism research, wiley periodicals, inc.
software_engineering	socially assistive robotics is an important emerging research area. socially assistive robotics is challenging as it is required to move robots out of laboratories and industrial settings to interact with ordinary human beings as peers, which requires social skills. the design process usually requires multidisciplinary research teams, which may comprise subject matter experts from various domains such as robotics, systems integration, medicine, psychology, gerontology, social and cognitive sciences, and neuroscience, among many others. unlike most other robotic applications, socially assistive robotics faces some unique software and systems integration challenges. in this paper, the healthbot robot architecture, which was designed to overcome these challenges, is presented. the presented architecture was implemented and used in several field trials. the details of the field trials are presented, and lessons learned are discussed with field trial results.
digital_control	a grid-connected inverter is indispensable for photovoltaic power generation and smart grid systems, and it must be designed for stable operation. the impedance method based on the nyquist criterion is often utilized to analyze the stability of grid-connected inverter systems. the impedance method is based on the eigenvalues of the product of the inverter output admittance and the line impedance matrices in the frequency domain. however, the frequency characteristics have so far been derived only for inverters with analog control systems. a new frequency analysis method for inverters with digital control systems is proposed in this paper. first, a stability analysis example for a three-phase lcl-type inverter controlled digitally is shown and the results are compared and validated with those by simulation using a saber simulator. finally, they are also compared and validated with experimental results digitally controlled by a dsp-based system. (c) 2017 wiley periodicals, inc.
control_engineering	soil degradation is one of the most serious ecological problems in the world. in arid and semi-arid northern china, soil degradation predominantly arises from wind erosion. trends in soil degradation caused by wind erosion in northern china frequently change with human activities and climatic change. to decrease soil loss by wind erosion and enhance local ecosystems, the chinese government has been encouraging residents to reduce wind-induced soil degradation through a series of national policies and several ecological projects, such as the natural forest protection program, the national action program to combat desertification, the ""three norths"" shelter forest system, the beijing-tianjin sand source control engineering project, and the grain for green project. all these were implemented a number of decades ago, and have thus created many land management practices and control techniques across different landscapes. these measures include conservation tillage, windbreak networks, checkerboard barriers, the non-watering and tube-protecting planting technique, afforestation, grassland enclosures, etc. as a result, the aeolian degradation of land has been controlled in many regions of arid and semiarid northern china. however, the challenge of mitigating and further reversing soil degradation caused by wind erosion still remains.
analog_signal_processing	in this study, a new voltage mode notch filter based on current differencing transconductance amplifier (cdta), which is a recently common used active building block in analog signal processing applications, is presented. the proposed filter 's performance has been evaluated by pspice. in simulation the mosis cmos 0.35 mu m model parameters used for cmos based cdta. the simulation results show that the proposed filter has high performance in terms of working both at low and high frequencies. it was seen that the simulation results verified the theory. also, the sensitivities of the passive circuit components are shown to be low.
data_structures	trees are a fundamental structure in algorithmics. in this paper, we study the transformation of an arbitrary binary tree s with n vertices into a completely balanced tree t via rotations, a widely studied elementary tree operation. combining concepts on rotation distance and data structures, we give a basic algorithm that performs the transformation in i similar to(n) time and i similar to(1) space, making at most 2n - 2 log(2)n rotations and improving on known previous results. the algorithm is then improved, exploiting particular properties of s. finally, we show tighter upper bounds and obtain a close lower bound on the rotation distance between a zig-zag tree and a completely balanced tree. we also find the exact rotation distance of a particular almost balanced tree to a completely balanced tree, and thus show that their distance is quite large despite the similarity of the two trees.
electricity	more than two decades have passed since the start of the worldwide market-oriented electricity sector reforms. the reforms have varied in terms of structure, market mechanisms, and regulation. however, the passage of time calls for taking stock of the performance of the reforms in developing countries. this paper surveys the empirical literature on electricity sector reforms and draws some conclusions with a view to the future. overall, the reforms have tended to improve the technical efficiency of the sector. the macroeconomic benefits of reforms are less clear and remain difficult to identify. also, the gains from the reforms have often not trickled down to consumers because of institutional and regulatory weaknesses. in order to achieve lasting benefits, reforms need to adopt measures that align their pursuit of economic efficiency with those of equity and provision of access. reforms can deliver more economic benefits and alleviate poverty when the poor have access to electricity. new technologies and institutional capacity building can help improve the performance of reforms.
computer_graphics	increasing networking performances as well as the emergence of mixed reality (mr) technologies make possible providing advanced interfaces to improve remote collaboration. in this paper, we present our novel interaction paradigm called vishnu that aims to ease collaborative remote guiding. we focus on collaborative remote maintenance as an illustrative use case. it relies on an expert immersed in virtual reality (vr) in the remote workspace of a local agent helped through an augmented reality (ar) interface. the main idea of the vishnu paradigm is to provide the local agent with two additional virtual arms controlled by the remote expert who can use them as interactive guidance tools. many challenges come with this: collocation, inverse kinematics (ik), the perception of the remote collaborator and gestures coordination. vishnu aims to enhance the maintenance procedure thanks to a remote expert who can show to the local agent the exact gestures and actions to perform. our pilot user study shows that it may decrease the cognitive load compared to a usual approach based on the mapping of 2d and de-localized informations, and it could be used by agents in order to perform specific procedures without needing to have an available local expert.
computer_graphics	in this paper, we conduct research on the computer graphics rendering technology based on gpu and parallel computing system. traditional geometry based on the polygon rendering technique, due to difficulty in modeling and rendering time is too long, has been more and more cannot adapt to the large-scale complex scene accurately modeling and real-time display. on the other hand, with the improvement of image acquisition equipment precision and falling prices is easy to get high precision of image information, based on image rendering technology gradually become one of the main means of scene rendering. under this basis circumstance we propose the new perspective of the methodology that will optimize the traditional ways and provide systematic modification.
operating_systems	one key aspect of synthetic biology is the development and characterization of modular biological building blocks that can be assembled to construct integrated cell-based circuits performing computational functions. likewise, the idea of extracting biological modules from the cellular context has led to the development of in vitro operating systems. this principle has attracted substantial interest to extend the repertoire of functional materials by connecting them with modules derived from synthetic biology. in this respect, synthetic biological switches and sensors, as well as biological targeting or structure modules, have been employed to upgrade functions of polymers and solid inorganic material. the resulting systems hold great promise for a variety of applications in diagnosis, tissue engineering, and drug delivery. this review reflects on the most recent developments and critically discusses challenges concerning in vivo functionality and tolerance that must be addressed to allow the future translation of such synthetic biology-upgraded materials from the bench to the bedside. (c) 2016 elsevier b.v. all rights reserved.
data_structures	there are billions of lines of sequential code inside nowadays' software which do not benefit from the parallelism available in modern multicore architectures. automatically parallelizing sequential code, to promote an efficient use of the available parallelism, has been a research goal for some time now. this work proposes a new approach for achieving such goal. we created a new parallelizing compiler that analyses the read and write instructions, and control-flow modifications in programs to identify a set of dependencies between the instructions in the program. afterwards, the compiler, based on the generated dependencies graph, rewrites and organizes the program in a task-oriented structure. parallel tasks are composed by instructions that cannot be executed in parallel. a work-stealing-based parallel runtime is responsible for scheduling and managing the granularity of the generated tasks. furthermore, a compile-time granularity control mechanism also avoids creating unnecessary data-structures. this work focuses on the java language, but the techniques are general enough to be applied to other programming languages. we have evaluated our approach on 8 benchmark programs against ooojava, achieving higher speedups. in some cases, values were close to those of a manual parallelization. the resulting parallel code also has the advantage of being readable and easily configured to improve further its performance manually.
system_identification	this study presents a class of fractional order models for system identification of thermal dynamics of buildings. fractional order dynamics has been found to be inherent in the nature of heat transfer problems. it is thus instinctive to use fractional order models to describe the overall thermal dynamics of a building. besides, fractional time series modeling is known by its long memory effect and capability of representing high-order complicated models in lower-order and compact forms. the reduction of model parameters can then relieve the computational overhead in the system identification procedure. this is of particular significance in model-based predictive control for building energy efficiency. in particular, a fractional order autoregressive model with exogenous input (farx) is formulated and a corresponding parameter estimation using least squares technique is also provided. furthermore, the farx model is validated using simulation data from a detailed model built via iessoftware and compared with the prediction using traditional arx model. it is found that the farx model can reduce the computational time largely while retaining the prediction accuracy. (c) 2016 the authors. published by elsevier b.v.
symbolic_computation	under consideration in this paper is a volterra lattice system. through symbolic computation, the lax pair and conservation laws are derived, an integrable lattice hierarchy and an n-fold darboux transformation (dt) are constructed for this system. furthermore, n-soliton solutions in terms of determinant are generated with the resulting n-fold dt. structures of the one-, two-and three-soliton solutions are shown graphically. overtaking inelastic solitonic interactions between/among the two and three solitons are discussed by figures plotted.
electrical_circuits	a novel low voltage high power multi-phase inverter is presented. based on an already designed iscad machine the specification of an electrical power up to 240 kw at a dc-link voltage below 60 v has to be achieved. for spreading the high currents and the corresponding power losses a 60 phase machine is built up. each phase is connected with one dedicated half-bridge, which includes power components and the driver circuit. the requirements on electrical circuits and components are investigated to ensure a safe operation of the system against voltage transients. further simulations show the electrical and thermal behavior of the printed circuit boards. experimental results validate the simulations and show the system boundaries.
computer_graphics	digital restoration of film content that has historical value is crucial for the preservation of cultural heritage. also, digital restoration is not only a relevant application area of various video processing technologies that have been developed in computer graphics literature but also involves a multitude of unresolved research challenges. currently, the digital restoration workflow is highly labor intensive and often heavily relies on expert knowledge. we revisit some key steps of this workflow and propose semiautomatic methods for performing them. to do that we build upon state-of-the-art video processing techniques by adding the components necessary for enabling (i) restoration of chemically degraded colors of the film stock, (ii) removal of excessive film grain through spatiotemporal filtering, and (iii) contrast recovery by transferring contrast from the negative film stock to the positive. we show that when applied individually our tools produce compelling results and when applied in concert significantly improve the degraded input content. building on a conceptual framework of film restoration ensures the best possible combination of tools and use of available materials. (c) 2017 spie and is&t
control_engineering	nowadays online resources play an important role in teaching and learning thanks to new advances in technology. this importance is enhanced in scientific areas and even more for distance education universities, where the classic hands-on laboratories are not always possible. for that reason, this face-to-face laboratory practices have been replaced or even complemented with online virtual and remote laboratories vrl. normally, these applications are developed with high level programming tools, and these, to greater or lesser extent, use java. unfortunately, the newly discovered java security issues and the impossibility to run java in smart devices are an restriction to the dissemination of this kind of applications. this work is the first step towards get a new structure to easy java/javascript simulations (ejss) that allows a remote connection with hardware devices. in this regard, the first objective is to solve the problems with java applications when using ejss. the proposed solution provides the user a structure to reuse their vrls using a java model that runs in a server and is linked with a javascript graphical user interface in the client device. (c) 2016, ifac (international federation of antomatic control) hosting by elsevier ltd. all rights reserved.
computer_programming	one of the major challenges related to teaching programming and algorithmics to amateur students is the time spent to explain a language 's syntax. also, students who undertake computer programming may find problems that hinder their understanding of concepts and the development of their problem-solving and programming skills. this paper presents the results of an experimental approach that evaluated the interaction of a group of colombian students with a web solution within the context of mobile robotics to learn programming and algorithmics. the designed web app is oriented towards autodidactic learning by using visual blocks programming through five interactive modules that include concepts to be learned by students such as the following: variables, sensors, conditionals, cycles, and functions. the solution is designed to present virtual scenarios for mobile robotics. this proposal was evaluated with middle school students from the colombian education system and was compared to the results obtained using scratch as a reference tool.
machine_learning	we present a methodology based on matrix factorization and gradient descent to predict the number of sessions established in the access points of a wi-fi network according to the users' behavior. as the network considered in this work is monitored and controlled by software in order to manage users and resources in real time, we may consider it as a cyber-physical system that interacts with the physical world through access points, whose demands can be predicted according to users' activity. these predictions are useful for relocating or reinforcing some access points according to the changing physical environment. in this work we propose a prediction model based on machine learning techniques, which is validated by comparing the prediction results with real user 's activity. our experiments collected the activity of 1095 users demanding 26,673 network sessions during one month in a wi-fi network composed of 10 access points, and the results are qualitatively valid with regard to the previous knowledge. we can conclude that our proposal is suitable for predicting the demand of sessions in access points when some devices are removed taking into account the usual activity of the network users. (c) 2017 elsevier b.v. all rights reserved.
control_engineering	multilevel inverters generate high-level voltage with high quality and low-harmonic distortion, and these unique properties have increased their applications in renewable energy sources. however, these inverters require several passive components and a complex pulse width modulation (pwm) control method. besides, they suffer from voltage balancing problems. in this work, a new inverter has proposed that generates seven-level voltage from one dc source by reduced number of switches which does not exhibit any voltage balancing problem. the proposed inverter without any extra boost circuit is able to increase the input voltage. the voltage stress on all the switches in the proposed inverter is the same. in this study, variable amplitude phase disposition pwm control method that is compatible with the proposed inverter is developed. moreover, extended structure of the proposed inverter and its new algorithm in generating all odd and even voltage levels are proposed. to validate the performance of the inverter, a prototype has been built and tested and also its performance has been modelled using pscad/emtdc software package. very good agreement has been achieved between experimental results and simulations.
relational_databases	use of cloud database-as-a-service (daas) is gradually increasing in private and government organizations. organizations are now considering outsourcing of their local databases to cloud database servers to minimize their operational and maintenance expenses. at the same time, users are apprehensive about the confidentiality breach of their vital data in cloud database. to achieve complete confidentiality of such data in outsourced databases, it is required to keep data in alwaysencrypted form in its entire life cycle i. e. at rest, in transition and while in operation in premises of cloud database services. searchable encryption is a scheme, which allows users to perform an encrypted keyword search on encrypted data stored in database server directly without decrypting it. in many applications, it requires to access the database by multiple users where data is written by different users using different encryption keys. in this paper, we propose schemes for multi user multi-key encryption search for cloud relational databases (mes-rd). it supports search operation on data encrypted under different keys by multiple users using a trusted proxy. these data may be stored in a shared table under one or other column of database server. to the best of our knowledge, the proposed schemes mes-rd are practical and first time proposed for databases.
electric_motor	the importance of fault diagnoses, in any kind of machinery, ca n't be over stated. any undetected small fault in machinery will most probably rise with time and will cause machinery to shut down thus resulting in both mechanical and more importantly economical loss for the industry. in recent years, researches have been done for the faults diagnosis through the analysis of their vibration and sound signatures. the extraction of those characteristic signatures is a complicated process because complexities in modern day machineries can results in many vibration and sound generating sources. this paper presents a condition based fault diagnoses technique to detect the condition of gear. an experimental setup, consisting of a worm gear driven by an electric motor, was setup to conduct tests under different working conditions. the vibration and sound signature signals of worm gear were examined for normal and faulty conditions under different speeds and oil levels. the collected data was then used for feature extraction, by using fast fourier transform to filter background noise signals and to collect only the signature of the gearbox vibration and sound signals. an mlp (multilayer perceptron) artificial neural network model has been developed to classify the signature signals. a thermal camera is also used to observe the heating patterns for all those working conditions. with the help of mlp artificial neural network it is possible to predict the speed and oil level of the gearbox and hence a possible fault diagnoses is also feasible. (c) 2016 elsevier ltd. all rights reserved.
network_security	data communication and network have changed the way business and other daily affair works. now, they rely on computer network and internetwork. computer network is a telecommunication channel through which we can share our data. it is also called data network. security for data transmission is one of the important aspects to be considered in modern communication system. in this paper data that is to be transferred is sent in certain pattern which is embedded in the huge amount of data that can be seen by everyone. the effectiveness of the proposed method is described in such a way to increase security of data. to hide data in a binary image, no key is needed here rather this algorithm is based on binary tree traversal through which the bits are plotted in msb (most significant bit), lsb(least significant bit) and middle bit of a byte. the proposed algorithm assures the data hiding and security.
operating_systems	we describe and evaluate a software-only implementation of a novel mechanism for accessing and streaming gpu-rendered content from the cloud to low-end user devices. the unique properties of our implementation enable the trivial cloud-deployment of graphics-intensive applications, even ones that were not originally intended to run in the cloud. we achieve this goal by creating virtual gpu nodes that appear to the application like hardware devices, but that do not incur the overhead of virtualization. the low-level access to the frame buffer maximizes the number of applications that work out-of-the-box without the system imposing any specific display manager or windowing system.
computer_vision	a microscope vision system to retrieve small metallic surface via micro laser line scanning and genetic algorithms is presented. in this technique, a 36 pm laser line is projected on the metallic surface through a laser diode head, which is placed to a small distance away from the target. the micro laser line is captured by a ccd camera, which is attached to the microscope. the surface topography is computed by triangulation by means of the line position and microscope vision parameters. the calibration of the microscope vision system is carried out by an adaptive genetic algorithm based on the line position. in this algorithm, an objective function is constructed from the microscope geometry to determine the microscope vision parameters. also, the genetic algorithm provides the search space to calculate the microscope vision parameters with high accuracy in fast form. this procedure avoids errors produced by the missing of references and physical measurements, which are employed by the traditional microscope vision systems. the contribution of the proposed system is corroborated by an evaluation via accuracy and speed of the traditional microscope vision systems, which retrieve micro-scale surface topography.
data_structures	genetic sequences of multiple genes are becoming increasingly common for a wide range of organisms including viruses, bacteria and eukaryotes. while such data may sometimes be treated as a single locus, in practice, a number of biological and statistical phenomena can lead to phylogenetic incongruence. in such cases, different loci should, at least as a preliminary step, be examined and analysed separately. the r software has become a popular platform for phylogenetics, with several packages implementing distance-based, parsimony and likelihood-based phylogenetic reconstruction, and an even greater number of packages implementing phylogenetic comparative methods. unfortunately, basic data structures and tools for analysing multiple genes have so far been lacking, thereby limiting potential for investigating phylogenetic incongruence. in this study, we introduce the new r package apex to fill this gap. apex implements new object classes, which extend existing standards for storing dna and amino acid sequences, and provides a number of convenient tools for handling, visualizing and analysing these data. in this study, we introduce the main features of the package and illustrate its functionalities through the analysis of a simple data set.
computer_vision	efficiently and effectively detecting shell-like structures of particular shapes is an important task in computer vision and image processing. this paper presents a generalized possibilistic c-means algorithm (pcm) for shell clustering based on the diversity index of degree-lambda proposed by patil and taillie [diversity as a concept and its measurement. j amer statist assoc. 1982;77:548-561]. experiments on various data sets in wang [possibilistic shell clustering of template-based shapes. ieee trans fuzzy syst. 2009;17:777-793] show that the the proposed generalized pcm performs better than wang 's [possibilistic shell clustering of template-based shapes. ieee trans fuzzy syst. 2009;17:777-793] possibilistic shell clustering method according two two criteria: (i) the 'grade of detection' g(d) for each target cluster; (ii) the amount of computation, denoted as k(c), required to attain a given g(d).
electric_motor	satellite systems offer several advantages to wireless internet communications. nevertheless, satellite radio links are affected by two severe problems, namely long propagation delays and relatively high error rates, which pose a difficult challenge to the internet protocols and in particular to tcp. among the potential solutions, we are specifically interested in the tcp enhancements that preserve the end-to-end semantics of tcp. in this paper, the authors evaluate the performance improvements provided by some additional features, when applied to tcp west-wood (tcpw), a promising transport protocol specifically designed to cope with errors on wireless links. this enhanced version (e-tcpw) is compared with both the original tcpw and other known tcp variants (newreno, sack, hybla), considering goodput, fairness and friendliness as performance figures. results, obtained through ns-2 simulations, seem very encouraging and suggest the inclusion of the proposed additional features in the future official versions of tcpw.
algorithm_design	suppose x is any exactly k-sparse vector in r-n. we present a class of sparse matrices a, and a corresponding algorithm that we call short and fast(1) (sho-fa) that, with high probability over a, can reconstruct x from ax. the sho-fa algorithm is related to the invertible bloom lookup tables recently introduced by goodrich et al., with two important distinctions-sho-fa relies on linear measurements, and is robust to noise. the sho-fa algorithm is the first to simultaneously have the following properties: 1) it requires only o(k) measurements; 2) the bit precision of each measurement and each arithmetic operation is o(log(n) + p) (here, 2(-p) corresponds to the desired relative error in the reconstruction of x); 3) the computational complexity of decoding is o(k) arithmetic operations and that of encoding is o(n) arithmetic operations; and 4) if the reconstruction goal is simply to recover a single component of x instead of all of x, with significant probability over a, this can be done in constant time. all the above constants are independent of all problem parameters other than the desired probability of success. for a wide range of parameters, these properties are information-theoretically order-optimal. in addition, our sho-fa algorithm works over fairly general ensembles of sparse random matrices, and is robust to random noise and (random) approximate sparsity for a large range of k. in particular, suppose the measured vector equals a(x + z) + e, where z and e correspond to the source tail and measurement noise, respectively. under reasonable statistical assumptions on z and e, our decoding algorithm reconstructs x with an estimation error of o(parallel to z parallel to(2) + parallel to e parallel to(2)). the sho-fa algorithm works with high probability over a, z, and e, and still requires only o(k) steps and o(k) measurements over o(log(n))-bit numbers. this is in contrast to most existing algorithms that focus on the worst case z model, where it is known that omega(k log(n/k)) measurements over o(log(n))-bit numbers are necessary. our algorithm has good empirical performance, as validated by simulations.
image_processing	sparse representations have proven their efficiency in solving a wide class of inverse problems encountered in signal and image processing. conversely, enforcing the information to be spread uniformly over representation coefficients exhibits relevant properties in various applications such as robust encoding in digital communications. antisparse regularization can be naturally expressed through an l(infinity) -norm penalty. this paper derives a probabilistic formulation of such representations. anew probability distribution, referred to as the democratic prior, is first introduced. its main properties as well as three random variate generators for this distribution are derived. then this probability distribution is used as a prior to promote antisparsity in a gaussian linearmodel, yielding a fully bayesian formulation of antisparse coding. two markov chain monte carlo algorithms are proposed to generate samples according to the posterior distribution. the first one is a standard gibbs sampler. the second one uses metropolis-hastings moves that exploit the proximity mapping of the log-posterior distribution. these samples are used to approximate maximum a posteriori and minimum mean square error estimators of both parameters and hyperparameters. simulations on synthetic data illustrate the performances of the two proposed samplers, for both complete and over-complete dictionaries. all results are compared to the recent deterministic variational fitra algorithm.
electrical_circuits	microwave processed ni1-xmgfe2o4 with x=0.0-1.0 are characterized fordc,ac conductivities and dielectric properties as a function of temperature and frequency. very low dielectric loss tangent is achieved at 5 mhz frequency. grain and grain boundary contribution towards conductivity is presented on the basis of nyquist plots and their resistances are evaluated from semi-circular arcs. equivalent electrical circuits and approximate r-c values are presented for better insight. high dielectric constant of 41 for x= 0.8 sampleinstigated the possibility of good electromagnetic absorption material. a shift in the transport phenomenon is suggested from band like to polaron hopping with rise in temperature.in addition the electromagnetic interference shielding properties are studied in x-band.the results show that the goodelectromagnetic interference shielding efficiency is achieved for x= 0.4-0.6 compositions ranging from 10 to 17 db (at 8.4 ghz) which is suitable for shielding application. (c) 2017 elsevier ltd. all rights reserved.
algorithm_design	much ink has been spilled regarding the trials and tribulations of adapting formal methods to the needs of software engineering practitioners with the exception of computer scientists with a passion for algorithm design and optimization, a plethora of greek letters and symbols can be an anathema to those whose first love is writing code. the advent of graphical modeling languages such as uml, and supporting tools that generate production quality code, executable modeling behavioral simulations for bridging the gap between formalism and coding. this paper proposes, with illustrative examples, an exploratory learning modality, by which the practicing engineer can investigate and empirically learn the semantic mapping of uml syntax to the semantic domains of system instantiation and reactive behavior.
computer_graphics	a tangent vector field on a surface is the generator of a smooth family of maps from the surface to itself, known as the flow. given a scalar function on the surface, it can be transported, or advected, by composing it with a vector field 's flow. such transport is exhibited by many physical phenomena, e.g., in fluid dynamics. in this paper, we are interested in the inverse problem: given source and target functions, compute a vector field whose flow advects the source to the target. we propose a method for addressing this problem, by minimizing an energy given by the advection constraint together with a regularizing term for the vector field. our approach is inspired by a similar method in computational anatomy, known as lddmm, yet leverages the recent framework of functional vector fields for discretizing the advection and the flow as operators on scalar functions. the latter allows us to efficiently generalize lddmm to curved surfaces, without explicitly computing the flow lines of the vector field we are optimizing for. we show two approaches for the solution: using linear advection with multiple vector fields, and using non-linear advection with a single vector field. we additionally derive an approximated gradient of the corresponding energy, which is based on a novel vector field transport operator. finally, we demonstrate applications of our machinery to intrinsic symmetry analysis, function interpolation and map improvement.
system_identification	most studies tackling hysteresis identification in the technical literature follow white-box approaches, i.e. they rely on the assumption that measured data obey a specific hysteretic model. such an assumption may be a hard requirement to handle in real applications, since hysteresis is a highly individualistic nonlinear behaviour. the present paper adopts a black-box approach based on nonlinear state-space models to identify hysteresis dynamics. this approach is shown to provide a general framework to hysteresis identification, featuring flexibility and parsimony of representation. nonlinear model terms are constructed as a multivariate polynomial in the state variables, and parameter estimation is performed by minimising weighted least-squares cost functions. technical issues, including the selection of the model order and the polynomial degree, are discussed, and model validation is achieved in both broadband and sine conditions. the study is carried out numerically by exploiting synthetic data generated via the bouc-wen equations. (c) 2016 elsevier ltd. all rights reserved.
data_structures	a novel dimensionality reduction method named nonlocal and local structure preserving projection (nllspp) is proposed and used for process monitoring. nllspp can simultaneously preserve the nonlocal structure (i.e., data variance) and the local structure (i.e., neighborhood relationships between data points) of the data set. according to nonadjacent or neighboring relationships of different pairs of data points, nllspp defines nonlocal or local similarity weight coefficients for pairwise data points on the basis of their distances. the nonlocal similarity weight coefficients force two nonadjacent data points to be projected far apart from each other. the local similarity weight coefficients force two neighboring data points to be projected near each other. in this way, nonlocal and local structures of the data set are naturally preserved and highlighted in a lower-dimensional space. because of this advantage, nllspp is more powerful than principal component analysis (pca) and locality preserving projections (lpp) in extracting important data characteristics. a process monitoring method is developed based on the nllspp algorithm. its advantages are illustrated by a case study on the tennessee eastman process. the results indicate that the nllspp-based method has better monitoring performance that the pca-based and lpp-based methods. (c) 2016 elsevier b.v. all rights reserved.
electric_motor	this paper describes a complex hybrid terrestrial-satellite mobile network which includes both satellite based network (sbn) and ancillary terrestrial component (atc) components that are integrated via a single logical standards-based core network based on 3gpp and 3gpp2 network entities. next generation session controls are implemented across its all-ip core and transport network via an ims core utilizing sip signaling. two satellite air-interfaces, gmr1-3g and satellite brpd (shrpd), operating over a geo satellite are described and their main and advanced features and performance are reviewed.
computer_graphics	3d mesh segmentation is considered an important process in the field of computer graphics. it is a fundamental process in different applications such as shape reconstruction in reverse engineering, 3d models retrieval, and cad/cam applications, etc. it consists of subdividing a polygonal surface into patches of uniform properties either from a geometrical point of view or from a perceptual/semantic point of view. in this paper, unsupervised clustering techniques for the 3d mesh segmentation problem are introduced. the k-means and the fuzzy c-means (fcm) clustering techniques are selected for the development of the proposed clustering-based 3d mesh segmentation techniques. since the mesh faces are considered the main element, the clustering technique is applied to the dual mesh. the 3d euclidean distance is used as the distance measure to compute matching between mesh elements. based on empirical results on a benchmark dataset of 3d mesh models, the fcm-based mesh segmentation technique outperforms the k-means-based one in terms of accuracy and consistency with human segmentations.
system_identification	signal detection in the presence of high noise is a challenge in natural sciences. from understanding signals emanating out of deep space probes to signals in protein interactions for systems biology, domain specific innovations are needed. the present work is in the domain of transfer alignment (ta), which deals with estimation of the misalignment of deliverable daughter munitions with respect to that of the delivering mother platform. in this domain, the design of noise filtering scheme has to consider a time varying and nonlinear system dynamics at play. the accuracy of conventional particle filter formulation suffers due to deviations from modeled system dynamics. an evolutionary particle filter can overcome this problem by evolving multiple system models through few support points per particle. however, this variant has even higher time complexity for real-time execution. as a result, measurement update gets deferred and the estimation accuracy is compromised. by running these filter algorithms on multiple processors, the execution time can be reduced, to allow frequent measurement updates. such scheme ensures better system identification so that performance improves in case of simultaneous ejection of multiple daughters and also results in better convergence of ta algorithms for single daughter.
state_space_representation	wastewater treatment processes with activated sludge are described in the specialized literature by complex models with nonlinear parameterization, such as for example activated sludge model asm1, asm2 or asm3. under these conditions, the design of control structures using the state space representation is very difficult. suitable techniques to approach the control of these processes are using control structures based on an input-output model or using control structures obtained without even knowing the process model. in this paper two techniques of this type are analyzed: a data driven technique, virtual reference feedback tuning (vrft), and a robust control technique, quantitative feedback theory (qft). the control structures designed by the two methods are implemented using a wastewater treatment plant implemented in the simulation software simba for which a complex influent was considered. the influent includes information on water temperature and gives data for a period of one year. the analysis of the two methods considers the quality of the obtained control results but, at the same time, the difficulty of implementing the two methods.
computer_vision	objectives: the impact of wearing lenses on visual and musculoskeletal complaints in vdu workers is currently unknown. the goal of this study was 1) to evaluate the impact of wearing vdu lenses on visual fatigue and self-reported neck pain and disability, compared to progressive lenses, and 2) to measure the effect of both lenses on head inclination and pressure pain thresholds during the performance of a vdu task. methods: thirty-five eligible subjects were randomly assigned to wear progressive vdu lenses (vdu group) (n = 18) or progressive lenses (p group) (n = 17). they were enquired about visual complaints (vfq), self-perceived pain (nrs) and disability (ndi) at baseline (with old lenses), and 1 week, 3 months and 6 months after wearing their new lenses. in addition, forward head angle (fha) and ppts were assessed during and after a vdu task before and 6 months after wearing the new lenses. a short questionnaire concerning the satisfaction about the study lenses was completed at the end of the study. results: in both groups, visual fatigue and neck pain was decreased at 3 and 6 months follow up, compared to baseline. all ppts were higher during the second vdu task, independent of the type of lenses. the vdu group reported a significantly higher suitability of the lenses for vdu work. conclusion: it can be concluded that there is little difference in effect of the different lenses on visual and musculoskeletal comfort. lenses should be adjusted to the task-specific needs and habits of the participant.
digital_control	in this paper, a current sensorless adaptive secondary-side control is proposed for the series resonant converter (src), making it a good candidate for mhz 48 voltage regulators. by means of varying ac equivalent resistance, the output voltage regulation is achieved by controlling the duty cycle of the synchronous mosfet. by taking advantage of the secondary-side control, srcs can operate under zero-voltage switching at any input voltage and load conditions. a current sensorless adaptive digital control is proposed to control the current-type synchronous mosfets, which automatically compensates the delay caused by the current-sensor circuit and the gate driver, and also eliminates the current sensor in the power path. a hybrid control strategy is introduced to overcome the efficiency degradation caused by the secondary-side control.
computer_vision	automatic computation of surface correspondence via harmonic map is an active research field in computer vision, computer graphics and computational geometry. it may help document and understand physical and biological phenomena and also has broad applications in biometrics, medical imaging and motion capture industries. although numerous studies have been devoted to harmonic map research, limited progress has been made to compute a diffeomorphic harmonic map on general topology surfaces with landmark constraints. this work conquers this problem by changing the riemannian metric on the target surface to a hyperbolic metric so that the harmonic mapping is guaranteed to be a diffeomorphism under landmark constraints. the computational algorithms are based on ricci flow and nonlinear heat diffusion methods. the approach is general and robust. we employ our algorithm to study the constrained surface registration problem which applies to both computer vision and medical imaging applications. experimental results demonstrate that, by changing the riemannian metric, the registrations are always diffeomorphic and achieve relatively high performance when evaluated with some popular surface registration evaluation standards.
microcontroller	an energy-harvesting wireless sensor node (wsn) integrates a 14-nm, 0.79-mm(2), 32-b intel architecture core-based near-threshold voltage (ntv) microcontroller (mcu) that provides 17-mu w/mhz always-on, always-sensing (aoas) capability. the mcu implements four independent voltage-frequency islands, managed by an integrated power management unit and features a subthreshold voltage capable on-die oscillator and 42-nm fin-pitch, 8.3-pa leakage-per-bit sram. the mcu operates across a wide frequency (voltage) range from 297 mhz (1 v) to 0.5 mhz (308 mv), dissipating 23.5 mw to 21 mu w, and achieves 4.8x better energy efficiency at an optimum supply voltage (vopt) of 370 mv, 3.5 mhz, and 17 pj/cycle. a functional aoas wsn incorporating the ntv mcu shows promise for sustained mu w operation.
image_processing	in image processing, it is often desirable to remove the noise and preserve image features. due to the strong edge preserving ability, the total variation (tv) based regularization has been widely studied. however, it produces undesirable staircase effect. to alleviate the staircase effect, the lot model proposed by lysaker et al. (ieee trans image process 13(10): 1345-1357, 2004) has been studied, which is called the two-step method. after that, this method has started to appear as one of the more effective methods for image denoising, which includes two energy functions: one is about the normal field, the other is about the reconstruction image using the normal field obtained in the first step. however, the smoothed normal field is only related to the original noisy image in the first step, which is not enough. in this paper, we proposed a modified lot model for image denoising, which lets the reconstruction vector field be related to the restored image. in addition, to compute the new model, we design a relaxed alternative direction method. the numerical experiments show that the new model can obtain the better results compared with some state-of-the art methods.
digital_control	this paper presents a new algorithm for controlling the magnetic induction waveform in a specific measurement system for the magnetic characterization and modeling of silicon steel sheets. experimental results show that, with this new control algorithm, the measurement system is able to characterize silicon steel sheets under sinusoidal or nonsinusoidal waveforms in wide frequency and amplitude range.
analog_signal_processing	a multi-channel mixed-signal full-customized cmos integrated biopotential sensor chip and microcontroller based electronic system have been developed for in vitro extracellular recording of neural signals. the multi-site planar microelectrode array sensors for simultaneous neural signal recording have been designed and prototyped with on-chip fully integrated analog signal processing circuitry and control system. the biosensor system is built with hierarchical modules that incorporate microelectrode electrophysiological sensors, analog signal buffers configured with two-stage amplifier, gain providing amplifiers based on operational transconductance amplifier (ota) with capacitive feedback and digital logic and interface units including clock generation and time division multiplexing control circuitry. the prototype ic was fabricated by mosis using ami c5 0.5 mu m, double poly, triple metal layer cmos technology. the electroless gold plating process is used to replace the aluminum material obtained from the standard cmos process with biocompatible metal gold in the planar microelectrode array sensors to prevent cell poisoning and undesirable electrochemical corrosion. the post-cmos processing and packaging techniques applied to the biosensor chip promotes biocompatibility and stability in the aqueous cell culture environment. a microcontroller based electronic system interfacing the biosensor ic with a client pc for the post processing of the action potential signals sensed by the biopotential sensor chip was also developed. the biosensor has been tested electrically in the presence of electrolyte environment and is shown to provide a satisfactory signal-to-noise ratio for neural signals with amplitudes in the range of 600 mu v-2mv and frequencies in the range of 100 hz - 10 khz. biological example in vitro recordings conducted with neurons from aplysia californica are shown in this research work, which proves the full functionality in neural recording of the biosensor chip incorporated with the interfacing electronic system based on 32-bit motorola coldfire mcf5307 risc processor. on-chip amplification and time division multiplexing techniques of the multi-channel biosensor chip allow the large-scale simultaneous recording of biological activities of neurons.
state_space_representation	this paper presents a novel prognostic method that allows a proper characterization of the uncertainty associated with the evolution in time of nonlinear dynamical systems. the method assumes a state-space representation of the system, as well as the availability of particle-filtering-based estimates of the state posterior density at the moment in which the prognostic algorithm is executed. our proposal significantly improves all particle-filtering-based prognosis frameworks currently available in two main aspects. first, it provides a correction for the expression that is used for the computation of the time-of failure (tof) probability mass function in the context of online monitoring schemes. secondly, it presents a method for improved characterization of the tails of the tof probability mass function via sequential propagation of sigma-points and the computation of gaussian mixture models (gmms). the proposed algorithm is tested and validated using experimental data related to the problem of lithium-ion battery state-of-charge prognosis. (c) 2016 elsevier ltd. all rights reserved.
system_identification	real-time structural parameter identification and damage detection are of great significance for structural health monitoring systems. the extended kalman filter has been implemented in many structural damage detection methods due to its capability to estimate structural parameters based on online measurement data. current research assumes constant structural parameters and uses static statistical process control for damage detection. however, structural parameters are typically slow-changing due to variations such as environmental and operational effects. hence, false alarms may easily be triggered when the data points falling outside of the static statistical process control range due to the environmental and operational effects. in order to overcome this problem, this article presents a novel real-time structural damage detection method by integrating extended kalman filter and dynamic statistical process control. based on historical measurements of damage-sensitive parameters in the state-space model, extended kalman filter is used to provide real-time estimations of these parameters as well as standard derivations in each time step, which are then used to update the control limits for dynamic statistical process control to detect any abnormality in the selected parameters. the numerical validation is performed on both linear and nonlinear structures, considering different damage scenarios. the simulation results demonstrate high detection accuracy rate and light computational costs of the developed extended kalman filter-dynamic statistical process control damage detection method and the potential for implementation in structural health monitoring systems for in-service civil structures.
computer_vision	this paper focuses on learning a smooth skeleton structure from noisy data-an emerging topic in the fields of computer vision and computational biology. many dimensionality reduction methods have been proposed, but none are specially designed for this purpose. to achieve this goal, we propose a unified probabilistic framework that directly models the posterior distribution of data points in an embedding space so as to suppress data noise and reveal the smooth skeleton structure. within the proposed framework, a sparse positive similarity matrix is obtained by solving a box-constrained convex optimization problem, in which the sparsity of the matrix represents the learned neighborhood graph and the positive weights stand for the new similarity. embedded data points are then obtained by applying the maximum a posteriori estimation to the posterior distribution expressed by the learned similarity matrix. the embedding process naturally provides a probabilistic interpretation of laplacian eigenmap and maximum variance unfolding. extensive experiments on various datasets demonstrate that our proposed method obtains the embedded points that accurately uncover inherent smooth skeleton structures in terms of data visualization, and the method yields superior clustering performance compared to various baselines.
software_engineering	effective team communication is a prerequisite for software quality and project success. it implies correctly elicited customer requirements, conduction of occurring change requests and to adhere releases. team communication is a complex construct that consists of numerous characteristics, individual styles, influencing factors and dynamic intensities during a project. these elements are complicated to be measured or scheduled, especially in newly formed teams. according to software developers with few experiences in teams, it would be highly desirable to recognize dysfunctional or underestimated communication behaviors already in early project phases. otherwise, negative affects may cause delay of releases or even endanger software quality. we introduce an approach on the feasibility of forecasting team 's communication behavior in student software projects. we build a very first forecasting model that involves software engineering and industrial psychological terms to extract multi week communication forecasts with accurate results. the model consists of a k-nearest neighbor machine learning algorithm and is trained and evaluated with 34 student software projects from a previously taken field study. this study is an encouraging first step towards forecasting team communication to reveal potential miscommunications during a project. it is our aim to give young software developing teams an experience-based assistance about their information flow and enable adjustment for dysfunctional communication, to avoid fire fighting situation or even risks of alternating software qualities.
electrical_network	the recently introduced concept of k-power domination generalizes domination and power domination, the latter concept being used for monitoring an electric power system. the k-power domination problem is to determine a minimum size vertex subset s of a graph g such that after setting x=n[s], and iteratively adding to x vertices x that have a neighbour v in x such that at most k neighbours of v are not yet in x, we get x=v(g). in this paper the k-power domination number of sierpia""ski graphs is determined. the propagation radius is introduced as a measure of the efficiency of power dominating sets. the propagation radius of sierpia""ski graphs is obtained in most of the cases.
analog_signal_processing	a compressive receiver (cr) is presented utilizing a composite right/left-handed (crlh) dispersive delay line (ddl) for analog signal processing applications. the crlh ddl offers advantages such as arbitrary frequency of operation and wide bandwidth, filling a gap with competing ddl technologies. the presented cr system utilizes an impulse-driven crlh ddl and mixer inversion for chirp generation required for real-time signal processing. at high frequencies, this eliminates frequency ramp generators. the cr is employed as a frequency discriminator and a tunable delay line with dispersion compensation. the simulation and experimental results fully validate the presented systems as proof-of-concept for high-frequency applications such as real-time fourier transformers and signal analyzers.
distributed_computing	cloud computing is an evolutionary model for distributed computing, which consists of centralized data centers providing resources for massive scalable computing. major security challenges are the generation, distribution, and usage of encryption keys in cloud systems. one of ways to provide security, proxy re-encryption scheme is proposed, in which a semi-trusted proxy transforms a cipher-text for data sender into a cipher-text for data receiver without seeing the underlying plaintext. this paper proposes a new re-encryption scheme for secure data sharing, which is based on a trusted authority. experimental results show that our scheme attains good performance than the other previous schemes.
image_processing	a key issue in fruit export is classification and sorting for acceptable marketing. in the present work, the image processing technique was employed to grade three varieties of oranges (bam, khooni and thompson) separately. the reason for choosing this fruit as the object of the study was its abundant consumption worldwide. in this study, 14 parameters were extracted: area, eccentricity, perimeter, length/ area, blue value, green value, red value, width, contrast, texture, width/ area, width/ length, roughness, and length. further, the anfis (adaptive network-based fuzzy inference system) method was utilized to estimate the orange mass from the data obtained using the image processing in three varieties. in anfis model, samples were divided into two sets, one with 70% for training set and the other one with 30% for testing set. the results of the present study demonstrated that the coefficient of determination (r-2) of the best model for bam, khooni and thompson measured 0.948, 0.99, and 0.98, respectively. in addition, the results indicated that the estimation accuracy of the best model for bam, khooni and thompson was measured as +/- 3.7 g, +/- 1.28 g, +/- 3.2 g, respectively. this result was very satisfactory for the application of anfis to estimate the orange mass.
data_structures	branch-and-bound (b&b) is a popular approach to accelerate the solution of the optimization problems, but its parallelization on graphics processing units (gpus) is challenging because of b&b 's irregular data structures and poor computation/communication ratio. the contributions of this paper are as follows: (1) we develop two cuda-based implementations (iterative and recursive) of b&b on systems with gpus for a practical application scenario-optimal design of multi-product batch plants, with a particular example of a chemical-engineering system (ces); (2) we propose and implement several optimizations of our cuda code by reducing branch divergence and by exploiting the properties of the gpu memory hierarchy; and (3) we evaluate our implementations and their optimizations on a modern gpu-based system and we report our experimental results.
cryptography	recently, he et al. proposed an anonymous two-factor authentication scheme following the concept of temporal-credential for wireless sensor networks (wsns), which is claimed to be secure and capable of withstanding various attacks. however, we reveal that the authentication phase of their scheme has several pitfalls. firstly, their scheme is susceptible to malicious user impersonation attack, in which a legal but malicious user can impersonate as other registered users. in addition, their scheme is also vulnerable to stolen smart card attack. furthermore, the scheme cannot provide untraceability and is prone to tracking attack. then we put forward an untraceable two-factor authentication scheme based on elliptic curve cryptography (ecc) for wsns. our new scheme makes up for the missing security features necessary for real-life applications while maintaining the desired features of the original scheme. we prove that the scheme fulfills mutual authentication in the burrows-abadi-needham (ban) logic. moreover, by way of informal security analysis, we show that the proposed scheme can resist a variety of attacks and provide more security features than he et al. 's scheme.
electrical_network	progress in power engineering is a continuous increase of so called non-linear loads in amount and power. such loads in electrical networks result in high harmonics production of voltage which causes a number of negative effects in electrical network equipment functioning. the valve inverter and regulating devices are the most widely used among nonlinear loads. these devices operate at 380/220 v. this work is aimed at analyzing high harmonics currents consumed by modern widely used non-linear electrical devices (tvs, computers, washing machines etc.). it is also analyzed the operation mode of the induction motor which is also equipped with acs 550 frequency converter. if a larger number of such devices is used it is necessary to minimize up to standard values high harmonics current and voltage in 380/220 v networks.
microcontroller	knowledge of peanut drying parameters, such as temperature and relative humidity of the ambient air, temperature and relative humidity of the air being blown into the peanuts, and kernel moisture content, is essential in managing the dryer for optimal drying rate. the optimal drying rate is required to preserve quality and desired flavor. in the current peanut-drying process, such parameters are elusive in real time and are either not measured or only measured periodically by an operator. a peanut-drying monitoring system, controlled by an embedded microcontroller and consisting of relative humidity and temperature sensors and a microwave peanut moisture sensor, was developed to monitor drying parameters in real time. it was deployed during the 2014 peanut harvest season at a peanut buying point in central georgia, usa. it was placed in 45-ft (13.7-m) drying semitrailers to monitor in-shell kernel moisture content, temperature of the drying peanuts, temperature, and relative humidity of the exhaust air from the peanuts and relative humidity of the air being blown into the peanuts in real time. in-shell kernel moisture content was determined with a standard error of performance of 0.55% moisture content when compared to the reference oven-drying method. data from drying parameters were time-stamped and stored on a compactflash card every 12s and were used to assess the efficiency of dryer control settings. ambient air conditions were measured by an on-site weather station. results of the study support the value of such a monitoring system and show that implementation of the system for dryer control has the potential for saving a buying point, in the current economical context, as much as $22,000 annually in costs of electric energy and propane.
analog_signal_processing	operational amplifiers are well-known and mostly used building blocks for analog circuit design. however, due to their limited performance, researchers look for better alternatives and other active blocks. as a result, there is significant amount of past and on-going research about new current-mode active building blocks such as operational transconductance amplifiers (ota), second generation current conveyors (ccii), current-feedback op-amps (cfoa), four terminal floating nullors (ftfn), differential voltage current conveyor (dvcc), differential difference current conveyor (ddcc), third-generation current-conveyor (cciii), dual x current conveyors (dxccii), current controlled current conveyors (cccii), current differencing trans conductance amplifiers (cdta) etc. using these new active elements for analog design and implementing them in cmos technology designers have acquired new possibilities to solve classic opamp based problems such as bandwidth, slew-rate etc. moreover, active-only and mos-only topologies provide further solutions for analog circuit design. additionally, usage of fgmos transistors in analog circuits is an alternative approach whose efficiency has been shown recently. this paper discusses these new possibilities in analog circuit design including applications on communication, measurement and rf systems, combining the main features for the circuit design with actual circuit realizations and demonstrating several performance limitations on chosen circuit examples.
voltage_law	this paper proposes a systematic method to allocate the power flow and loss for deregulated transmission systems. the proposed method is developed based on the basic circuit theories, equivalent current injection and equivalent impedance. four steps are used to trace the voltages, currents, power flows, and losses contributed by each generator sequentially. using this method, the real and reactive power on each transmission lines and their sources and destinations can be calculated. the loss allocation of each line, which is produced by each generator, can also be obtained. test results show that the proposed method can satisfy the power flow equation, the power balance equation and the basic circuit theories. comparisons with previous methods are also provided to demonstrate the contributions of the proposed method. (c) 2005 elsevier ltd. all fights reserved.
distributed_computing	cloud, fog and dew computing concepts offer elastic resources that can serve scalable services. these resources can be scaled horizontally or vertically. the former is more powerful, which increases the number of same machines (scaled out) to retain the performance of the service. however, this scaling is tightly connected with the existence of a balancer in front of the scaled resources that will balance the load among the end points. in this paper, we present a successful implementation of a scalable low-level load balancer, implemented on the network layer. the scalability is tested by a series of experiments for a small scale servers providing services in the range of dew computing services. the experiments showed that it adds small latency of several milliseconds and thus it slightly reduces the performance when the distributed system is underutilized. however, the results show that the balancer achieves even a super-linear speedup (speedup greater than the number of scaled resources) for a greater load. the paper discusses also many other benefits that the balancer provides.
relational_databases	rough set theory provides a powerful tool for dealing with uncertainty in data. application of variety of rough set models to mining data stored in a single table has been widely studied. however, analysis of data stored in a relational structure using rough sets is still an extensive research area. this paper proposes compound approximation spaces and their constrained versions that are intended for handling uncertainty in relational data. the proposed spaces are expansions of tolerance approximation ones to a relational case. compared with compound approximation spaces, the constrained version enables to derive new knowledge from relational data. the proposed approach can improve mining relational data that is uncertain, incomplete, or inconsistent. (c) 2016 elsevier inc. all rights reserved.
computer_programming	community editing is an effective tool for improving contributions in peer production communities like wikipedia and question-answer (q&a) communities. however, the mechanisms behind who edits and why is not well understood. previous studies have focused on the effectiveness of editing and emergent hierarchies in editing communities. what is unknown is how editing is executed in a system that contains gamified motivations for contributing edits. in this paper, we examine participants editing unfit questions on stack overflow (so), a large computer programming q&a community. the combination of so 's community and reputation system with the dynamics of unfit questions allows us to examine how different actors behave. we find that early edits come from high-reputation users who do not participate as a questioner or answerer, indicating that these users work to retain certain questions. these results suggest that high-reputation user actions can be used to identify bad questions that have archival quality.
computer_vision	end-to-end learning machines enable a direct mapping from the raw input data to the desired outputs, eliminating the need for hand-crafted features. despite less engineering effort than the hand-crafted counterparts, these learning machines achieve extremely good results for many computer vision and medical image analysis tasks. two dominant classes of end-to-end learning machines are massive-training artificial neural networks (mtanns) and convolutional neural networks (cnns). although mtanns have been actively used for a number of medical image analysis tasks over the past two decades, cnns have recently gained popularity in the field of medical imaging. in this study, we have compared these two successful learning machines both experimentally and theoretically. for that purpose, we considered two well-studied topics in the field of medical image analysis: detection of lung nodules and distinction between benign and malignant lung nodules in computed tomography (ct). for a thorough analysis, we used 2 optimized mtann architectures and 4 distinct cnn architectures that have different depths. our experiments demonstrated that the performance of mtanns was substantially higher than that of cnn when using only limited training data. with a larger training dataset, the performance gap became less evident even though the margin was still significant. specifically, for nodule detection, mtanns generated 2.7 false positives per patient at 100% sensitivity, which was significantly (p < 0.05) lower than the best performing cnn model with 22.7 false positives per patient at the same level of sensitivity. for nodule classification, mtanns yielded an area under the receiver-operating-characteristic curve (auc) of 0.8806 (95% ci: 0.8389-0.9223), which was significantly (p < 0.05) greater than the best performing cnn model with an auc of 0.7755 (95% ci: 0.7120-0.8270). thus, with limited training data, mtanns would be a suitable end-to-end machine-learning model for detection and classification of focal lesions that do not require high-level semantic features.
analog_signal_processing	the discreteness of device parameters exists in the analog signal processing using conventional phase measurement methods, and the error caused by threshold voltage of comparator is difficult to estimate and eliminate. due to this shortcoming, a method based on tms320f28335 ecap module for measuring the phase difference is presented. firstly, the ac signal is amplified and filtered to eliminate the error introduced by electromagnetic interference, and then the digital signal through the schmitt trigger designed by cpld is converted to wave signal with the same frequency of the signal, by capturing the edge-triggered, enters the capture interruption subroutine to calculate the number of the sampling points of one period, finally the phase difference is calculated according to correlation method. hardware circuit and software flow chart are given. the experimental results verify the method has higher reliability and precision than conventional methods.
operating_systems	heterogeneous system architecture (hsa) is an architecture developed by the hsa foundation aiming at reducing programmability barriers as well as improving communication efficiency for heterogeneous computing. for example, hsa allows heterogeneous computing devices to share the same virtual address space. this feature allows programmers to bypass explicit data copying between devices, as was required in the past. hsa features such as job dispatching through user level queues and memory based signaling help to reduce communication latency between the host and other computing devices. while the new features in hsa enable more efficient heterogeneous computing, they also introduce new challenges to system virtualization, especially in memory virtualization and i/o virtualization. this work investigates the issues involved in hsa virtualization and implements a kvm-based hypervisor that supports the main features of hsa inside guest operating systems. furthermore, this work shows that with the newly introduced hypervisor for hsa, system resources in hsa-compliant amd kaveri can be effectively shared between multiple guest operating systems.
computer_graphics	combining high-resolution level set surface tracking with lower resolution physics is an inexpensive method for achieving highly detailed liquid animations. unfortunately, the inherent resolution mismatch introduces several types of disturbing visual artifacts. we identify the primary sources of these artifacts and present simple, efficient, and practical solutions to address them. first, we propose an unconditionally stable filtering method that selectively removes sub-grid surface artifacts not seen by the fluid physics, while preserving fine detail in dynamic splashing regions. it provides comparable results to recent error-correction techniques at lower cost, without substepping, and with better scaling behavior. second, we show how a modified narrow-band scheme can ensure accurate free surface boundary conditions in the presence of large resolution mismatches. our scheme preserves the efficiency of the narrow-band methodology, while eliminating objectionable stairstep artifacts observed in prior work. third, we demonstrate that the use of linear interpolation of velocity during advection of the high-resolution level set surface is responsible for visible grid-aligned kinks; we therefore advocate higher-order velocity interpolation, and show that it dramatically reduces this artifact. while these three contributions are orthogonal, our results demonstrate that taken together they efficiently address the dominant sources of visual artifacts arising with high-resolution embedded liquid surfaces; the proposed approach offers improved visual quality, a straightforward implementation, and substantially greater scalability than competing methods.
electrical_network	the use of the smart grid for developing intelligent applications is a current trend of great importance. one advantage lies in the possibility of direct monitoring of all devices connected to the electrical network in order to prevent possible malfunctions. therefore, this paper proposes a method for an automatic detection of the malfunctioning of low-intelligence consumer electrical devices. malfunctioning means any deviation of a household device from its normal operating schedule. the method is based on a comparison technique, consisting in the correlation between the current power signature of a device and an ideal signature (the standard signature provided by the manufacturer). the first step of this method is to achieve a simplified form of power signature which keeps all the original features. further, the signal is segmented based on the data provided by an event detection algorithm (values of the first derivatives) and each resulting component is approximated using a regression function. the final step consists of an analysis based on the correlation between the computed regression coefficients and the coefficients of the standard signal. following this analysis all the differences are classified as a malfunctioning of the analyzed device.
symbolic_computation	lump solutions are rationally localized in all directions in the space. a general class of lump solutions to the (2 + 1)-dimensional b-kadomtsev-petviashvili (bkp) equation is presented through symbolic computation with maple. the hirota bilinear form of the equation is the starting point in the computation process. like the kp equation, the resulting lump solutions contain six arbitrary parameters. two of the parameters are due to the translation invariances of the bkp equation with the independent variables, and the other four need to satisfy a nonzero determinant condition and the positivity condition, which guarantee analyticity and rational localization of the solutions.
electric_motor	this paper studies the dynamic performance of an electric machine integrated with the transrotary magnetic gear (mitromag) in a motoring mode of operation. mitromag is formed by mechanically coupling a rotary electric machine to the rotor of a trans-rotary magnetic gear (tromag). tromag is a magnetic device that, through magnetic fields, converts a low-torque, high-speed rotation of its rotor to a high-force, low-speed linear motion of its translator, and vice versa. in a motoring mode of operation, the rotor of the tromag is driven by a rotary electric motor, and as a result, its translator drives a reciprocating load. a nonlinear dynamic model is developed for the tromag. oscillation tests are presented as examples of how the model can be used to predict the dynamic behavior of the device. the model is then linearized to derive system transfer functions and study the dynamic response of the mitromag to speed commands. experimental results confirm the analysis.
electrical_network	this work presents the application of the power series method (psm) to find solutions of partial differential-algebraic equations (pdaes). two systems of index-one and index-three are solved to show that psm can provide analytical solutions of pdaes in convergent series form. what is more, we present the post-treatment of the power series solutions with the laplace-pade (lp) resummation method as a useful strategy to find exact solutions. the main advantage of the proposed methodology is that the procedure is based on a few straightforward steps and it does not generate secular terms or depends of a perturbation parameter.
computer_vision	this article proposes an automatic image processing method that can be an effective diagnostic tool to detect and grade the severity of diabetic retinopathy. this computer vision-based algorithm imitates the logic and medical sense used by ophthalmologist in detecting the abnormality and its location in the image for grading the severity of the disease. the detection is based on finding abnormalities, such as exudates and red lesions, and the grading is based on the location of these abnormalities in the image referred with its distance from the macula. accordingly the entire image has been divided into regions and occurrence of abnormalities in these regions indicates the severity of the disease. the methodology stresses on two major factors, accuracy of the results and computation time. it is found that both these design parameters are nicely achieved in the proposed method. the experimental results indicate that overall accuracy over 90% can be achieved in the proposed method and also significantly reduce the computational complexity in this region-based approach.
state_space_representation	the main contribution of the paper is the modeling approach used to describe a pure three-phase shunt active filter, and the application of the h infinity control design tool in order to improve the quality of electrical energy. advanced power electronics devices have widely contributed to the degradation of power quality due to the injection of non-sinusoidal currents into the utility system. therefore, it is essential to use an active compensator which can attenuate current harmonics to an acceptable level on the line side of the power source. in this work, a three-phase active filter connected in parallel to a supply system feeding a non-linear load is described, in a complex framework, by a linear multivariable state space representation in order to guarantee that the system is mathematically decoupled and therefore to simplify the controller design. this representation includes a sensor to measure perturbations, and allows one to calculate a linear robust control law. the originality of this paper is that a linear matrix inequality based h infinity synthesis is performed to design a static state feedback controller with complex-valued parameters. the robustness of this controller with respect to network impedance uncertainties is investigated. moreover, simulation and experimental results are given to reveal the effectiveness of the synthesized control law.
relational_databases	in recent years, many researchers have studied reversible watermarking techniques for relational databases. most of the developed schemes have been based on a primary key attribute in order to determine the selected tuples and attributes to carry the watermark bits. what happens, however, when the primary key attribute does not exist for a relational database? in this paper, we propose a blind robust reversible watermarking scheme for a textual relational database. this scheme does not rely on the primary key attribute. to avoid the absolute dependence on the primary key attribute, as in existing schemes, in the proposed scheme the content of textual attributes are used to generate the virtual primary attribute that is applied in tuple and attribute selections. moreover, the selection of attributes does not depend on the order of attributes in the relational database. model and robustness analysis demonstrate that our proposed scheme achieves a high resilience against different types of tuple attacks, i.e., tuple attacks and attribute attacks. the experimental results also confirm that the proposed scheme is more secure and robust than other existing schemes.
image_processing	the magnetic moment of magnetically labeled cells, microbubbles or microspheres is an important optimization parameter for many targeting, delivery or separation applications. the quantification of this property is often difficult, since it depends not only on the type of incorporated nanoparticle, but also on the intake capabilities, surface properties and internal distribution. we describe a method to determine the magnetic moment of those carriers using a microscopic set-up and an image processing algorithm. in contrast to other works, we measure the diversion of superparamagnetic nanoparticles in a static fluid. the set-up is optimized to achieve a homogeneous movement of the magnetic carriers inside the magnetic field. the evaluation is automated with a customized algorithm, utilizing a set of basic algorithms, including blob recognition, feature-based shape recognition and a graph algorithm. we present example measurements for the characteristic properties of different types of carriers in combination with different types of nanoparticles. those properties include velocity in the magnetic field as well as the magnetic moment. the investigated carriers are adherent and suspension cells, while the used nanoparticles have different sizes and coatings to obtain varying behavior of the carriers.
operational_amplifier	a low component sensitivity band-pass filter has been proposed. the filter has only one operational amplifier as active component and three resistors and one grounded capacitor as passive components. two resistors provide the positive feedback and one resistor is used for independent tuning of q factor. the capacitor is grounded which is an advantage in integrated technology. the circuit uses the pole frequency of the operational amplifier for its working and can be operated at high frequency range. pspice simulations have been presented to verify theoretical analysis.
analog_signal_processing	with the integration of integrated circuits continues to rise, the feature size of integrated devices has entered nanometer. single electron transistor (set) is satisfied as nanoelectronic devices, and the set will be mixed with the composition of nano-mos devices (setmos), is one of the hot current study. setmos as a new hybrid device combine the advantages of both, it also has the same coulomb oscillation characteristics with the set and mos high gain. integrated analog signal processing filters as the basic unit circuit, it must conform to the development of the times. based on the i-v characteristics of a setmos hybrid device model, a setmos integrator is designed, and expounding it 's the operating condition, structure, performance, parameter and characteristics. the transmission performance of the integrator designed is simulated by spice. the conclusion is proved by simulation result.
algorithm_design	sketching as a natural mode for human communication and creative processes presents opportunities for improving human-computer interaction in geospatial information systems. however, to use a sketch map as user input, it must be localized within the underlying spatial data set of the information system, the base metric map. this can be achieved by a matching process called qualitative map alignment in which qualitative spatial representations of the two input maps are used to establish correspondences between each sketched object and one or more objects in the metric map. the challenge is that, to the best of our knowledge, no method for matching qualitative spatial representations suggested so far is applicable in realistic scenarios due to excessively long runtimes, incorrect algorithm design or the inability to use more than one spatial aspect at a time. we address these challenges with a metaheuristic algorithm which uses novel data structures to match qualitative spatial representations of a pair of maps. we present the design, data structures and performance evaluation of the algorithm using real-world sketch and metric maps as well as on synthetic data. our algorithm is novel in two main aspects. firstly, it employs a novel system of matrices known as local compatibility matrices, which facilitate the computation of estimates for the future size of a partial alignment and allow several types of constraints to be used at the same time. secondly, the heuristic it computes has a higher accuracy than the state-of-the-art heuristic for this task, yet requires less computation. our algorithm is also a general method for matching labelled graphs, a special case of which is the one involving complete graphs whose edges are labelled with spatial relations. the results of our evaluation demonstrate practical runtime performance and high solution quality.
pid_controller	in this paper, the nonlinear systems with time delay network control is discussed transmission delays and packet dropouts for networked control system with random time delay are analyzed. in this paper, online delay estimation method to obtain the delay value, the delay value is an input parameter of fuzzy adaptive pid controller, fuzzy pid temporal adjustment based on genetic algorithm and particle swarm optimization algorithm to optimization objective function, three parameters of pid is adjusted online in order to improve the system stability, through matlab co-simulation tool true time, the shows the fuzzy logic control system base on pso algorithm promote reduce transmission delays and packet dropouts. the paper also shows the superiority of fuzzy pid controllers over their traditional pid for ncs applications.
computer_vision	different studies in the field of agricultural engineering have successfully related irrigation needs of plants with the percentage of green cover in crop images, by using simple allometric equations. therefore, the problem of segmenting plants from soil in digital images becomes a key component of many water management systems. the development of automatic computer vision algorithms avoids slow and expensive procedures which require the supervision of human experts. in this sense, color analysis techniques have shown to yield the best results in accuracy and efficiency. this paper describes the design and development of a new web application with two different color segmentation techniques to estimate the percentage of green cover. the system allows a remote monitoring of crops, including functionality to upload images, analyze images, database storage, and graphical visualization of the results. an extensive experimental validation of this tool has been carried out on a lettuce crop of variety 'little gem'. the two segmentation methods - based on probabilistic color models using histograms, and clustering in the rgb space using the fuzzy c-means algorithm - are compared with respect to a manual segmentation technique which allows the human expert to validate the outcome of the process for each image. the experimental results demonstrate the feasibility of these two automatic methods as substitutes of the supervised process. the first method achieves a relative error below 2.4% in the obtained segmentation, while the second method has an error below 4.8%. both techniques require less than 1 s of processing time in the server. equations to compute the crop coefficient parameter are also included and validated for the same kind of crop.(c) 2016 elsevier b.v. all rights reserved.
operating_systems	the social relationships graph i.e. sociogram allows a transparent view of people in their surroundings to whom we have a certain relationship. such options have already depicted many tools. they generally use data from social networks, e.g. facebook or google+. certainly, not every such a graph is entirely transparent and usable. a sociogram contains a large number of vertices and edges when there are a larger number of people in their surroundings. then it is not possible to simply work with the graph and subsequently describe it. in this article, we introduce options that will make the sociogram transparent, thus offering easier work with it. we work with a software tool from the ihmc company, called cmaptools, which normally operates on desktop operating systems. in our case, we are working with a version for the android os, which has been externally developed for the company for a long time, but has not yet been publicly introduced.
machine_learning	we present a supervised machine learning approach for markerless estimation of human full-body kinematics for a cyclist from an unconstrained colour image. this approach is motivated by the limitations of existing marker-based approaches restricted by infrastructure, environmental conditions, and obtrusive markers. by using a discriminatively learned mixture-of-parts model, we construct a probabilistic tree representation to model the configuration and appearance of human body joints. during the learning stage, a structured support vector machine (ssvm) learns body parts appearance and spatial relations. in the testing stage, the learned models are employed to recover body pose via searching in a test image over a pyramid structure. we focus on the movement modality of cycling to demonstrate the efficacy of our approach. in natura estimation of cycling kinematics using images is challenging because of human interaction with a bicycle causing frequent occlusions. we make no assumptions in relation to the kinematic constraints of the model, nor the appearance of the scene. our technique finds multiple quality hypotheses for the pose. we evaluate the precision of our method on two new datasets using loss functions. our method achieves a score of 91.1 and 69.3 on mean probability of correct keypoint (pck) measure and 88.7 and 66.1 on the average precision of keypoints (apk) measure for the frontal and sagittal datasets respectively. we conclude that our method opens new vistas to robust user-interaction free estimation of full body kinematics, a prerequisite to motion analysis. (c) 2017 elsevier ltd. all rights reserved.
operational_amplifier	this paper presents an integrated bandgap reference circuit which is addressing low current consumption and a wide supply voltage range, using a current mode structure. embedded in a sophisticated power management unit (pmu) for a gnss receiver, this bandgap reference has an output of 0.60 v and it can reach a temperature coefficient of 33 ppm/degrees c in the range from -40 degrees c to 125 degrees c. with a 1.4 v supply voltage, the power is only 3.5 mu w and the psrr is 57 db at dc frequency. occupying 0.125 mm(2) chip area, this bandgap reference has been implemented in the cmos 28 nm technology from globalfoundries and successfully validated in the lab.
network_security	the rapid development of the internet, especially the emergence of the social networks, leads rumor propagation into a new media era. rumor propagation in social networks has brought new challenges to network security and social stability. this paper, based on partial differential equations (pdes), proposes a new sis rumor propagation model by considering the effect of the communication between the different rumor infected users on rumor propagation. the stabilities of a nonrumor equilibrium point and a rumor-spreading equilibrium point are discussed by linearization technique and the upper and lower solutions method, and the existence of a traveling wave solution is established by the cross-iteration scheme accompanied by the technique of upper and lower solutions and schauder 's fixed point theorem. furthermore, we add the time delay to rumor propagation and deduce the conditions of hopf bifurcation and stability switches for the rumor-spreading equilibrium point by taking the time delay as the bifurcation parameter. finally, numerical simulations are performed to illustrate the theoretical results.
analog_signal_processing	all-pass networks with prescribed group delay are used for analog signal processing and equalization of transmission channels. the state-of-the-art methods for synthesizing quasi-arbitrary group delay functions using all-pass elements lack a theoretical synthesis procedure that guarantees minimum-order networks. we present an analytically-based solution to this problem that produces an all-pass network with a response approximating the required group delay to within an arbitrary minimax error. for the first time, this method is shown to work for any physical realization of second-order all-pass elements, is guaranteed to converge to a global optimum solution without any choice of seed values as an input, and allows synthesis of pre-defined networks described both analytically and numerically. the proposed method is also demonstrated by reducing the delay variation of a practical system by any desired amount, and compared to state-of-the-art methods in comparison examples.
machine_learning	the grasslands of western jilin province in china have experienced severe degradation during the last 50 years. radial basis function neural networks (rbfnn) and support vector machines (svm) were used to predict the carbon, nitrogen, and phosphorus contents of leymus chinensis (l. chinensis) and explore the degree of grassland degradation using the matter-element extension model. both rbfnn and svm demonstrated good prediction accuracy. the results indicated that there was severe degradation, as samples were mainly concentrated in the 3rd and 4th levels. the growth of l chinensis was shown to be limited by either nitrogen, phosphorus, or both during different stages of degradation. the soil chemistry changed noticeably as degradation aggravated, which represents a destabilization of l chinensis community homeostasis. soil salinization aggravates soil nutrient loss and decreases the bioavailability of soil nutrients. this, along with the destabilization of c/n, c/p and n/p ratios, weakens the photosynthetic ability and productivity of l chinensis. this conclusion was supported by observations that l. chinensis is gradually being replaced by a chloris virgata, puccinellia tenuiflora and suaeda acuminate mixed community. (c) 2017 elsevier ltd. all rights reserved.
computer_vision	although the introduction of commercial rgb-d sensors has enabled significant progress in the visual navigation methods for mobile robots, the structured-light-based sensors, like microsoft kinect and asus xtion pro live, have some important limitations with respect to their range, field of view, and depth measurements accuracy. the recent introduction of the second- generation kinect, which is based on the time-of-flight measurement principle, brought to the robotics and computer vision researchers a sensor that overcomes some of these limitations. however, as the new kinect is, just like the older one, intended for computer games and human motion capture rather than for navigation, it is unclear how much the navigation methods, such as visual odometry and slam, can benefit from the improved parameters. while there are many publicly available rgb-d data sets, only few of them provide ground truth information necessary for evaluating navigation methods, and to the best of our knowledge, none of them contains sequences registered with the new version of kinect. therefore, this paper describes a new rgb-d data set, which is a first attempt to systematically evaluate the indoor navigation algorithms on data from two different sensors in the same environment and along the same trajectories. this data set contains synchronized rgb-d frames from both sensors and the appropriate ground truth from an external motion capture system based on distributed cameras. we describe in details the data registration procedure and then evaluate our rgb-d visual odometry algorithm on the obtained sequences, investigating how the specific properties and limitations of both sensors influence the performance of this navigation method.
network_security	the proliferation of low-cost ieee 802.15.4 zigbee wireless devices in critical infrastructure applications presents security challenges. network security commonly relies on bit-level credentials that are easily replicated and exploited by hackers. unauthorized access can be mitigated by physical layer (phy) security measures that exploit device-dependent emission characteristics that are sufficiently unique to discriminate devices. rf distinct native attribute (rf-dna) fingerprinting is a phy-based security measure, which computes statistical features extracted from such device emissions. however, the rf-dna fingerprints can be numerous, correlated, and noisy, therefore, a dimensional reduction analysis (dra) via feature selection is, therefore, of interest. device classification with dra feature subsets is evaluated using a multiple discriminant analysis (mda) classifier. determining feature relevance from mda was generally dismissed in prior rf fingerprinting work and is seldom considered in other applications. here, the mda feature relevance is revisited using a proposed eigen-based mda loadings fusion (mlf) methodology. the mda classification models are adopted and used to assess device identification (id) classification and verification performance for both the authorized and unauthorized (rogue) devices using a claimed versus actual biometric methodology. performance is compared for six dra methods using: 1) a two-sample kolmogorov-smirnov test; 2) one-way analysis of variance f-test statistics; 3) a wilk 's lambda ratio; 4) generalized relevance learning vector quantized-improved relevance; 5) randomly selected; and 6) the proposed mlf method. quantitative and qualitative dimensionality assessment methods are compared and contrasted to establish upper bounds on the number of retained features. experimentally collected zigbee emissions are considered and zigbee device classification and id verification performance using dra subsets are compared with a full-dimensional feature set. results show that dra via the proposed mlf method is superior and more robust than competing methods.
relational_databases	database models for road inventories are based on classical schemes for relational databases: many related tables, in which the database designer establishes, a priori, every detail that they consider relevant for inventory management. this kind of database presents several problems. first, adapting the model and its applications when new database features appear is difficult. in addition, the different needs of different sets of road inventory users are difficult to fulfil with these schemes. for example, maintenance management services, road authorities and emergency services have different needs. in addition, this kind of database cannot be adapted to new scenarios, such as other countries and regions (that may classify roads or name certain elements differently). the problem is more complex if the language used in these scenarios is not the same as that used in the database design. in addition, technicians need a long time to learn to use the database efficiently. this paper proposes a flexible, multi-language and multipurpose database model, which gives an effective and simple solution to the aforementioned problems. (c) 2016 the authors. published by elsevier b.v.
bioinformatics	egfr-mutated nsclc is a genetically heterogeneous disease that includes more than 200 distinct mutations. the implications of mutational subtype for both prognostic and predictive value are being increasingly understood. although the most common egfr mutations exon 19 deletions or l858r mutations predict sensitivity to egfr tyrosine kinase inhibitors (tkis), it is now being recognized that outcomes may be improved in patients with exon 19 deletions. additionally, 10% of patients will have an uncommon egfr mutation, and response to egfr tki therapy is highly variable depending on the mutation. given the growing recognition of the genetic and clinical variation seen in this disease, the development of comprehensive bioinformatics-driven tools to both analyze response in uncommon mutation subtypes and inform clinical decision making will be increasingly important. clinical trials of novel egfr tkis should prospectively account for the presence of uncommon mutation subtypes in study design. (c) 2016 international association for the study of lung cancer. published by elsevier inc. all rights reserved.
electrical_network	smart grid concept promises a reliable and efficient supply of electricity. it recognizes the growing importance of information and communication technologies (icts). by incorporating ict in the existing electrical network, it will transform into the smart or intelligent grid. a vivid study of components of the smart grid i.e. smart meter, tod meter, ict, advanced metering infrastructure (ami) is illustrated which is based on the visits at different places like lavasa, kalkhairewadi and bhigwan in pune district in maharashtra state of india. application of smart meters for fault location is focused in this paper. the efforts have been taken to highlight the issues in the traditional fault locating techniques for transmission and distribution network.
computer_graphics	despite the recent advent of various radiographic imaging techniques, it is still very difficult to correctly distinguish a pediatric osteolytic lesion in the occipital condyle, which makes it further complicated to decide on the necessity of and the adequate timing for radical resection and craniocervical fusions. to establish a legitimate therapeutic strategy for this deep-seated lesion, surgical biopsy is a reasonable choice for first-line intervention. the choice of surgical approach becomes very important because a sufficient amount of histological specimen must be obtained to confirm the diagnosis but, ideally, the residual bony structures and the muscular structures should be preserved so as not to increase craniocervical instability. in this report, we present our experience with a case of solitary langerhans cell histiocytosis (lch) involving the occipital condyle that was successfully treated with minimally invasive surgical biopsy with a far lateral condylar approach supported by preoperative 3d computer graphic simulation. an 8-year-old girl presented with neck pain. magnetic resonance imaging and computed tomography (ct) revealed an osteolytic lesion of the left occipital condyle. at surgery, the patient was placed in the prone position. a 3-cm skin incision was made in the posterior auricular region, and the sternocleidomastoid and splenius capitis muscles were dissected in the middle of the muscle bundle along the direction of the muscle fiber. under a navigation system, we approached the occipital condyle through the space between the longissimus capitis muscle and the posterior belly of the digastric muscle and lateral to the superior oblique muscle, verifying each muscle at each depth of the surgical field and, finally, obtained sufficient surgical specimen. after the biopsy, her craniocervical instability had not worsened, and chemotherapy was performed. twelve weeks after chemotherapy, her neck pain had gradually disappeared along with her torticollis, and ct showed remission of the lesion and marked regeneration of the left occipital condyle. within our knowledge, this is the first reported case of lch involving the occipital condyle. although very rare, our case indicated that lch can be an alternative in the differential diagnosis of osteolytic lesions in the craniocervical junction, in which early bone regeneration with sufficient cervical stability is expected after chemotherapy. in cases of pediatric osteolytic lesions, when they initially presented with apparent cervical instability, craniocervical fusion may possibly become unnecessary after a series of treatments. thus, the effort to maximally preserve the musculoskeletal structure should be made until its histological diagnosis is finally confirmed.
electricity	with the advancement in technologies, the power requirement around the globe is tremendously increasing, putting extra loads on grids. the existing grids cannot bear that load and also do not provide the interface with distributed renewable energy sources (dres). building new lines and substations alone do not serve the purpose of overcoming energy shortfall. thus a major transformation in electricity infrastructure is need of the hour to meet the ever growing demands of electricity. converting current power management system to a smart autonomic system is pertinent to achieve an increasing amount of renewable energy generation. this paper presents a comprehensive review of advances in control of smart grids. various robust and adaptive strategies are spotlighted with a detailed description of control of overloads and power smart grids. also, power generation, storage and management techniques and development of operational schedule of sources and loads are elaborated. recently reported systems and information and communication technologies (ict) techniques in smart grid are highlighted. renewable energy has potential to eliminate the current electricity crisis in pakistan 's energy sector. the solar, wind, hydro and biogas/biomass are the alternative energy resources found abundantly in the country, which have tremendous potential to offer environment-friendly energy solutions. this in-depth study reveals that a lot of opportunities and potential of smart grid technology exist in developing countries like pakistan that need to be exploited so as to cope with energy crisis.
pid_controller	this paper presents the modeling and control of a hybrid wind-tidal turbine with hydraulic accumulator. the hybrid turbine captures the offshore wind energy and tidal current energy simultaneously and stores the excess energy in hydraulic accumulator prior to electricity generation. two hydraulic pumps installed respectively in wind and tidal turbine nacelles are used to transform the captured mechanical energy into hydraulic energy. to extract the maximal power from wind and tidal current, standard torque controls are achieved by regulating the displacements of the hydraulic pumps. to meet the output power demand, a proportion integration differentiation (pid) controller is designed to distribute the hydraulic energy between the accumulator and the pelton turbine. a simulation case study based on combining a 5 mw offshore wind turbine and a 1 mw tidal current turbine is undertaken. case study demonstrates that the hybrid generation system not only captures all the available wind and tidal energy and also delivers the desired generator power precisely through the accumulator damping out all the power fluctuations from the wind and tidal speed disturbances. energy and exergy analyses show that the energy efficiency can exceed 100% as the small input speeds are considered, and the exergy efficiency has the consistent change trends with demand power. further more parametric sensitivity study on hydraulic accumulator shows that there is an inversely proportional relationship between accumulator and hydraulic equipments including the pump and nozzle in terms of dimensions. (c) 2016 elsevier ltd. all rights reserved.
computer_programming	this article presents a proposal for the detection of programming source code similitude in academic environments. the objective of this proposal is to provide support to professors in detecting plagiarism in student homework assignments in introductory computer programming courses. the developed tool, codesight, is based on a modification of the greedy string tiling algorithm. the tool was tested in one theoretical and three real scenarios, obtaining similitude detections for assignments ranging from those that contained code without modifications to assignments containing insertions of procedural instructions inside the main code. the results verified the efficiency of the tool at the first five levels of the plagiarism spectrum for programming code, in addition to supporting suspicions of plagiarism in real scenarios. (c) 2013 wiley periodicals, inc. comput appl eng educ 23:13-22, 2015; view this article online at ; doi
electricity	vibration exists everywhere especially in the public railway operation system. the vibration acceleration is the key factor to monitor and evaluate the structure health of the railway equipment. in this paper, a kind of self-powered triboelectric nano vibration accelerometer (teva) is presented. a low frequency spring mass vibration model is built to calculate the vibration sensitive performance and the electric output of the teva. the prototype of the teva is demonstrated and characterized through the railway vibration simulation platform. it has been testified that teva can successfully harvest the low frequency vibration energy and convert it to electrical power to achieve the self-powered vibration acceleration monitoring system. the output current and voltage of teva are also sensitive to the vibration acceleration from 1.07 m/s(2) to 1.25 m/s(2) linearly. hence it can be used as a self-powered nano vibration accelerator for the fault diagnosis. in addition, the generated electricity is used for charging the lithium battery (from 1.5v to 3.1 v) which supplies power to the zigbee module. the experiment shows that the charged battery through teva can support the wireless communication between zigbee modules, with temperature and humidity sensors embedded on it. the temperature and humidity on the train are 22 degrees c and 35% rh respectively. therefore, the vibration energy can be harvested and stored for the power supply of wireless sensor network nodes in the near future.
computer_graphics	providing optimal mechanical ventilation to critically-ill children remains a challenge. patient-ventilator dyssynchrony results frequently with numerous deleterious consequences on patient outcome including increased requirement for sedation, prolonged duration of ventilation, and greater imposed work of breathing. most currently used ventilators have real-time, continuously-displayed graphics of pressure, volume, and flow versus time (scalars) as well as pressure, and flow versus volume (loops). a clear understanding of these graphics provides a lot of information about the mechanics of the respiratory system and the patient ventilator interaction in a dynamic fashion. using this information will facilitate tailoring the support provided and the manner in which it is provided to best suit the dynamic needs of the patient. this paper starts with a description of the scalars and loops followed by a discussion of the information that can be obtained from each of these graphics. a review will follow, on the common types of dyssynchronous interactions and how each of these can be detected on the ventilator graphics. the final section discusses how graphics can be used to optimize the ventilator support provided to patients.
control_engineering	nowadays. tuition of control engineering in the courses, which are usually obligatory for all students attending technical universities, is unimaginable without passing a practical part in laboratories. set-ups in such laboratories have undergone its evolution. instead of demos of real industrial control solutions on small-scale laboratory models, increasing interest is paid to the tasks presenting control problems on attractive models invoking natural interest for heuristic mastering them. these specially designed model devices are linked with pcs in order to provide realistic hmi and, then, of course, with internet. the aim of the paper is a short presentation of these set-ups by their names characterizing the demonstrated activity. in addition we wish to present our experience from the application of various technologies used in creating virtual version of these tasks. the virtual versions try to be true computer copies of the real models. this makes possible a preliminary preparation of the students for the given task and after that a certain confrontation of the results with those obtained in reality carrying out similar out similar experiment on the place in the laboratory or through remote access via internet. (c) 2015, ifac (international federation of automatic control) hosting by elsevier ltd. all rights reserved.
pid_controller	this paper presents the design of capacitive wireless power transfer systems based on a class-e inverter approach. the main reason for adopting the class-e inverter approach is because of its high efficiency, theoretically 100%. however, the operation of a class-e inverter is highly sensitive to its circuit 's parameters. in a typical capacitive wireless power transfer application, the capacitive coupling distance between plates is subject to changes, and hence its power transfer efficiency is greatly affected if the class-e inverter is properly tuned. this drawback motivates us to develop an auto frequency tuning algorithm for a class-e inverter which maintains its power transfer efficiency in spite of the variations of capacitive coupling distances between plates and circuit 's parameters. finally, simulation and experiment are carried out to verify the effectiveness of the auto frequency tuning algorithm.
operating_systems	background: hypertension or high blood pressure is on the rise. not only does it affect the elderly but is also increasingly spreading to younger sectors of the population. treating this condition involves exhaustive monitoring of patients. the current mobile health services can be improved to perform this task more effectively. objective: to develop a useful, user-friendly, robust and efficient app, to monitor hypertensive patients and adapted to the particular requirements of hypertension. methods: this work presents bpcontrol, an android and ios app that allows hypertensive patients to communicate with their health-care centers, thus facilitating monitoring and diagnosis. usability, robustness and efficiency factors for bpcontrol were evaluated for different devices and operating systems (android, ios and system-aware). furthermore, its features were compared with other similar apps in the literature. results: bpcontrol is robust and user-friendly. the respective start-up efficiency of the android and ios versions of bpcontrol were 2.4 and 8.8 times faster than a system-aware app. similar values were obtained for the communication efficiency (7.25 and 11.75 times faster for the android and ios respectively). when comparing plotting performance, bpcontrol was on average 2.25 times faster in the android case. most of the apps in the literature have no communication with a server, thus making it impossible to compare their performance with bpcontrol. conclusions: its optimal design and the good behavior of its facilities make bpcontrol a very promising mobile app for monitoring hypertensive patients.
electrical_network	given an undirected graph, the resistance distance between two nodes is the resistance one would measure between these two nodes in an electrical network if edges were resistors. summing these distances over all pairs of nodes yields the so-called kirchhoff index of the graph, which measures its overall connectivity. in this work, we consider erdos-renyi random graphs. since the graphs are random, their kirchhoff indices are random variables. we give formulas for the expected value of the kirchhoff index and show it concentrates around its expectation. we achieve this by studying the trace of the pseudoinverse of the laplacian of erdos-renyi graphs. for synchronization (a class of estimation problems on graphs) our results imply that acquiring pairwise measurements uniformly at random is a good strategy, even if only a vanishing proportion of the measurements can be acquired. (c) 2014 elsevier b.v. all rights reserved.
signal-flow_graph	this paper presents a systemic analysis for the steady-state performance of novel cascade boost converters based on a developed switching signal flow graph (sfg) method. the effects caused by parasitic parameters are considered. the general guidelines for drawing switching sfg and the derivation of steady-state information are provided. with the applications to the examples, the proposed graphical analytical method shows the advantages of high convenience and practicability to the cascade boost converters. both the circuit simulation and experimental results are provided to support the theoretical analysis.
computer_programming	tabulation method is usually adopted to describe the mapping relation of the analytic function of the local rules of cellular automaton. although tabulation method is quite suitable to describe the mapping relation among discrete variables, there are numerous if-else sentences for the state decision of independent variables in computer programming. in this paper, we define an analytic function of the local rules of an elementary cellular automaton by constructing the recognition function of the states of the cell and the neighbors. therefore, a huge number of calculations by if-else sentences are transferred to the function calculation due to the adoption of the function of the local rules during the evolution of the eca. finally, the simulation results show that the programming structure is optimized and the programming efficiency is enhanced. in addition, the proposed method can also be extended to other 2-state cellular automata. (c) 2015 elsevier inc. all rights reserved.
system_identification	operational modal analysis is the primary tool for modal parameter identification in civil engineering. bayesian statistics offers an ideal framework for analyzing uncertainties associated with the identified modal parameters. however, the exact bayesian formulation is usually intractable due to the high computational demand in obtaining the posterior distributions of modal parameters. in this paper, the variational bayes method is employed to provide an approximate solution. unlike the laplace approximation and monte carlo sampling, the variational bayes approach provides a gradient-free algorithm to analytically approximate the posterior distributions. working with the state-space representation of a dynamical system, the variational bayes approach for identification of modal parameters is derived by ignoring statistical correlation between latent variables and the model parameters. in this approach, the joint distribution of the state-transition and observation matrices as well as the joint distribution of the process noise and measurement error are firstly calculated analytically using conjugate priors. the distribution of modal parameters is extracted from these obtained joint distributions using a first-order taylor series expansion. a robust implementation of the method is discussed by using square-root filtering and cholesky decomposition. the proposed approach is illustrated by its application to an example mass-spring system and the one rincon hill tower in san francisco.
computer_graphics	3d digital visualization technology is a new research field along with the rapid development of computer technology. it is a multi-scale technology which consists of computer graphics, image information processing, computer aided design. this paper is about the research and development of products innovation design method, thereby realize the innovation of product design rapidly. at the same time to verify the feasibility and practicality and broad application prospect of applying 3d scan technology to the rapid development, design and manufacture of products.
software_engineering	purpose: this article aims to the evaluation of a prototypal assistive technology for alzheimer 's disease (ad) patients that helps them to remember personal details of familiar people they meet in their daily lives. method: an architecture is proposed for a personal information system powered by face recognition, where the main ad patient 's interaction is performed in a smart watch device and the face recognition is carried out on the cloud. a prototype was developed to perform some tests in a real-life scenario. results: the prototype showed correct results as a personal information system based on face recognition. however, usability flaws were identified in the interaction with the smart watch. conclusions: our architecture showed correct performance and we realized that it could be introduced in other fields, apart from assistive technology. however, when being targeted to patients with dementia some usability problems appeared, such as difficulties to read information in a small screen or take a proper photo. these problems should be addressed in further research.
analog_signal_processing	in this paper we present a cmos implementation of a 512x512-cell associative content addressable memory (acam) in 180 nm cmos. the memory can be operated either as an associative cam or it can be configured into a willshaw memory for operating with sparse data. the vector matching operation can use a tunable hit threshold or the strongest hit can be selected with a winner-take-all (wta) network. built-in row and column circuitry can perform logic operations on the contents of the row and column memories. the operation of the circuit is verified experimentally with an example on computing with random vectors.
symbolic_computation	a web-based knowledge database and computing platform for nonlinear differential equations is presented, which could provide computing and graphing based on symbolic computing system maple and some of its built-in packages. users can not only calculate specific types of analytical solutions of nonlinear differential systems by calling the packages, but also carry out any symbolic computations associated with equations and other kinds of simple computations in an interactive mode with visual output. the knowledge database of differential equations has all functions of the general database. furthermore, each equation has a web page to show its properties and research results. in addition, each mathematica formula is stored in its infix form in the knowledge database and can be displayed visually.
computer_vision	the woven fabric is a flexible object and to specify its parameters, applying inflexible and ordinary methods of image processing ever have considerable errors. in this regards, proposing an adaptable method to fabric image properties is concentrated to detect the yarns position. in this research, a flexible algorithm is proposed containing two stages: first, the inexact ranges of fabric parameters are determined by preprocessing colored fabric images using wavelet transform and clustering methods. then, the hybrid genetic and imperialist competitive algorithm is applied to optimize the obtained ranges and detect the yarns position. to achieve better results, the parameters of the hybrid ica-ga are calibrated using the taguchi method. results indicate that in this new method, the error value of detecting structural fabric parameters has considerably decreased to 5% as compared with common gray-scale projection method. the proposed method is capable of detecting the exact yarns position in colored fabric images with uneven color intensity and low-density weave with mean precision value of 96.2%. in the fabric images with high density weaves, the mean precision value is more than 94.72%.
bioinformatics	n-6-methyladenosine (m(6)a) is a prevalent modification present in the mrnas of higher eukaryotes. yth domain family 2 (ythdf2), an m(6)a reader protein, can recognize mrna m(6)a sites to mediate mrna degradation. however, the regulatory mechanism of ythdf2 is poorly understood. to this end, we investigated the post-transcriptional regulation of ythdf2. bioinformatics analysis suggested that the microrna mir-145 might target the 3-untranslated region (3-utr) of ythdf2 mrna. the levels of mir-145 were negatively correlated with those of ythdf2 mrna in clinical hepatocellular carcinoma (hcc) tissues, and immunohistochemical staining revealed that ythdf2 was closely associated with malignancy of hcc. interestingly, mir-145 decreased the luciferase activities of 3-utr of ythdf2 mrna. mutation of predicted mir-145 binding sites in the 3-utr of ythdf2 mrna abolished the mir-145-induced decrease in luciferase activity. overexpression of mir-145 dose-dependently down-regulated ythdf2 expression in hcc cells at the levels of both mrna and protein. conversely, inhibition of mir-145 resulted in the up-regulation of ythdf2 in the cells. dot blot analysis and immunofluorescence staining revealed that the overexpression of mir-145 strongly increased m(6)a levels relative to those in control hcc cells, and this increase could be blocked by ythdf2 overexpression. moreover, mir-145 inhibition strongly decreased m(6)a levels, which were rescued by treatment with a small interfering rna-based ythdf2 knockdown. thus, we conclude that mir-145 modulates m(6)a levels by targeting the 3-utr of ythdf2 mrna in hcc cells.
analog_signal_processing	the objective of this paper is to upgrade a wireless sensing unit which can meet the following requirements: 1) improvement of system powering and analog signal processing 2) enhancement of signal resolution and provide reliable wireless communication data, 3) enhance capability for continuous long-term monitoring. based on the prototype of the wireless sensing unit developed by prof. lynch at the stanford university, the following upgrading steps are summarized: 1. reduce system noise by using smd passive elements and preventing the coupling digital and analog circuits, and increasing the capacity of power. 2. improve the adc sampling resolution and accuracy with a higher resolution analog-to-digital converter (adc): a 24bits adc with programmable gain amplifier. 3. improve wireless communication by using the wireless radio 9xtend which supported by the router (digi mesh) communication function using 900mhz frequency band. based on the upgrade wireless sensing unit, verification of the new wireless sensing unit was conducted from the ambient vibration survey of a base-isolated building. this new upgrade wireless sensing unit can provide more reliable data for continuous structural health monitoring. incorporated with the identification software (modified stochastic subspace identification method) the smart sensing system for shm is developed.
digital_control	the use of a digital architecture in pwm controllers for point-of-load (pol) applications, together with system identification techniques, allows the development of fully automated routines for in-situ system performance optimization where controller parameters are specifically tailored to the application. in this context, this paper proposes a method for performing parametric system identification of digitally controlled power converters using a conventional analog frequency response analyzer (fra). nonlinearities intrinsic to the digital loop are taken into account, thus leading to accurate estimation of converter parameters. the proposed method has been verified on a digitally controlled pol with v-in=12v, v-out=1.2v, i-out=10a and f(sw)=400khz for various bulk capacitor scenarios.
algorithm_design	in this paper, an algorithm is designed for shooting games under strong background light. six leds are uniformly distributed on the edge of a game machine screen. they are located at the four corners and in the middle of the top and the bottom edges. three leds are enlightened in the odd frames, and the other three are enlightened in the even frames. a simulator is furnished with one camera, which is used to obtain the image of the leds by applying inter-frame difference between the even and odd frames. in the resulting images, six led are six bright spots. to obtain the leds' coordinates rapidly, we proposed a method based on the area of the bright spots. after calibrating the camera based on a pinhole model, four equations can be found using the relationship between the image coordinate system and the world coordinate system with perspective transformation. the center point of the image of leds is supposed to be at the virtual shooting point. the perspective transformation matrix is applied to the coordinate of the center point. then we can obtain the virtual shooting point 's coordinate in the world coordinate system. when a game player shoots a target about two meters away, using the method discussed in this paper, the calculated coordinate error is less than ten mm. we can obtain 65 coordinate results per second, which meets the requirement of a real-time system. it proves the algorithm is reliable and effective.
computer_graphics	as a result of the relief image surface pattern shapes are often very complicated, no rules of geometry and detailed, with traditional computer graphics methods is difficult to achieve realistic embossed reproduction effect and the practical processing effect. at present, there are few new theoretical achievements in this field in china.this paper designed a simple method to get the 3 d relief effect fast, color images based on cellular neural networks (cnn) embossment effect processing method, through simulation experiment, this method has proved its convenient operation and implementation, and its application in the hail cloud layer image pre-processing,achieved good results.
symbolic_computation	studied in this paper is a ()-dimensional nonlinear schrodinger equation with the group velocity dispersion, fiber gain-or-loss and nonlinearity coefficient functions, which describes the evolution of a slowly varying wave packet envelope in the inhomogeneous optical fiber. with the hirota method and symbolic computation, the bilinear form and dark multi-soliton solutions under certain variable-coefficient constraint are derived. interactions between the different-type dark two solitons have been asymptotically analyzed and presented. both velocities and amplitudes of the two linear-type dark solitons do not change before and after the interaction. the two parabolic-type dark solitons propagating with the opposite directions both change their directions after the interaction. interaction between the two periodic-type dark solitons is also presented. interactions between the linear-, parabolic- and periodic-type dark two solitons are elastic.
machine_learning	twitter spam has become a critical problem nowadays. recent works focus on applying machine learning techniques for twitter spam detection, which make use of the statistical features of tweets. in our labeled tweets data set, however, we observe that the statistical properties of spam tweets vary over time, and thus, the performance of existing machine learning-based classifiers decreases. this issue is referred to as ""twitter spam drift"". in order to tackle this problem, we first carry out a deep analysis on the statistical features of one million spam tweets and one million non-spam tweets, and then propose a novel lfun scheme. the proposed scheme can discover ""changed"" spam tweets from unlabeled tweets and incorporate them into classifier 's training process. a number of experiments are performed to evaluate the proposed scheme. the results show that our proposed lfun scheme can significantly improve the spam detection accuracy in real-world scenarios.
state_space_representation	we present a novel formulation that employs task-specific muscle synergies and state-space representation of neural signals to tackle the challenging myoelectric control problem for lower arm prostheses. the proposed framework incorporates information about muscle configurations, e.g., muscles acting synergistically or in agonist/antagonist pairs, using the hypothesis of muscle synergies. the synergy activation coefficients are modeled as the latent system state and are estimated using a constrained kalman filter. these task-dependent synergy activation coefficients are estimated in real-time from the electromyogram (emg) data and are used to discriminate between various tasks. the task discrimination is helped by a post-processing algorithm that uses posterior probabilities. the proposed algorithm is robust as well as computationally efficient, yielding a decision with >90% discrimination accuracy in approximately 3 ms. the real-time performance and controllability of the algorithm were evaluated using the targeted achievement control (tac) test. the proposed algorithm outperformed common machine learning algorithms for single-as well as multi-degree-of-freedom (dof) tasks in both off-line discrimination accuracy and real-time controllability (p < 0.01).
computer_programming	data structures and algorithms are important foundation topics in computer science education. however, they are considered to be hard to teach and learn because usually model complicated concepts, refer to abstract mathematical notions, or describe complex dynamic changes in data structures. many students in programming courses have difficulties to master all required competencies and skills especially at introductory level. in the literature there are different ways to enhance learning programming and deal with the important dropout rate. recently, games are increasingly being used for education in various fields. we hypothesize that games have the potential to be an important teaching tool for their interactive, engaging and immersive activities. so they can improve student engagement, motivation, and consequently learning. to this end, we are developing a game to teach basic algorithmic concepts and algorithms. we aim to initially investigate the educational games developed for and used in the computer programming domain and review to which level they address the aforementioned difficulties. then, we propose a role playing game called algogame based on existing solutions and incorporates new elements. a pre validation of the game with novice students was very encouraging and demonstrates that learning programming can be enhanced by playing with algogame.
digital_control	in these days, three degree of freedom (3dof) cranes are considered as backbone in most of industries. it is mostly used for picking and placing of heavy objects from one place to another place. the common part in mostly cranes is jib system. two main tasks of jib system are movement of the trolley and loading/unloading of the payload. the safety of crane mostly depends upon these sub tasks. in most cases, number of unwanted vibrations due to undesirable initial jerks of trolley results uneven operation of crane. these jerks are usually happened during acceleration in the start and deceleration in the end of crane operation. so, it is desirable to develop a control technique that tries to reduce theses initial trolley jerks by providing a reasonable input to the trolley. moreover, reduction of jerks reduce the payload vibrations. so, it results smooth operation of crane. in this research work, we have implemented pd control technique for payload vibration and trolley position control of jib system of three 3dof crane. the gains of pd controllers have been found through two methods namely lqr and pole placement. the performance of controllers have been investigated on matlab/simulink. the results shows the effectiveness of pd tune by lqr as compared to pd tune by pole placement in context of settling time and rise time of both trolley position and payload vibrations. the former technique is also helpful in reduction of payload vibrations or payload load anti-swing. it has also improved the overshoot of the trolley.
computer_programming	computer programming is an important competence for engineering and computer science students. teaching and learning programming concepts and skills have been recognized as being a big challenge to both teachers and students. accordingly, researchers have indicated that 'learning strategy,' lack of study' and 'lack of practice' are the causal attributes of success or failure in a computer programming course. therefore, to cope with this problem, an interactive test system is proposed to enhance students' learning outcomes in computer programming courses in this study. an experiment has been conducted on a college computer programming course to evaluate the effectiveness of the proposed method. the experimental results show that the proposed approach can benefit the students in enhancing their programming skills. in addition, the students' attitudes toward learning computer programming were improved.
distributed_computing	time-triggered architectures form an important component of many distributed computing platforms for safety-critical real-time applications such as avionics and automotive control systems. tta, flexray, and ttcan are examples of such time-triggered architectures that have been popular in recent times. these architectures involve a number of algorithms for synchronizing a set of distributed computing nodes for meaningful exchange of data among them. the algorithms include a startup algorithm whose job is to integrate one or more nodes into the group of communicating nodes. the startup algorithm runs on every node when the system is powered up, and again after a failure occurs. some critical issues need to be considered in the design of the startup algorithms, for example, the algorithms should be robust under reasonable assumptions of failures of nodes and channels. the safety-critical nature of the applications where these algorithms are used demands rigorous verification of these algorithms, and there have been numerous attempts to use formal verification techniques for this purpose. this paper focuses on various formal verification efforts carried out for ensuring the correctness of the startup algorithms. in particular, the verification of different startup algorithms used in three time-triggered architectures, tta, flexray, and ttcan, is studied, compared, and contrasted. besides presenting the various verification approaches for these algorithms, the gaps and possible improvements on the verification efforts are also indicated.
system_identification	the presence of damage in a civil structure alters its stiffness and consequently its modal characteristics. the identification of these changes can provide engineers with useful information about the condition of a structure and constitutes the basic principle of the vibration-based structural health monitoring. while eigenfrequencies and mode shapes are the most commonly monitored modal characteristics, their sensitivity to structural damage may be low relative to their sensitivity to environmental influences. modal strains or curvatures could offer an attractive alternative but current measurement techniques encounter difficulties in capturing the very small strain (sub-microstrain) levels occurring during ambient, or operational excitation, with sufficient accuracy. this paper investigates the ability to obtain sub-microstrain accuracy with standard fiber-optic bragg gratings using a novel optical signal processing algorithm that identifies the wavelength shift with high accuracy and precision. the novel technique is validated in an extensive experimental modal analysis test on a steel i-beam which is instrumented with fbg sensors at its top and bottom flange. the raw wavelength fbg data are processed into strain values using both a novel correlation-based processing technique and a conventional peak tracking technique. subsequently, the strain time series are used for identifying the beam 's modal characteristics. finally, the accuracy of both algorithms in identification of modal characteristics is extensively investigated.
electric_motor	these days electrical motors are generally utilized as a part of our everyday life, no matter as small as in our laptop 's hard disc till as large as in other electrical machines, for example, fan, refrigerator, washing machine and many more. electric motors are the sources to drive or direct any equipment with mechanical perspective. this paper mainly focuses on the application of linear motion motors for the linear movement of image sensor. from the various electrical motors, stepper motor has advantage of micro stepping ability to manoeuvre it as per needed steps. stepper motor miniaturized scale venturing is finished by pulse width modulation of a varying current. considering the accuracy of every step is 3% to 5% and error inside the last step ca n't be collected into ensuing step, the stepper motor has higher position preciseness and sensible repetitive motion make them increasingly attractive for the image sensor applications. in this paper, diverse electric motors are examined and compared to see the benefits of each motor and identify the one that is more suitable to be utilized as a part of the movement of sensor/lens.
relational_databases	purpose - the purpose of this paper is to present a four-level architecture that aims at integrating, publishing and retrieving ecological data making use of linked data (ld). it allows scientists to explore taxonomical, spatial and temporal ecological information, access trophic chain relations between species and complement this information with other data sets published on the web of data. the development of ecological information repositories is a crucial step to organize and catalog natural reserves. however, they present some challenges regarding their effectiveness to provide a shared and global view of biodiversity data, such as data heterogeneity, lack of metadata standardization and data interoperability. ld rose as an interesting technology to solve some of these challenges. design/methodology/approach - ecological data, which is produced and collected from different media resources, is stored in distinct relational databases and published as rdf triples, using a relational-resource description format mapping language. an application ontology reflects a global view of these datasets and share with them the same vocabulary. scientists specify their data views by selecting their objects of interest in a friendly way. adata view is internally represented as an algebraic scientific workflow that applies data transformation operations to integrate data sources. findings - despite of years of investment, data integration continues offering scientists challenges in obtaining consolidated data views of a large number of heterogeneous scientific data sources. the semantic integration approach presented in this paper simplifies this process both in terms of mappings and query answering through data views. social implications - this work provides knowledge about the guanabara bay ecosystem, as well as to be a source of answers to the anthropic and climatic impacts on the bay ecosystem. additionally, this work will enable evaluating the adequacy of actions that are being taken to clean up guanabara bay, regarding the marine ecology. originality/value - mapping complexity is traded by the process of generating the exported ontology. the approach reduces the problem of integration to that of mappings between homogeneous ontologies. as a byproduct, data views are easily rewritten into queries over data sources. the architecture is general and although applied to the ecological context, it can be extended to other domains.
electric_motor	this paper describes a novel, low-profile antenna for the satellite digital audio radio service. the antenna consists of a thin cavity with a pair of crossed slots having unequal length. both slots are fed by a single-probe-type feed, resulting in a simple low-cost structure. this antenna is left-hand circularly polarized toward the sky for satellite reception, and vertically polarizated toward the horizon for terrestrial reception. the result is a low-profile antenna that can receive simultaneously from both satellite broadcasters and terrestrial repeaters, and can be built using low-cost printed circuit fabrication methods.
analog_signal_processing	this paper presents the design and measurement results of a novel frequency-mixing transimpedance amplifier (fm-tia), which is the key building block towards a monolithically integrated optical sensor front-end for frequency domain near-infrared (nir) spectroscopy (fd-nirs). the fm-tia employs a t-feedback network incorporating a gate-controlled transistor for resistance modulation, enabling the simultaneous down-conversion and amplification of the high frequency modulated photodiode (pd) current. the proposed fm-tia is capable of operating either in the traditional wideband mode or the frequency-mixing mode, depending on the applied gate control voltage. a wideband post amplifier is implemented on chip to characterize both modes for comparative study. the wideband mode achieves 107 db omega transimpedance gain with 200 mhz bandwidth for 4 pf photodiode capacitance. the measured total integrated input referred current noise is 158 na(rms). when the tia is modulated by a 100 mhz signal with 0.5 v amplitude in the mixing mode, it achieves 92 db omega conversion gain. the measured 1 db compression point is 3.1 mu a and iip3 is 10.6 mu a. the input-referred current noise integrated up to 50 khz is only 10.4, na(rms), which is 15 times lower than the wideband mode noise. the fm-tia together with the post amplifier draws 23 ma from a 1.8 v power supply, where the output buffer consumes 16.15 ma.
electric_motor	four adult (2m:2f) snow leopards (uncia uncia) were radio-monitored (vhf; one also via satellite) year-round during 1994-1997 in the altai mountains of southwestern mongolia where prey densities (i.e., ibex, capra siberica) were relatively low (-0.9/km(2)). marked animals were more active at night (51%) than during the day (35%). within the study area, marked leopards showed strong affinity for steep and rugged terrain, high use of areas rich in ungulate prey, and affinity for habitat edges. the satellite-monitored leopard moved more than 12 kin on 14% of consecutive days monitored. home ranges determined by standard telemetry techniques overlapped substantially and were at least 13-141 km(2) in size. however, the satellite-monitored individual apparently ranged over an area of at least 1590 km(2), and perhaps over as much as 4500 km(2). since telemetry attempts from the ground were frequently unsuccessful (x = 72%), we suspect all marked animals likely had large home ranges. relatively low prey abundance in the area also suggested that home ranges of >500 km(2) were not unreasonable to expect, though these are >10-fold larger than measured in any other part of snow leopard range. home ranges of snow leopards may be larger than we suspect in many areas, and thus estimation of snow leopard conservation status must rigorously consider logistical constraints inherent in telemetry studies, and the relative abundance of prey. (c) 2005 elsevier ltd. all rights reserved.
system_identification	a triaxial force-sensitive microrobot was developed to dynamically perturb skin in multiple deformation modes, in vivo. wiener static nonlinear identification was used to extract the linear dynamics and static nonlinearity of the force-displacement behavior of skin. stochastic input forces were applied to the volar forearm and thenar eminence of the hand, producing probe tip perturbations in indentation and tangential extension. wiener static nonlinear approaches reproduced the resulting displacements with variances accounted for (vaf) ranging 94-97%, indicating a good fit to the data. these approaches provided vaf improvements of 0.1-3.4% over linear models. thenar eminence stiffness measures were approximately twice those measured on the forearm. damping was shown to be significantly higher on the palm, whereas the perturbed mass typically was lower. coefficients of variation (cvs) for nonlinear parameters were assessed within and across individuals. individual cvs ranged from 2% to 11% for indentation and from 2% to 19% for extension. stochastic perturbations with incrementally increasing mean amplitudes were applied to the same test areas. differences between full-scale and incremental reduced-scale perturbations were investigated. different incremental preloading schemes were investigated. however, no significant difference in parameters was found between different incremental preloading schemes. incremental schemes provided depth-dependent estimates of stiffness and damping, ranging from 300 n/m and 2 ns/m, respectively, at the surface to 5 kn/m and 50 ns/m at greater depths. the device and techniques used in this research have potential applications in areas, such as evaluating skincare products, assessing skin hydration, or analyzing wound healing.
computer_vision	rgb-d sensors have been widely used in various areas of computer vision and graphics. a good descriptor will effectively improve the performance of operation. this article further analyzes the recognition performance of shape features extracted from multi-modality source data using rgb-d sensors. a hybrid shape descriptor is proposed as a representation of objects for recognition. we first extracted five 2d shape features from contour-based images and five 3d shape features over point cloud data to capture the global and local shape characteristics of an object. the recognition performance was tested for category recognition and instance recognition. experimental results show that the proposed shape descriptor outperforms several common global-to-global shape descriptors and is comparable to some partial-to-global shape descriptors that achieved the best accuracies in category and instance recognition. contribution of partial features and computational complexity were also analyzed. the results indicate that the proposed shape features are strong cues for object recognition and can be combined with other features to boost accuracy.
electric_motor	the purpose of this study was to evaluate the presence of dentinal defects after root canal preparation with hand instruments and two different reciprocating instruments. sixty freshly extracted mandibular incisor teeth were selected for this in vitro study. on the basis of root length, mesiodistal and buccolingual dimensions, the teeth were allocated into three identical experimental groups (n = 15) and one control group (n = 15). the teeth in the control group were left unprepared. the other groups were: stainless steel hand instruments, waveone (r) primary instruments and reciproc (r) r25 instruments. the reciprocating instruments were used with a reciprocating gentle in-and-out motion in a torque-limited electric motor at the appropriate preset mode. horizontal sections were made 3, 6 and 9 mm from the apex. samples were stained with methylene blue and viewed through a stereomicroscope. the presence of dentinal defects (fractures, incomplete cracks and craze lines) and their locations were investigated by two endodontists. these data were analysed statistically by fisher 's exact and chi-square tests. no defects were observed in the unprepared group. all instruments caused dentinal defects, with no significant differences between the instrument systems. all experimental groups demonstrated significantly more defects at the 3-mm level in comparison with the unprepared group (p = 0.032). at the other levels, there was no significant difference between the experimental groups and the control group. the use of hand or reciprocating instruments could induce the formation of dentinal defects during root canal preparation.
machine_learning	high performance, parallel applications with irregular data accesses are becoming a critical workload class for modern systems. in particular, the execution of such workloads on emerging many-core systems is expected to be a significant component of applications in data mining, machine learning, scientific computing and graph analytics. however, power and energy constraints limit the capabilities of individual cores, memory hierarchy and on-chip interconnect of such systems, thus leading to architectural and software trade-offs that must be understood in the context of the intended application 's behavior. irregular applications are notoriously hard to optimize given their data-dependent access patterns, lack of structured locality and complex data structures and code patterns. we have ported two irregular applications, graph community detection using the louvain method (grappolo) and high-performance conjugate gradient (hpccg), to the tilera many-core system and have conducted a detailed study of platform-independent and platform-specific optimizations that improve their performance as well as reduce their overall energy consumption. to conduct this study, we employ an auto-tuning based approach that explores the optimization design space along three dimensions memory layout schemes, gcc compiler flag choices and openmp loop scheduling options. we leverage mit 's opentuner auto-tuning framework to explore and recommend energy optimal choices for different combinations of parameters. we then conduct an in-depth architectural characterization to understand the memory behavior of the selected workloads. finally, we perform a correlation study to demonstrate the interplay between the hardware behavior and application characteristics. using auto-tuning, we demonstrate whole-node energy savings and performance improvements of up to 49.6% and 60% relative to a baseline instantiation, and up to 31% and 45.4% relative to manually optimized variants. (c) 2016 elsevier inc. all rights reserved.
software_engineering	this paper presents a controlled experiment in which the goodness of using theory belbin roles for the integration of software development teams is explored. the study takes place in an academic environment with students from the engineering of software and compares the quality of the readability of the code generated by integrated teams with roles compatible - according to the theory of belbin- and traditional teams, in our case, integrated teams with students selected randomly. the results provide positive evidence on the use of this theory and motivate researchers to continue studies in other activities related to the software development process; on the other hand, from a pedagogical perspective, the results obtained with the experiment, allow proposing as an alternative to integration teams, learning scenarios related courses software engineering, theory of roles of belbin.
algorithm_design	information retrieval and web search present a challenging question to researches. today users urge for accurate and precise hands on information from search machine. interpreting of user query goal is major challenge in past and present. numerous algorithms and frameworks have be proposed, but fail to incorporate user aims, as query without proper intent processing retrieves irrelevant information pattern discovery has ability to solve in limitations of keyword and image disambiguates with phrase learning ie, pattern discovery. today 's search machines are based on ranking model eliminating boolean retrieval constraint and boosting natural language use. even though word sense and concept extraction is major challenge which comes up with keywords. information can be presented in better way with image presentation, which is been used in news portals to communicate fastly happing news and social websites instagram facebook, flicker. user purchase goods by sighting product images on flipkart. so today uses have sifted their approach from text based information to image based, which has given rise to research domain of image information retrieval (iir) but large number of image attributes also give rise to image classification ambiguity. relevance is major factor that influence information retrieval system performance with impact precision and recall. relevance re-ranking is methodology opted in to retrieve most optimized relevant results eliminating non-relevant. large amount of image with associated word annotations are present on different web portals. in this research we build a semantic search engine which selects network design pattern and integrate reinformant learning approach (agent based learning) that help in selecting information from various networks and help in network structuring with wair (web agents for information retrieval) architecture at core. agent helping in retrieving precise objects from different portals and linking them. a optimized procedure e-simrank is been implemented to count in link semantic in network and content based knowledge learning for reinforcing better results. performance evaluation show that proposed architecture and algorithm design present faster and relevance result. a image based recommendation system is our research outcome which contributes to image retrieval domain. the research work is been developed by studying 24 core vital articles on image retrieval and find research scope with major challenges which have common ground and need to be addressed. the found research analysis query (raq) help in directing to study better techniques to overcome problem. our research innovation is reinforment learning algorithm agent based system development. existing state of art of present algorithms have been optimized with this innovation integration. future scope of research lies to image to image base retrieval or video recommendation system.
structured_storage	micro-blog as an important part of the network media has become an important access to information for netizens. some hot topics have an immeasurable impact on the public opinion formation and dissemination, and also potential security risks are absolutely not underestimated. collecting the relevant data in the micro-blog can provide data base for public opinion analysis. the study, social topic detection system based on micro-blog is mainly centered on the key technologies in the information capture and the chinese handling of micro-blog. this study invokes the api of sina micro-blog through three kinds of capture strategy, and then uses rmm reverse maximum matching algorithm to capture the information of micro-blog, after this using classification of self-build public opinion to do information classification of micro-blog for structured storage. at last this study finishes the research and implement of the system based on micro-blog. the system has realized the hot topics of timely capture, collection, classification, storage and retrieval which lay the foundation for further public opinion analysis.
computer_graphics	texture synthesis is a well-established area, with many important applications in computer graphics and vision. however, despite their success, synthesis techniques are not used widely in practice because the creation of good exemplars remains challenging and extremely tedious. in this paper, we introduce an unsupervised method for analyzing texture content across multiple scales that automatically extracts good exemplars from natural images. unlike existing methods, which require extensive manual tuning, our method is fully automatic. this allows the user to focus on using texture palettes derived from their own images, rather than on manual interactions dictated by the needs of an underlying algorithm. most natural textures exhibit patterns at multiple scales that may vary according to the location (non-stationarity). to handle such textures many synthesis algorithms rely on an analysis of the input and a guidance of the synthesis. our new analysis is based on a labeling of texture patterns that is both (i) multi-scale and (ii) unsupervised - that is, patterns are labeled at multiple scales, and the scales and the number of labeled clusters are selected automatically. our method works in two stages. the first builds a hierarchical extension of superpixels and the second labels the superpixels based on random walk in a graph of similarity between superpixels and a nonnegative matrix factorization. our label-maps provide descriptors for pixels and regions that benefit state-of-the-art texture synthesis algorithms. we show several applications including guidance of non-stationary synthesis, content selection and texture painting. our method is designed to treat large inputs and can scale to many megapixels. in addition to traditional exemplar inputs, our method can also handle natural images containing different textured regions.
microcontroller	owing to various advantages over conventional drying systems, microwave drying technology has been widely applied to vast industrial applications. during microwave drying especially in high moisture content products such as fruits and vegetables, temperature will increase dramatically since they are very responsive to microwave absorption. the characteristics of materials may change with the uncontrolled temperature and result in thermal burning and non-uniform temperature distribution in treated materials. to ensure the effective control without the material degradation, in this paper we propose the automatic phase-controlled of magnetron driver based on temperature detection. the low cost and non-contact infrared temperature measurement is implemented and evaluated in microwave environment. the objective of this proposed control is to automatically control the power output of the magnetron according to the actual product temperature. the hardware component selections and software flowchart are described. the feedback control algorithm based on microcontroller arduino mega 2560 is also presented in details. experimental results of the proposed automatic temperature control of microwave drying system are investigated and verified the effectiveness of the proposed control system.
data_structures	we introduce transactions into libraries of concurrent data structures; such transactions can be used to ensure atomicity of sequences of data structure operations. by focusing on transactional access to a well-defined set of data structure operations, we strike a balance between the ease-ofprogramming of transactions and the efficiency of customtailored data structures. we exemplify this concept by designing and implementing a library supporting transactions on any number of maps, sets (implemented as skiplists), and queues. our library offers efficient and scalable transactions, which are an order of magnitude faster than state-of-theart transactional memory toolkits. moreover, our approach treats stand-alone data structure operations (like put and enqueue) as first class citizens, and allows them to execute with virtually no overhead, at the speed of the original data structure library.
image_processing	a microstructure-based modeling method is developed to predict the mechanical behaviors of lithium ion battery separators. existing battery separator modeling methods cannot capture the structural features on the microscale. to overcome this issue, we propose an image-based microstructure representative volume element (rve) modeling method, which facilitates the understanding of the separators complex macro mechanical behaviors from the perspective of microstructural features. a generic image processing workflow is developed to identify different phases in the microscopic image. the processed rve image supplies microstructural information to the finite element analysis (fea). both mechanical behavior and microstructure evolution are obtained from the simulation. the evolution of microstructure features is quantified using the stochastic microstructure characterization methods. the proposed method successfully captures the anisotropic behavior of the separator under tensile test, and provides insights into the microstructure deformation, such as the growth of voids. we apply the proposed method to a commercially available separator as the demonstration. the analysis results are validated using experimental testing results that are reported in literature. (c) 2017 elsevier b.v. all rights reserved.
cryptography	mobile cloud computing (mcc) combines the features of mobile computing, cloud computing, and wireless networks to create the healthy computational resources to mobile cloud users. the aim of mcc is to execute the highly attractive mobile applications on a plethora of mobile cellular telephones, with highly rich user experience. from the perspective of mobile computing, quality of service (qos) provisioning depends on the efficiency of the handoff process. thus, it is highly important to introduce an energy efficient and secure handoff process to improve the performance. in this paper, we propose a secure seamless fast handoff (ssfh) scheme to improve the energy efficiency and the qos in the mcc. the proposed scheme consists of four layers: application layer, service layer, infrastructure layer, and media layer. these four layers collectively handle the security, energy-efficiency, and the qos. existing service-oriented architectures designed for the mcc are based on the symmetric encryption protocols to support the application layer. however, it is much easier for an adversary to expose the symmetric key and gain access to the confidential data. the application layer is secured using a combination of both attribute-based encryption and an asymmetric encryption cryptography. to extend the mobile lifetime, energy detection (ed) model is deployed at the infrastructure layer to detect the energy level of the mobile devices prior to the pre-registration process. furthermore, a dual authentication process is performed on the service and at the application layer to minimize the possibility of identity high jacked or impersonation attack. the media layer supports the secure handoff process using policy enforcement module that allows only legitimate users to complete the re registration process after initiating the handoff. thus, a significant amount of the bandwidth and energy could be preserved. finally, the secure service-oriented architecture is programmed using c++ platform and the results are compared with other well-known existing service-oriented architectures. the experimental results confirm the validity and the effectiveness of our proposed architecture. (c) 2017 elsevier ltd. all rights reserved.
electrical_circuits	leaf movements in mimosa pudica, are in response to thermal stress, touch, and light or darkness, appear to be regulated by electrical, hydrodynamical, and chemical signal transduction. the pulvinus of the m. pudica shows elastic properties. we have found that the movements of the petiole, or pinnules, are accompanied by a change of the pulvinus morphing structures. after brief flaming of a pinna, the volume of the lower part of the pulvinus decreases and the volume of the upper part increases due to the redistribution of electrolytes between these parts of the pulvinus; as a result of these changes the petiole falls. during the relaxation of the petiole, the process goes in the opposite direction. ion and water channel blockers, uncouplers as well as anesthetic agents diethyl ether or chloroform decrease the speed of alert wave propagation along the plant. brief flaming of a pinna induces bidirectional propagation of electrical signal in pulvini. transduction of electrical signals along a pulvinus induces generation of an action potential in perpendicular direction between extensor and flexor sides of a pulvinus. inhibition of signal transduction and mechanical responses in m. pudica by volatile anesthetic agents chloroform or by blockers of voltage gated ion channels shows that the generation and propagation of electrical signals is a primary effect responsible for turgor change and propagation of an excitation. there is an electrical coupling in a pulvinus similar to the electrical synapse in the animal nerves. (c) 2013 elsevier gmbh. all rights reserved.
electric_motor	pond aeration systems were developed to sustain large quantities of fish and biomass materials. in this study the importance and functions of aeration were examined and prototype paddle wheel aerator was developed. the main features of the paddle wheel aerator were electric motor used as prime mover which was of one horse power capacity, and paddle hubs with six paddles all mounted on a shaft made of stainless steel and brass materials. aeration experiment was conducted in water basin made up of plastic. paddle - wheel aerator performance evaluation was conducted using unsteady state test. physico-chemical properties of water sampled from the tested ponds were determined in accordance with the american public health association standards (apha, 2005). performance test carried out showed that the overall oxygen transfer co-efficient (k(l)a) was observed to be as high as 8.19 hr(-1) and standard oxygen transfer rate (sotr) and standard aerator efficiency (sae) ranged from 1.1-1.2 kg o-2 hr(-1) and 1.1-1.3 kg o-2 kw(-1) hr(-1) respectively. the paddle wheel aerator improved the water quality by addition of oxygen leading to appreciable increase in the fish stock density which has been a major setback of low-income fish farmer in nigeria.
control_engineering	verifying that complex systems such as power plants satisfy the requirements that ensure their proper operation, in particular with respect to safety, dependability and environmental regulations, is difficult due to the large number of potential situations to be explored in terms of initiating events and their chain of consequences on the behavior of the system. the paper presents a new framework for supporting a methodology that aims at reconciling innovation (ability to modify the system) and safety (ability to comply with regulatory requirements). the general principle is to produce independently formal models of the requirements, of the possible variants of the design, and of the dynamic behavior of the system for the possible designs, then assemble them together to simulate the full system 's behavior to automatically detect possible violations of the requirements.
signal-flow_graph	the next generation wireless local area networks (wlans) with enhanced throughput performance have attracted significant amounts of attention in recent years. based on the ieee 802.11n standard, frame aggregation is considered one of the major factors to improve the system performance of wlans from the medium access control perspective. in order to fulfill the requirements of the high throughput performance, feasible design of automatic repeat request (arq) mechanisms is considered important for providing reliable data transmission. in this paper, an aggregated selective repeat arq (asr-arq) algorithm is proposed, which incorporate the conventional selective repeat arq scheme with the consideration of frame aggregation. a novel analytical model based on the signal flow graph is established in order to realize the behaviors of asr-arq algorithm. simulations are also conducted to validate the effectiveness of proposed asr-arq mechanism.
symbolic_computation	the integrability and multi-shock wave solutions of the djkm equation are studied by means of bell polynomials scheme, hirota bilinear method, and symbolic computation. a more generalized bilinear system of the djkm equation is constructed via bell polynomials scheme. moreover, lax pair and infinite conservation laws of this equation are first obtained via its corresponding bell-polynomials-type backlund transformation. furthermore, the multi-shock wave solutions are also obtained by applying standard hirota bilinear method, and the propagation and collision of shock waves are graphically demonstrated by graphs.
distributed_computing	mapreduce is the most widely used distributed computing framework due to its excellent parallelism and scalability in dealing with large-scale data. it is one of the most important research point in distributed computing field to improve the performance of mapreduce application in datacenter network. openflow protocol makes it possible to schedule network resource dynamically to provide better link bandwidth for shuffle traffic. current openflow-based scheduling method runs on a single controller, which cannot meet the needs of excessive switch requests in large scale data center networks. the performance of those scheduling method will decrease obviously due to some conflict problem when they run on distributed controllers. this paper proposed dscheduler, a dynamic network scheduling method for distributed controllers. dscheduler is running as an application on each sdn controller and avoid a majority of conflict problems in scheduling with small cost by using lock and communication between each controller. we implement a prototype system on floodlight to demonstrate our design and test the performance. experimental results show that dscheduler has a significant effect on decreasing the occurrence times of conflict situations and improving the performance of openflow-based scheduling method on distributed controllers.
software_engineering	evolution of systems during their operational life is mandatory and both updates and upgrades should not impair their dependability properties. dependable systems must evolve to accommodate changes, such as new threats and undesirable events, application updates or variations in available resources. a system that remains dependable when facing changes is called resilient. in this paper, we present an innovative approach taking advantage of component-based software engineering technologies for tackling the online adaptation of fault tolerance mechanisms. we propose a development process that relies on two key factors: designing fault tolerance mechanisms for adaptation and leveraging a reflective component based middleware enabling fine-grained control and modification of the software architecture at runtime. we thoroughly describe the methodology, the development of adaptive fault tolerance mechanisms and evaluate the approach in terms of performance and agility. (c) 2017 elsevier b.v. all rights reserved.
electrical_network	the solution of the secondary circuits effect consideration problem during electrical network calculation is presented in the paper. the analysis of statistical operational data concerning primary and secondary equipment failures taken directly from the plant was performed. it follows from the analysis results that relay protection and automation consideration during the reliability calculation is appropriate. the model which permits to solve the reliability assessment problems of the elementary electrical substations circuits with the use of the probabilistic methods and classical reliability theory was developed on the base of statistical data. the basic problems of reliability calculation method application under the conditions of real branched networks were considered and the method importance and further development were also evaluated.
distributed_computing	there is a strong relationship between scientific research and technology advancement. the former generally focuses on studying phenomena happening in the real world, the latter improves tools that are at the basis of this research. from this perspective, information and communication technologies allow the implementation of ever faster tools for analyzing data generated by experiments. the aim of demogrape project is to study the interaction of the upper earth atmosphere and the gnss ( global navigation satellite systems) signals received at ground, in critical environments such as the polar regions. this paper describes the ict infrastructure used to manage the software applications used to analyzed data collected during project experimental campaigns, taking into account the following constraints: (i) the intellectual property of the applications must be protected; (ii) the underlying infrastructure resembles a cloud-federation; (iii) data are over-sized; (iv) provide a unified vision of the available resources to the user (i.e., what are the available applications, and where experimental data reside). leveraging on a lightweight virtualization system, we proposed a management system that copes with all these four constraints. a case study is used to show the process of deploying an application through the proposed system on a specific node where data of interest reside.
pid_controller	this paper studies the use of a fuzzy proportional integral derivative (pid) controller based on a genetic algorithm (ga) in a docking maneuver of two spacecraft in the space environment. the docking maneuver consists of two parts: translation and orientation. to derive governing equations for the translational phase, hill linear equations in a local vertical-local horizontal (lvlh) frame will be used. in fuzzy pid (fpid) controller design, two fuzzy inference motors will be utilized. the single input fuzzy inference motor (sifim) is the first to have only one input, and for each state variable, a separate sifim is defined. another fuzzy inference motor, the preferrer fuzzy inference motor (pfim), represents the control priority order of each state variable and a supervisory role in large deviations. this fpid controller covers a servicer 's translation of a docking maneuver, which tries to dock with a stable nonrotating target. various conflicting objective functions are distance errors from the set point and control efforts. to enter the control limit in an optimization problem, the maximal value of the thrust force is constrained. considering these objective functions, a statistical analysis on the ga parameters will be performed, and the test with the best minimum fuel consumption and minimum deviations of the servicer from the equilibrium point will be chosen as the best test. the three-dimensional (3d) pareto frontiers corresponding to the best test will be plotted, and the optimal points related to the objective functions will be demonstrated on them; the time response figures corresponding to these points will then be generated. the results prove that this controller shows an efficient performance in the docking maneuver of the servicer spacecraft. in comparison with similar work, a number of system performance parameters (e.g., settling time) will be improved, and overshoot (as a critical parameter in docking maneuver) will be truncated. (c) 2017 american society of civil engineers.
machine_learning	emerging technologies are often not part of any official industry, patent or trademark classification systems. thus, delineating boundaries to measure their early development stage is a nontrivial task. this paper is aimed to present a methodology to automatically classify patents concerning service robots. we introduce a synergy of a traditional technology identification process, namely keyword extraction and verification by an expert community, with a machine learning algorithm. the result is a novel possibility to allocate patents which (1) reduces expert bias regarding vested interests on lexical query methods, (2) avoids problems with citation approaches, and (3) facilitates evolutionary changes. based upon a small core set of worldwide service robotics patent applications, we derive apt n-gram frequency vectors and train a support vector machine, relying only on titles, abstracts, and ipc categorization of each document. altering the utilized kernel functions and respective parameters, we reach a recall level of 83% and precision level of 85%.
electric_motor	tight integration of cyber-dominated control systems and physical systems has helped electric vehicles (ev) as a cyber-physical system (cps) to achieve zero-emission transportation capability. however, it poses major difficulties such as poor driving range, high price, and troublesome recharging which demotivate their consumers. these problems have arisen due to the stringent constraints on the ev battery packs. moreover, the battery capacity degrades overtime and this degradation defines the battery lifetime and shortens the driving range further. the driving range and battery lifetime are mainly influenced by the route behavior, electric motor, and heating, ventilation, and air conditioning (hvac) power consumption. in this paper, we present a novel jointly optimized eco-friendly automotive climate control and navigation system methodology. the integration between these two systems helps us to optimize the hvac utilization and route for better battery lifetime and driving range. we have compared the performance of our methodology with the state-of-the-arts for different weather and route behavior. we have seen upto 24% improvement in battery lifetime and 17% reduction in energy consumption.
network_security	there is an enormous growth of industrial applications using internet communication. secure network is a prime objective for the survival of any organization. network monitoring and defence systems have become an integral part of network security for identifying and preventing potential attacks. intrusion detection and prevention systems (idps) are network based defence systems which combines intrusion detection system (ids) and a firewall. in contrast to ids, idps is a proactive technique which provides both quick reactions to potential threats and attacks in a network as well as preventing the attacks from entering the network. current generation idps have their limitations on their performance and effectiveness. some studies have proven that the modern idps have difficulties in dealing with high-speed network traffic. meeting the current network requirements there exist several research approaches to find an efficient idps. nevertheless, serious security and privacy breaches still occur every day, creating an absolute necessity to provide secure and safe information security systems. this survey provides an up-to-date comprehensive review on state of the art of idps based on different accelerating techniques, different detection algorithms, types of hardware and optimizing algorithms to match the demand requirements of high speed network. a detailed overview on high performance ids and idps along with pros and cons of individual techniques will be given. this paper also highlights and discusses the requirement for developing a new idps to detect the known and unknown threats.
computer_graphics	this paper presents analysis on two 3d mesh to 2d map strategies applied to unwrap images of rock tunnels and facilitate visualization of large datasets. first, we examined mesh parameterization algorithms which are used in computer graphics to convert a 3d mesh model to a 2d representation. we found that while these methods were automatic and could provide 2d maps with minimal metric distortion (ie: conservation of lengths in 3d when mapped to 2d), they exhibited twisted shapes and were not intuitive to interpret. second, we proposed two novel approaches, combining mesh deformation algorithms, which are used in computer animation to reshape a 3d mesh to resemble a 3d plane, and projection onto a 2d plane. we found that while these methods required user interaction and introduced a greater amount of metric distortion, their outputs were fairly intuitive to interpret. to compare the relative merits of mesh parameterization and mesh deformation and projection, the different strategies are applied to a 8.2 m wide by 41 m long by 6.7 m high subsection of a mining tunnel. the metric distortion produced was calculated and their respective output 20 maps are presented and discussed. (c) 2016 elsevier ltd. all rights reserved.
electricity	important energy reductions can be achieved in the building sector by providing occupants with feedback about their energy-consumption levels. recent studies link the success of energy-feedback methods to the level of occupant engagement with people in their social circles and the resulting peer pressure to conform to certain social norms. despite promising results, the literature remains limited in scope to individual rather than groups of buildings. this has limited the design of feedback initiatives leveraging social connections that exist, or that can be induced, within and between buildings. the current paper addresses the identified gap by proposing a multilayer agent-based model that serves as a test bed to simulate and optimize feedback methods applied on any building stock (e.g.,community and city). monte carlo and sensitivity analyses show that connecting occupants of different buildings, while increasing their engagement with the feedback mechanism, can lead to energy reductions exceeding 10%. the findings confirm the role of social networks in energy-conservation diffusion, setting the stage for large-scale and socially engaging energy-conservation initiatives. (c) 2017 american society of civil engineers.
signal-flow_graph	a general synthesis procedure is given for a versatile signal flow graph realization of a general transfer function by using current differencing buffered amplifier (cdba). the proposed configuration uses n + 1 cdbas, n capacitors and at most 2n + 4 resistors. this number of resistors can be reduced to n + i for special cases. the circuit is eligible to obtain a variety of transfer characteristics with the same common denominator polynomial, and it is easily converted to different modes of operations. it is straightforward to find the values of the passive elements from the coefficients of the transfer function to be realized. simulations results are obtained by using commercially available active component ad844 and cmos technology as well. all of these make the proposed circuit attractive. (c) 2006 elsevier gmbh. all rights reserved.
computer_graphics	reversible logic has various applications in fields of computer graphics, optical information processing, quantum computing, dna computing, ultra low power cmos design and communication. as our day to day life is demanding more and more portable electronic devices, challenging focus on technology is demanding great system performance without any compromise in power consumption. it is obvious to find tradeoff between processing power and heat generation. as decreased processing speed leads to reduced power consumption but obviously compromise in performance is not acceptable for sophisticated applications. thus power consumption is a prime target now days. needless to say, researchers will now look at reversible logic in this vein. primitive component of reversible logic synthesis are reversible logic gates. thus it is very important for a new researcher to look into extensive literature survey of reversible logic gates. many papers have been reported with review of reversible logic gates. this paper aims on updates in reversible logic gates which are stepping stones in design and synthesis of any complex reversible logic based synthesis.
image_processing	background and objective: the manual transformation of dna fingerprints of dominant markers into the input of tools for population genetics analysis is a time-consuming and error-prone task; especially when the researcher deals with a large number of samples. in addition, when the researcher needs to use several tools for population genetics analysis, the situation worsens due to the incompatibility of data formats across tools. the goal of this work consists in automating, from banding patterns of gel images, the input-generation for the great diversity of tools devoted to population genetics analysis. methods: after a thorough analysis of tools for population genetics analysis with dominant markers, and tools for working with phylogenetic trees; we have detected the input requirements of those systems. in the case of programs devoted to phylogenetic trees, the newick and nexus formats are widely employed; whereas, each population genetics analysis tool uses its own specific format. in order to handle such a diversity of formats in the latter case, we have developed a new xml format, called popxml, that takes into account the variety of information required by each population genetics analysis tool. moreover, the acquired knowledge has been incorporated into the pipeline of the ceti system - a tool for analysing dna fingerprint gel images - to reach our automatisation goal. results: we have implemented, in the gel.j system, a pipeline that automatically generates, from gel banding patterns, the input of tools for population genetics analysis and phylogenetic trees. such a pipeline has been employed to successfully generate, from thousands of banding patterns, the input of 29 population genetics analysis tools and 32 tools for managing phylogenetic trees. conclusions: gelj has become the first tool that fills the gap between gel image processing software and population genetics analysis with dominant markers, phylogenetic reconstruction, and tree editing software. this has been achieved by automating the process of generating the input for the latter software from gel banding patterns processed by gelj. (c) 2016 elsevier ireland ltd. all rights reserved.
electrical_circuits	this paper presents the well-documented concept of synchronization of low frequency oscillation occurring in power systems and describes the characteristics of sync occurring in basic electrical circuits. the theory of sync, observed in basic circuits, is extended to analyze the dynamic characteristics of low-frequency oscillation in power systems.
network_security	as networks applications are growing fast, data are more generated and transmitted, leaving it vulnerable to modification. besides that, the significance, sensitivity and preciseness of that information cause a big security issue, increasing the needs to keep it safe. one proper solution for this problem is cryptography, which is a technique used to transform data to unrecognizable information and useless to any unauthorized person. by being the main core of network security and since new attacks techniques are daily invented, ciphers are constantly under test by cryptanalysis attacks to harden their safety. this paper contains a fair comparison between serval ciphers in speed test under different platforms, also in performance and risk to globalize the vision about the most fast safe algorithm.
software_engineering	context: component-based software engineering is aimed at managing the complexity of large-scale software development by composing systems from reusable parts. to understand or validate the behavior of such a system, one needs to understand the components involved in combination with understanding how they are configured and composed. this becomes increasingly difficult when components are implemented in various programming languages, and composition is specified in external artifacts. moreover, tooling that supports in-depth system-wide analysis of such heterogeneous systems is lacking. objective: this paper contributes a method to analyze and visualize information flow in a component based system at various levels of abstraction. these visualizations are designed to support the comprehension needs of both safety domain experts and software developers for, respectively, certification and evolution of safety-critical cyber-physical systems. method: we build system-wide dependence graphs and use static program slicing to determine all possible end-to-end information flows through and across a system 's components. we define a hierarchy of five abstractions over these information flows that reduce visual distraction and cognitive overload, while satisfying the users' information needs. we improve on our earlier work to provide interconnected views that support both systematic, as well as opportunistic navigation scenarios. results: we discuss the design and implementation of our approach and the resulting views in a prototype tool called flowtracker. we summarize the results of a qualitative evaluation study, carried out via two rounds of interview, on the effectiveness and usability of these views. we discuss a number of improvements, such as more selective information presentations, that resulted from the evaluation. conclusion: the evaluation shows that the proposed approach and views are useful for understanding and validating heterogeneous component-based systems, and address information needs that could earlier only be met by manual inspection of the source code. we discuss lessons learned and directions for future work. (c) 2016 elsevier b.v. all rights reserved.
signal-flow_graph	the input-output weight enumerator of a convolutional code characterizes the distance spectrum and allows error probability bounds to be conveniently evaluated. to efficiently compute the weight enumerator, pimentel recently introduced the so-called state reduction algorithm which has a convenient implementation using existing symbolic mathematical software. in this paper, we propose a dynamic state elimination ordering heuristic to further accelerate the algorithm. as demonstrated by our empirical results, the accelerated state reduction algorithm can achieve impressive complexity savings relative to the original algorithm when applied to compute the weight enumerators and its various truncated versions of convolutional codes with moderate-to-large constraint lengths.
distributed_computing	with the proliferation of application specific accelerators, the use of heterogeneous clusters is rapidly increasing. consisting of processors with different architectures, a heterogeneous cluster aims at providing different performance and cost tradeoffs for different types of workloads. in order to achieve peak performance, software running on heterogeneous cluster needs to be designed carefully to provide enough flexibility to explore its variety. we propose a design methodology to modularize complex software applications with data dependencies. the software application designed in this way have the flexibility to be reconfigured for different hardware platforms to facilitate resource management, and features high scalability and parallelism. using a neuromorphic application as a case study, we present the concept of modularization and discuss the management, scheduling and communication of the modules. we also present experimental results demonstrating the improvements and effects of system scaling on throughput.
analog_signal_processing	digital signal processing techniques were employed to investigate the joint use of charge division and risetime analyses for the resistive anode (ra) coupled to a microchannel plate detector (mcp). in contrast to the typical approach of using the relative charge at each corner of the ra, this joint approach results in a significantly improved position resolution. a conventional charge division analysis utilizing analog signal processing provides a measured position resolution of 170 mu m (fwhm). by using the correlation between risetime and position we were able to obtain a measured resolution of 92 mu m (fwhm), corresponding to an intrinsic resolution of 64 mu m (fwhm) for a single z-stack mcp detector. (c) 2015 elsevier b.v. all rights reserved.
operational_amplifier	this paper presents a low power, high slew rate, high gain, ultra wide band two stage cmos cascode operational amplifier for radio frequency application. current mirror based cascoding technique and pole zero cancelation technique is used to ameliorate the gain and enhance the unity gain bandwidth respectively, which is the novelty of the circuit. in cascading technique a common source transistor drive a common gate transistor. the cascoding is used to enhance the output resistance and hence improve the overall gain of the operational amplifier with less complexity and less power dissipation. to bias the common gate transistor, a current mirror is used in this paper. the proposed circuit is designed and simulated using cadence analog and digital system design tools of 45 nanometer cmos technology. the simulated results of the circuit show dc gain of 63.62 db, unity gain bandwidth of 2.70 ghz, slew rate of 1816 v/mu s, phase margin of 59.5 degrees, power supply of the proposed operational amplifier is 1.4 v ( rail- to- rail +/- 700 mv), and power consumption is 0.71 mw. this circuit specification has encountered the requirements of radio frequency application.
relational_databases	dbmask is a system that implements encrypted query processing with support for complex queries and fine grained access control with create, update, delete and cryptographically enforced read (crud) operations for data stored on an untrusted database server hosted in a public cloud. past research efforts have not adequately addressed flexible access control on encrypted data at different granularity levels which is critical for data sharing among different users and applications. dbmask proposes a novel technique that separates fine grained access control from encrypted query processing when evaluating sql queries on encrypted data and enforces fine grained access control at the granularity level of a column, row and cell based on an expressive attribute-based group key encryption scheme. dbmask does not require modifications to the database engine, and thus maximizes the reuse of the existing dbms infrastructures. our experiments evaluate the performance of an encrypted database, managed by dbmask, using queries from tpc-h benchmark in comparison to plain-text postgres. we further evaluate the functionality of our prototype using a policy simulator and a multi-user web application. the results show that dbmask is efficient and scalable to large datasets.
network_security	honeypots and honeynets are popular tools in the area of network security and network forensics. the deployment and usage of these tools are influenced by a number of technical and legal issues, which need to be carefully considered. in this paper, we outline the privacy issues of honeypots and honeynets with respect to their technical aspects. the paper discusses the legal framework of privacy and legal grounds to data processing. we also discuss the ip address, because by eu law, it is considered personal data. the analysis of legal issues is based on eu law and is supported by discussions on privacy and related issues.
analog_signal_processing	there is a need to explore circuit application in new emerging technologies for their rapid commercialization as the cmos technology is approaching its limits. carbon nanotube field-effect transistor (cnfet) is a promising candidate for future electronic devices for low-power low-voltage digital or analog circuit application. in this paper, we presented a low-power, low-voltage cnfet operational amplifier (opamp) based analog arithmetic computing circuit such as inverting amplifier, noninverting amplifier, summer, substractor, differentiator, and integrator for low-power analog signal processing application. the proposed computing circuits operation are studied by using hspice software for circuit simulation at 0.9v input supply voltage. simulation results show that the proposed computing circuits well suited for low-power low-voltage analog signal processing application for their lower power consumption, and high speed operation. (c) 2013 the authors. published by elsevier ltd.
pid_controller	analytical methods are usually applied for tuning fractional controllers. the present paper proposes an empirical method for tuning a new type of fractional controller known as pid-fractional-order-filter (fof-pid). indeed, the setpoint overshoot method, initially introduced by shamsuzzoha and skogestad, has been adapted for tuning fof-pid controller. based on simulations for a range of first order with time delay processes, correlations have been derived to obtain pid-fof controller parameters similar to those obtained by the internal model control (imc) tuning rule. the setpoint overshoot method requires only one closed-loop step response experiment using a proportional controller (p-controller). to highlight the potential of this method, simulation results have been compared with those obtained with the imc method as well as other pertinent techniques. various case studies have also been considered. the comparison has revealed that the proposed tuning method performs as good as the imc. moreover, it might offer a number of advantages over the imc tuning rule. for instance, the parameters of the fractional controller are directly obtained from the setpoint closed-loop response data without the need of any model of the plant to be controlled. (c) 2016 isa. published by elsevier ltd. all rights reserved.
relational_databases	recently, there has been a renovated interest in functional dependencies due to the possibility of employing them in several advanced database operations, such as data cleaning, query relaxation, record matching, and so forth. in particular, the constraints defined for canonical functional dependencies have been relaxed to capture inconsistencies in real data, patterns of semantically related data, or semantic relationships in complex data types. in this paper, we have surveyed 35 of such functional dependencies, providing a classification criteria, motivating examples, and a systematic analysis of them.
symbolic_computation	in this paper, we employ the extended variable-coefficient homogeneous balance method (evchb), the painlev,-backlund transformation and the simplified hirota 's method to derive auto-backlund transformation, multiple soliton solutions and multiple singular soliton solutions of the (3+1)-dimensional potential-ytsf equation. we also obtain a variety of traveling wave solutions, soliton-type solutions and rational solutions of distinct physical structures.
machine_learning	the present paper proposes a novel cluster-basedmethod, named as agglomerative concentric hypersphere (ach), to detect structural damage in engineering structures. continuous structural monitoring systems often require unsupervised approaches to automatically infer the health condition of a structure. however, when a structure is under linear and nonlinear effects caused by environmental and operational variability, data normalization procedures are also required to overcome these effects. the proposed approach aims, through a straightforward clustering procedure, to discover automatically the optimal number of clusters, representing the main state conditions of a structural system. three initialization procedures are introduced to evaluate the impact of deterministic and stochastic initializations on the performance of this approach. the ach is compared to state-of-the-art approaches, based on gaussian mixture models and mahalanobis squared distance, on standard data sets from a post-tensioned bridge located in switzerland: the z-24 bridge. the proposed approach demonstrates more efficiency in modeling the normal condition of the structure and its corresponding main clusters. furthermore, it reveals a better classification performance than the alternative ones in terms of false-positive and false-negative indications of damage, demonstrating a promising applicability in real world structural health monitoring scenarios.(c) 2017 elsevier ltd. all rights reserved.
parallel_computing	this paper presents a distributed computing architecture for solving a distribution optimal power flow (dopf) model based on a smart grid communication middleware (sgcm) system. the system is modeled as an unbalanced three-phase distribution system, which includes different kind of loads and various components of distribution systems. in this paper, fixed loads are modeled as constant impedance, current and power loads, and neural network models of controllable smart loads are integrated into the dopf model. a genetic algorithm is used to determine the optimal solutions for controllable devices, in particular load tap changers, switched capacitors, and smart loads in the context of an energy management system for practical feeders, accounting for the fact that smart loads consumption should not be significantly affected by network constraints. since the number of control variables in a realistic distribution power system is large, solving the dopf for real-time applications is computationally expensive. hence, to reduce computational times, a decentralized system with parallel computing nodes based on an sgcm system is proposed. using a ""mapreduce"" model, the sgcm system runs the dopf model, communicates between master and worker computing nodes, and sends/receives data among different parts of parallel computing system. compared to a centralized approach, the proposed architecture is shown to yield better optimal solutions in terms of reducing energy losses and/or energy drawn from the substation within adequate practical run-times for a realistic test feeder.
structured_storage	in face of high partial and complete disk failure rates and untimely system crashes, the executions of low-priority background tasks become increasingly frequent in large-scale data centers. however, the existing algorithms are all reactive optimizations and only exploit the temporal locality of workloads to reduce the user i/o requests during the low-priority background tasks. to address the problem, this paper proposes intelligent data outsourcing (ido), a zone-based and proactive data migration optimization, to significantly improve the efficiency of the low-priority background tasks. the main idea of ido is to proactively identify the hot data zones of raid-structured storage systems in the normal operational state. by leveraging the prediction tools to identify the upcoming events, ido proactively migrates the data blocks belonging to the hot data zones on the degraded device to a surrogate raid set in the large-scale data centers. upon a disk failure or crash reboot, most user i/o requests addressed to the degraded raid set can be serviced directly by the surrogate raid set rather than the much slower degraded raid set. consequently, the performance of the background tasks and user i/o performance during the background tasks are improved simultaneously. our lightweight prototype implementation of ido and extensive trace-driven experiments on two case studies demonstrate that, compared with the existing state-of-the-art approaches, ido effectively improves the performance of the low-priority background tasks. moreover, ido is portable and can be easily incorporated into any existing algorithms for raid-structured storage systems.
cryptography	in wireless sensor networks (wsns), a large number of nodes are densely deployed in an open environment to gather some useful required information. these nodes are small in size, operating on limited processing capabilities with scarce working memory and battery life and not very powerful radio transceivers. they can only communicate with each other through wireless media. radio waves are insecure in nature; therefore, by using such waves for communication there are always opportunities for different attacks on the network. most wireless techniques are founded on the cluster-based sensor network. forwarding cluster head 's (chs) data in a secure manner is very important because chs collect data from the cluster members and send it to the sink node or base station. for securing ch 's data, we propose a mechanism termed icmds (inter-cluster multiple key distribution scheme for wireless sensor networks), which enables the securing of the entire network. in icmds, we use two phases of security implementations for the sensor node 's authenticity while communicating with the ch. a recovery phenomena is also stated at the time when a ch ceases to function due to its high energy consumption. (c) 2016 elsevier b.v. all rights reserved.
electric_motor	satellite radio-location data from 57 adult male pacific walruses (odobenus rosmarus divergens) were used to estimate haul-out fidelity, broadly describe seasonal foraging distributions, and determine the approximate timing of autumn migration from bristol bay, alaska. data were collected intermittently during 1987-91 and 1995-2000, primarily during the period from may to october. transmitter longevity ranged from less than i day to 560 days (median 75 d). the four tagging sites were the only haul-outs that were commonly used in the bay from spring through autumn. mean fidelity, defined as the chance that an animal will return to an area where it previously hauled out, was 0.56 (se = 0.09). however, small sample sizes precluded comparisons of fidelity among years and among haul-outs by season. no tagged animals migrated out of the bay between spring and early autumn. combined monthly locations suggest that foraging occurred primarily in the southern and eastern areas of the bay in spring and gradually shifted towards northwestern areas in late autumn and winter. ninety-eight percent of the in-water locations were in waters under 60 m deep, which account for 76% of the study area. some animals migrated out of the bay in late autumn and winter; others remained within the bay throughout the year. those making long-range migrations departed the bay during november and december.
computer_programming	normal flow depth is an important parameter in design of open channels and analysis of gradually varied flow. in open channels with parabolic and rectangular cross-sections, the governing equations are nonlinear in terms of the normal depth and thus solution of the implicit equations involves numerical methods. in current research explicit solutions for these channels have been obtained using asymptote matching technique. for the parabolic channel, the maximum error of proposed equation for normal depth is less than 0.07% (near exact solution). but, in rectangular channels, the maximum error of proposed equation for normal depth is less than 1.94% which is not very accurate. the efficiency of the asymptote matching technique can be considerably improved by adding a power-law function between two asymptotes. for rectangular channel a new solution for normal flow depth is developed using the improved asymptote matching technique proposed in this research. the maximum error of this full range solution is less than 0.12%. the results showed that the improvement in proposed solution is substantial. proposed full range solutions have definite physical concept, high accuracy and easy calculation and are well-suited for manual calculations and computer programming. (c) 2015 elsevier ltd. all rights reserved.
operating_systems	control applications are implemented using real-time operating systems. digital control theory is based on sampling intervals that have to be strictly met in order to get predictable behaviors. however, a real-time system may introduce execution jitters that may cause unpredictable effects on the control application. stability, overshoot and settling time may be affected when an inadequate real-time system is used. several papers have proposed different mechanisms to measure the jitter that a real time system produces. however, jitter can not be translated as a performance criterion in control theory. on the other hand, frequency domain techniques are widely applied in control theory for designing control strategies, as well as analyzing and measuring the performance of control mechanisms. in this paper, frequency domain analysis is used to measure the perturbations that a real-time operating system may produce on a control application. harmonic distortion is defined as a criterion to evaluate the control performance of the the application. experiments show that higher priority tasks are likely to be used for control tasks since the perturbation produced up to an utilization factor of 70% is adequate for most control applications.
system_identification	nonlinear system identification is a vast research field, today attracting a great deal of attention in the structural dynamics community. ten years ago, an mssp paper reviewing the progress achieved until then [1] concluded that the identification of simple continuous structures with localised nonlinearities was within reach. the past decade witnessed a shift in emphasis, accommodating the growing industrial need for a first generation of tools capable of addressing complex nonlinearities in larger-scale structures. the objective of the present paper is to survey the key developments which arose in the field since 2006, and to illustrate state-of-the-art techniques using a real-world satellite structure. finally, a broader perspective to nonlinear system identification is provided by discussing the central role played by experimental models in the design cycle of engineering structures. (c) 2016 elsevier ltd. all rights reserved.
parallel_computing	this paper describes a learning parallel constraint programming (cp) solver designed for solving cp problems with several instances on massively parallel computing platforms comprising multi-core parallel machines or many integrated cores. the cp solver proposed in this work is based on a portfolio parallelization that employs a linear reward inaction learning algorithm in order to obtain the best possible performance for a large set of instances of the same problem. the linear reward inaction algorithm enables the prediction of the number of cores to be assigned to each search strategy based on previous experiments, reducing the computing time required to solve constraint satisfaction and optimization problems. the underlying principle of the portfolio approach is to run n sequential search strategies using n computing cores (n to n portfolio) where each core uses its own strategy in order to perform a search that is different from strategies used by the other cores. the first strategy that finds a solution stops all other strategies. the problem with the n to n portfolio approach is that the number of search strategies is very small compared with the current number of computing cores used by the parallel machines. however, using an internal parallelization for each search strategy, it is possible to run n parallel search using p computing cores with p >>n (n to p portfolio). this n to p portfolio performs suboptimally for solving different cp problems because many computing resources are wasted. to improve this portfolio model, an adaptive n to p portfolio was proposed, which tries to privilege the strategy that is most likely to find a solution first in order to give it more computing cores than the other strategies. however, the main problem with the adaptive portfolio is that it loses all the learned information at the end of each search; it is designed to solve just one cp problem. furthermore, many computational resources are wasted by both portfolio solvers, the non-adaptive (n to n and n to p) and the adaptive n to p portfolio, when employed in some industrial projects, such as the pajero project, which always solves different instances of the same cp problem. to minimize the amount of wasted resources and to learn the most efficient search strategies, we propose a new learning portfolio solver that uses a learning algorithm that configures automatically number of cores to each search. the performance obtained using the different portfolio solvers is compared and illustrated by solving cp problems using as example the google or-tools solver. copyright (c) 2016 john wiley & sons, ltd.
pid_controller	direct torque control (dtc) has been employed to give fast torque response, which is very important in traction and electric vehicle applications, in high dynamic performance induction motor (im) drives. fast torque response can be achieved by optimizing the selection of the inverter voltage vectors in the conventional dtc. this paper introduces a method for selecting voltage vectors; in dtc controlled im drives, to achieve fast torque response at constant switching frequency. also, the application of the fuzzy pid (fpid) control technique improves the system speed and torque responses. simulation results show that both torque and speed responses are faster with the proposed controller than the conventional dtc.
electrical_circuits	carbon fiber (cf) composites of organometallic intercalated polyaniline (pani) and polypyrrole (ppy) doped with polystyrene sulfonate (pss) were electrochemically synthesized and tested as electrodes for lithium-ion batteries. from the results obtained by cyclic voltammetry, x-ray photoelectron spectroscopy, and energy-dispersive x-ray spectroscopy, it was concluded that the incorporation of copper(ii) ions in the polymeric composite was successfully attained by adsorption of cu2+ ions and 2,5-dimercapto-1,3,4-thiadiazole (dmct) monomers on the carbon microfibers. the experimental electrochemical impedance response of the obtained pani(dmct-cu ion)/cf composite was simulated by adequate equivalent electrical circuits. after 20 charge/discharge cycles, the experimental discharge specific capacity of the pani(dmct-cu ion)/cf composite was 118 ma h g(-1) (100% coulombic efficiency) using a 1 mol l-1 liclo4 solution in propylene carbonate, and 110 ma h g(-1) when a polymeric electrolyte was used. in the charge/discharge tests of the ppy-pss/pani/cf composite as anode, a high discharge specific capacity of 225 ma h g(-1) was obtained after 20 cycles. the resulting ppy-pss/pani/cf/polymeric electrolyte/pani(dmct-cu ion)/cf battery presented a specific capacity of 62 ma h g(-1) and could be charged up to 2.0 v, yielding an energy density 425 w h g(-1), with a coulombic efficiency of about 98%. (c) 2012 elsevier b.v. all rights reserved.
lorentz_force_law	this paper presents the torque model of a ball-joint-like three-degree-of-freedom (3-dof) permanent magnet (pm) spherical actuator. this actuator features a ball-shaped rotor with multiple pm poles and a spherical stator with circumferential air-core coils. an analytical expression of the magnetic field of the rotor is obtained based on laplace 's equation. based on this expression and properties of air-core stator coils, lorentz force law is employed for the study of the relationship between the rotor torque and coil input currents. by using linear superposition, the expression of the actuator torque in terms of current input to the stator coils can be obtained in a matrix form. the linear expression of the actuator torque will facilitate real-time motion control of the actuator as a servo system. experimental works are carried out to measure the actual magnetic field distribution of the pm rotor in three-diamensional (3-d) space as well as to measure the actual 3-d motor torque generated by the actuator coils. the measurement results were coincident with analytical study on the rotor magnetic field distribution and actuator torque expressions. the linearity and superposition of the actuator torque were also verified through the experiments.
distributed_computing	distributed systems for big data management very often face the problem of load imbalance among nodes. to address this issue, there exist almost as many load balancing strategies as there are different systems. when designing a scalable distributed system geared towards handling large amounts of information, it is often not so easy to anticipate which kind of strategy will be the most efficient to maintain adequate performance regarding response time, scalability, and reliability at any time. based on this observation, we describe a generic api to implement and experiment any strategy independently from the rest of the code, prior to a definitive choice for instance. we then show how existing load balancing strategies used by famous systems could be implemented with this api. we also present how this work has helped us implement load balancing on our distributed system and modify the behavior of our strategy in a few lines of code. this led us to easily perform various experiments to determine the most efficient scheme for our system. this paper is an extension to our work presented at workshop on parallel and distributed computing for big data applications (wpba) 2014. we detail here more experiments and extend the use of the api to a broad class of big data storage systems. copyright (c) 2015 john wiley & sons, ltd.
system_identification	a control-oriented, two-timescale, linear, dynamic, response model of the rotational transform iota profile and the normalized beta beta(n) is proposed based on experimental data from the diii-d tokamak. dedicated system-identification experiments without feedback control have been carried out to generate data for the development of this model. the data-driven dynamic model, which is both device-specific and scenario-specific, represents the response of the iota profile and beta(n) to the electric field due to induction as well as to the heating and current drive (h&cd) systems during the flat-top phase of an h-mode discharge in diii-d. the control goal is to use both induction and the h&cd systems to locally regulate the plasma iota profile and beta(n) around particular target values close to the reference state used for system identification. a singular value decomposition (svd) of the plasma model at steady state is carried out to decouple the system and identify the most relevant control channels. a mixed-sensitivity robust control design problem is formulated based on the dynamic model to synthesize a stabilizing feedback controller without input constraints that minimizes the reference tracking error and rejects external disturbances with minimal control energy. the feedback controller is then augmented with an anti-windup compensator, which keeps the given controller well-behaved in the presence of magnitude constraints in the actuators and leaves the nominal closed-loop system unmodified when no saturation is present. the proposed controller represents one of the first feedback profile controllers integrating magnetic and kinetic variables ever implemented and experimentally tested in diii-d. the preliminary experimental results presented in this work, although limited in number and constrained by actuator problems and design limitations, as it will be reported, show good progress towards routine current profile control in diii-d and leave valuable lessons for further advancements in the field. (c) 2017 elsevier b.v. all rights reserved.
distributed_computing	in mapreduce environment, problem of data redundancy, a large number of tasks to be processing and mass data storage come up, in order to solve these problems, we put forward the way of data prefetching, preprocessing of hid the remote data access latency, by adjusting the allocation of resources to reduce the business, we put forward the method of than before, caused by the reduce tasks of remote data access performance problems caused by time delay and resource competition system, the hidden by prefetching data the method reduce task of remote data access latency, and reduce task control through the resource allocation, to reduce resource competition caused the reduce task, the experiment results show that with the default hadoop graphs and hadoop online prototype (hop), compared with the method the system performance can be improved by more than 10%.
electrical_circuits	thin sn-o-te films with a thickness of 60 nm have been deposited by co-evaporation of sn and teo2 on alumina substrates with interdigitated silver-palladium electrodes. during the co-evaporation a chemical reaction between the two substances takes place, resulting in the formation of a sn-oxide matrix and finely dispersed phases of te, sn, teo2 or snte, depending on the atomic ratio of sn to te (r-sn/te). to study the morphology and structure as well as to determine the atomic ratio r-sn/te of the films, electron microscopy techniques (tem, saed) and analytical methods (eds in sem) have been applied. the electrical properties of the sensors studied have been investigated in the frequency range of 20 hz - 5 mhz using a precision impedance analyzer. the measurements have been taken on samples placed in a controlled humidity and temperature chamber. the characteristics of the resistance r, capacitance c, impedance z and phase theta as functions of relative humidity rh%, the frequency dependences of r, c, z and center dot, the nyquist plots and equivalent electrical circuits of the sensors have been obtained. as a result, the relation between the type of water adsorption, impedance spectra and the properties of the films as humidity sensors are presented in this paper.
voltage_law	this paper presents a simple approach for load flow analysis of a radial distribution network with embedded generation. the proposed approach utilizes forward and backward sweep algorithm based on kirchoff 's current law (kcl) and kirchoff 's voltage law (kvl) for evaluating the node voltages iteratively. in this approach, computation of branch current depends only on the current injected at the neighbouring node and the current in the adjacent branch. this approach starts from the end nodes of sub lateral line, lateral line and main line and moves towards the root node during branch current computation. the node voltage evaluation begins fro in the root node and moves towards the nodes located at the far end of the main, lateral and sub lateral lines. the proposed approach has been tested using three radial distribution systems of different size and configuration and is found to be computationally efficient. the effectiveness of the proposed approach is further demonstrated by integrating the embedded generation into the load flow analysis of the radial distribution network.
digital_control	the division-summation (d-sigma) current control and one-cycle voltage regulation (ocvr) of a 5-kw surface-mounted permanent-magnet synchronous generator (spmsg) drive is developed. with the advancement of motor manufacturing, motor design, digital control units and power electronics converters, the permanent-magnet synchronous generator (pmsg) is broadly applied to electric vehicles, hybrid electric vehicles, flywheel energy storage system and wind power generators. satisfactory current control scheme of a pmsg is significant to achieve desired generating performance. the d-sigma current control is proposed and derived from the conventional space-vector modulation and two-phase modulation. a simplification of the complex self-and mutual inductances in a pmsg is demonstrated. the proposed current control can achieve the current waveform tracking through the simplification of winding inductances without parameter designing procedure of the feedback controller. the computation time of the microcontroller is reduced via the proposed current control scheme. the processing times of the conventional control and the d-sigma control are compared. moreover, the dc-link voltage can be well regulated by the proposed ocvr. this method can reduce the complexity of the voltage controller design. the merits of these two methods are easy to implement and the parameter designing procedure of the feedback controller is unnecessary. in addition, the system stability and the parameter sensitivity are analyzed and evaluated. some measured waveforms verify the current tracking, torque ripple, dynamic performance and voltage regulation of the spmsg drive. the reduction of the switching losses is verified by the calculation results.
software_engineering	knowledge management within companies and institutions is one of the main problems when defining and developing new solutions to improve information systems. currently, information systems have evolved into technological ecosystems that are a set of different components related to each other through information flows in a physical environment that supports these flows, where users are part of the ecosystem. particularly, during the last several years, the open source software has been used to develop these technological solutions. the aim of this paper is to formalize an architectural pattern to support the right description and implementation of elearning ecosystems. the theoretical basis has been provided in previous works by using a comparative analysis of the strengths, weaknesses, opportunities and threats of several real case studies developed in different contexts. the problems detected through the previous analysis have been modelled using the business process model and notation. next, the pattern has been formalized with the service oriented architecture modelling language. finally, the pattern has been tested in a real context, namely, an institutional development for the spanish public administration, which has demonstrated that the pattern works properly. as a result, we have obtained a set of business process model and notation diagrams that provide a high abstraction level for the main detected problems in elearning ecosystems. we have also obtained an architectural pattern composed of several layers and a set of external elements that provides a solution to these problems. (c) 2016 elsevier b.v. all rights reserved.
network_security	the failure on all homogeneous devices due to the same reason is called homogeneous fault in networks. in contrast, heterogeneous platforms deployed simultaneously in the network are more robust against homogeneous faults. one of the challenging problems is how to design survivable networks that against homogeneous faults. this paper utilizes edge-colored graphs to investigate the network topology with homogeneous faults, in order to guarantee network connectivity using minimum number of links. two types of network topologies are proposed on the edge-colored graph. one type of networks is characterized by the fact that all the edges of the same color form a hamiltonian path or a hamiltonian cycle. an upper bound on the number of colors used in the proposed network topologies is obtained. the network topologies of the second type have edges colored with at most five colors. additionally, the subnetworks induced by the edges of two colors contain a hamiltonian path, or a hamilton cycle in some cases.
computer_programming	a research has been carried out on the dynamic analysis and simulation of parallel robots due to the situation where parallel robots tend to break down on account of large stress during movements. in order to study the force condition of the robot on the move, a mathematical model, based on the kane method, has been built and the driving force of each electric cylinder has been calculated by computer programming. in the meantime, a dynamic simulation model and a simulation control system are established on the basis of adams and matlab and through analyzing the joint simulation, we can obtain the driving force of each cylinder. the gap between the simulation results and the results obtained by the mathematical model is within 7%, which verifies the correctness of the kane dynamic system and gives provide the foundation for future studies of dynamics and structure optimization.
digital_control	this paper presents a 1v -70db thd audio automatic gain control (agc) circuits. the proposed agc is based on feedback topologies and the gain is digital controlled. a pi-type resistors network is used in the programmable gain amplifier (pga) as the passive feedback device to realize gain linearity in decibels and increase the gain accuracy. the hysteresis comparator eliminate the chattering effects when the output signal of peak detector changes rapidly around the threshold. the design is implemented in 0.18 mu m cmos and occupies an active area of 0.41mm2. the power consumption of agc is about 0.17mw at 1v supply voltage. the gain of pga in the agc loop ranges from 0db to 40db in 2db step with gain error not more than 0.2db. the integrated noise in the audio range (20 hz similar to 20 khz) is 2.28 mu vrms when the gain is set at 40db. the total harmonic distortion (thd) is below -70db over the audio frequencies at 0.4-vpp differential output.
microcontroller	a low cost, fast and reliable microcontroller based protection scheme using wavelet transform and artificial neural network has been proposed and its effectiveness evaluated in real time. the proposed scheme, based on the hardware co-simulation approach performs all the functions of transmission line protection i.e. fault detection/classification, fault zone/section identification and location estimation. the fault detection/classification and zone identification algorithms use fundamental frequency current component to estimate a fault index. the fault location estimation module uses wavelet transform coefficients in hybridization with a parallel artificial neural network structure. for hardware implementation, a 8-bit atmega microcontroller is used and interfaced with the simulated power system model using integrated development environment (ide). the scheme is tested on a power system model of 400 kv, 50 hz three phase double circuit line with source at both the ends. laboratory tests have been performed in real time for 20,000 fault cases including evolving faults with varying fault resistance, fault inception angle, fault distance, direction of power flow angle and its magnitude. the tests confirm the suitability and reliability of proposed scheme even with current transformer (ct) saturation. the implementation of the proposed approach on a low cost microcontroller with the lesser execution time, makes the prototype ideal for implementation on a digital platform (digital relay), thus leading to financial viability and sustainability of the protection scheme. (c) 2016 elsevier ltd. all rights reserved.
electrical_circuits	this paper discusses diffusion of a pulsed magnetic field into a resistive element fabricated from a low-carbon steel. the developed numerical model shows that the process of the magnetic field diffusion into the steel at the leading edge of the pulse can be conventionally described by three stages: initial stage extending up to saturation of the steel surface layers, stage of saturation when the discharge current diffuses into the bulk of the steel, and stage of conduction when the discharge current is distributed practically uniformly in the steel. approximate analytical relations describing the voltage drop across the resistive element are derived for each of the three stages. these relations are used for estimation of the effect of the ferromagnetic properties of the steel on transients in electrical circuits with the resistive element. experiments prove the validity of the obtained analytical results.
system_identification	underwater gliders are used for deep-water gliding to observe large areas with minimal energy consumption. the pitch angle of the underwater glider is an important control parameter. this study involved designing a fuzzy-pid controller for the pitch angle of an underwater glider based on hydrodynamics analysis. the formula of pitch angle is obtained and a system identification method was used to identify the transfer function based on the time-domain equation and initial experimental data. the fuzzy-pid control algorithm was used to design the controller. lake and sea trials indicated that the minimum overshoot reached 0% and the settling time was about 34s when the change of the angle was 15 degrees. the minimum steady-state error was 0.8 degrees. these advantages could reduce the consumption of energy and improve the accuracy of gliding trajectory. therefore, this control algorithm should be applied to control the pitch of the gliders. (c) 2017 all rights reserved.
electricity	with the development of home area network, residents have the opportunity to schedule their power usage at the home by themselves aiming at reducing electricity expenses. moreover, as renewable energy sources are deployed in home, an energy management system needs to consider both energy consumption and generation simultaneously to minimize the energy cost. in this paper, a smart home energy management model has been presented that considers both energy consumption and generation simultaneously. the proposed model arranges the household electrical and thermal appliances for operation such that the monetary expense of a customer is minimized based on the time-varying pricing model. in this model, the home gateway receives the electricity price information as well as the resident desired options in order to efficiently schedule the appliances and shave the peak as well. the scheduling approach is tested on a typical home including variety of home appliances, a small wind turbine, pv panel and a battery over a 24-h period. (c) 2017 elsevier ltd. all rights reserved.
operational_amplifier	this paper proposes a low power and low output ripple regulator for radio frequency identification tags. the inner blocks of regulator is supplied from elementary stages output of rectifier. the proposed operational amplifier works on ab class and its bias is in adaptive biasing form. the bandgap reference and sampling voltage resistors used in this paper are completely designed with transistors which culminate in low power dissipation. the regulator output voltage is 1.07 v, while the output ripple is +/- 1.1 mv. the value of line regulation, power supply rejection ratio, and regulator efficiency are 5.5 mv/v, 45.2 db, and 71.3%, respectively. a 111 mu w power consumption has been calculated with 20 k omega load. the simulation is done with the help of cadence software in 0.18 mu m cmos technology, while its operational frequency is 960 mhz. the layout of the proposed regulator is 0.00125 mm(2).
parallel_computing	this paper presents the features and functions of a software tool called fatigue prediction utility for abaqus/cae (fpu). it is designed as a plugin for the abaqus commercial fe code allowing for fatigue predictions based on the results of abaqus fe analyses. it also contains an interface for data transfer between abaqus and pragtic, a standalone fatigue post-processor. the program contains a simple and intuitive graphical interface, which makes preparation of a fatigue analysis straightforward. the fpu fatigue solver may be executed on multiple cpu cores independently from abaqus/cae, which allows large-scale problems to be solved on server machines in reasonable time. an overview of the functionality of the plugin, available prediction models and the concept of data exchange between abaqus and pragtic is given. illustrative examples are given, where appropriate, in order to introduce features of the tool. possible ways of adapting the code for interconnection with an fe solver other than abaqus are discussed. (c) 2016 elsevier ltd. all rights reserved.
algorithm_design	overlapping community detection algorithm research is one of hot topics in current social network analysis. in this paper, we applied the idea of weighted label propagation to overlapping community detection algorithm design, and propose a weighted label propagation algorithm (wlpa). moreover, in order to evaluate the performance results of various overlapping community detection algorithms, we put forward a series of evaluation criteria based on error distribution curve of overlapping vertices. the experiment results show that the algorithm has a faster speed and better community detection results, and the evaluation criteria is in line with the inherent characteristics of the social network overlapping community structure.
software_engineering	this paper presents a formal model of a decision making system for public transport routes. the approach focuses on (1) environmental and societal sustainability aspects of green software engineering, (2) spatial planning and optimisation for smarter sustainable cities, and (3) user satisfaction with this information system for the various contexts of passenger, driver and overall system view.
algorithm_design	automated systems based on programmable logic controllers (plc) are still applied in discrete event systems (des) for controlling and monitoring of industrial processes signals. plc-based control systems are characterized for having physical input and output signals coming from and going to sensors and actuators, respectively, which they are in direct contact with the production or manufacturing process. the input subsystem to plc consists of sensor-wiring-physical inputs module, and it can present two kinds of faults: short circuit or open circuit, in one or more signals of the process physical inputs, which it causes faults in the control and/or in the control algorithms behavior. ladder diagram (ld) is one of the five programming languages supported by the international electrotechnical commission (iec) through the iec-61131-3 standard, and it remains being used at industry for control algorithm design of plc-based systems. this paper proposes the simulation and validation of control algorithms developed in ld by using petri nets (pn) in order to deal with the possible fault options (short circuit and/or open circuit) in the physical inputs subsystem of a plc-based control system. one control algorithms in ld have been analyzed in order to show the advantages of the proposed approach.
cryptography	we explain how to share photons between two distant parties using concatenated entanglement swapping and assess performance according to the two-photon visibility as the figure of merit. from this analysis, we readily see the key generation rate and the quantum bit error rate as figures of merit for this scheme applied to quantum key distribution (qkd). our model accounts for practical limitations, including higher-order photon pair events, dark counts, detector inefficiency, and photon losses. our analysis shows that compromises are needed among the runtimes for the experiment, the rate of producing photon pairs, and the choice of detector efficiency. from our quantitative results, we observe that concatenated entanglement swapping enables secure qkd over long distances but at key generation rates that are far too low to be useful for large separations. we find that the key generation rates are close to both the takeoka-guha-wilde and the pirandola-laurenza-ottaviani-banchi bounds. (c) 2017 society of photo-optical instrumentation engineers (spie)
image_processing	countercurrent flow limitation (ccfl) was experimentally investigated in a 1/3.9 downscaled collider facility with a 190 mm pipe 's diameter using air/water at 1 atmospheric pressure. previous investigations provided knowledge over the onset of ccfl mechanisms. in current article, ccfl characteristics at the collider facility are measured and discussed along with time-averaged distributions of the air/water interface for a selected matrix of liquid/gas velocities. the article demonstrates the time-averaged interface as a useful method to identify ccfl characteristics at quasi-stationary flow conditions eliminating variations that appears in single images, and showing essential comparative flow features such as: the degree of restriction at the bend, the extension and the intensity of the two-phase mixing zones, and the average water level within the horizontal part and the steam generator. consequently, making it possible to compare interface distributions obtained at different investigations. the distributions are also beneficial for cfd validations of ccfl as the instant chaotic gas/liquid interface is impossible to reproduce in cfd simulations. the current study shows that final ccfl characteristics curve (and the corresponding ccfl correlation) depends upon the covered measuring range of water delivery. it also shows that a hydraulic diameter should be sufficiently larger than 50 mm in order to obtain ccfl characteristics comparable to the 1:1 scale data (namely the uptf data). finally, the study shows that the change of the flow condition inside the hot-leg is not only related to the water and air inlet velocities, but is also dependent upon the existent interface distribution within the hot-leg, and that several ccfl cases of identical inlet flow conditions can exist with different interface distribution and pressure difference. the last result is of a special importance to the investigation of this phenomenon during sbloca accidents, since the entire phenomenon is driven by pressure difference between the steam generator and reactor vessel, as well as by gravity. this result show also that ccfl characteristics cannot be investigated using 1d codes, as the interface distribution within the hot-leg during a sbloca accident will depend upon flow history or previous interface distribution. current investigations support the effort to provide more knowledge over ccfl in order to extrapolate results obtained in downscaled models into the 1:1 scale. (c) 2017 elsevier ltd. all rights reserved.
distributed_computing	in many application fields such as social networks, e-commerce and content delivery networks there is a constant production of big amounts of data in geographically distributed sites that need to be timely elaborated. distributed computing frameworks such as hadoop (based on the mapreduce paradigm) have been used to process big data by exploiting the computing power of many cluster nodes interconnected through high speed links. unfortunately, hadoop was proved to perform very poorly in the just mentioned scenario. we designed and developed a hadoop framework that is capable of scheduling and distributing hadoop tasks among geographically distant sites in a way that optimizes the overall job performance. we propose a hierarchical approach where a top-level entity, by exploiting the information concerning the data location, is capable of producing a smart schedule of low-level, independent mapreduce sub-jobs. a software prototype of the framework was developed. tests run on the prototype showed that the job scheduler makes good forecasts of the expected job 's execution time.
distributed_computing	it is now several years since scientists in poland can use the resources of the distributed computing infrastructure - plgrid. it is a flexible, large-scale e-infrastructure, which offers a homogeneous, easy to use access to organizationally distributed, heterogeneous hardware and software resources. it is built in accordance with good organizational and engineering practices, taking advantage of international experience in this field. since the scientists need assistance and close collaboration with service providers, the e-infrastructure is relied on users' requirements and needs coming from different scientific disciplines, being equipped with specific environments, solutions and services, suitable for various disciplines. all these tools help to lowering the barriers that hinder researchers to use the infrastructure.
computer_graphics	filters with slowly decaying impulse responses have many uses in computer graphics. recursive filters are often the fastest option for such cases. in this paper, we derive closed-form formulas for computing the exact initial feedbacks needed for recursive filtering infinite input extensions. we provide formulas for the constant-padding (e.g. clamp-to-edge), periodic (repeat) and even-periodic (mirror or reflect) extensions. these formulas were designed for easy integration into modern block-parallel recursive filtering algorithms. our new modified algorithms are state-of-the-art, filtering images faster even than previous methods that ignore boundary conditions.
computer_vision	one of the first steps in numerous computer vision tasks is the extraction of keypoints in images. despite the large number of works proposing image keypoint detectors, only a few methodologies are able to efficiently use both visual and geometrical information. in this work we introduce kvd (keypoints from visual and depth data), a novel keypoint detector which is scale invariant and combines intensity and geometrical data using a decision tree. we present results from several experiments showing that the detector created with our methodology outperforms state-of-the-art methods, both in repeatability scores for rotations, translations and scale changes, as well as in robustness to corrupted visual or geometric data. additionally, as far as processing time is concerned, kvd yields the best time performance among the methods that also use depth and visual data. (c) 2016 elsevier b.v. all rights reserved.
electrical_network	the increasing integration of fluctuating and nl (non-linear) loads in the main grid can introduce problems to the distribution power system quality. this study was interested in a mg (micro-grid) based on rdg (renewable distributed generator) to participate in system services and to improve the efficiency of the power electrical system. the purpose of this paper is to investigate a multi-objective control strategy for the integration of an mg into electrical network in order to ensure simultaneously active power supply, reactive power compensation, harmonic current damping and grid frequency regulation. this control is mainly composed of two parts: the first one is the ""nl loads currents identification system"" used to extract the fundamental active current from the disruptive one in order to provide the required harmonic and reactive currents to the considered nl loads. the second one is the ""active power transfer and frequency control algorithm"" used to manage the mg in six operation modes in order to control the fundamental active power flow exchange between the mg and the electrical network making the grid frequency in an allowable range of stability. (c) 2015 elsevier ltd. all rights reserved.
software_engineering	with over 10 million git repositories, github is becoming one of the most important sources of software artifacts on the internet. researchers mine the information stored in github 's event logs to understand how its users employ the site to collaborate on software, but so far there have been no studies describing the quality and properties of the available github data. we document the results of an empirical study aimed at understanding the characteristics of the repositories and users in github; we see how users take advantage of github 's main features and how their activity is tracked on github and related datasets to point out misalignment between the real and mined data. our results indicate that while github is a rich source of data on software development, mining github for research purposes should take various potential perils into consideration. for example, we show that the majority of the projects are personal and inactive, and that almost 40 % of all pull requests do not appear as merged even though they were. also, approximately half of github 's registered users do not have public activity, while the activity of github users in repositories is not always easy to pinpoint. we use our identified perils to see if they can pose validity threats; we review selected papers from the msr 2014 mining challenge and see if there are potential impacts to consider. we provide a set of recommendations for software engineering researchers on how to approach the data in github.
pid_controller	the legendre orthogonal functions are employed to design the family of pid controllers for a variety of plants. in the proposed method, the pid controller and the plant model are represented with their corresponding legendre series. matching the first three terms of the legendre series of the loop gain with the desired one gives the pid controller parameters. the closed loop system stability conditions in terms of the legendre basis function pole (lambda) for a wide range of systems including the first order, second order, double integrator, first order plus dead time, and first order unstable plants are obtained. for first order and double integrator plants, the closed loop system stability is preserved for all values of lambda and for the other plants, an appropriate range in terms of lambda is obtained. the optimum value of lambda to attain a minimum integral square error performance index in the presence of the control signal constraints is achieved. the numerical simulations demonstrate the benefits of the legendre based pid controller.
analog_signal_processing	this brief presents two original implementations of improved accuracy current-mode multiplier/divider circuits. besides the advantage of their simplicity, these original multiplier/divider structures present the advantage of very small linearity errors that can be obtained as a result of the proposed design techniques (0.75% and 0.9%, respectively, for an extended range of the input currents). the original multiplier/divider circuits permit a facile reconfiguration, the presented structures representing the functional basis for implementing complex function synthesizer circuits. the proposed computational structures are designed for implementing in 0.18-mu m cmos technology, with a low-voltage operation (a supply voltage of 1.2 v). the circuits' power consumptions are 60 and 75 mu w, respectively, while their frequency bandwidths are 79.6 and 59.7 mhz, respectively.
electricity	the life cycle assessment of several zinc oxide (zno) nanostructures, fabricated by a facile microwave technique, is presented. key synthesis parameters such as annealing temperature, varied from 90 degrees c to 220 degrees c, and microwave power, varied from 110 w to 710 w, are assessed. the effect of these parameters on both the structural characteristics and the environmental sustainability of the nanostructures is examined. the nanostructures were characterized by means of x-ray diffraction (xrd), focused ion beam scanning electron microscopy (fib-sem), ultraviolet-visible spectroscopy (uv-vis), photoluminescence (pl) and brunauer-emmett-teller (bet) analysis. crystalline site was found to be 22.40 nm at 110 w microwave power, 24.83 nm at 310 w, and 24.01 nm at 710 w. microwave power and synthesis temperature were both directly proportional to the surface area at 110 w the surface area was 10.44 m(2)/g, at 310 w 12.88 m(2)/g, and at 710 w 14.60 m(2)/g; while it was found to be 11.64 m(2)/g at 150 degrees c and 18.09 m(2)/g at 220 degrees c. based on these, a life cycle analysis (lca) of the produced zno nanoparticles was carried out, using the zno surface area (1 m(2)/g) as the functional unit it was found that the main environmental weaknesses identified during the production process were; (a) the use of ethanol for purifying the produced nanomaterials and (b) the electricity consumption for the zno calcination, provided by south africa 's fossil-fuel dependent electricity source. when the effect of the key synthesis parameters on environmental sustainability was examined it was found that an increase of either microwave power (from 110 to 710 w) or synthesis temperatures (from 90 to 220 degrees c), results in higher sustainability, with the environmental footprint reduced by 27% and 41%, respectively. through a sensitivity analysis, it was observed that an electricity mix based on renewable energy could improve the environmental sustainability of the nanoparticles by 25%. (c) 2017 elsevier b.v. all rights reserved.
relational_databases	one of the biggest challenges to health data sharing is regulations that prohibit the transmission and distribution of personal health information (phi) even among collaborating organizations. this impedes research and reduces the utility of these datasets. anonymization can address this issue by hiding phi while maintaining the analytical utility of the data. much research has focused on data that is static, independent and complete. unfortunately, this is not typical of health data. instead of static, independent tables, health data is in relational databases with multiple high-dimensional tables that are transactional and constantly changing. data recipients usually receive multiple versions of the database over time. this study reviews literature on anonymization methodologies for large and fast changing high-dimensional datasets, especially health data. relevant papers are analyzed, categorized and compared in terms of scope, and contributions. finally, we used the extracted details from our analysis to outline possible research direction for developing a realistic anonymization framework for health data sharing. (c) 2015 the authors. published by elsevier b.v.
state_space_representation	the subsampling of a linear periodically time-varying system results in a collection of linear time-invariant systems with common poles. this key fact, known as ""lifting"", is used in a two-step realization method. the first step is the realization of the time-invariant dynamics (the lifted system). computationally, this step is a rank-revealing factorization of a block-hankel matrix. the second step derives a state space representation of the periodic time-varying system. it is shown that no extra computations are required in the second step. the computational complexity of the overall method is therefore equal to the complexity for the realization of the lifted system. a modification of the realization method is proposed, which makes the complexity independent of the parameter variation period. replacing the rank-revealing factorization in the realization algorithm by structured low-rank approximation yields a maximum likelihood identification method. existing methods for structured low-rank approximation are used to identify efficiently a linear periodically time-varying system. these methods can deal with missing data. (c) 2014 elsevier ltd. all rights reserved.
operational_amplifier	the current-mode first-order allpass filter (app) using only the active elements has been studied in the present paper. the proposed circuit comprises two operational transconductance amplifiers (otas) and one operational amplifier (oa) which is suitable to future development into an integrated circuit. the pole frequency and phase response can be electronically adjusted with changing the dc bias currents of otas. the apf has high output impedance, which is easy to cascade in high-order filter or drive load without using a buffering device. the current-mode quadrature oscillator is included to show the usability of the proposed filter. the results of pspice simulation are accordant with the theoretical analysis.
bioinformatics	background: japanese encephalitis virus (jev) is a mosquito-borne flavivirus that causes japanese encephalitis (je) and acute encephalitis syndrome (aes) in humans. genotype-i (as co-circulating cases with genotype-iii) was isolated in 2010 (jev28, jev21) and then in 2011 (jev45) from midnapur district, west bengal (wb) for the first time from clinical patients who were previously been vaccinated with live attenuated sa14-14-2 strain. we apply bioinformatics and immunoinformatics on sequence and structure of e protein for analysis of crucial substitutions that might cause the genotypic transition, affecting protein-function and altering specificity of epitopes. results: although frequency of substitutions in e glycoprotein of jev28, jev21 and jev45 isolates vary, its homologous patterns remain exactly similar as earlier japan isolate (ishikawa). sequence and 3d model-structure based analyses of e protein show that only four of all substitutions are critical for genotype-i specific effect of which n103k is common among all isolates indicating its role in the transition of genotype-iii to genotype-i. predicted b-cell and t-cell epitopes are seen to harbor these critical substitutions that affect overall conformational stability of the protein. these epitopes were subjected to conservation analyses using a large set of the protein from asian continent. conclusions: the study identifies crucial substitutions that contribute to the emergence of genotype-i. predicted epitopes harboring these substitutions may alter specificity which might be the reason of reported failure of vaccine. conservation analysis of these epitopes would be useful for design of genotype-i specific vaccine.
distributed_computing	the ability to design effective solutions using parallel processing should be a required competency for every computing student. however, teaching parallel concepts is sometimes challenging and costly, specially at early stages of a computer science degree. for such reasons we present a set of modules to teach parallel computing paradigms using as examples problems that are computationally intensive, but easy to understand and can be easily implemented using the python parallelization libraries mpi for python and disco.
state_space_representation	a space-time kinetics based inverse architecture method is suggested to analyze the reactivity variations associated with power excursions in a generic candu reactor. it is intended to provide diagnosis tools to gain enhanced control thereby ensuring safe operation of the plant. a methodology for analyzing the data available from the in core flux detectors and extracting the unknown reactivity coefficients is presented. the proposed system uses a reference model in conjunction with an optimal estimator. the reference model is composed of a state space representation of the space-time dynamics of neutron flux in the core, based on modal expansion approximation, and a time domain optimal estimator filter. we investigated three different estimation techniques based on recursive prediction error method (rpem), dual extended kalman filter (dekf), and joint extended kalman filter (jekf). we compared their applicability to the estimation of coolant-void dynamic reactivity in loss-of-coolant accident in a candu reactor. the state equations also include the characteristics of the detector responses. the thermal hydraulic models were not included in the calculations. two different types of detectors are considered in this analysis, the over prompt responsive platinum detector of the reactor shutdown systems, and the under delayed responsive vanadium detector of the flux mapping system. (c) 2012 elsevier ltd. all rights reserved.
analog_signal_processing	the development of assistive technologies by means of human machine interface is turning out to be one of the most attractive areas of today 's research. innovation in power consumption, signal processing and wireless communication has been the focus for the development of such systems. however, these devices have not reached the mass market yet. this system incorporates texas embedded processor, wireless communication solutions and highly-customized analog front ends. as a proof of concept, this technology integrates mcv architecture, instrumentation amplifiers as analog front end and further single supply quad op-amp for analog signal processing in an effective manner. the development of such a cost effective versatile system can impact clinical and rehabilitative control applications in most of the developing countries thus revolutionizing this domain.
computer_graphics	the article describes efficient methods to visualize the results from finite element analysis and implementation of these methods in post-processing results. the work is based on premise that computer memory and performance are limited and amount of data processed by complex finite element analysis is enormous. therefore, some kind of simplification and approximation of resulting data has to be used. multigrid method was the inspiration for research work and development of post-processor. the stored data from finite element analysis are discrete values. the paper deals with several ways of replacing them by continuous functions suitable for representation in computer graphics, which are different from the approximation functions used in finite element method. special attention is devoted to approximation errors-difference between these functions. finite element mesh is decomposed into sub domains with respect to approximation errors. the ways of creating mesh hierarchy are described in details and also the possibilities of nodal value interpolations in simplified mesh are discussed in the text. besides the approximation of data in space, also the approximation in time is used. pseudo-code of the approximation algorithm key parts is shown. various types of approximation functions were investigated to reach the lowest approximation error and the highest compression factor. results are summarized in the article. (c) 2016 elsevier ltd. all rights reserved.
distributed_computing	host cardinality is defined as the number of distinct peers that a host communicates with in the network. there have been several algorithms proposed to monitor network traffic and identify high-cardinality hosts at a centralized network operation center (noc). due to massive amounts of distributed data and limitations on transforming and processing them at the noc, it is desirable to design mergable and reversible data structures summarizing traffic measurements in a distributed network monitoring system. a mergable data structure summarizes traffic measurements at each local monitor, and these summaries from different monitors can be merged at the noc, while preserving the error guarantee without increasing space. a reversible data structure can report interested (high-cardinality) hosts efficiently using compressed information without querying every single host in the network. in this paper, we propose a new data streaming algorithm to identify high-cardinality hosts over the network-wide traffic measurements. our algorithm introduces a new mergable and reversible data structure for the distributed network monitoring system, which is designed by noisy group testing. we have theoretically analyzed our algorithm and evaluated it against real-world data sets.
bioinformatics	alternative splicing provides a major mechanism to generate protein diversity. increasing evidence suggests a link of dysregulation of splicing associated with cancer. genome-wide alternative splicing profiling in lung cancer remains largely unstudied. we generated alternative splicing profiles in 491 lung adenocarcinoma (wad) and 471 lung squamous cell carcinoma (lusc) patients in tcga using rna-seq data, prognostic models and splicing networks were built by integrated bioinformatics analysis. a total of 3691 and 2403 alternative splicing events were significantly associated with patient survival in luad and lusc, respectively, including egfr, cd44, pik3c3, rras2, mapkapi and fgfr2. the area under the curve of the receiver-operator characteristic curve for prognostic predictor in nsclc was 0.817 at 2000 days of overall survival which were also over 0.8 in luad and lusc, separately. interestingly, splicing correlation networks uncovered opposite roles of splicing factors in luad and lusc. we created prognostic predictors based on alternative splicing events with high performances for risk stratification in nsclc patients and uncovered interesting splicing networks in luad and lusc which could be underlying mechanisms. (c) 2017 elsevier b.v. all rights reserved.
computer_graphics	the increased availability of consumer-grade virtual reality (vr) head-mounted displays (hmd) has created significant demand for affordable and reliable 3d input devices that can be used to control 3d user interfaces. accurate positioning of a user 's body within the virtual environment is essential in order to provide users with convincing and interactive vr experiences. existing full-body motion tracking systems from academia and industry have suffered from problems of occlusion and accumulated sensor error while often lacking absolute positional tracking. this paper describes a wireless sensor array system that uses multiple inertial measurement units (imus) for calculating the complete pose of a user 's body. the system corrects gyroscope errors by using magnetic sensor data. the sensor array system is augmented by a positional tracking system that consists of a rotary-laser base station and a photodiode-based tracked object worn on the user 's torso. the base station emits horizontal and vertical laser lines that sweep across the environment in sequence. with the known configuration of the photodiode constellation, the position and orientation of the tracked object can be determined with high accuracy, low latency, and low computational overhead. as will be shown, the sensor fusion algorithms used result with a full-body tracking system that can be applied to a wide variety of 3d applications and interfaces.
software_engineering	context: the trustworthiness of research results is a growing concern in many empirical disciplines. aim: the goals of this paper are to assess how much the trustworthiness of results reported in software engineering experiments is affected by researcher and publication bias, given typical statistical power and significance levels, and to suggest improved research practices. method: first, we conducted a small-scale survey to document the presence of researcher and publication biases in software engineering experiments. then, we built a model that estimates the proportion of correct results for different levels of researcher and publication bias. a review of 150 randomly selected software engineering experiments published in the period 2002-2013 was conducted to provide input to the model. results: the survey indicates that researcher and publication bias is quite common. this finding is supported by the observation that the actual proportion of statistically significant results reported in the reviewed papers was about twice as high as the one expected assuming no researcher and publication bias. our models suggest a high proportion of incorrect results even with quite conservative assumptions. conclusion: research practices must improve to increase the trustworthiness of software engineering experiments. a key to this improvement is to avoid conducting studies with unsatisfactory low statistical power. (c) 2015 elsevier inc. all rights reserved.
image_processing	incident angle of light source is a key factor that affects imaging resolution of direct optical imaging for a reflected target. for a large incident angle, it is easy to form the ""blind area"" in which the image of the object cannot be distinguished clearly. using classical statistical optics, we study ghost imaging (gi) for a reflected object numerically and experimentally and show that by measuring the second-order correlation of light fields, a ghost-image with good quality can be retrieved in the ""blind area."" unlike transmitted ghost imaging, which is affected greatly by the transverse size of the test detector, the size has almost no effect on the resolution of reflective ghost imaging when the blind area appears.
network_security	nowadays, denial of service (dos) attacks have become a major security threat to networks and the internet. therefore, even a naive hacker can launch a large-scale dos attack to the victim from providing internet services. this article deals with the evaluation of the snort ids in terms of packet processing performance and detection. this work describes the aspect involved in building campus network security system and then evaluates the campus network security risks and threats, mainly analyses the attacks dos and ddos, and puts forward new approach for snort campus network security solutions. the objective is to analyze the functional advantages of the solution, deployment and configuration of the open source based on snort intrusion detection system. the evaluation metrics are defined using snort namely comparison between basic rules with new ones, available bandwidth, cpu loading and memory usage.
cryptography	card-based protocols enable us to easily perform cryptographic tasks such as secure multiparty computation using a deck of physical cards. since the first card-based protocol appeared in 1989, many protocols have been designed. a protocol is usually described with a series of somewhat intuitive and verbal descriptions, such as ""turn over this card,"" ""shuffle these two cards,"" ""apply a random cut to these five cards,"" and so on. on the other hand, a formal computational model of card-based protocols via abstract machine was constructed in 2014. by virtue of the formalization, card-based protocols can be treated more rigorously; for example, it enables one to discuss the lower bounds on the number of cards required for secure computations. in this paper, an overview of the computational model with its applications to designing protocols and a survey of the recent progress in card-based protocols are presented.
system_identification	in this study, the authors propose an l(0)-norm penalised shrinkage linear least mean squares (l(0)-sh-lms) algorithm and an l(0)-norm penalised shrinkage widely linear least mean squares (l(0)-sh-wl-lms) algorithm for sparse system identification. the proposed algorithms exploit the priori and the posteriori errors to calculate the varying step-size, thus they can adapt to the time-varying channel. meanwhile, in the cost function they introduce a penalty term that favours sparsity to enable the applicability for sparse condition. moreover, the l(0)-sh-wl-lms algorithm also makes full use of the non-circular properties of the signals of interest to improve the tracking capability and estimation performance. quantitative analysis of the convergence behaviour for the l(0)-sh-wl-lms algorithm verifies the capabilities of the proposed algorithms. simulation results show that compared with the existing least mean squares-type algorithms, the proposed algorithms perform better in the sparse channels with a faster convergence rate and a lower steady-state error. when channel changes suddenly, a filter with the proposed algorithms can adapt to the variation of the channel quickly.
control_engineering	in many control engineering problems, it is desired to analyze the systems at particular frequency intervals of interest. this paper focuses on the development of frequency interval cross gramians for both linear and bilinear systems. new generalized sylvester equations for calculating the frequency interval cross gramians are derived in order to be used to obtain information regarding controllability and observability within a single matrix. the advantage of the proposed method is that it is computationally more efficient compared to existing gramian-based techniques since only half of the number of equations need to be solved in order to obtain information regarding the controllability and observability of a system compared to existing techniques. numerical examples are provided to demonstrate the computational efficiency of the proposed method which uses frequency interval cross gramians relative to existing methods.
relational_databases	remote sensing of resource in a geographic space at regular temporal intervals has paved way for the evolution of geo-spatial information processing. knowledge engineering of facts acquired through this technology primarily aims at qualitative results to support human in solving complex tasks that cannot be solved through quantitative relational query processing methods with database management systems (dbms). this necessitates the need for automated inference mechanism to be built over relational databases. automated reasoning, a systematic process of formal symbolic representation to codify the acquired facts enables the system to infer new knowledge which can further update the facts. a formal representation of event attributed spatial entity (ease) knowledge base is proposed using the theory of allen 's interval calculus and randel 's rcc-8. the objective of the proposed knowledge base is to formalize spatial entities in a geographic region whose temporal attributes are events occurring in an interval, at time instant and over successive intervals to qualitatively answer the event-based queries on prediction of spatial process. the significance of this formal approach is shown using query evaluation on real datasets. the working of proposed knowledge base is explained with illustrative results. towards the end of this work, the direction for enhancement of ease to explore its use is discussed.
parallel_computing	we report on the first application of the graphics processing units (gpus) accelerated computing technology to improve performance of numerical methods used for the optical characterization of evaporating microdroplets. single microdroplets of various liquids with different volatility and molecular weight (glycerine, glycols, water, etc.), as well as mixtures of liquids and diverse suspensions evaporate inside the electrodynamic trap under the chosen temperature and composition of atmosphere. the series of scattering patterns recorded from the evaporating microdroplets are processed by fitting complete mie theory predictions with gradientless lookup table method. we showed that computations on gpus can be effectively applied to inverse scattering problems. in particular, our technique accelerated calculations of the mie scattering theory on a single-core processor in a matlab environment over 800 times and almost 100 times comparing to the corresponding code in c language. additionally, we overcame problems of the time-consuming data post-processing when some of the parameters (particularly the refractive index) of an investigated liquid are uncertain. our program allows us to track the parameters characterizing the evaporating droplet nearly simultaneously with the progress of evaporation.
bioinformatics	pax3 functions at the nodal point in neural stem cell maintenance and differentiation. using bioinformatics methods, we identified pax3 as a potential regulator of beta-tubulin-iii (tubb3) gene transcription, and the results indicated that pax3 might be involved in neural stem cell (nsc) differentiation by orchestrating the expression of cytoskeletal proteins. in the present study, we reported that pax3 could inhibit the differentiation of nscs and the expression of tubb3. further, using luciferase and electrophoretic mobility shift assays, we demonstrated that pax3 could bind to the promoter region of tubb3 and inhibit tubb3 transcription. finally, we confirmed that pax3 could bind to the promoter region of endogenous tubb3 in the native chromatin of nscs. these findings indicated that pax3 is a pivotal factor targeting various molecules during differentiation of nscs in vitro. (c) 2017 elsevier inc. all rights reserved.
signal-flow_graph	according to the switching rules of iso2859-1:1999(e), using the method of signal flow graph combined with probability generating function, this paper derives the formulas of scheme operating characteristic curves and average scheme sample number of iso2859-1:1999(e). based on these formulas, we calculate the performance measures using sas code.
network_security	while all cloud based platforms possess security vulnerabilities, the additional security challenges with container systems stem from the sharing of host os among independent containers. if a malicious application was to break into the root of container daemon, it could gain root access into the host kernel thereby compromising the entire system. it could create denial-of-service attack for other user applications, rejecting service to other applications. in this paper, we propose a quantum network security framework for the cloud. we devise a means by which quantum particles, denoted entangled bell pairs, are routed to network nodes. this enables teleportation of quantum information between source and destination only when root privileges are required by an application. the secure quantum channel works on a use-once only policy, so the key data cannot be easily copied, regenerated or spoofed without detection. a network framework for multiple pre-staged channels is devised and we illustrate that policy for network routing of entangle particles formulated as a multi-tenant teleportation network, capable of disseminating key data to servers hosting docker container applications. the framework can achieve provably high levels of security and is capable of integration into a cloud data center for securing applications using docker containers. we also describe quantum network layer protocols for cloud container security that leverage the unique properties of quantum entanglement. to resolve security concerns, this layer would control access between application and container daemon, thereby facilitating restricted communication with proper authentication.
data_structures	this article describes a new open source scientific workflow system, the timestudio project, dedicated to the behavioral and brain sciences. the program is written in matlab and features a graphical user interface for the dynamic pipelining of computer algorithms developed as timestudio plugins. timestudio includes both a set of general plugins (for reading data files, modifying data structures, visualizing data structures, etc.) and a set of plugins specifically developed for the analysis of event-related eyetracking data as a proof of concept. it is possible to create custom plugins to integrate new or existing matlab code anywhere in a workflow, making timestudio a flexible workbench for organizing and performing a wide range of analyses. the system also features an integrated sharing and archiving tool for timestudio workflows, which can be used to share workflows both during the data analysis phase and after scientific publication. timestudio thus facilitates the reproduction and replication of scientific studies, increases the transparency of analyses, and reduces individual researchers' analysis workload. the project website (http://timestudioproject.com) contains the latest releases of timestudio, together with documentation and user forums.
algorithm_design	in view of the special structure of isolated grid, the backtracking algorithm which is widely used in black-start path optimization has its defect, such as time-consuming and blind optimizing. in this paper, minimal spanning tree integrated with backtracking algorithm is proposed to realize the path optimization for black-start. firstly, this paper builds the weight factors of transmission line and unit to identify significant nodes. then, the optimal black start topology is built with the maximum weight factors of transmission line. after that, backtracking algorithm is introduced to calculate the specific black-start path from the optimal tree topology, where the target is to maximize the weight factor of path. the optimization algorithm can effectively reduce the path search space and has high robustness. finally, new england to-unit 39-bus system is used as an example to verify the effectiveness of the proposed algorithm.
computer_graphics	city models by 3d cg (computer graphics) are important in promoting public participation for smart city, which will use solar photovoltaic (pv) generation. but, creating city models are labor intensive. in order to automate laborious steps, we proposed new technology by integration of a gis (geographic information system) and cg. the proposed integrated system automatically generates 3d building models, based on building polygons or building footprints on digital maps, which show most building polygons' edges meet at right angles (orthogonal polygon). a complicated orthogonal polygon can be partitioned into a set of rectangles. the proposed integrated system partitions orthogonal building polygons into a set of rectangles and places rectangular roofs and box-shaped building bodies on these rectangles. in this paper, we propose to automatically generate 3d building models topped with double shed roofs attached by pv arrays. the sizes and positions, slopes of roof boards and under roof constructions are made clear by designing the top view and side view of a double shed roof house. for the application example of the developed system, we simulate the solar photovoltaic generation change of a city block by performing land readjustment and changing shape of buildings, that is, ordinary roof house or double shed roof house suitable for greater pv generation. our simulation reveals that double shed roof houses have greatly improved the solar photovoltaic generation.
digital_control	in applications involving digital control, the set of admissible control actions is finite/quantized. coupled with state constraints and fast dynamics, explicit model predictive control (empc) provides an attractive control formalism. however, the design of data-driven empcs with finite admissible control sets is a challenging and relatively unexplored problem. in this paper, a systematic data-driven method is proposed for the design of quantized empcs (q-empcs) for time-varying output tracking in nonlinear systems. the design involves: 1) sampling the admissible state space using low-discrepancy sequences to provide scalability to higher dimensional nonlinear systems; 2) at each sampled data point, solving for optimal quantized model predictive control actions and determining feasibility of the intrinsic mixed-integer nonlinear programming problem; and 3) constructing the q-empc control surface using multiclass support vector machines (mc-svms). in particular, four widely used mc-svm algorithms are employed to construct the proposed data-driven q-empc. extensive testing and comparison among the different mc-svm algorithms is performed on 2-d and 5-d benchmark examples to demonstrate the effectiveness and scalability of the proposed methodology.
signal-flow_graph	in the power plant simulation system, fluid network is widely present. model accuracy largely determines the merits of the simulation system. the concept of signal flow graph has been introduced into the mechanism modeling process to describe the fluid network. various structures in the fluid network are classified as node and branch, and the algorithm relationship of node 's pressure and according to identify the unknown parameters in the model using the pso, the influence from parameters of pso to the process of optimization could be studied. then the range of unknown parameters could be determined. optimization could be accelerated, so as to achieve optimal results.
microcontroller	the security of information transmission is of paramount importance in all sectors of society, whether civilian or defence related. in ancient times the encryption of secret messages was mainly realized by physical or chemical means, but this was later supplemented by mathematical techniques. in parallel, the breaking of enemy codes has also been a subject of intense study. to date, the only known absolutely secure means of encryption is through quantum cryptography. however, this still has to be implemented by equipment that is vulnerable to various physical attacks, so it is important to study these methods of attack, both for legitimate users and for the surveillance of criminal activities. today, nearly all transactions have to be realized through the computer and much effort has been devoted to cracking the software. however, little attention has been paid to the hardware, and it has only recently been realized that computer chips themselves can leak sensitive information, from which a code may even be deciphered. by studying the photonic emission and the data dependency of a cryptographic chip during operation, the correspondence between the hamming weight of the operand and the number of photons emitted may be established, based on which a simple and effective method is proposed to crack the advanced encryption standard (aes) cipher chip. an experimental platform has been set up for measuring and analyzing the leaked photonic emission using time-correlated single-photon counting. an at89c52 microcontroller implementing the operation of the aes cipher algorithm is used as a cipher chip. the emitted photons are collected when the first addroundkey and subbytes of the aes encryption arithmetic are executed, and their respective numbers are found to have a linear relationship with the operand hamming weight. the sources of noise affecting the photon emission trace have been analyzed, so that the measurement error and uncertainty can be reduced effectively. with the help of our hamming weight simulation model, by selecting one or several groups of plain text and comparing the corresponding relationship between the hamming weight of the intermediate values and the number of photons emitted by the cipher chip, the key of the aes encryption algorithm has been successfully recovered and cracked. this confirms the effectiveness of this method of attack, which can therefore pose a severe threat to the security of the aes cipher chip. for the next step in the future, our method will be optimized to narrow the search range, and also combined with other photonic emission analysis attacks (such as simple photonic emission analysis and differential photonic emission analysis) to improve the efficiency. a comparison and evaluation of the various methods will be made. at the same time, our current experimental configuration will be improved to obtain a better collection efficiency and signal-to-noise ratio.
state_space_representation	with the increase in the urban population witnessed in all major cities worldwide, efficient urban traffic planning, modeling and control are indispensable. in this paper we propose a novel macro-model for urban networks based on queuing theory and cast in a state-space representation. the model for each junction incorporates a switching mechanism capturing both the nonlinear dynamics of normal traffic conditions and the linear evolution of vehicle queues during junction block-back scenarios. moreover, while competing models suffer a quadratic increase in computational cost with every added junction, our model exhibits only a linear increase in dimensionality and thus significantly lowers its computational demands. the simulation results from the proposed model are validated against a standard micro-modelling simulation package. these results will demonstrate through a monte carlo simulation that given correct model parameters, the proposed macro-model can well capture the complex vehicle dynamics of an urban region, thus paving the way for an accurate analysis of the network and for the development of efficient urban traffic control strategies.
electric_motor	this paper describes a low cost, small scale spin rig. the rig is housed in a steel vacuum chamber of 203 mm (8 in) diameter and powered by a 3hp variable speed dc electric motor. the small rig was developed to test the experimental procedure and data acquisition techniques and to investigate the dynamic characteristics of a high speed rotating system. using this rig, fan-blade-out (fbo) experiments were carried out. the notched blade releasing mechanism was investigated. the relationship between the notch depth and the release speed was modified with the consideration of the notch concentration factor. the predicted release speed agreed reasonably well with the experimental data. a simple wire trigger method for data acquisition was developed. synchronized high speed video images and sensor signals during fbo events were obtained. the observed phenomena were similar to those reported using larger spin rigs.
analog_signal_processing	a 3 - 5 ghz uwb radar chip for surveillance and reconnaissance applications is fabricated in 0.13um cmos process. the uwb radar chip employs the equivalent time sampling and 4-channel time interleaved sampler architecture. the dc offset calibrator and bjt based circuit greatly reduce the dc offset issues. the analog signal processing part employs the proposed high speed track and hold (t/h) circuit. the direct loop back test shows the feasibility of the distance sensing with 3 cm resolution at the several meter distance. the chip size is 4 mm x 2.5 mm, and 81 ma / 38ma (rx/tx) are consumed at 1.5 v supply.
operating_systems	in the ""design4all"" project, a hardware and software architecture is under development for the implementation of adaptable and adaptive applications aimed to support all people in carrying out an independent life at home. in this paper, the problems of interactions with applications implemented in the android platform, chosen for the experiments of interaction with the developed applications, are discussed with main emphasis on two main aspects: (i) the use of facilities supporting accessibility available in the most commonly used operating systems (mainstreaming) and (ii) the portability of solutions across different platforms.
algorithm_design	movement primitive segmentation enables long sequences of human movement observation data to be segmented into smaller components, termed movement primitives, to facilitate movement identification, modeling, and learning. it has been applied to exercise monitoring, gesture recognition, humanmachine interaction, and robot imitation learning. this paper proposes a segmentation framework to categorize and compare different segmentation algorithms considering segment definitions, data sources, application-specific requirements, algorithm mechanics, and validation techniques. the framework is applied to human motion segmentation methods by grouping them into online, semionline, and offline approaches. among the online approaches, distance-based methods provide the best performance, while stochastic dynamic models work best in the semionline and offline settings. however, most algorithms to date are tested with small datasets, and algorithm generalization across participants and to movement changes remains largely untested.
electricity	solar energy is one of the most popular clean energy sources and is a promising alternative to fulfill the increasing energy demands of modern society. solar cells have long been under intensive research attention for harvesting energy from sunlight with a high power-conversion efficiency and low cost. however, the power outputs of photovoltaic devices suffer from fluctuations due to the intermittent instinct of the solar radiation. integrating solar cells and energy-storage devices as self-powering systems may solve this problem through the simultaneous storage of the electricity and manipulation of the energy output. this review summarizes the research progress in the integration of new-generation solar cells with supercapacitors, with emphasis on the structures, materials, performance, and new design features. the current challenges and future prospects are discussed with the aim of expanding research and development in this field.
algorithm_design	dynamic optimization problems (dops) have attracted increasing attention in recent years. analyzing the fitness landscape is essential to understand the characteristics of dops and may provide guidance for the algorithm design. existing measures for analyzing the dynamic fitness landscape, such as the dynamic fitness distance correlation and the severity of change, cannot give a comprehensive evaluation of the landscape and have many disadvantages. in this paper, we used discrete-time fourier transform( dtft) and dynamic time warping (dtw) distance to acquire information of fitness landscape from frequency and time domains. five measures are proposed, including the stationarity of amplitude change, the keenness, the periodicity, the change degree of average fitness and the similarity. they can reflect the features of fitness landscape from the aspects of outline, keenness, period, fitness value and similarity degree, respectively. these criteria can obtain essential information that cannot be acquired by existing criteria, and do not depend on the distribution of variables, the prior information of solutions and algorithms. to illustrate the performance of the five measures, experiments are conducted based on three types of standard dops with a two-peak function. in addition, we also apply these criteria on the test task scheduling problem for illustrating the fairness and adaptability. the experiment results show that these criteria can reflect the change characteristics of dynamic fitness landscape, and are consistent with the theoretical analysis. (c) 2016 elsevier b.v. all rights reserved.
computer_programming	there are repetitive patterns in strategies of manipulating source code. for example, modifying source code before acquiring knowledge of how a code works is a depth-first style and reading and understanding before modifying source code is a breadth-first style. to the extent we know there is no study on the influence of personality on them. the objective of this study is to understand the influence of personality on programming styles. we did a correlational study with 65 programmers at the university of stuttgart. academic achievement, programming experience, attitude towards programming and five personality factors were measured via self-assessed survey. the programming styles were asked,in the survey or mined from the software repositories. performance in programming was composed of bug-proneness of programmers which was mined from software repositories, the grades they got in a software project course and their estimate of their own programming ability. we did statistical analysis and found that openness to experience has a positive association with breadth-first style and conscientiousness has a positive association with depth-first style. we also found that in addition to having more programming experience and better academic achievement, the styles of working depth-first and saving coarse-grained revisions improve performance in programming. (c) 2015 elsevier inc. all rights reserved.
image_processing	document image segmentation into text lines is one of the stages in unconstrained handwritten document recognition. this paper presents a new algorithm for text line separation in handwriting. the developed algorithm is based on a method using the projection profile. it employs thresholding, but the threshold value is variable. this permits determination of low or overlapping peaks of the graph. the proposed technique is shown to improve the recognition rate relative to traditional methods. the algorithm is robust in text line detection with respect to different text line lengths.
control_engineering	computer numerical control technology is mechanical movement with digital information and work process control technology, data processing is the reverse engineering of important technical aspects, which determines whether the subsequent model reconstruction process easy and accurate manner. in this paper, computer numerical control machining complex surfaces feature full potential of existing computer numerical control equipment, automatic control system designed to make computer numerical control machining equipment to achieve higher processing speed, high precision machining, and computer numerical control equipment in order to achieve high efficiency machining.
analog_signal_processing	in this work, a voltage-mode biquad filter realizing low-pass, band-pass and high-pass characteristics is presented. the proposed filter, which employs two fdcciis, two grounded capacitors and two nmos transistors, provides electronic tunability with the control voltage applied to the gate. nmos transistors act as linear resistor. furthermore, the proposed circuit still enjoys realization using a low number of active and passive components, no requirement with the component choice conditions to realize specific filtering functions, high input impedance, and low active and passive sensitivities performance. simulation results using spice program are given to show the performance of the filter and verify the theory. copyright (c) 2010 john wiley & sons, ltd.
image_processing	detailed information on the distribution of airway diameters during bronchoconstriction in situ is required to understand the regional response of the lungs. imaging studies using computed tomography (ct) have previously measured airway diameters and changes in response to bronchoconstricting agents, but the manual measurements used have severely limited the number of airways measured per subject. hence, the detailed distribution and heterogeneity of airway responses are unknown. we have developed and applied dynamic imaging and advanced image-processing methods to quantify and compare hundreds of airways in vivo. the method, based on ct, was applied to house dust-mite-sensitized and control mice during intravenous methacholine (mch) infusion. airway diameters were measured pre-and post-mch challenge, and the results compared demonstrate the distribution of airway response throughout the lungs during mechanical ventilation. forced oscillation testing was used to measure the global response in lung mechanics. we found marked heterogeneity in the response, with paradoxical dilation of airways present at all airway sizes. the probability of paradoxical dilation decreased with decreasing baseline airway diameter and was not affected by pre-existing inflammation. the results confirm the importance of considering the lung as an entire interconnected system rather than a collection of independent units. it is hoped that the response distribution measurements can help to elucidate the mechanisms that lead to heterogeneous airway response in vivo. new & noteworthy information on the distribution of airway diameters during bronchoconstriction in situ is critical for understanding the regional response of the lungs. we have developed an imaging method to quantify and compare the size of hundreds of airways in vivo during bronchoconstriction in mice. the results demonstrate large heterogeneity with both constriction and paradoxical dilation of airways, confirming the importance of considering the lung as an interconnected system rather than a collection of independent units.
state_space_representation	building energy simulation programs in most cases solve heat conduction through walls by considering one-dimensional heat flows, neglecting thermal bridges. the paper shows a new method for implementing bi-dimensional and three-dimensional heat transfer in dynamic energy simulation software, allowing a great improvement of their capabilities. the new procedure starts from the theory of state space representation of transfer functions, and then introduces simplifications for reducing computational time and the required cpu sources. starting from a first case study, aimed to verify the achievable correspondence of the simplified new method compared to the original one, two common thermal bridges have been deeply analysed, comparing the proposed methodologies and numerical solution based on using finite volume methods. the investigated building structures determine bi-dimensional heat flows because of discontinuities in both materials and geometry. by comparing the achieved outcomes to those derived by much more onerous cfd studies, several cases changing grid refinement, timestep, ambient condition and so on, the proposed method shows its suitability, with maximum errors never higher than 4.5%, also under hourly-variable outdoor temperature and solar radiation. (c) 2013 elsevier ltd. all rights reserved.
software_engineering	context: several research efforts have been targeted to support architecture centric development and evolution of software for robotic systems for the last two decades. objective: we aimed to systematically identify and classify the existing solutions, research progress and directions that influence architecture-driven modeling, development and evolution of robotic software. research method: we have used systematic mapping study (sms) method for identifying and analyzing 56 peer-reviewed papers. our review has (i) taxonomically classified the existing research and (ii) systematically mapped the solutions, frameworks, notations and evaluation methods to highlight the role of software architecture in robotic systems. results and conclusions: we have identified eight themes that support architectural solutions to enable (i) operations, (ii) evolution and (iii) development specific activities of robotic software. the research in this area has progressed from object-oriented to component-based and now to service-driven robotics representing different architectural models that emerged overtime. an emerging solution is cloud robotics that exploits the foundations of service-driven architectures to support an interconnected web of robots. the results of this sms facilitate knowledge transfer- benefiting researchers and practitioners- focused on exploiting software architecture to model, develop and evolve robotic systems. (c) 2016 elsevier inc. all rights reserved.
system_identification	two methods have been compared for the determination of the inertial properties of a small, fixed-wing un-manned aerial vehicle. the first method uses the standard single degree of freedom pendulum method and the second method implements a novel, potentially easier, 3 degrees of freedom pendulum method, which yields the entire inertia tensor from a single swing test. both methods are using system identification of the pendulum motion to estimate the inertial properties. substantial corrections (up to 25%) have to be applied to the experimental results. these corrections are caused by the acceleration of the pendulum being immersed in the surrounding air, also called the added mass effect. it has been found that the methods presented in literature to determine the corrections for full-scale aircraft do not give the correct results for the small-scale un-manned aerial vehicle under consideration. the only feasible, cost-effective method to generate these corrections utilise swing tests with a geometrically similar object of known inertial properties. it has also been found that the corrections are unique with respect to the experimental methods. several benchmarking methods, including the innovative use of static and dynamic wind-tunnel test data, give high confidence in the results.
pid_controller	this study studies the precision motion control of a developed planar motor motion system under the existence of external disturbance, non-linearity, uncertainty, and crosstalk coupling problems those inevitably deteriorate the achievable control object and even make the system unstable. to address these issues, an integrated robust tracking controller consists of feedforward (ff), proportional-integral-derivative (pid), and robust compensator (rc), is developed for the planar motor stage to practically achieve high control performance. specifically, the ff term is designed based on the stage dynamics model to reduce the tracking error, and the pid term is synthesised by pole assignment to stabilise the nominal model. more importantly, rc is particularly designed to suppress the effects of equivalent lumped disturbances including the external disturbances, uncertainties, non-linearities, and crosstalk couplings. the proposed integrated controller possesses robust stability under the uncertain disturbances, and facilitates parameter tuning which is meaningful for practical implementation. finally, comparative experiments are conducted on a developed planar motor of wafer stage, and the results validate the practical effectiveness and high-performance nature of the proposed control strategy.
network_security	security in terms of networks have turn out to be more significant to organizations, military and personal computer user 's. since various kinds of threats are for data from sending it from sender side over internet till it reaches to receiver. here we will focus on ssl it is a technique used to give client and server authentication, data confidentiality and data integrity. it transform our data into unintelligible form, data which we will be sending can be text or no text form, by encrypting our data we can save it from attacks like eavesdropping, in which interception of communication by unauthorized person, he can either listen or can add malicious information in our data which can lead to catastrophic results. this technique of secure data transmission is very useful in securing the integrity of data sent by the unmanned aerial vehicles in military application to commercially used electricity meter. since the above mentioned devices uses microcontroller to send data through internet hence this data is always going to be susceptible to above mentioned threats so it is important to ensure that it does n't fall in wrong hands, our objective is that our microcontroller sends the data to remote location has authenticity, confidentiality and integrity. first we will send some meaningful text already stored in controller of stm3240g eval-board then that data will be sent to server. these encrypted packets will be sending to remote server through ethernet. at the receiver end this data will be received and decrypted to get the original captured data.
algorithm_design	the increase in the number of cores per processor and the complexity of memory hierarchies make cache coherence key for programmability of current shared memory systems. however, ignoring its detailed architectural characteristics can harm performance significantly. in order to assist performance-centric programming, we propose a methodology to allow semi-automatic performance tuning with the systematic translation from an algorithm to an analytic performance model for cache line transfers. for this, we design a simple interface for cache line aware optimization, a translation methodology, and a full performance model that exposes the block-based design of caches to middleware designers. we investigate two different architectures to show the applicability of our techniques and methods: the many-core accelerator intel xeon phi and a multi-core processor with a numa configuration (intel sandy bridge). we use mathematical optimization techniques to tune synchronization algorithms to the microarchitectures, identifying three techniques to design and optimize data transfers in our model: single-use, single-step broadcast, and private cache lines.
voltage_law	this paper introduces a novel backward/forward sweep algorithm for both fundamental and harmonics flow calculation in distribution network. in this algorithm, the fundamental and harmonic currents of each branch are calculated by equivalent current injection method. the relationship between branch currents and harmonic currents of each order on a radial feeder can be calculated by summing the injection current from the receiving end toward the sending end of the feeder. after obtaining the branch currents, both the harmonics bus voltage and the fundamental bus voltage can be easily obtained from the sending end to the receiving end based on the kirchhoff 's voltage law. by using this method, the lu decomposition is avoided and it will save huge computational time. base on special hierarchy characteristic of radial network, the branches are sorted by layers. so that the branch power loss and voltage drop can be computed in parallel at each level. the computational time can be further reduced. the test results demonstrate the flexible, accuracy and efficiency of the proposed method.
data_structures	we propose a new sharing analysis of object-oriented programs based on abstract interpretation. two variables share when they are bound to data structures which overlap. we show that sharing analysis can greatly benefit from linearity analysis. we propose a combined domain including aliasing, linearity and sharing information. we use a graph-based representation of aliasing information which naturally encodes sharing and linearity information, and define all the necessary operators for the analysis of a java-like language.
operating_systems	in recent years smart mobile devices have bolstered new interaction scenarios that require more sophisticated human-machine interfaces. the leading developers of operating systems for these devices now provide apis (application programming interface) for developers to implement their own applications, including different solutions for developing graphical interfaces, control sensors and providing oral interaction. despite the usefulness of these resources, defined strategies are still needed for developing multimodal interfaces to take greater advantage of these devices for identifying and meeting the needs of users. currently, these applications are typically ad-hoc and facilitate oral communication only through simple commands. in this paper we propose the practical application of context-sensitive multimodal conversational agents to provide advanced library services that dynamically consider specific user needs and preferences, as well as the specific characteristics of the environment in which the interaction occurs. such agents would improve and customize the service provided by a mobile device with internet access. our proposal integrates features of android apis on a modular architecture emphasizing the management of interactions and context awareness in order to create robust applications that can be easily updated and adapted to the user.
symbolic_computation	under investigation in this paper are the (1+1)-dimensional and (2+1)-dimensional ito equations. with the help of the bell polynomials method, hirota bilinear method and symbolic computation, the bilinear representations, n-soliton solutions, bilinear backlund transformations and lax pairs of these two equations are obtained, respectively. in particular, we obtain a new bilinear form and n-soliton solutions of the (2+1)-dimensional ito equation. the bilinear backlund transformation and lax pair of the (2+1)-dimensional ito equation are also obtained for the first time. copyright (c) 2014 john wiley & sons, ltd.
network_security	future home networks are expected to become extremely sophisticated, yet only the most technically adept persons are equipped with skills to secure them. in this paper, we provide a novel solution to detect and prevent attacks on home routers based on anomalous power consumption. we developed a means of measuring power consumption that could be used in a wide variety of home networks, although our primary focus on is on profiling homenet-based residential routers, specifically to detect attacks against homenet routing infrastructure. several experimental results are presented when the infrastructure is exposed to various types of attacks, which show strong evidence of the feasibility of our approach.
pid_controller	in this paper, the considered hybrid power system (hps) is having a wind turbine generator, a diesel engine generator (deg) and a storage device (such as capacitive energy storage). this paper presents a comparative study of frequency and power control for the studied isolated wind-diesel hps with four different classical controllers for the pitch control of wind turbines and the speed governor control of deg the classical controllers considered are integral, proportional-integral, integral-derivative and proportional-integral-derivative (pid) controller. a quasi-oppositional harmony search (qohs) algorithm is proposed for the tuning of the controller gains. the comparative dynamic simulation response results indicate that better performance may be achieved with choosing pid controller among the considered classical controllers, when subjected to different perturbation. stability and sensitivity analysis, presented in this paper, reveals that the optimized pid controller gains offered by the proposed qohs algorithm are quite robust and need not be reset for wide changes in system perturbations. (c) 2015 elsevier b.v. all rights reserved.
system_identification	recent development of system identification using bayesian models or stochastic filtering provides probabilistic descriptions (i.e., probability density function or statistical parameters like mean and variance) of the identified model parameters (e.g., mass, stiffness, and damping). optimal design of passive controllers for these systems whose parameters are uncertain has remained an open problem. with this in view, the present study aims to develop numerical solution scheme for the optimal design of tuned mass damper (tmd) operating in uncertain environment. deterministic design of tmd in these cases suffers detuning as the system parameters are random. thus, a reliability-based design optimization (rbdo) scheme is presented in this paper for better performance of the tmd when exposed to uncertainties. to solve the rbdo problem, response surface methodology is used along with the moving least squares technique. dual response surfaces are used for separate handling of optimization and reliability analysis. first response surface performs optimization of the design variables of tmd, while the second response surfaces are used for the estimation of the statistical properties like mean and variance to satisfy the constrained conditions. numerical analysis is presented to show the effectiveness of the proposed algorithm for rbdo of single degree of freedom-tmd system as a proof of concept. the proposed meta-model-based algorithm can be applied for the optimal design of controller for large structures where conventional technique may face difficulty to handle both optimization and uncertainty quantification simultaneously. copyright (c) 2016 john wiley & sons, ltd.
state_space_representation	in this article we review some intelligent and robotic algorithm approaches and propose a novel neural-network (nn) based approach for nonlinear systems. the nonlinear systems can be represented by the nonlinear tagaki-sugeno (t-s) and nn models. the linear differential inclusion state-space representation is utilized to deal with the controlled systems. the stability conditions and controller design for this representation are derived based on the fuzzy parallel distributed compensation scheme which is employed to construct a global fuzzy logic controller by blending all local state feedback controllers. the time-delay states that exist in the nonlinear simulated example, including the chaotic disturbances, are given to show the feasibility of the proposed fuzzy controller design approach.
computer_graphics	implicit representations have gained an increasing popularity in geometric modeling and computer graphics due to their ability to represent shapes with complicated geometry and topology. however, the storage requirement, e.g. memory or disk usage, for implicit representations of complex models is relatively large. in this paper, we propose a compact representation for multilevel rational algebraic spline (mras) surfaces using low-rank tensor approximation technique, and exploit its applications in surface reconstruction. given a set of 3d points equipped with oriented normals, we first fit them with an algebraic spline surface defined on a box that bounds the point cloud. we split the bounding box into eight sub-cells if the fitting error is greater than a given threshold. then for each sub-cell over which the fitting error is greater than the threshold, an offset function represented by an algebraic spline function of low rank is computed by locally solving a convex optimization problem. an algorithm is presented to solve the optimization problem based on the alternating direction method of multipliers (admm) and the candecomp/parafac (cp) decomposition of tensors. the procedure is recursively performed until a certain accuracy is achieved. to ensure the global continuity of the mras surface, quadratic b-spline weight functions are used to blend the offset functions. numerous experiments show that our approach can greatly reduce the storage of the reconstructed implicit surface while preserve the fitting accuracy compared with the state-of-the-art methods. furthermore, our method has good adaptability and is able to produce reconstruction results with high quality. (c) 2016 elsevier ltd. all rights reserved.
electrical_circuits	semistability is the property whereby the solutions of a dynamical system converge to a lyapunov stable equilibrium point determined by the system initial conditions. we extend the theory of semistability to a class of first-order evolution variational inequalities, and study the finite-time semistability. these results are lyapunov-based and are obtained without any assumptions of sign definiteness on the lyapunov function. our results are supported by some examples from unilateral mechanics and electrical circuits involving nonsmooth elements such as coulomb 's friction forces and diodes.
operational_amplifier	method for estimation of structural defects density over whole wafer area by parametric wafer map creation is considered. this technique allows fast and accurate estimation of defects density over wafer area and in wafer batch. input offset voltage of operational amplifier (op-amp) is calculated as a function of structural defects density and an example of corresponding parametric map is shown. the opportunity to localize the origin of structural defects on technological route is discussed.
network_security	a secure and safe authentication on a vehicular ad-hoc network (vanet) is essential for network security. a safe data transmission requires integrity, availability and privacy protection features as well as efficient communication in diverse settings. recently proposed security protocols for vehicular communication cannot authenticate in a complex way in areas of heavy traffic due to the increasing number of messages in proportion to the number of vehicles. for efficient communication, data volume need be reduced and communication should be safe against a range of attacks. hence, the present paper proposes a protocol that accelerates message processing by sending a low data volume for communication in areas of heavy traffic and that blocks replay attacks by checking timestamps. in addition, casper/fdr (lowe in casper: a compiler for the analysis of security protocols. user manual and tutorial, version 1.12, 2009; formal systems (europe) ltd in failures-divergence renement. fdr2 user manual, 2010) is used to verify the proposed protocol for its security and efficiency against any security vulnerabilities.
distributed_computing	assembling and simultaneously using different types of distributed computing infrastructures (dci) like grids and clouds is an increasingly common situation. because infrastructures are characterized by different attributes such as price, performance, trust, and greenness, the task scheduling problem becomes more complex and challenging. in this paper we present the design for a fault-tolerant and trust-aware scheduler, which allows to execute bag-of-tasks applications on elastic and hybrid dci, following user defined scheduling strategies. our approach, named promethee scheduler, combines a pull-based scheduler with multi-criteria promethee decision making algorithm. because multi-criteria scheduling leads to the multiplication of the possible scheduling strategies, we propose soft, a methodology that allows to find the optimal scheduling strategies given a set of application requirements. the validation of this method is performed with a simulator that fully implements the promethee scheduler and recreates an hybrid dci environment including internet desktop grid, cloud and best effort grid based on real failure traces. a set of experiments shows that the promethee scheduler is able to maximize user satisfaction expressed accordingly to three distinct criteria: price, expected completion time and trust, while maximizing the infrastructure useful employment from the resources owner point of view. finally, we present an optimization which bounds the computation time of the promethee algorithm, making realistic the possible integration of the scheduler to a wide range of resource management software. (c) 2015 elsevier b.v. all rights reserved.
microcontroller	we present an embedded system designed for enabling telemedicine and remote monitoring of the people 's progresses during physical rehabilitation tasks. the system consists of a modular electronics designed to interface a matrix of 32 bendable force sensors (piezoresistive or piezoelectric) assembled on a flexible pcb. it implements the analog conditioning and digital processing of sensors readout to build a pressure map of the patients' activity with up to 62.5 ksps sampling rate. moreover, the wi-fi interface integrated on the microcontroller allows a live communication between user and physician, in addition to standard local logging of workout information. the reduced power consumption in live streaming conditions (less than 750mw) permits more than 8 hours autonomy of the system with a standard battery supply. results demonstrate the performance of the proposed mapping system.
control_engineering	today, manufacturers do not fully leverage the potential of computer aided engineering (cae) for the design of machine tools and production machines. common design tools for drive systems and other machine components build on an algebraic system description. however, dynamic quality criteria that have a significant impact on the achievable accuracy and productivity cannot be evaluated with purely algebraic descriptions. generally, dynamic criteria can be incorporated in signal-oriented models from control engineering, but the modeling process is time-consuming, knowledge-intensive and the reusability of models is limited. this paper presents a methodology to simplify the optimization of machine components, such as feed drives, while taking dynamic quality criteria into account. the method is based on the object-and component-oriented modeling language modelica. for the quick development of models with limited expert-knowledge the models are integrated in an extensible model library. modern mathematical optimization methods support the systematic search for a combination of system components and parameters with regards to the defined quality criteria. therefore different design alternatives can quickly be analyzed and compared. (c) 2015 the authors. published by elsevier b.v.
relational_databases	advances in high-throughput proteomics have led to a rapid increase in the number, size, and complexity of the associated data sets. managing and extracting reliable information from such large series of data sets require the use of dedicated software organized in a consistent pipeline to reduce, validate, exploit, and ultimately export data. the compilation of multiple mass-spectrometry-based identification and quantification results obtained in the context of a large-scale project represents a real challenge for developers of bioinformatics solutions. in response to this challenge, we developed a dedicated software suite called heidi to manage and combine both identifications and semiquantitative data related to multiple lcms/ms analyses. this paper describes how, through a user-friendly interface, heidi can be used to compile analyses and retrieve lists of nonredundant protein groups. moreover, heidi allows direct comparison of series of analyses, on the basis of protein groups, while ensuring consistent protein inference and also computing spectral counts. heidi ensures that validated results are compliant with miape guidelines as all information related to samples and results is stored in appropriate databases. thanks to the database structure, validated results generated within heidi can be easily exported in the pride xml format for subsequent publication. heidi can be downloaded from http://biodev.extra.cea.fr/docs/heidi.
bioinformatics	background: next-generation sequencing (ngs) allows ultra-deep sequencing of nucleic acids. the use of sequence-independent amplification of viral nucleic acids without utilization of target-specific primers provides advantages over traditional sequencing methods and allows detection of unsuspected variants and co-infecting agents. however, ngs is not widely used for small rna viruses because of incorrectly perceived cost estimates and inefficient utilization of freely available bioinformatics tools. methods: in this study, we have utilized ngs-based random sequencing of total rna combined with barcode multiplexing of libraries to quickly, effectively and simultaneously characterize the genomic sequences of multiple avian paramyxoviruses. thirty libraries were prepared from diagnostic samples amplified in allantoic fluids and their total rnas were sequenced in a single flow cell on an illumina miseq instrument. after digital normalization, data were assembled using the mira assembler within a customized workflow on the galaxy platform. results: twenty-eight avian paramyxovirus 1 (apmv-1), one apmv-13, four avian influenza and two infectious bronchitis virus complete or nearly complete genome sequences were obtained from the single run. the 29 avian paramyxovirus genomes displayed 99.6% mean coverage based on bases with phred quality scores of 30 or more. the lower and upper quartiles of sample median depth per position for those 29 samples were 2984 and 6894, respectively, indicating coverage across samples sufficient for deep variant analysis. sample processing and library preparation took approximately 25-30 h, the sequencing run took 39 h, and processing through the galaxy workflow took approximately 2-3 h. the cost of all steps, excluding labor, was estimated to be 106 usd per sample. conclusions: this work describes an efficient multiplexing ngs approach, a detailed analysis workflow, and customized tools for the characterization of the genomes of rna viruses. the combination of multiplexing ngs technology with the galaxy workflow platform resulted in a fast, user-friendly, and cost-efficient protocol for the simultaneous characterization of multiple full-length viral genomes. twenty-nine full-length or near-full-length apmv genomes with a high median depth were successfully sequenced out of 30 samples. the applied de novo assembly approach also allowed identification of mixed viral populations in some of the samples.
pid_controller	brushless dc motor (bldc) are widely used for many industrial applications because of their high efficiency, high torque and low volume. this paper focuses on speed control of bldc motor using soft computing technique. the problems related to control systems are undesirable overshoot, longer settling times and vibrations while going from one state to another. to overcome the maximum overshoot and longer settling times, pid and self-tuning fuzzy pid control techniques were used in the closed loop controller architecture. the speed control of bldc motor was simulated using matlab/ simulink and the results are obtained. the simulation results revealed that the proposed self-tuning fuzzy pid controller provides better performance than conventional controller. the prototype model of bldc motor is presented and the speed response of bldc motor is observed by lcd display.
relational_databases	time is pervasive of reality, and many relational database approaches have been developed to cope with it. in practical applications, facts can repeat several times, and only the overall period of time containing all the repetitions may be known (consider, e.g., on january, john attended five meetings of the bioinformatics project). while some temporal relational databases have faced facts repeated at (known) periodic time, or single facts occurred at temporally indeterminate time, the conjunction of non-periodic repetitions and temporal indeterminacy has not been faced yet. coping with this problem requires an in-depth extension of current techniques. in this paper, we have introduced a new data model, and new definitions of relational algebraic operators coping with the above issues. we have studied the properties of the new model and algebra (with emphasis on the reducibility property), and how it can be integrated with other models in the literature.
operational_amplifier	this paper presents the results of study on utilization of z-copy voltage controlled current follower differential input transconductance amplifier (zc-vccfdita) active element in a single purpose filtering structure. this active element has three voltage-controlled parameters (intrinsic resistance of current input, voltage gain and transconductance of output section) and is very useful for design of oscillators, signal generators and frequency filters with just one active element. in this paper, the important parameters of possible behavioural model of zc-vccfdita are shown and a particular solution of the controllable band-pass filter is presented. theoretical, calculated, simulated and moreover also measured results are mutually compared.
software_engineering	in mexico, the small and medium size enterprises (smes) are key for the software development industry. for them, having highly qualified personal for the development of high quality software products is a fundamental piece to guarantee their permanency in the market. therefore, matching the software industry requirements with the academy training represents a significant problem that must be addressed for both sectors benefit. this paper presents an analysis of the coverage between the moprosoft norm, standard developed to be used for software industry to ensure quality in software engineering practices, and ten academic curricular programs of higher education related to computer science and informatics; to get an overview of the knowledge and skills that computer science students acquire at universities, regarding knowledge required in organizations that work under process models. in addition, a survey to 32 smes was conducted to contrast the coverage results with their hired, recently graduated, personal.
parallel_computing	modelling of multi-million atomic semiconductor structures is important as it not only predicts properties of physically realizable novel materials, but can accelerate advanced device designs. this work elaborates a new technology-computer-aided-design (tcad) tool for nanoelectronics modelling, which uses a sp(3)d(5)s(*) tight-binding approach to describe multi-million atomic structures, and simulate electronic structures with high performance computing (hpc), including atomic effects such as alloy and dopant disorders. being named as quantum simulation tool for advanced nanoscale devices (q-and), the tool shows nice scalability on traditional multi-core hpc clusters implying the strong capability of large-scale electronic structure simulations, particularly with remarkable performance enhancement on latest clusters of intel xeon phi (tm) coprocessors. a review of the recent modelling study conducted to understand an experimental work of highly phosphorus-doped silicon nanowires, is presented to demonstrate the utility of q-and. having been developed via intel parallel computing center project, q-and will be open to public to establish a sound framework of nanoelectronics modelling with advanced hpc clusters of a many-core base. with details of the development methodology and exemplary study of dopant electronics, this work will present a practical guideline for tcad development to researchers in the field of computational nanoelectronics. (c) 2016 the author(s). published by elsevier b.v. this is an open access article under the cc by-nc-nd license.
computer_vision	the ability to automatically recognize human faces based on dynamic facial images is important in security, surveillance and the health/independent living domains. specific applications include access control to secure environments, identification of individuals at a particular place and intruder detection. this research proposes a real-time system for surveillance using cameras. the process is broken into two steps: (1) face detection and (2) face recognition to identify particular persons. for the first step, the system tracks and selects the faces of the detected persons. an efficient recognition algorithm is then used to recognize detected faces with a known database. the proposed approach exploits the viola-jones method for face detection, the kanade-lucas-tomasi algorithm as a feature tracker and principal component analysis (pca) for face recognition. this system can be implemented at different restricted areas, such as at the office or house of a suspicious person or at the entrance of a sensitive installation. the system works almost perfectly under reasonable lighting conditions and image depths.
algorithm_design	in the real world, it is not uncommon to face an optimization problem with more than three objectives. such problems, called many-objective optimization problems (maops), pose great challenges to the area of evolutionary computation. the failure of conventional pareto-based multi-objective evolutionary algorithms in dealing with maops motivates various new approaches. however, in contrast to the rapid development of algorithm design, performance investigation and comparison of algorithms have received little attention. several test problem suites which were designed for multi-objective optimization have still been dominantly used in many-objective optimization. in this paper, we carefully select (or modify) 15 test problems with diverse properties to construct a benchmark test suite, aiming to promote the research of evolutionary many-objective optimization (emao) via suggesting a set of test problems with a good representation of various real-world scenarios. also, an open-source software platform with a user-friendly gui is provided to facilitate the experimental execution and data observation.
electrical_network	size and complexity of power systems impose significant challenges for the power system analysis and control. as the power system becomes more complex there is a great need to develop improved and sophisticated tools for power system analysis and simulation. these tools should be able to accurately replicate real events that occur in electric power network and help to understand dynamics of changes. a number of software packages have been developed for power system research, analysis, planning, designing and teaching. this paper describes how to utilize an electric power system analyzer (psa) as a useful instrument for power flow studies. the analyzer is designed to be user-friendly, easy-to-use, with the ability to optimize power flow and to visualize the effects of changing problem parameters. psa can handle power system networks up to 100.000 nodes.
relational_databases	flexible business processes can often be modelled more easily using a declarative rather than a procedural modelling approach. process mining aims at automating the discovery of business process models. existing declarative process mining approaches either suffer from performance issues with real-life event logs or limit their expressiveness to a specific set of constaint types. lately, relationalxes, a relational database architecture for storing event log data, has been introduced. in this paper, we introduce a mining approach that directly works on relational event data by querying the log with conventional sql. by leveraging database performance technology, the mining procedure is fast without limiting itself to detecting certain control-flow constraints. queries can be customised and cover process perspectives beyond control flow, e.g., organisational aspects. we evaluated the performance and the capabilities of our approach with regard to several real-life event logs.
operational_amplifier	operational amplifier is an important portion of various analog and mixed signal circuits. today use of mixed mode integrated circuits rises. analog circuits particularly operational amplifiers in cmos technology are difficult to design due to challenging and time consuming tasks like counting various conflicting benchmarks and a wide variety of design factors. this paper presents the use of particle swarm optimization (pso) algorithm for the optimum plan of two stage cmos operational amplifier circuit. pso algorithm has been used to accept required functionalities and performance specifications considering ideal sizing of two-stage op-amp. for circuit optimization c code of pso algorithm has been integrated with ngspice circuit simulator. the circuit is simulated using bsim3v3 mosfet models in tsmc 0.18 mu m and 0.35 um cmos processes technology. the complete optimization system test setup is run on ubuntu operating system. results obtained by pso algorithm are compared with earlier works.
digital_control	this paper presents finite-control-set modelpredictive control (fcs-mpc) for a three-phase quasi-zsource (qzs) four-leg inverter under unbalanced load condition. the key novelty of the proposed control approach is eliminating the double-line frequency ripple in the inductor current with a simple and effective approach. the proposed four-leg qzs inverter with an output lc filter can handle buck/boost and dc/ac conversion features in a single stage. furthermore, the fcs-mpc-based control algorithm helps in maintaining balanced point of common coupling voltages for stand-alone unbalanced loads. the behavior of the predictive controller has been investigated under different operating conditions, and its robustness with the qzs network and the lc filter parameter variations are also studied. furthermore, the effect of double-line frequency ripple and its relation with the inductor current constraint have been tackled comprehensively. to verify the performance of the proposed approach, simulation and experimental studies were performed for balanced and unbalanced loads.
analog_signal_processing	this paper presents some results of a study to evaluate energy conversion potential of an innovative electrical generator, employing a ybco superconductor thin film disk rotor. creating a rate of change of flux in a magnetic field using the ""flux repulsion"" property of superconductors, an electrical generator is realized. using ansys simulation and a simplified experimental set up, the feasibility of the design concept of proposed device is evaluated for different magnetic field strengths and at different rotating speeds of the superconductor disk.
pid_controller	bobbin tool friction stir welding (btfsw) is a relatively new, solid-state welding technology, but its control is not the same as the conventional friction stir welding (fsw) due to the unique welding tool structure. in this paper, closed-loop control system was developed and the smith predictive proportional-integral-derivative (pid) control method was presented to assist the welding system in producing an appropriate interface temperature response. as it is difficult to accurately detect the temperature in full range of the welding zone, the tool-workpiece interface temperature is detected by thermocouple and wireless transmission technology. initial experiments were conducted to derive a qualitative understanding of bobbin tool friction stir welding processes. ziegler-nichols setting method was adopted to determine parameters of the pid controller. while examining the capabilities of smith predictive pid control in btfsw, this paper focuses on the control effect of hysteretic characteristics of welding temperature during butt welding. a compensation strategy was setting gaps along the welding path, and the gap could affect the distribution of temperature. through our experiments, we demonstrate that temperature control strategy is feasible, and the tensile properties of the weld are uniform along the welding direction.
microcontroller	a new pulsed-flow design of hose-based solar collector is presented, which uses a long hose connected to district-grid water in the same way that the basic hose design does. but on contrary that this last, here the exit is not connected directly to consumption and instead the hot water flow is controlled by a thermostat that purges the hose to an insulated tank every time it reaches the desired temperature. so, this water-pond collector works close its maximum efficiency along the day and minimizes nocturnal cooling effect, improving noticeably the performance of the original hose design. as was demonstrated by thermal modeling, this new pulsed-flow design could satisfy the domestic demand of sanitary hot water even in high-latitude locations and furthermore, its performance could be noticeably improved by adding a smart microcontroller. the economic analysis shows this design could be highly competitive applied to large hot-water demands and relatively good for single family demands. (c) 2015 elsevier ltd. all rights reserved.
computer_graphics	artists and animators have observed that children 's movements are quite different from adults performing the same action. previous computer graphics research on human motion has primarily focused on adult motion. there are open questions as to how different child motion actually is, and whether the differences will actually impact animation and interaction. we report the first explicit study of the perception of child motion (ages 5 to 9 years old), compared to analogous adult motion. we used markerless motion capture to collect an exploratory corpus of child and adult motion, and conducted a perceptual study with point light displays to discover whether naive viewers could identify a motion as belonging to a child or an adult. we find that people are generally successful at this task. this work has implications for creating more engaging and realistic avatars for games, online social media, and animated videos and movies.
algorithm_design	the fully polynomial-time approximation scheme (fptas) is a class of approximation algorithms for optimisation problems that is able to deliver an approximate solution within any chosen ratio in polynomial time. by generalising bird and de moor 's thinning theorem to a property between three orderings, we come up with a datatype-generic strategy for constructing fold-based fptass. greedy, thinning, and approximation algorithms can thus be seen as a series of generalisations. components needed in constructing an fptas are often natural extensions of those in the thinning algorithm, design of complex fptass is thus made easier, and some of the resulting algorithms turn out to be simpler than those in previous works. (c) 2014 elsevier b.v. all rights reserved.
operating_systems	silent data corruptions (sdcs) are errors that corrupt the system or falsify results while remaining unnoticed by firmware or operating systems. in numerical integration solvers, sdcs that impact the accuracy of the solver are considered significant. detecting sdcs in high-performance computing is necessary because results need to be trustworthy and the increase of the number and complexity of components in emerging large-scale architectures makes sdcs more likely to occur. until recently, sdc detection methods consisted in replicating the processes of the execution or in using checksums (for example algorithm-based fault tolerance). recently, new detection methods have been proposed relying on mathematical properties of numerical kernels or performing data analysis of the results modified by the application. none of those methods, however, provide a lightweight solution guaranteeing that all significant sdcs are detected. we propose a new method called hot rod as a solution to this problem. it checks and potentially corrects the data produced by numerical integration solvers. our theoretical model shows that all significant sdcs can be detected. we present two detectors and conduct experiments on streamline integration from the wrf meteorology application. compared with the algorithmic detection methods, the accuracy of our first detector is increased by 52% with a similar false detection rate. the second detector has a false detection rate one order of magnitude lower than these detection methods while improving the detection accuracy by 23 %. the computational overhead is lower than 5% in both cases. the model has been developed for an explicit runge-kutta method, although it can be generalized to other solvers.
computer_programming	this paper presents a systematic literature review in the internet of things and ambient intelligence areas. the goal was to identify the best software tools that allow end users, namely people without competencies in computer programming, to manage and configure the behaviors of a smart home. the review selected 48 papers out of 1049 papers found through automatic and manual search. from these papers, 11 tools have been identified and analyzed by means of eight technical characteristics. finally, among the eleven tools, six tools have been chosen for a qualitative comparison on the basis of seven design principles for smart home control proposed in a literature paper.
electric_motor	in recent years a lot of research has been done about electric hybrid vehicles (hv) (including those with internal combustion engine or fuel cell). the main aim of the studies has been the design of an electric system capable of feeding an electric motor, giving the same or similar performance as an internal combustion engine vehicle (icev). this is the first step for substituting the icev for hvs, since the final user will not accept any downgrade. nowadays, cars bring other kind of services that make the vehicle more comfortable. air conditioning is one of them. all the modern vehicles must be prepared to include an air conditioning system (acs), even in the smallest sizes. therefore the acs and its effects over the energy management must be taken into account in the design of a hv. the power consumption of the acs depends directly on the thermal load of the vehicle cabin (latent and sensible), the ambient conditions and the dc/dc converter efficiency between compressor and car power system of the car. the main objective of the research is to analyze the behavior of a fuel cell car under different driving cycles, ambient conditions and passenger load. the fuel consumption data is taken performing the cycles. an increment of hydrogen consumption between 3 and 12.1% was found when the acs is switched on. copyright (c) 2015, hydrogen energy publications, llc. published by elsevier ltd. all rights reserved.
system_identification	parameter estimation plays an important role in modeling and system identification. however, parameter estimation of chaotic systems has some basic differences with other dynamical systems due to butterfly effect. in this paper, we apply a new cost function for parameter estimation in a very interesting chaotic system, a system with a plane of equilibrium which belongs to a newly introduced category of dynamical systems: systems with hidden attractor. the nonlinear dynamics of this system is described in terms of equilibria and its stability, phase portraits, bifurcation diagram and lyapunov exponents. in order to minimize the proposed cost function and obtain the correct parameters, we use a new efficient optimization method, krill herd algorithm. the results show the success of proposed procedures.
system_identification	in conventional hybrid simulation (hs) and real time hybrid simulation (rths) applications, the information exchanged between the experimental substructure and numerical substructure is typically restricted to the interface boundary conditions (force, displacement, acceleration, etc.). with additional demands being placed on rths and recent advances in recursive system identification techniques, an opportunity arises to improve the fidelity by extracting information from the experimental substructure. online model updating algorithms enable the numerical model of components (herein named the target model), that are similar to the physical specimen to be modified accordingly. this manuscript demonstrates the power of integrating a model updating algorithm into rths (rthsmu) and explores the possible challenges of this approach through a practical simulation. two bouc-wen models with varying levels of complexity are used as target models to validate the concept and evaluate the performance of this approach. the constrained unscented kalman filter (cukf) is selected for using in the model updating algorithm. the accuracy of rthsmu is evaluated through an estimation output error indicator, a model updating output error indicator, and a system identification error indicator. the results illustrate that, under applicable constraints, by integrating model updating into rths, the global response accuracy can be improved when the target model is unknown. a discussion on model updating parameter sensitivity to updating accuracy is also presented to provide guidance for potential users. (c) 2016 elsevier ltd. all rights reserved.
analog_signal_processing	in this study, an ultra low-voltage low-power operational transconductance amplifier (ota) is proposed. dynamic threshold voltage mos (dtmos) transistors are utilized in the design for using very low supply voltages efficiently. the proposed ota circuit is employed in a fourth-order band-pass filter topology which is used in eeg data processing with the help of spice and matlab programs. it is found that simulations are in close agreement with the theoretical calculations.
system_identification	recent contributions have framed linear system identification as a nonparametric regularized inverse problem. relying on l(2)-type regularization which accounts for the stability and smoothness of the impulse response to be estimated, these approaches have been shown to be competitive w.r.t. classical parametric methods. in this paper, adopting maximum entropy arguments, we derive a new l(2) penalty; to do so we exploit the structure of the hankel matrix, thus controlling at the same time complexity, measured by the mcmillan degree, stability and smoothness of the identified models. as a special case, we recover the nuclear norm penalty on the squared block hankel matrix. in contrast with the previous literature on reweighted nuclear norm penalties, our kernel is described by a small number of hyper-parameters, which are iteratively updated through marginal likelihood maximization; constraining the structure of the kernel acts as a (hyper)regularizer which helps controlling the effective degrees of freedom of our estimator. to optimize the marginal likelihood, we adapt a scaled gradient projection (sgp) algorithm which is proved to be significantly computationally cheaper than other first and second order off-the-shelf optimization methods. the paper also contains an extensive comparison with many state-of-the-art methods on several monte-carlo studies, which confirms the effectiveness of our procedure. (c) 2017 elsevier ltd. all rights reserved.
system_identification	system identification of structures is one of the important aspects of structural health monitoring. the accuracy and efficiency of identification results is affected severely by measurement noises, especially when the structure system is large, such as bridge structures, and when online system identification is required. in this paper, the least square estimation (lse) method is used combined with the substructure approach for identifying structural parameters of a cable-stay bridge with large degree of freedoms online. numerical analysis is carried out by first dividing the bridge structure into smaller substructures and then estimates the parameters of each substructure online using lse method. simulation results demonstrate that the proposed approach is capable of identifying structural parameters, however, the accuracy and efficiency of identification results depend highly on the noise sensitivities of loading region, loading pattern as well as element size.
digital_control	in this paper, we illustrate a proposed method for control that combines the outputs of several individual controllers to improve global control of complex nonlinear plants. in the first part of this paper, we illustrate the proposed method that consists of two levels, where in the top level a fuzzy system represents a superior control that is designed for adjusting the behavior of the individual fuzzy controllers at the lower level. to test the approach, we consider the problem of flight control because it requires several individual controllers. also a comparison is performed, where the hierarchical control strategy is compared with a simple control approach using the t student test. in this paper, we show that the proposed method outperforms the conventional fuzzy control approach. in the optimal design of the proposed control architecture a genetic algorithm was also applied to tune the parameters of the fuzzy systems in an optimal fashion. (c) 2015 elsevier b.v. all rights reserved.
symbolic_computation	in this paper, we show an algorithmic procedure to compute abelian subalgebras and ideals of a given finite-dimensional leibniz algebra, starting from the non-zero brackets in its law. in order to implement this method, the symbolic computation package maple 12 is used. moreover, we also show a brief computational study considering both the computing time and the memory used in the two main routines of the implementation. finally, we determine the maximal dimension of abelian subalgebras and ideals for 3-dimensional leibniz algebras and 4-dimensional solvable ones over .
computer_vision	aim: alzheimer 's disease patients are increasing rapidly every year. scholars tend to use computer vision methods to develop automatic diagnosis system. (background) in 2015, gorji et al. proposed a novel method using pseudo zernike moment. they tested four classifiers: learning vector quantization neural network, pattern recognition neural network trained by levenberg-marquardt, by resilient backpropagation, and by scaled conjugate gradient. method: this study presents an improved method by introducing a relatively new classifier-linear regression classification. our method selects one axial slice from 3d brain image, and employed pseudo zernike moment with maximum order of 15 to extract 256 features from each image. finally, linear regression classification was harnessed as the classifier. results: the proposed approach obtains an accuracy of 97.51%, a sensitivity of 96.71%, and a specificity of 97.73%. conclusion: our method performs better than gorji 's approach and five other state-of-the-art approaches. therefore, it can be used to detect alzheimer 's disease.
network_security	the frequency transformation methods like fast fourier transform algorithms can be competently used in realization of discrete fourier transforms over galois field, which have broad applications in network security and digital communication in error correcting codes. the cyclotomic fast fourier transform (cfft) is a type of fast fourier transform algorithm over finite fields this method utilizes the benefit of cyclic decomposition. the cyclotomic breakdown of input data is used to reduce the number of operations which can be equally exploited to get a set by set treatment of the input sequence. common subexpression elimination (cse) is an useful optimization process to solve the multiple constant multiplication problems. in this paper, common subexpression elimination algorithm for cyclotomic fast fourier transform over fixed field 23 is designed. using cse algorithm, we reduce the additive complexities of cyclotomic fast fourier transform. the design of cse is to spot regular patterns that are present in expressions more than once and replace them with a single variable. using above method every regular pattern calculates only once, thus minimizing the area of cfft architecture required in vlsi implementation.
system_identification	a set of novel explicit expressions for the identification of stable, unstable and integrating first-order plus dead time process dynamics is presented. in the absence of sensor noise/static load disturbances, an autonomous relay control system with an asymmetrical relay induces a smooth limit cycle at the process output. dynamic model parameters are estimated using the set of proposed expressions which depend on the parameters of limit cycle output and its derivatives. however, in practice, the process output is generally corrupted by the measurement noise, thereby rendering an erroneous identification of process dynamics. furthermore, static load disturbance during an identification test also induces an asymmetrical limit cycle output resulting in inaccurate measurements. hence, a fast fourier transform technique and biased relay feedback methods are implemented to obviate the problem of asymmetries and chattering in the limit cycle output yielding the original limit cycle and its subsequent derivatives. the proposed method has been validated, considering five typical examples from literature. an extensive comparison study with existing approaches based on nyquist plots demonstrate the efficacy of the method presented.
control_engineering	laboratory experimentation plays an essential role in engineering and scientific education. virtual and remote labs reduce the costs associated with conventional hands-on labs due to their required equipment, space, and maintenance staff. furthermore, they provide additional benefits such as supporting distance learning, improving lab accessibility to handicapped people, and increasing safety for dangerous experimentation. this paper analyzes the literature on virtual and remote labs from its beginnings to 2015, identifying the most influential publications, the most researched topics, and how the interest in those topics has evolved along the way. to do so, bibliographical data gathered from isi web of science, scopus and grc2014 have been examined using two prominent bibliometric approaches: science mapping and performance analysis. (c) 2016 elsevier ltd. all rights reserved.
signal-flow_graph	in this paper, the filtering characteristics of the two kinds of complementary ring-resonator add/drop filters are modeled and investigated. a graphical approach with signal flow graph is employed here for the analytical derivation of the optical transfer functions in z-domain of filters. the characteristics of the complementary circuits including the transmittance and group delay of the drop port with respect to the input port are simulated. the present analysis is restricted to directional couplers characterized by two parameters, the power coupling coefficient k and power coupling loss y. explicit expressions for the phase delay, the full-width at half maximum, the q-factor and the finesse are also given. using appropriate coupling coefficients, the filtering characteristics can be optimized. (c) 2006 elsevier b.v. all rights reserved.
symbolic_computation	in this paper, a modified discrete g'/g-expansion method is used to construct exact solutions of toda lattice equation and ablowitz-ladik lattice equations. with the aid of computer symbolic computation, we obtained in a uniform way hyperbolic function solutions, trigonometric function solutions and rational solutions of these two nonlinear lattice equations. when the parameters are taken as special values, some known solutions are recovered. it is shown that the modified method with symbolic computation provides a more effective mathematical tool for solving nonlinear lattice equations in science and enginnering.
electrical_network	in a mixed-valence polyoxometalate, electrons are usually delocalized within the cluster anion because of low level of inter-cluster interaction. herein, we report the structure and electrical properties of a single crystal in which mixed-valence polyoxometalates were electrically wired by cationic -molecules of tetrathiafulvalene substituted with pyridinium. electron-transport characteristics are suggested to represent electron hopping through strong interactions between cluster and cationic pi-molecules.
software_engineering	this paper introduces the potential for reusing ui elements in the context of model-based ui development (mbuid) and provides guidance for future mbuid systems with enhanced reutilization capabilities. our study is based upon the development of six inter-related projects with a specific mbuid environment which supports standard techniques for reuse such as parametrization and sub-specification, inclusion or shared repositories. we analyze our experience and discuss the benefits and limitations of each technique supported by our mbuid environment. the system architecture, the structure and composition of ui elements and the models specification languages have a decisive impact on reusability. in our case, more than 40% of the elements defined in the ul specifications were reused, resulting in a reduction of 55% of the specification size. inclusion, parametrization and sub-specification have facilitated modularity and internal reuse of ui specifications at development time, whereas the reuse of ul elements between applications has greatly benefited from sharing repositories of ui elements at run time. (c) 2015 elsevier ltd. all rights reserved.
operational_amplifier	this paper presents the development of a wireless flow transmitter using rotameter and operational amplifier based signal conditioning circuit. the rotameter is a linear gravity based flow measuring device. it consists of a display unit which directly displays the flow rate. for industrial applications a new circuitry is required to transmit the measured flow rate to the control unit at remote areas. a ferromagnetic wire attached to the float of rotameter acts as a core of an inductance pickup coil constitutes the flow sensor. the self-inductance of the coil changes according to the change in flow rate. an operational amplifier based circuit is used for the measurement of self-inductance. the voltage corresponding to the flow rate is finally converted into 4-20 ma current. a wireless readout is provided using a microcontroller unit and a bluetooth module. the results show a linear relation between the variation of self-inductance of a pickup coil as well as transmitter output with respect to flow rate. the theoretical equations and the simulation results are added in this paper.
control_engineering	metabolic pathways can be engineered to maximize the synthesis of various products of interest. with the advent of computational systems biology, this endeavour is usually carried out through in silico theoretical studies with the aim to guide and complement further in vitro and in vivo experimental efforts. clearly, what counts is the result in vivo, not only in terms of maximal productivity but also robustness against environmental perturbations. engineering an organism towards an increased production flux, however, often compromises that robustness. in this contribution, we review and investigate how various analytical approaches used in metabolic engineering and synthetic biology are related to concepts developed by systems and control engineering. while trade-offs between production optimality and cellular robustness have already been studied diagnostically and statically, the dynamics also matter. integration of the dynamic design aspects of control engineering with the more diagnostic aspects of metabolic, hierarchical control and regulation analysis is leading to the new, conceptual and operational framework required for the design of robust and productive dynamic pathways.
computer_vision	we have proposed an effective machine learning method to analyze multimedia content addressing gesture event detection and recognition. our machine learning method is based on well-studied techniques such that procrustes analysis, combination of local and global representations, linear shape model, and application to smart tv virtual keyboard. in this paper, we address gesture event detection specially fingertip gesture detection to get smart and advanced usage of technology. our modern vision keyboard could be a good next generation replacement of smart tv remote control. it can be more economical as we do n't need physical object like traditional keyboard, remote control and their energy resources like batteries. more information and demonstrations of the proposed keyboard can be accessed at http://video.minelab.tw/mcaoged/.
software_engineering	nowadays environmental protection has become a valuable asset for the entire society. the information based society can provide more efficient solutions in its risks mitigation. there are already in place complex infrastructures used to monitor and control the natural environment, but most of them have lower or no interdependency. a solution to gain this integration level is represented by the ""smart cities"" concept. this study will present an approach used to integrate almost every existing system related to environmental monitoring and control into one common view. this is required in order to quickly integrate the produced data or commands for control instruments in the main big data stream. as a result, the ability to solve environmental specific issues will be further increased due to their superior analytical ability.
analog_signal_processing	analog signal processing based radar systems enable reduction in total system power consumption, over conventional digital signal processing based radar systems. in this paper, detection performance degradation of a previously proposed system, based on analog cross-correlation, due to time synchronization is addressed and analog auto-correlation based radar architecture is proposed. by adopting the digital radio frequency memory technique, accurate and tunable delays for autocorrelation process are realized. the probability of detection performance degradation of the previously proposed system, due to mismatch, is evaluated by simulations while varying signal to noise ratios and mismatches at the matched filter. the proposed system 's probability of detection performance will also be simulated versus varying signal to noise ratios, compared to the results of the previously proposed system and analysis of conditions when the proposed system is more beneficial than the previously proposed system will be made.
bioinformatics	preeclampsia presents serious risk of both maternal and fetal morbidity and mortality. biomarkers for the detection of preeclampsia are critical for risk assessment and targeted intervention. the goal of this study is to screen potential biomarkers for the diagnosis of preeclampsia and to illuminate the pathogenesis of preeclampsia development based on the differential expression network. two groups of subjects, including healthy pregnant women, subjects with preeclampsia, were recruited for this study. the metabolic profiles of all of the subjects' serum were obtained by liquid chromatography quadruple time of -flight mass spectrometry. correlation between metabolites was analyzed by bioinformatics technique. results showed that the pc(14:0/00), proline betaine and proline were potential sensitive and specific biomarkers for preeclampsia diagnosis and prognosis. perturbation of corresponding biological pathways, such as inos signaling, nitric oxide signaling in the cardiovascular system, mitochondrial dysfunction were responsible for the pathogenesis of preeclampsia. this study indicated that the metabolic profiling had a good clinical significance in the diagnosis of preeclampsia as well as in the study of its pathogenesis. (c) 2017 elsevier inc. all rights reserved.
image_processing	computer-assisted orthopedic surgery allows clinicians to have better results and decreases the number of early prosthetic replacements. nevertheless, the patient follow-up from pre-operative diagnosis to post-operative control cannot be assessed in a constant referential. in this paper, a real-time algorithm that extracts bone edges from images and, then, derives bony landmarks from these edges is proposed. indeed, we assess in real-time the bone structure positions via ultrasound imaging to create a useful referential for pre-operative, intra-operative and post-operative measurements. to assist the clinician while acquiring bony anatomical landmarks, the extraction of the bone-soft tissue interface and bony landmarks from ultrasound images is done automatically. the experimentations were performed on a database of images from healthy volunteers, and the obtained results showed the efficiency and the stability of the performance of the proposed method.
electric_motor	the expansion of the electric vehicle (ev) market will bring changes in the type of environmental impact generated by the transport sector. this will be partially associated to the introduction of new technologies for energy storage and powertrains, including electric motors technology, which can play a critical role for the ev. to assure its optimal performance, key components and innovative materials are integrated in current motor designs. such is the case of permanent magnets (pm), commonly made of rare-earth elements, which have a history of ecological concerns related to its mining. the goal of the paper is to study novel traction e-motors and to assess the influence of its components, in the environmental performance of the motor and the electric vehicle. in this study, a life cycle assessment (lca) is performed, including the manufacturing, use, and end of life stages of a traction electric motor for ev applications. a comparison is presented, where the rare-earth magnets are replaced by ferrite magnets, under several efficiency scenarios. average european conditions are considered for framing the modeling. a functional unit of 1 km driven by the vehicle is used. twelve impact categories were selected to present the potential environmental impact of the motors. energy consumption during the use stage was identified as a hotspot responsible for an important share of the impact. the amount of energy consumed is highly dependent on the efficiencies of the powertrain, which is why improving efficiency should be regarded as crucial for decreasing the environmental damage produced by the motor. the use of rare-earth magnets during manufacturing does not represent a significant share of the impact, as they only take 2 % of the total mass. other components, including laminations, housing and windings were instead recognized as more significant than the mangets, mainly for climate change, toxicity of humans, soil and water bodies, as well as metal depletion. the use of alternative materials for rare-earth magnets can contribute in the reduction of the potential impact, as long as the overall efficiency of the motor remains the same or increases. based on the study results, it can be concluded that the environmental performance of traction motor is closely tight to its efficiency. selection of materials during design should focus more on preserving or improving the efficiency of the motor, than on materials with low environmental impact during production.
computer_graphics	with the development of computer graphics technology, machine vision and virtual reality technology in recent years, 3d reconstruction method through the sequence of images of outdoor scenes has become a key research direction in computer vision and graphics. during the acquisition process of image, due to the measurement equipment and environment, single shot sequence of photos may not be able to extract enough surface information and lead to unable to complete the reconstruction of 3d objects. to solve this problem, fusion method of point clouds from multi-group images is adopted in the thesis. firstly the color histogram matching is used to complete the supplement image sequence. next the point cloud from the supplement image sequence is solely calculated. then the transform parameters in overlap area of different point clouds are computed by using the improved iterative closest point algorithm. finally the registration and fusion among the point cloud data of different photos is conducted. the experiments show that this method can effectively supplement point cloud data for reconstruction.
electric_motor	the work includes using a brushless direct current motor ventilator as a machine which fills a container where methane sensor is researched. the main issue is to choose the best controlling method and implement it to self-made driver of the motor.
electric_motor	the world 's first implantable total artificial heart was designed by vladimir demikhov as a fourth year biology student in voronezh, soviet union, in 1937. as a prototype of his device, demikhov must have used an apparatus for extracorporeal blood circulation invented by sergei bryukhonenko of moscow. the device was the size of a dog 's native heart and consisted of two diaphragm pumps brought into motion by an electric motor. a dog with an implanted device lived for 2.5 hours. in addition to having the prototype, the preconditions for demikhov 's artificial heart creation were his manual dexterity, expertise in animal physiology, and his mechanistic worldview.
bioinformatics	signaling pathways driven by protein and lipid kinases are altered in most human diseases. therefore, pharmacological inhibitors of cell signaling are one of the most intensively pursued therapeutic approaches for the treatment of diseases such as cancer, neurodegeneration, and metabolic syndromes. phosphoproteomics is a technique that measures the products of kinase activities and, with the appropriate bioinformatics techniques, the methodology can also provide measures of kinase pathway activation and network circuitry. hence, due to recent technological advantages, lc-ms-based quantitative phosphoproteomics provides relevant information for the design and implementation of kinase inhibitor based therapies. here, we review how phosphoproteome profiling is being used in translational research as a means to identify drug targets and biomarkers for personalizing therapies based on kinase inhibitors.
computer_programming	in this paper, we propose an encryption scheme based on phase-shifting digital interferometry. according to the original system framework, we add a random amplitude mask and replace the fourier transform by the fresnel transform. we develop a mathematical model and give a discrete formula based on the scheme, which makes it easy to implement the scheme in computer programming. the experimental results show that the improved system has a better performance in security than the original encryption method. moreover, it demonstrates a good capability of anti-noise and anti-shear robustness.
signal-flow_graph	this paper proposes a new approach for the systematic synthesis of active inductors via signal-flow graphs (sfgs). the basic idea consists of proposing and using sfg stamps of active basic building blocks (abbs) to construct the equivalent sfg of a classical inductor. we show that a large number of active inductors can be thus synthesized; twelve are proposed, most of them are novel. known abbs, as well as newly proposed ones are used, namely current conveyors (cc), operational transconductance amplifiers (ota), current conveyor transconductance amplifiers (ccii-ta), current feedback operational amplifiers (cfoa), operational transresistance amplifiers (otra), current backward transconductance amplifiers (cbta), current feedback transconductance amplifiers (cfta) and voltage differencing inverting buffered amplifiers (vdiba). spice simulations are given to show the viability of the proposed technique. (c) 2013 elsevier ltd. all rights reserved.
system_identification	the branch of complex system spans over a wide range of areas from physical and technological systems to social and biological systems. as the first step of any complex system analysis, modeling is an important task in scientific studies field. then both the theory and practice of complex system modeling has been considered in recent years. it is well known that system identification is the theory and methods of establishing mathematical models of complex systems. consequently, an identification approach for a class of complex nonlinear system is put forward in this paper. the idea of the identification method employs a system model composed with classical models so as to transform the system structure identification problem into a combinatorial optimization problem initially. then, the artificial fish swarm optimization algorithm is used to synchronously implement the identification on the system 's structure and parameters. finally, in simulation, compared with other algorithm, simulation results show that the proposed scheme is feasible.
image_processing	this exploratory work is concerned with generation of natural language descriptions that can be used for video retrieval applications. it is a step ahead of keyword-based tagging as it captures relations between keywords associated with videos. firstly, we prepare hand annotations consisting of descriptions for video segments crafted from a trec video dataset. analysis of this data presents insights into human 's interests on video contents. secondly, we develop a framework for creating smooth and coherent description of video streams. it builds on conventional image processing techniques that extract high-level features from individual video frames. natural language description is then produced based on high-level features. although feature extraction processes are erroneous at various levels, we explore approaches to putting them together to produce a coherent, smooth and well-phrased description by incorporating spatial and temporal information. evaluation is made by calculating rouge scores between human-annotated and machine-generated descriptions. further, we introduce a task-based evaluation by human subjects which provides qualitative evaluation of generated descriptions.
algorithm_design	gnss-based navigation technology for lunar mission with more than 60,000 km above earth, which is still lack of relevant research and simulation. in this paper, ""chang-e one"" lunar mission is used with three stages of orbiting the earth, earth-moon transfer, and around moon. a detailed analysis of feasibility of autonomous navigation using gps, galileo navigation system alone and combination under sidelobe signals is given. the number of visible satellites gnss receiver to receive, dop value, receiving signal level and dynamic, etc. are analyzed, and autonomous navigation algorithm design under different observation conditions were also considered. as can be seen from the theoretical analysis and simulation results, the use of gnss signals fully meet user needs that realize autonomous navigation around earth, earth-moon transfer, and around moon three-stages, which can be considered as the foundation for future engineering applications.
relational_databases	clustering is an unsupervised learning algorithm. k-means algorithm is one of the well-known and promising clustering algorithms that can converge to a local optimum in few iterative. in our work, we will be hybridizing k-means algorithm with genetic algorithms to look for the solution in the global search space in order to converge to a global optima. the problem for clustering is that when the number of clusters increases up to the same number of total records in the dataset, it leads to a scenario in which a cluster only contains a single record, and thus the cluster purity is maximized to the maximum value, 1. however, it will be useless since the common regularities among records will not be seen. therefore, choosing the best number of clusters is trivial. instead of choosing an inappropriate number of clusters and risking the main purpose of the clustering process, a genetic algorithm based k-means ensemble is proposed in order to find the consensus result of several runs of clustering task using different number of clusters, k.
microcontroller	this paper presents a novel speed tracking control approach based on a model predictive control (mpc) framework for autonomous ground vehicles. a switching algorithm without calibration is proposed to determine the drive or brake control. combined with a simple inverse longitudinal vehicle model and adaptive regulation of mpc, this algorithm can make use of the engine brake torque for various driving conditions and avoid high frequency oscillations automatically. a simplified quadratic program (qp) solving algorithm is used to reduce the computational time, and the approach has been applied in a 16-bit microcontroller. the performance of the proposed approach is evaluated via simulations and vehicle tests, which were carried out in a range of speed-profile tracking tasks. with a well-designed system structure, high-precision speed control is achieved. the system can robustly model uncertainty and external disturbances, and yields a faster response with less overshoot than a pi controller. (c) 2016 elsevier ltd. all rights reserved.
data_structures	this paper presents an analytical study on parsec benchmark suite in order to examine the auto-vectorization potential of emerging workloads by icc and gcc compilers. for investigating auto-vectorization potential, we have analyzed the amount of vectorized and non-vectorized loops and the number of vector instructions of application. we have found most of the time-consuming loops of the applications have not been vectorized. then, we have modified the applications and profiled them again. we have shown applying the modifications have a considerable effect on the amount of vectorized loops but the number of instructions has not reduced to what we expect because of the limited size of simd-width of current processors. as a result, in addition to applying some algorithmic methods such as loop unrolling, splitting large loops, definition of data structures, replacing function calls in loops with function bodies removing control flows from the loops in possible cases and so on to help the compilers for auto-vectorization, increasing the simd-width of the vector extension of cpus is an important issue in order to improve the speed and performance. (c) 2016 elsevier b.v. all rights reserved.
operating_systems	current day networks operate on multiple hardware devices assisted by numerous numbers of operating systems. systems may have vulnerabilities. these are explored and then exploited. among the overall malicious activity countries, india ranked third after us and china. this paper has made an attempt to explore possibility of quantifying various probabilities. cyber system can be modeled in different ways. there are various attack vectors that make cyber network vulnerable. a compromised employee is an insider to any network and contributes significantly to the network vulnerability. keeping in mind various random variables that affect the safety of cyber random space, there may be a need to quantify the probability associated with different cyber exploitation related activities.
state_space_representation	this paper presents research done towards the goal of achieving automatic flight control for commercial airliners in formation flight. the motivation for this research is to ultimately reduce fuel-consumption through a reduction in the drag of the follower aircraft, which is a result of the formation flight. traditional aerodynamic equations for conventional flight of fixed-wing aircraft are expanded to include formation flight interactions. a trim analysis uncovers risks, challenges and feasible trim regions for the formation follower to maintain. these regions include a potentially risky region which is sandwiched between two untrimmable regions, with respect to a maximum aileron setting, and an outside region which has only one untrimmable bound, making it less risky but with lower fuel-consumption benefit. next, a state space representation is constructed, allowing for a linear dynamics analysis. the poles and their movement as a function of the lateral and vertical separation of the follower aircraft relative to the leader aircraft are shown, and indicate greater changes in flight dynamics due to vertical separation than to lateral separation. the results of the trim analysis and linear dynamics analysis form the basis for the design of a formation flight control system.
computer_vision	due to the edge-preserving ability, the bilateral filter is considered as the fundamental tool in computer vision and computer graphics. however, its computational complexity has a close connection with the size of the box window. this drawback leads that the bilateral filter is inappropriate for the computational insensitive application. one way to accelerate the bilateral filter is to approximate the gaussian range kernel by trigonometric functions and synthesise final results from a set of filtering results of fast convolutions. a novel approximation that can be applied to any range kernel is proposed. specifically, first the z transformation of the range kernel is obtained, then approximate the z transformation of the range kernel using the pade approximation. finally, inverse the transformation of the pade approximation and obtain an exponential sum to approximate original range kernel, where the coefficients of the exponential basis are computed by solving a set of linear equations. experiments show the method achieves state-of-the-art results in terms of accuracy and speed.
network_security	with the development and popularization of internet, computer network has been widely used in various trades and fields. computer network has been used frequently in daily office, management, life and service. for example, government departments, institutions, enterprises, etc., the subsequent application of internet technology has encountered some difficulties in practice, it is necessary for network problems in the application to improve, especially in network maintenance and security risks therefore, the research and analysis on the maintenance and security management of the network are of great significance to further guarantee the network operation and work. in this paper, the author first describes the concept of network maintenance and security management, and then analyzes the application of network security management technology and the corresponding multi-level protection content; finally, on this basis, pointed out that the current network maintenance and security management problems, and pointed out the perfect strategy for the new era of network development and maintenance to provide new ideas.
analog_signal_processing	most forging shops started using natural gas fired furnaces to heat the parts to be forged. with the use of induction heating the parts are heated faster, with more control, semi-automatically, more efficiently, with less decarb and much less scale. induction heating is a much better system to heat billets with less wasted energy. it is possible to use the natural gas to generate electricity and use this electricity to power and operate the induction heating systems. the generating system can range from a few kilowatts to many megawatts with a turbine generating system. we will investigate the cost and payback time for this type of system. with the generation of your own electricity the problem of electrical noise on the electrical line from the induction heating would be eliminated for 3(rd),5(th) and 7(th) harmonics electrical noise. the heat from the generating system can be used for other purposes, this is called cogeneration. the heat could be used to generate steam to run the forging hammers or heat the office buildings or used in an absorption type of cooling system. with fuel cell just around the corner, this will further increase the efficiency of the system and could further reduce the cost.
electricity	this paper presents a novel approach to demand side management (dsm), using an ""individualized"" price policy, where each end user receives a separate electricity pricing scheme designed to incentivize demand management in order to optimally manage flexible demands. these pricing schemes have the objective of reducing the peaks in overall system demand in such a way that the average electricity price each individual user receives is non-discriminatory. it is shown in this paper that this approach has a number of advantages and benefits compared to traditional dsm approaches. the ""demand aware price policy"" approach outlined in this paper exploits the knowledge, or demand-awareness, obtained from advanced metering infrastructure. the presented analysis includes a detailed case study of an existing european distribution network where dsm trial data was available from the residential end-users.
pid_controller	this paper uses a particle swarm optimization (pso) algorithm, an adaptive weighted pso (awpso) algorithm, and a genetic algorithm (ga) to determine the optimal proportional-integral-derivative controller 's parameters of a hydraulic position control system. a typical hydraulic servo system has been selected as an application. the mathematical model of this hydraulic servo system which comprises the most relevant dynamics and nonlinear effects is considered. the model simulates the behavior of a rexroth servo valve and includes the nonlinearities of friction forces, valve dynamics, oil compressibility, and load influence. the performance indices, which have been used in the optimization process, are integral absolute error, integral square error and integral time absolute error. the proposed controller is implemented on the simulation model to identify the best method for tuning the controller. compared with ga and awpso results, the pso method has been found to be more efficient and robust in improving the step response of a position control for hydraulic systems in terms of settling time, maximum overshoot and undershoot.
operational_amplifier	temperature is one of the basic biophysical quantity monitored for various biomedical systems. moreover, the variation of temperature is also an important parameter which can be used for estimating other measurands, such as respiratory airflow. this paper proposes a simple operational amplifier-based astable multivibrator circuit for linearization of the characteristic of a negative temperature coefficient thermistor constituting one of the timing resistors. the circuit has been combined with a lookup table to get the unknown temperature value from multivibrator output. moreover, the same system topology can be used as a linearizer for measurement of respiratory airflow. the performance of the composite system has been verified experimentally. a linearity of approximately +/- 0.75% has been achieved over 30 degrees c-110 degrees c in the case of temperature measurement and +/- 1.2% for airflow of 10-60 lpm. better results can also be achieved with the introduction of interpolation algorithms, but at a higher computational and component cost. the compactness of the complete system makes it a good candidate for embedded sensing applications in biomedical systems, such as point-of-care monitoring or in sleep study.
computer_programming	computer programming remains a difficult discipline to teach. e-learning can help improve student engagement and outcomes but offerings designed to teach programming in a university context are rudimentary when compared to publicly available sites such as code academy. this paper describes nooblab, an e-learning platform for teaching programming. the environment provides a complete suite of features surpassing prior work, and has successfully been used in a number of undergraduate modules to improve student outcomes, satisfaction, and inform pedagogy.
data_structures	this paper presents a novel automated procedure for discovering expressive shape specifications for sophisticated functional data structures. our approach extracts potential shape predicates based on the definition of constructors of arbitrary user-defined inductive data types, and combines these predicates within an expressive first-order specification language using a lightweight data-driven learning procedure. notably, this technique requires no programmer annotations, and is equipped with a type-based decision procedure to verify the correctness of discovered specifications. experimental results indicate that our implementation is both efficient and effective, capable of automatically synthesizing sophisticated shape specifications over a range of complex data types, going well beyond the scope of existing solutions.
analog_signal_processing	this paper presents a new four inputs and one output voltage-mode universal filter using single-ended operational transconductance amplifiers (otas) and grounded capacitors. by appropriately connecting the input terminals, the proposed circuit can provide low-pass, band-pass, high-pass, band-stop and all-pass voltage responses. the filter also offers an orthogonal control of the natural frequency and the quality factor by adjusting the biasing currents of otas. the performances of the proposed filter are simulated with pspice to confirm the presented theory.
system_identification	a fuzzy algorithm, the takagi-sugeno model, is implemented to develop a fuzzy inference system for predicting the holding capacity of suction caisson foundations for offshore platforms. the premise parameters of the fuzzy model are optimized by using a subtractive clustering algorithm. the consequent parameters are optimally determined via a weighted least square estimation. the input variables used for training the fuzzy model include the aspect ratio of the caisson, the undrained shear strength of the clay, and the angle that the chain force forms with the horizontal. the output of the proposed fuzzy model is the capacity of the suction caisson anchor. to demonstrate the effectiveness of the fuzzy modeling framework, the results of extensive finite element analyses are investigated. comparisons of the trained fuzzy model with the data demonstrate that the proposed modeling framework is an effective method to estimate the holding capacity of offshore suction caisson systems. moreover, the performance of the fuzzy model is robust against higher levels of input data uncertainties. copyright (c) 2017 john wiley & sons, ltd.
electricity	demand response (dr) is a recent effort to improve the efficiency of the electricity market and the stability of the power system. a successful implementation relies on both appropriate policy design and enabling technology. this paper presents a multiagent system to evaluate optimal residential dr implementation in a distribution network, in which the main stakeholders are modeled by heterogeneous home agents (has) and a retailer agent (ra). the ha is able to predict and control electricity load demand. a real-time price prediction model is developed for the ha and the ra. the optimal control of electricity consumption is formulated into a convex programming problem to minimize electricity payment and waiting time under real-time pricing. simulation results show that the peak-to-average power ratio and electricity payments are significantly reduced using the proposed algorithms. the ha, with the proposed optimal control algorithms, can be embedded into a home energy management system to make intelligent decisions on behalf of homeowners responding to dr policies. the proposed agent system can be utilized to evaluate various strategies and emerging technologies that enable the implementation of dr.
analog_signal_processing	this paper describes a dual-stroke acting hydraulic power take-off (pto) system employed in the wave energy converter (wec) with an inverse pendulum. the hydraulic pto converts slow irregular reciprocating wave motions to relatively smooth, fast rotation of an electrical generator. the design of the hydraulic pto system and its control are critical to maximize the generated power. a time domain simulation study and the laboratory experiment of the full-scale beach test are presented. the results of the simulation and laboratory experiments including their comparison at full-scale are also presented, which have validated the rationality of the design and the reliability of some key components of the prototype of the wec with an inverse pendulum with the dual-stroke acting hydraulic pto system.
image_processing	introduction: huntington 's disease (hd) is a genetic neurodegenerative disorder that primarily affects striatal neurons. striatal volume loss is present years before clinical diagnosis; however, white matter degradation may also occur prior to diagnosis. diffusion-weighted imaging (dwi) can measure microstructural changes associated with degeneration that precede macrostructural changes. dwi derived measures enhance understanding of degeneration in prodromal hd (pre-hd). methods: as part of the predict-hd study, n=191 pre-hd individuals and 70 healthy controls underwent two or more (baseline and 1-5 year follow-up) dwi, with n=649 total sessions. images were processed using cutting-edge dwi analysis methods for large multicenter studies. diffusion tensor imaging (dti) metrics were computed in selected tracts connecting the primary motor, primary somato-sensory, and premotor areas of the cortex with the subcortical caudate and putamen. pre-hd participants were divided into three cag-age product (cap) score groups reflecting clinical diagnosis probability (low, medium, or high probabilities). baseline and longitudinal group differences were examined using linear mixed models. results: cross-sectional and longitudinal differences in dti measures were present in all three cap groups compared with controls. the high cap group was most affected. conclusions: this is the largest longitudinal dwi study of pre-hd to date. findings showed dti differences, consistent with white matter degeneration, were present up to a decade before predicted hd diagnosis. our findings indicate a unique role for disrupted connectivity between the premotor area and the putamen, which may be closely tied to the onset of motor symptoms in hd. (c) 2017 wiley periodicals, inc.
parallel_computing	image enhancement and edge-preserving denoising are relevant steps before classification or other postprocessing techniques for remote sensing images. however, multisensor array systems are able to simultaneously capture several low-resolution images from the same area on different wavelengths, forming a high spatial/spectral resolution image and raising a series of new challenges. in this paper, an open computing language based parallel implementation approach is presented for near real-time enhancement based on bayesian maximum entropy (bme), as well as an edge-preserving denoising algorithm for remote sensing imagery, which uses the local linear stein 's unbiased risk estimate (llsure). bme was selected for its results on synthetic aperture radar image enhancement, whereas llsure has shown better noise removal properties than other commonly used methods. within this context, image processing methods are algorithmically adapted via parallel computing techniques and efficiently implemented using cpus and commodity graphics processing units (gpus). experimental results demonstrate the reduction of computational load of real-world image processing for near real-time gpu adapted implementation.
relational_databases	the main aspect of database protection is to prove the ownership of data that describes who is the originator of data. it is of particular importance in the case of electronic data, as data sets are often modified and copied without proper citation or acknowledgement of originating data set. we present a novel method for watermarking relational databases for identification and proof of ownership based on the secure embedding of blind and multi-bit watermarks using bacterial foraging algorithm (bfa). feasibility of bfa implementation is shown in the framed watermarking databases application. identification of owner is cryptographically made secure and used as an embedded watermark. an improved hash partitioning approach is used that is independent of primary key of the database to secure ordering of the tuples. strength of bfa is explored to make the technique robust, secure and imperceptible. bfa is implemented to give nearly global optimal values bounded by data usability constraints and thus makes database fragile to any attack. the parameters of bfa are tuned to reduce the execution time. bfa is experimentally proved to be better solution than genetic algorithm (ga). the technique proposed is experimentally proved to be resilient against malicious attacks.
state_space_representation	this paper presents modeling, design and analysis of a bidirectional half-bridge dc/dc converter suitable for power electronic interface between the main energy storage system and the electric traction drive in hybrid electric vehicles. a hybrid energy storage system composed of a battery unit and an ultracapacitor pack is considered. a parallel dc-linked multi-input converter with a half-bridge bidirectional dc/dc cell topology is chosen to link the battery/ultracapacitor storage unit with the dc-link. the paper focuses on modeling the proposed converter for both dynamic and steady state analysis. averaging and linearization techniques are applied to obtain the averaged state space models and small signal models of the converter in both boost and buck operation modes. a criterion for sizing the converter passive components based on the imposed design specifications and constraints is illustrated. simulation results of the buck-boost converter during normal functioning and under faulty conditions are presented. in particular, short-circuit faults and open-circuit faults of diodes and transistors are analyzed.
network_security	an attack graph depicts multiple-step attack and provides a description of system security vulnerabilities. it illustrates critical information necessary to identify potential weaknesses and areas for enhanced defense. attack graphs include multiple attack paths, which are a focus for further detailed analysis and risk mitigation. considering that different vulnerabilities have different probabilities of being exploited, this paper proposes an algorithm to dynamically generate the top k attack paths with maximum probabilities for every node of a system. the proposed algorithm does not require generation of the full attack graph to calculate the k attack paths. instead, it directly processes and analyzes the system input data and dynamically identifies the k attack paths. the computational time, based upon the complexity of the attack paths, can be constrained by the parameter k. experimental results show that the algorithm is scalable and efficient.
computer_vision	we consider the problem of automatically re-identifying a person of interest seen in a ""probe"" camera view among several candidate people in a ""gallery"" camera view. this problem, called person re-identification, is of fundamental importance in several video analytics applications. while extracting knowledge from high dimensional visual representations based on the notions of sparsity and regularization has been successful for several computer vision problems, such techniques have not been fully exploited in the context of the re-identification problem. here, we develop a principled algorithm for the re-identification problem in the general framework of learning sparse visual representations. given a set of feature vectors for a person in one camera view (corresponding to multiple images as they are tracked), we show that a feature vector representing the same person in another view approximately lies in the linear span of this feature set. furthermore, under certain conditions, the associated coefficient vector can be characterized as being block sparse. this key insight allows us to design an algorithm based on block sparse recovery that achieves stateof-the-art results in multi-shot person re-identification. we also revisit an older feature transformation technique, fisher discriminant analysis, and show that, when combined with our proposed formulation, it outperforms many sophisticated methods. additionally, we show that the proposed algorithm is flexible and can be used in conjunction with existing metric learning algorithms, resulting in improved ranking performance. we perform extensive experiments on several publicly available datasets to evaluate the proposed algorithm. (c) 2016 elsevier b.v. all rights reserved.
pid_controller	this paper presents a new pole-zero-assignment-based design method of a two-degree-of-freedom pid controller which is applicable to both positioning and tracking drives of linear servo motors. this method can uniquely determine the five pid control parameters by only giving five items; namely, mover mass, maximum load mass, thrust constant, cutoff frequency of position control system, crossover frequency of sensitivity and complementary sensitivity functions, and pole-angle in the s-plane. simulation and experimental results validate the proposed method.
digital_control	phase-shift modulation (psm) is a commonly used technique for controlling the active power flow in resonant dc-ac and dc-dc converters. although traditionally developed as an analog modulation scheme, psm is being increasingly implemented digitally in conjunction with advanced multivariable digital controllers and online efficiency optimization algorithms. while analog psm is known not to introduce additional dynamics from a small-signal standpoint, the analysis disclosed in this study indicates that discrete-time, or uniformly sampled, psm introduces a transport delay of small-signal nature. furthermore, and in close analogy with the theory of uniformly sampled pulse width modulators, such delay depends on the modulator carrier type as well as on the converter operating point. this paper first clarifies the modeling procedure for describing the small-signal dynamics of uniformly sampled phase-shift modulators. second, it provides an extension of the traditional phasor modeling to digital phase-controlled converters, allowing to account for the additional modulator dynamics in the design of the closed-loop compensation. theoretical findings are validated via simulation and experimental results.
computer_vision	in order to reduce the security risk of commercial aircraft, passengers are not allowed to take certain items in their carry-on baggage. for this reason, human operators are trained to detect prohibited items using a manually-controlled baggage screening process. in this paper, the use of an automated method based on multiple x-ray views is proposed to recognise certain regular objects with highly-defined shapes and sizes. the method consists of two steps: 'monocular analysis', to obtain possible detections in each view of a sequence, and 'multiple view analysis', to recognise the objects of interest using matching in all views. the search for matching candidates is efficiently performed using a look-up table that is computed offline. in order to illustrate the effectiveness of the proposed method, experimental results on recognising regular objects (clips, springs and razor blades) in pencil cases are shown achieving high precision and recall (p-r = 95.7%, r-e = 92.5%) for 120 objects. we believe that it would be possible to design an automated aid in a target detection task using the proposed algorithm.
computer_graphics	limmersive displays for virtual reality systems can be roughly classified into spatially immersive displays (similar to cave-like displays or large-screen simulators) or head-mounted displays. the former type is usually static in spatial configuration and configured to support a small group of users. the latter supports only a single user. we propose a new class of actuated, reconfigurable display that can support both small groups and individual users: in particular we suggest a robotic display that can change shape. the display can change shape to support different usage conditions, and can also move rapidly to give a larger apparent field of view for an individual user. we explore the potential advantages of a display that can move independently from its user(s), and we present a prototype that demonstrates some of the potential use scenarios.
digital_control	with the advances of stem cell research, development of intelligent biomaterials and three-dimensional biofabrication strategies, highly mimicked tissue or organs can be engineered. among all the biofabrication approaches, bioprinting based on inkjet printing technology has the promises to deliver and create biomimicked tissue with high throughput, digital control, and the capacity of single cell manipulation. therefore, this enabling technology has great potential in regenerative medicine and translational applications. the most current advances in organ and tissue bioprinting based on the thermal inkjet printing technology are described in this review, including vasculature, muscle, cartilage, and bone. in addition, the benign side effect of bioprinting to the printed mammalian cells can be utilized for gene or drug delivery, which can be achieved conveniently during precise cell placement for tissue construction. with layer-by-layer assembly, three-dimensional tissues with complex structures can be printed using converted medical images. therefore, bioprinting based on thermal inkjet is so far the most optimal solution to engineer vascular system to the thick and complex tissues. collectively, bioprinting has great potential and broad applications in tissue engineering and regenerative medicine. the future advances of bioprinting include the integration of different printing mechanisms to engineer biphasic or triphasic tissues with optimized scaffolds and further understanding of stem cell biology.
electrical_network	a promising development in the design of datacenters is the hybrid network architecture consisting of both optical and electrical elements, in which end-to-end traffic can be routed through either an electrical path or an optical path. the core optical switch is used to dynamically create optical paths between pairs of electrical edge-switches in such a datacenter network. in this context, the joint problem of bandwidth allocation and vm-placement poses new and different challenges not addressed yet in hybrid datacenter. in particular, we foresee two issues: (i) the number of edge-switches that can be simultaneously reached using optical paths from an edge-switch is limited by the size of the optical switch, (ii) the dynamic creation of optical paths can potentially establish a constrained optical network topology leading to poor performance. in this work, we abstract the requests of tenants as virtual networks, and study the problem of embedding virtual networks on a hybrid datacenter. we formulate the problem as a non-linear optimization problem and analyze its complexity. we develop and analyse three algorithms for embedding dynamically arriving virtual network demands on a hybrid optical-electrical datacenter. through simulations, we demonstrate the effectiveness of not only exploiting the already established optical paths, but also of using electrical network in embedding requests of virtual networks. (c) 2015 elsevier b.v. all rights reserved.
operational_amplifier	this paper presents a new family of class-ab operational transconductance amplifier (ota) circuits based on single-stage topologies with non-linear current amplifiers. the proposed variable-mirror amplifier (vma) architecture is mainly characterized by generating all class-ab current in the output transistors only, by exhibiting very low sensitivity to both technology and temperature deviations, and by avoiding the need for any internal frequency-compensation mechanism. hence, this family of otas is well-suited for low-power switched-capacitor circuits and specifically optimized for switched-opamp fast on-off operation and multi-decade load-capacitance specifications. analytical expressions valid in all regions of operation are presented to minimize vma settling time in discrete-time circuits. also, a complete ota design example integrated in 0.18 mu m 1p6m mim 1.8 v cmos technology is supplied with detailed simulation and experimental results. compared to resistor-free state-of-art class-ab opamp and ota literature, the proposed architecture returns the highest measured figure-of-merit value.
software_engineering	much of software engineering research needs to provide an implementation as proof of -concept. often such implementations are created as exploratory prototypes without polished user interfaces, making it difficult to (1) run user studies to validate the tool 's contribution, (2) validate the author 's claim by fellow scientists, and (3) demonstrate the utility and value of the research contribution to any interested parties. however, turning an exploratory prototype into a ""proper"" tool for end-users often entails great effort. heavyweight mainstream frameworks such as eclipse do not address this issue; their steep learning curves constitute substantial entry barriers to such ecosystems. in this paper, we present the model analyzer/checker (mach), a stand-alone tool with a command-line interpreter. mach integrates a set of research prototypes for analyzing uml models. by choosing a simple command line interpreter rather than (costly) graphical user interface, we achieved the core goal of quickly deploying research results to a broader audience while keeping the required effort to an absolute minimum. we analyze mach as a case study of how requirements and constraints in an academic environment influence design decisions in software tool development. we argue that our approach while perhaps unconventional, serves its purpose with a remarkable cost-benefit ratio. (c) 2015 elsevier b.v. all rights reserved.
analog_signal_processing	a preamplifier based on the source-follower direct injection (sfdi) topology for use in read-out integrated circuits (roic) of quantum-well infrared photodetectors focal plane arrays (qwip-fpa) is demonstrated. the fabricated circuit shows high linearity, high integration time (from hundreds of mu s to few ms) and low current detection capabilities for a wide range of input current (order of few pa). this performance was achieved through the use of a poly1-poly2 capacitor that, although presenting some penalties in area consumption, provides a higher linearity, lower leakage current and higher temperature stability than all others capacitors found in literature. secondary effects such as charge injection and clock feed-through are observed in the experimental results and classical techniques, like the use of dummy transistor, are shown to be effective in minimizing these effects and maximizing the linearity of the response. the overall results indicate that this circuit architecture has a great potential to be practically integrated in larger qwip-fpa roics, showing an improved performance relating to previous works in literature.
electric_motor	this paper proposes a new operation and control strategy for power-assisted wheelchairs (paw) using one brushless dc (bldc) motor. the conventional electrical wheelchairs are too heavy and large for one person to move because they have two electric motor wheels. on the other hand, the proposed paw system has a small volume and is easy to move due to the presence of a single wheel motor. unlike the conventional electric wheelchairs, this structure for a paw does not have a control joystick to reduce its weight and volume. to control the wheelchair without a joystick, a special control system and algorithm are needed for proper operation of the wheelchair. in the proposed paw system uses only one sensor to detect the acceleration and direction of paw 's movement. by using this sensor, speed control can be achieved. with a speed control system, there are three kinds of operations that can be done on the speed of a paw: the increment of paw speed by summing external force, the decrement of paw speed by subtracting external force, and emergency breaking by evaluating the time duration of external force. the validity of the proposed algorithm is verified through experimental results.
state_space_representation	this paper develops a novel approach for estimating latent state variables of dynamic stochastic general equilibrium (dsge) models that are solved using a second-order accurate approximation. i apply the kalman filter to a state-space representation of the second-order solution based on the 'pruning' scheme of kim et al. (j econ dyn control 32:3397-3414, 2008). by contrast to particle filters, no stochastic simulations are needed for the deterministic filter here; the present method is thus much faster; in terms of estimation accuracy for latent states it is competitive with the standard particle filter. use of the pruning scheme distinguishes the filter here from the deterministic quadratic kalman filter presented by ivashchenko (comput econ, 43:71-82, 2014). the filter here performs well even in models with big shocks and high curvature.
relational_databases	a comprehensive ontology can ease the discovery, maintenance and popularization of knowledge in many domains. as a means to enhance existing ontologies, attribute extraction has attracted tremendous research attentions. however, most existing attribute extraction techniques focus on exploring a single type of sources, such as structured (e.g., relational databases), semi-structured (e.g., extensible markup language (xml)) or unstructured sources (e.g., web texts, images), which leads to the poor coverage of knowledge bases (kbs). this paper presents a framework for ontology augmentation by extracting attributes from four types of sources, namely existing knowledge bases (kbs), query stream, web texts, and document object model (dom) trees. in particular, we use query stream and two major kbs, dbpedia and freebase, to seed the attribute extraction from web texts and dom trees. we specially focus on exploring the extraction technique from dom trees, which is rarely studied in previous works. algorithms and a series of filters are developed. experiments show the capability of our approach in augmenting existing kb ontology.
analog_signal_processing	this paper presents a smart sensory platform based on field programmable analog array (fpaa) to support a wide variety of mems sensors applications. a discrete-time (dt) and continuous-time (ct) dual-mode fpaa is proposed to improve the analog signal conditioning flexibility. a gain-programmable low-noise multi-mode sensor readout circuit (roc) is designed for versatile sensor weak signal acquisition, which can sense capacitive, voltage or current signal. a microcontroller (mcu) and a 12-bit sar adc are used for digital signal processing and analog-digital conversion. the platform is implemented in 0.18 mu m m cmos process. the multi-mode sensor readout circuit achieves an input referred noise of 140nv/hz, 200pa/hz and 5af/hz for voltage, current and capacitive signal readout mode, respectively. analog signal processing functions, such as ct pga, dt filter, ct adder and comparator, are realized through the configuration of the dual-mode fpaa. the sar adc shows 10.2bit effective number of bits with 450 mu a power consumption at 1msps sampling rate.
system_identification	there has been little full-scale physical experimentation to support the findings of numerous computational studies regarding the contribution of various substructure components to overall bridge-foundation system behavior. in response to this lack of experimental data, a field testing program was undertaken to investigate the in situ dynamic characteristics of a 27-m-long, three-span, precast-concrete bridge. forced vibration testing and system identification were used to characterize the dominant modal behavior of the bridge-foundation system in each loading direction, leading to identification of the likely force-transfer mechanisms between the structure and the substructure components. it was determined that both the transverse and longitudinal responses of the bridge were dominated by the abutment stiffness, with the passive resistance of the buried settlement slab contributing significantly to the transverse response and the backfill passive resistance dominating the longitudinal response.
operating_systems	optimization can be defined as the operation of finding the best solution for a problem. this operation is performed by changing the initial parameters using existing data. there are various optimization algorithms to solve these kinds of problems; however, it cannot be expected that all optimization algorithms offer a proper and effective solution to all optimization problems. therefore, it is necessary to select the proper algorithm by using similar benchmark functions to the problem, and to determine the best parameter values for the selected algorithm. in this study, a test tool that can run on the devices using the windows, os x, android, and ios operating systems was developed for eight different optimization algorithms: genetic, artificial immune, differential evolution, particle swarm optimization, simulated annealing, tabu search, artificial bee colony, and ant colony optimization algorithms. six hump camel back, rastrigin, shubert, schwefel, and drop wave were the preferred benchmark functions. special user defined special functions were also permitted. the developed test tool was tested for all the optimization algorithms in different platforms. in spite of the small differences in the running times, the results show that the tool can easily be used in windows, os x, android, and ios devices. (c) 2016 wiley periodicals, inc.
software_engineering	agility is a concept and practice with significant importance in managing projects and organizations, although it can also be very risky due to its degree of fuzziness if not properly defined. this research re-defines agility, emphasizes the need for ontologies for its management, and creates an application to measure the degree of agility inside an organization. in this research, various definitions of agility were gathered for the creation of ontology through a mind map revealing the characteristics of agility. as part of the co-evolute theory and methodology, the first agility ontology was developed as well as an application that evaluates the degree of agility in an organization. the application includes statements on which the respondents give opinions concerning the current and future desired states of agility and its importance in an evaluative way. the application has proven to operate well and extensive validation and verification of the tests runs will follow.
computer_vision	gaussian noise is an important problem in computer vision. the novel methods that become popular in recent years for gaussian noise reduction are bayesian techniques in wavelet domain. in wavelet domain, the bayesian techniques require a prior distribution of wavelet coefficients. in general case, the wavelet coefficients might be better modeled by non-gaussian density such as laplacian, two-sided gamma, and pearson type vii densities. however, statistical analysis of textural image is gaussian model. so, we require flexible model between non-gaussian and gaussian models. indeed, gumbel density is a suitable model. so, we present new bayesian estimator for gumbel random vectors in awgn (additive white gaussian noise). the proposed method is applied to dual-tree complex wavelet transform (dt-cwt) as well as orthogonal discrete wavelet transform (dwt). the simulation results show that our proposed methods outperform the state-of-the-art methods qualitatively and quantitatively.
network_security	cloud computing is an internet based computing where virtual shared servers provide software, infrastructure, platform and other resources to the customer on pay-as-you-use basis. cloud computing is increasingly becoming popular as many enterprise applications and data are moving into cloud platforms. however, with the enormous use of cloud, the probability of occurring intrusion also increases. there is a major need of bringing security, transparency and reliability in cloud model for client satisfaction. one of the security issues is how to reduce the impact of any type of intrusion in this environment. to address this issue, a security solution is proposed in this paper. we provide a collaborative framework between our hybrid intrusion detection system (hy-ids) based on mobile agents and virtual firewalls. therefore, our hybrid intrusion detection system consists of three types of ids namely ids-c, ids-cr and ids-m, which are dispatched over three layer of cloud computing. in the first layer, we use ids-c over our framework to collect, analyze and detect malicious data using mobile agents. in case of attack, we collect at the level of the second layer all the malicious data detected in the first layer for the generation of new signatures using ids-cr, which is based on a signature generation algorithm (sga) and network intrusion detection system (nids). finally, through an ids-m placed in the third layer, the new signatures will be used to update the database nids belonging to ids-cr, then the database to nids belonging of ids-cr the cluster neighboring and also their ids-c. hardware firewall is unable to control communication between virtual machines on the same hypervisor. moreover, they are blind to virtual traffic. mostly, they are deployed at virtual machine monitor-level (vmm) under cloud provider 's control. equally, the mobile agents play an important role in this collaboration. they are used in our framework for investigation of hosts, transfer data malicious and transfer update of a database of neighboring ids in the cloud. with this technique, the neighboring ids will use these new signatures to protect their area of control against the same type of attack. by this type of close-loop control, the collaborative network security management framework can identify and address new distributed attacks more quickly and effectively.
electrical_network	the resistance distance between any two vertices of a connected graph is defined as the effective resistance between them in the electrical network constructed from the graph by replacing each edge with a unit resistor. the kirchhoff index of a graph is defined as the sum of all the resistance distances between any pair of vertices of the graph. let g = h[g(1), g(2),., g(k)] be the generalised join graph of g(1), g(2), ..., g(k) determined by h. in this paper, we first give formulae for resistance distances and kirchhoff index of g in terms of parameters of g(i) 's and h. then, we show that computing resistance distances and kirchhoff index of g can be decomposed into simpler ones. finally, we obtain explicit formulae for resistance distances and kirchhoff index of g when g(i) 's and h take some special graphs, such as the complete graph, the path, and the cycle.
computer_graphics	this demonstration illustrates the possibilities of new 3d technologies in conveying large scale historical photographic databases in interactive 3d virtual environments. we illustrate the visualization of the state library of western australia (slwa) 's photographic collection containing over 1 million photographs dating back to the 1850s utilizing curtin 's hub for immersive visualization and eresearch (hive). our application was intended to explore the possibilities in visualizing cultural data sets on the hive 's cylinder, a 3 m high, eight-meter diameter, and 180 degrees cylindrical projection surface. our demonstration illustrated the potentials of virtual environments in creating interactive information designs for photographic imagery, which can be explored according location, time-period, creator, and subject.
analog_signal_processing	floating oscillating-bodies constitute an important class of offshore wave energy converters. the testing of their power take-off equipment (pto) (high-pressure hydraulics, linear electrical generator or other) under realistically simulated sea conditions is usually regarded as a major task. a laboratory rig, consisting of a u-tube enclosing an oscillating column of water driven by a time-varying air-pressure, was devised to simulate the hydrodynamics of an oscillating buoy absorbing energy from sea waves, especially the inertia and the resonant frequency of the oscillating body. the pto force is applied (by means of a piston) on one of the ends of the u-tube oscillating water column, whereas the other end is subject to a controlled time-varying air pressure. this is found to provide a reasonably realistic way of testing the pto system (including its control) at an adequate scale (say about 1:5 to 1:4), which would avoid the use of a much more expensive experimental facility (very large wave tank) or testing in real wind-generated sea-waves. the matching conditions that the u-tube geometry and the driving time-varying air pressure must meet to ensure an adequate simulation are derived. these conditions leave some freedom to the u-tube rig designer and operator, allowing practical and engineering issues to be taken into account. (c) 2010 elsevier ltd. all rights reserved.
pid_controller	the aim of this paper is to propose a low cost, automated furnace control system for the heat treatment of steel. we used an open source electronic prototyping platform to control the furnace temperature, thus reducing human interaction during the heat process. the platform can be adapted to non-controlled commercial furnaces, which are often used by small businesses. a proportional-integral-derivative (pid) controller was implemented to regulate the furnace temperature based on a defined heat treatment cycle. the embedded system activates the furnace resistors through pulse width modulation (pwm), allowing for control of electrical power supplied to the furnace. hardening and tempering were performed on standard steel samples using a traditional method (visual inspection without temperature control) as well the embedded system with pid feedback control. the results show that the proposed system can reproduce an arbitrary heat treatment curve with accuracy and provide the desired final hardness as inferred through metallographic analysis. in addition, we observed a 6% saving in energy consumption using the proposed control system. furthermore, the estimated cost to implement the system is 42% lower than a commercial controller model implemented in commercial furnaces. (c) 2016 elsevier ltd. all rights reserved.
distributed_computing	this paper describes a multi-institution effort to develop a ""data science as a service"" platform. this platform integrates advanced federated data management for small to large datasets, access to high performance computing, distributed computing and advanced networking. the goal is to develop a platform that is flexible and extensible while still supporting domain research and avoiding the walled garden problem. some preliminary lessons learned and next steps will also be outlined.
structured_storage	current computer programs for intracellular recordings often lack advanced data management, are usually incompatible with other applications and are also difficult to adapt to new experiments. we have addressed these shortcomings in e-phys, a suite of electrophysiology applications for intracellular recordings. the programs in e-phys use component object model (com) technologies available in the microsoft windows operating system to provide enhanced data storage, increased interoperability between e-phys and other com-aware applications, and easy customization of data acquisition and analysis thanks to a script-based integrated programming environment. data files are extensible, hierarchically organized and integrated in the windows shell by using the structured storage technology. data transfers to and from other programs are facilitated by implementing the activex automation standard and distributed com (dcom). activex scripting allows experimenters to write their own event-driven acquisition and analysis programs in the vbscript language from within e-phys. scripts can reuse components available from other programs on other machines to create distributed meta-applications. this paper describes the main features of e-phys and how this package was used to determine the effect of the atypical antipsychotic drug clozapine on synaptic transmission at the neuromuscular junction. (c) 2003 elsevier b.v. all rights reserved.
electric_motor	this paper presents an economical launching and accelerating mode, including four ordered phases: pure electrical driving, clutch engagement and engine start-up, engine active charging, and engine driving, which can be fit for the alternating conditions and improve the fuel economy of hybrid electric bus (heb) during typical city-bus driving scenarios. by utilizing the fast response feature of electric motor (em), an adaptive controller for em is designed to realize the power demand during the pure electrical driving mode, the engine starting mode and the engine active charging mode. concurrently, the smoothness issue induced by the sequential mode transitions is solved with a coordinated control logic for engine, em and clutch. simulation and experimental results show that the proposed launching and accelerating mode and its control methods are effective in improving the fuel economy and ensure the drivability during the fast transition between the operation modes of heb. (c) 2016 elsevier ltd. all rights reserved.
signal-flow_graph	a fast three-dimensional discrete cosine transform algorithm (3d fct) and a fast 3d inverse cosine transform (3d ifct) algorithm are presented, suitable for analysis of 3d data points. many existing algorithms for three-dimensional data points make use of either the 1d cosine transform or both the 2d and 1d cosine transforms. existing algorithms based on the 1d discrete cosine transform (dct) apply the separable 1d transform to the data points in the x, y, and z directions, respectively, while those based on 2d and 1d transforms apply the 2d cosine transform for the x-y planes and then the 1d cosine transform in the z direction. the proposed 3d dct algorithms handle the 3d data points directly and have been shown to be computationally efficient. they involve a 3d decomposition process where a data volume is recursively decomposed in each dimension until unit data cubes are obtained. the algorithms are presented in the form of a signal flow graph which captures the various computations involved. a complexity analysis along with empirical results is included, demonstrating the performance of the proposed direct 3d dct algorithms. as 3d fct and ifct are symmetric and relatively fast, they can be used in any application requiring a real-time symmetric codec, such as video conferencing, online multiparty video games, and three-dimensional graphics rendering.
analog_signal_processing	experimental investigations were carried out in order to identify the portable device requirements for in-vitro muscle tissue monitoring over time. based on these investigations, specifications for the measurement system were defined considering the type and amplitude of excitation signals (500 mv), frequency range (1 khz 10 mhz) and impedance range (10 omega-4 k omega). for these requirements, a portable device structure is proposed based on the magnitude ratio and phase difference detection using a gain phase detector. to fulfill the requirements of the gain phase detector circuit 's inputs, an interface circuit is proposed with an error lower than 0.09% from 2 m v up to 200 mv.
control_engineering	the optimal control of fractional-order active isolation system is researched based on the optimal control theory, and the effect of fractional-order derivative on passive isolation system is also analyzed. the mechanical model is established where viscoelastic features of isolation materials are described by fractional-order derivative. the viscoelastic property of the fractional-order derivative in dynamical system is studied and the fractional-order derivative could be divided into linear stiffness and linear damping. it is found that both the fractional coefficient and the fractional order could affect not only the resonance amplitude through the equivalent linear damping coefficient but also the resonance frequency by the equivalent linear stiffness. based on optimal control theory, the feedback gain of fractional-order active isolation system under harmonic excitation is obtained, which is changed with the excitation frequency. the statistical responses of the displacement and velocity for passive and active vibration isolation systems subjected to random excitation are also presented, which further verifies the excellent performance of fractional-order derivative in vibration control engineering.
signal-flow_graph	in electrical engineering we can use various analytical tools for the circuit analysis. one possible method is the analysis by means of signal flow graphs. analysis of electronic circuits using the mb graph is in detail described in [2, 3]. there are derived mb models (graphs) of passive elements (r, l, c) and of known amplifier structures, too. however, there are not described the transformer models - the circuit element with mutual inductance (m). in this article will be derived a signal flow graph of the transformer, therefore.
data_structures	when compared to earlier programming and data structure experiences that our students might have, the perspective changes on computers and programming when introducing theoretical computer science into the picture. underlying computational models need to be addressed, and mathematical tools employed, to understand the quality criteria of theoretical computer science. focus shifts from doing to proving. over several years, we have tried to make this perspective transition smoother for the students of a third-year mandatory algorithms, data structures, and computational complexity course. the concepts receiving extra attention in this work are np-completeness, one of the most central concepts in computer science, and dynamic programming, an algorithm construction method that is powerful but somewhat unintuitive for some students. the major difficulties that we attribute to np-completeness are that the tasks look similar but have a different purpose than in algorithm construction exercises. students do not immediately see the usefulness of the concept, and hence motivation could be one issue. one line of attacking np-completeness has been to emphasize its algorithmic aspects using typical tools for teaching algorithms. some potential difficulties associated with dynamic programming are that the method is based on a known difficult concept-recursion-and that there are many ingredients in a dynamic programming solution to a problem. for both dynamic programming and np-completeness, we have invented several new activities and structured the teaching differently, forcing students to think and adopt a standpoint, and practice the concepts in programming assignments. student surveys show that these activities are appreciated by the students, and our evaluations indicate that they have positive effects on learning. we believe that these activities could be useful in any similar course. the approach to improving the course is action research, and the evaluation has been done using course surveys, self-efficacy surveys, rubrics-like grading protocols, and grades. we have also interviewed teaching assistants about their experiences.
software_engineering	with the rapid development of computer technology, people pay more attention to the security of computer data and the computer virus has become a chief threat to computer data security. by using an antivirus system that can identify randomly generated computer viruses and on the basis of the basic characteristics of the computer code, this paper investigates the heuristic scanning technique. this paper proposes the minimum distance classifier and detection model through the analysis of the malicious code. this model can identify unknown feature codes of illegal procedures and construct a healthy network environment by using a combination of model and experimental method, which can intercept the illegal virus program in the installation and operation stages. (c) 2016 elsevier b.v. all rights reserved.
data_structures	1. while phylogenies have been getting easier to build, it has been difficult to reuse, combine and synthesize the information they provide because published trees are often only available as image files, and taxonomic information is not standardized across studies. 2. the open tree of life (otl) project addresses these issues by providing a digital tree that encompasses all organisms, built by combining taxonomic information and published phylogenies. the project also provides tools and services to query and download parts of this synthetic tree, as well as the source data used to build it. here, we present rot1, an r package to search and download data fromthe open tree of life directly in r. 3. rot1 uses common data structures allowing researchers to take advantage of the rich set of tools and methods that are available in r to manipulate, analyse and visualize phylogenies. here, and in the vignettes accompanying the package, we demonstrate how rot1 can be used with other r packages to analyse biodiversity data. 4. as phylogenies are being used in a growing number of applications, rot1 facilitates access to phylogenetic data and allows their integration with statistical methods and data sources available inr.
analog_signal_processing	read out circuit is a critical component needed for infrared and visible light imaging system. advances in image sensors and microelectronics have led to the development of digital read out fabricated using deep sub micro integrated circuit techniques. an brief review is given of the image sensor developing. major adaptation circuit are review including source follower, direct injection, and capacitance trans impedance amplifier. on chip analog signal processing and analog to digital conversion techniques are also discussed. noise shaping modulation is a promising technique to build a low power, ultra small area, high precision pixel level ad convertor.
microcontroller	a new device for continuous measurement of fruit or stem growth on the basis of an optoelectronic reflex sensor and a microcontroller board was developed and successfully tested under open field conditions. the principle of the system is based on the detection of alternating narrow white and blacks bars printed on a flexible tape, which is tightened as a loop around the measured object and slides under an infrared reflex sensor in response to the object 's radial growth. the design of this new sensor allows continuous, long term measurements without the need of periodic maintenance or physical adjustments of the measurement device. the new system measures changes of fruit or stem perimeter rather than diameter, thus yielding a more relevant information about the growth of objects which are intrinsically not of perfectly circular cross-sectional shape. the described sensor is very lightweight and does not require any mechanical frame or support structure. the tested prototypes had a measurement resolution of 0.5 mm of perimeter, corresponding to a resolution of about 0.16 mm of diameter for a spherical object. the cost of the sensor is very modest, as it consists of only few and inexpensive components. (c) 2016 elsevier b.v. all rights reserved.
electrical_circuits	the observability of a system with respect to its possible outputs is usually evaluated using the rank criterion of the observability matrix or the observability indices. in addition, this paper uses the properties of the differential equations characterizing real-time electrical circuits which base their nonlinearities on the exponential function. interplay between mathematical tools and practical considerations is done through observability coefficients, observability matrices and high order sliding mode observers for the colpitts chaotic system, representative for such nonlinearities.
analog_signal_processing	this paper presents an extension to the classical gradient-based extremum seeking control for the case when the disturbances responsible for changes in the extremum of a selected performance function are available for measurement. based on these additional measurements, an adaptive extremum seeking disturbance feedforward is designed that approximates the unknown, static mapping between the disturbances and the optimal inputs. for this purpose, orthogonal, multivariate tchebyshev polynomials are used. the feedforward enables the extremum seeking to be conducted in the proximity of the extremum thus yielding improvements both in terms of accuracy and increased convergence speed compared to the traditional scheme. simulation results given for a turbine driven electrical generator system demonstrate the benefits of the presented design.
pid_controller	study on rotary valve system (rvs) for automotive engines has been carried out over many years. recent researches have already successfully implemented the idea, but none of design can provide variable valve timing and flow area control simultaneously. therefore, a rvs with variable valve control system is proposed in this paper. the system design and dynamic analysis of the proposed rvs are first presented. moreover, the selection of the proportional, integral and derivative (pid) controller parameters for the valve control based on an emerging artificial intelligent technique, cuckoo search (cs), is also discussed. experimental and simulation results show that the proposed tuning method is better than the traditional ziegler and nichols method, and the proposed variable rotary valve control system is feasible.
algorithm_design	battery recovery effect is a phenomenon that the available capacity of a battery could increase if the battery can sleep for a certain period of time since its last discharging. accordingly, the battery can work for a longer time when it takes some rests between consecutive discharging processes than when it works all the time. however, this effect has not been considered in the design of energy-efficient topology control algorithms for wireless sensor networks. in this paper, we propose a distributed battery recovery effect aware connected dominating set constructing algorithm (bre-cds) for wireless sensor networks. in bre-cds, each network node periodically decides to join the connected dominating set or not. nodes that have slept in the preceding round have priority to join the connected dominating set in the current round while nodes that have worked in the preceding round are encouraged to take sleep in the current round for battery recovery. detailed algorithm design is presented. the computational complexity of bre-cds is deduced to be o(d-2), where d is node degree. simulation results show that bre-cds can significantly prolong the network lifetime as compared with existing work. copyright (c) 2016 john wiley & sons, ltd.
analog_signal_processing	the paper presents a simple transresistor attractive for on-chip analog-signal-processing. the proposed circuit offers not only a quite good linearity of dc transfer characteristic but, first of all, a relatively low value of its output resistance. this enables a voltage mode operation even if our circuit is loaded by a not necessarily very high resistor. the obtained rather low value of output resistance in our circuit is due to adding to the transresistor-input-stage a simple rail-to-rail voltage follower. to the author 's knowledge, the proposed solution is original and not published yet in the literature. input stage of the transresistor is built of only 4 mos transistors and creates a simple quasi-linear current-to-voltage convertor. output stage of it is built of 9 mos transistors, plays a role of a very precise and simple rail-to-rail cmos-pair-based nonstandard voltage follower. in respect of simplicity and headroom, our follower is better than conventional oa-based voltage followers. preliminary simulation results are in a good agreement with the theory presented.
network_security	ipv6 provides more address space, improved address design, and greater security than ipv4. different transition mechanisms can be used to migrate from ipv4 to ipv6 which includes dual stack networks, tunnels and translation technologies. within all of this, network security is an essential element and therefore requires special attention. this paper analyses two transition technologies which are dual stack and tunnel. both technologies are implemented using cisco packet tracer and gns3. this work will also analyse the security issues of ipv6 to outline the most common vulnerabilities and security issues during the transition. finally, the authors will design and implement the dual stack, automatic and manual tunnelling transition mechanisms using riverbed modeler simulation tool to analyse the performance and compare with the native ipv4 and ipv6 networks.
network_security	in this paper, we conduct research on the wireless sensor network management methods based on the runtime model. with the deepening of the research, scalability and maintainability of wireless sensor network has become an important target of its application promotion. consider that the nodes randomly distributed monitoring area, looking for a complete coverage of this area several disjoint nodes which uses genetic algorithm to optimize the network survival time nodes and corresponding coverage. from the point of view of software engineering, most of the specific software system knowledge hidden in the program and document, the model as the main content of the document and procedures of high-level abstractions. the management of the network is urgently needed. as the additional research, we also conduct theoretical analysis on the wireless sensor network security enhancement methodology with the tradition game theory and mathematical optimization approaches which will be meaningful. game theory is on the interaction between much of decision-making behavior has, according to the different subjects in the control information and the cognition of their own capabilities which will be a novel method for the analysis. the numerical simulation shows that our method performed better compared with other related approaches. in the future, more research will be conducted to polish the current method.
distributed_computing	with the rapid development of embedded system and internet of things technology, embedded system and smart device based on embedded system is collecting huge amounts of data, and corresponding data processing and application method have been greatly changed, different from the traditional big data and cloud computing focus, local processing and application become important trend. this paper tries to take cortex-a7 as the main system with the stronger ability, hadoop distributed computing system is deployed in embedded system and could meet the demand of the future data process with directly managing the resource-constrained sensors, embedded systems and smart devices. successfully deploying over 20gb data in the test, the system is verified that it can complete most of the functions of data processing cluster, and can also manage the collected sensors and embedded system terminal, with better research and market promotional value.
symbolic_computation	the modeling of wave propagation in microstructured materials should be able to account for various scales of microstructure. based on the proposed new exponential expansion method, we obtained the multiple explicit and exact traveling wave solutions of the strain wave equation for describing different types of wave propagation in microstructured solids. the solutions obtained in this paper include the solitary wave solutions of topological kink, singular kink, non-topological bell type solutions, solitons, compacton, cuspon, periodic solutions, and solitary wave solutions of rational functions. it is shown that the new exponential method, with the help of symbolic computation, provides an effective and straightforward mathematical tool for solving nonlinear evolution equations arising in mathematical physics and engineering. (c) 2014 faculty of engineering, ain shams university. production and hosting by elsevier b. v. this is an open access article under the cc by-nc-nd license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
computer_graphics	volume rendering has been a relevant topic in scientific visualization for the last decades. however, the exploration of reasonably big volume datasets requires considerable computing power, which has limited this field to the desktop scenario. but the recent advances in mobile graphics hardware have motivated the research community to overcome these restrictions and to bring volume graphics to these ubiquitous handheld platforms. this survey presents the past and present work on mobile volume rendering, and is meant to serve as an overview and introduction to the field. it proposes a classification of the current efforts and covers aspects such as advantages and issues of the mobile platforms, rendering strategies, performance and user interfaces. the paper ends by highlighting promising research directions to motivate the development of new and interesting mobile volume solutions.
network_security	achieving efficient security solutions for wireless sensor networks (wsn) is a daring challenge due to vulnerable nature of wireless medium. routing is a major threat to security. an adversary can inject bogus routing to en-route nodes causing false decision and drain the sensors energy in the network system. to identify and prune the adversaries, pruning route modifiers (prm) algorithm based on the collaborative authentication system has been proposed. the algorithm considers the random deployment of sensor nodes. based on the collaborative authentication scheme, the prm algorithm can save energy by pruning the malicious nodes at early stage. the simulation results and theoretical analysis reveals that prm algorithm is effective in terms of efficient and secure routing. this algorithm reduces the consumption of energy by pruning and establishes the shortest path that leads to efficient network and enables security.
machine_learning	objective. automated behavioral state classification can benefit next generation implantable epilepsy devices. in this study we explored the feasibility of automated awake (aw) and slow wave sleep (sws) classification using wide bandwidth intracranial eeg (ieeg) in patients undergoing evaluation for epilepsy surgery. approach. data from seven patients (age $34\pm 12$ , 4 women) who underwent intracranial depth electrode implantation for ieeg monitoring were included. spectral power features (0.1600 hz) spanning several frequency bands from a single electrode were used to train and test a support vector machine classifier. main results. classification accuracy of 97.8 +/- 0.3% (normal tissue) and 89.4 +/- 0.8% (epileptic tissue) across seven subjects using multiple spectral power features from a single electrode was achieved. spectral power features from electrodes placed in normal temporal neocortex were found to be more useful (accuracy 90.8 +/- 0.8%) for sleep-wake state classification than electrodes located in normal hippocampus (87.1 +/- 1.6%). spectral power in high frequency band features (ripple (80250 hz), fast ripple (250600 hz)) showed comparable performance for aw and sws classification as the best performing berger bands (alpha, beta, low gamma) with accuracy ?90% using a single electrode contact and single spectral feature. significance. automated classification of wake and sws should prove useful for future implantable epilepsy devices with limited computational power, memory, and number of electrodes. applications include quantifying patient sleep patterns and behavioral state dependent detection, prediction, and electrical stimulation therapies.
bioinformatics	helicases play a critical role in processes such as replication or recombination by unwinding double-stranded dna; mutations of these genes can therefore have devastating biological consequences. in humans, mutations in genes of three members of the recq family helicases (blm, wrn, and recq4) give rise to three strikingly distinctive clinical phenotypes: bloom syndrome, werner syndrome, and rothmund-thomson syndrome, respectively. however, the molecular basis for these varying phenotypic outcomes is unclear, in part because a full mechanistic description of helicase activity is lacking. because the helicase core domains are highly conserved, it has been postulated that functional differences among family members might be explained by significant differences in the n-terminal domains, but these domains are poorly characterized. to help fill this gap, we now describe bioinformatics, biochemical, and structural data for three vertebrate blm proteins. we pair high resolution crystal structures with saxs analysis to describe an internal, highly conserved sequence we term the dimerization helical bundle in n-terminal domain (dhbn). we show that, despite the n-terminal domain being loosely structured and potentially lacking a defined three-dimensional structure in general, the dhbn exists as a dimeric structure required for higher order oligomer assembly. interestingly, the unwinding amplitude and rate decrease as blm is assembled from dimer into hexamer, and also, the stable dhbn dimer can be dissociated upon atp hydrolysis. thus, the structural and biochemical characterizations of n-terminal domains will provide new insights into how the n-terminal domain affects the structural and functional organization of the full blm molecule.
algorithm_design	mobile hotspots have made the dream of ubiquitous internet access come true, while the widespread applications are still hindered by the limited power of smart phones. to address this issue, we propose a novel distributed cooperative data transmission scheme for energy-rechargeable mobile devices. in particular, we not only let a mobile phone help the nearby client devices connect to the internet via its cellular accessing, but also let those clients replenish the mobile hotspot energy via wireless power transfer. we mathematically formulate the mutually beneficial relationship between mobile hotspots and clients into an optimization problem, with the objective of conducting the cooperative wireless data and energy transmission to maximize the system utility. resorting to methods from combinatorics and matching theory, we develop a near optimal solution for many-to-one matching when there is a single mobile hotspot and a distributed matching strategy for the general case by considering the nature of data communication and the characteristic of wireless power transfer. by extensive simulation, we show that the proposed distributed solution achieves a performance close to the centralized method, and it outperforms the greedy matching strategy and the classic gale-shapley matching strategy in different scenarios.
relational_databases	in this paper the process and program model of universal microelectromechanical systems data extracting and update mechanism from different relational databases to nosql database mongodb is described.
software_engineering	game development is an interdisciplinary concept that embraces software engineering, business, management, and artistic disciplines. this research facilitates a better understanding of the business dimension of digital games. the main objective of this research is to investigate empirically the effect of business factors on the performance of digital games in the market and to answer the research questions asked in this study. game development organizations are facing high pressure and competition in the digital game industry. business has become a crucial dimension, especially for game development organizations. the main contribution of this paper is to investigate empirically the influence of key business factors on the business performance of games. this is the first study in the domain of game development that demonstrates the interrelationship between key business factors and game performance in the market. the results of the study provide evidence that game development organizations must deal with multiple business key factors to remain competitive and handle the high pressure in the digital game industry. furthermore, the results of the study support the theoretical assertion that key business factors play an important role in game business performance. (c) 2015 elsevier b.v. all rights reserved.
state_space_representation	the paper presents a control-oriented modeling approach for multi-zone buildings with mixed-mode cooling, based on the linear state-space representation with varying coefficient matrices. key features are the time-variant thermal resistances, associated with the heat extraction due to airflow, calculated using an airflow network model. this approach was validated with experimental data collected in a two-zone test-building under four operation modes. a forward linear time-variant state-space (ltv-ss) model, developed based on first principles, was then used as a true representation of the building, to identify the parameters of a low-order ltv-ss gray-box model. the low-order model can predict the building thermal dynamics with sufficient accuracy with a root mean square error (rmse) of 0.58 degrees c for the air and 1.08 degrees c for the area-weighted mean surface temperature in the south direct gain zone. furthermore, the study develops a progressive refinement (prore) optimization method, following the multi-level optimization topology and branch and bound decision trimming strategy, to find sequences of binary (open/close) decisions for the motorized windows. due to the significant improvement in computing time, the models and algorithms presented in this paper enable long-term simulation for mpc performance evaluation and implementation of predictive strategies in real controllers. (c) 2014 elsevier ltd. all rights reserved.
software_engineering	this paper presents a literature review in the field of summarizing software artifacts, focusing on bug reports, source code, mailing lists and developer discussions artifacts. from jan. 2010 to apr. 2016, numerous summarization techniques, approaches, and tools have been proposed to satisfy the ongoing demand of improving software performance and quality and facilitating developers in understanding the problems at hand. since aforementioned artifacts contain both structured and unstructured data at the same time, researchers have applied different machine learning and data mining techniques to generate summaries. therefore, this paper first intends to provide a general perspective on the state of the art, describing the type of artifacts, approaches for summarization, as well as the common portions of experimental procedures shared among these artifacts. moreover, we discuss the applications of summarization, i.e., what tasks at hand have been achieved through summarization. next, this paper presents tools that are generated for summarization tasks or employed during summarization tasks. in addition, we present different summarization evaluation methods employed in selected studies as well as other important factors that are used for the evaluation of generated summaries such as adequacy and quality. moreover, we briefly present modern communication channels and complementarities with commonalities among different software artifacts. finally, some thoughts about the challenges applicable to the existing studies in general as well as future research directions are also discussed. the survey of existing studies will allow future researchers to have a wide and useful background knowledge on the main and important aspects of this research field.
image_processing	in this paper a novel and effective approach for automated audio classification is presented that is based on the fusion of different sets of features, both visual and acoustic. a number of different acoustic and visual features of sounds are evaluated and compared. these features are then fused in an ensemble that produces better classification accuracy than other state-of-the-art approaches. the visual features of sounds are built starting from the audio file and are taken from images constructed from different spectrograms, a gammatonegram, and a rhythm image. these images are divided into sub windows from which a set of texture descriptors are extracted. for each feature descriptor a different support vector machine (svm) is trained. the svms outputs are summed for a final decision. the proposed ensemble is evaluated on three well-known databases of music genre classification (the latin music database, the ismir 2004 database, and the gtzan genre collection), a dataset of bird vocalization aiming specie recognition, and a dataset of right whale calls aiming whale detection. the mat lab code for the ensemble of classifiers and for the extraction of the features will be publicly available (https://www.delunipclit/node/2357 +pattern recognition and ensemble classifiers). (c) 2017 elsevier b.v. all rights reserved.
parallel_computing	we propose a novel parallel computing framework for a nonlinear finite element method (fem)-based cell model and apply it to simulate avascular tumor growth. we derive computation formulas to simplify the simulation and design the basic algorithms. with the increment of the proliferation generations of tumor cells, the fem elements may become larger and more distorted. then, we describe a remesh and refinement processing of the distorted or over large finite elements and the parallel implementation based on message passing interface to improve the accuracy and efficiency of the simulation. we demonstrate the feasibility and effectiveness of the fem model and the parallelization methods in simulations of early tumor growth.
distributed_computing	searching for new efficient algorithms to solve complex optimization problems in big data scenarios is a priority, especially when the search space increases exponentially with the problem size, making impossible to find a solution through a mere blind search. networks of evolutionary processors (nep) is a formal framework formed of highly parallel and distributed computing models inspired and abstracted from biological evolution that is able to solve hard problems in an efficient way. however, nep is not expressive enough to model quantitative aspects present in many problems. in this paper we propose nepo, a new model based on the nep evolutionary processors. nepo deals with a class of data that is able to solve hard optimization problems and defines a novel selection process based on a quantitative filtering strategy. we present a linear time solution to a well known np-complete optimization problem (the 0/1 knapsack problem) in order to demonstrate nepo advantages. this result suggests that nepo 's quantitative filtering is more suitable to tackle practical solutions to optimization problems in order to deploy them on highly scalable distributed computational platforms. (c) 2016 elsevier b.v. all rights reserved.
cryptography	many identity-based proxy signature (ibps) schemes have been proposed, but most were proved to be secure using a random oracle model, which has attracted considerable criticism. cao and cao proposed an ibps scheme using the standard model, but their scheme was shown to be insecure because it could not resist a delegator attack. in order to overcome this weakness, gu et al. proposed a new ibps scheme in 2013 that uses the standard model and they also provided a detailed security model for ibps. however, in this study, we demonstrate that gu et al. 's scheme is still vulnerable to delegator attack. in order to correct this problem, we propose an improvement of the ibps scheme described by gu et al. we also present an efficiency analysis for our scheme and a detailed security proof based on the computational diffie-hellman assumption.
electricity	the term smart grid refers to a modernization of the electrical network consisting in the integration of various technologies such as dispersed generation, dispatchable loads, communication systems and storage devices which operates in grid-connected and islanded modes. as a result, traditional optimization techniques in new power systems have been seriously influenced during the last decade. one of the most important technical and economical tools in this regard is the optimal power flow (opf). as a fundamental optimization tool in the operation and planning fields, opf has an undeniable role in the power system. this paper reviews and compares the opf approaches mainly related to smart distribution grids. in this work, the main opf approaches are compared in terms of their objective functions, constraints, and methodologies. furthermore, computational performances, case study networks and the publication date of these methods are reported. finally, some basic challenges arising from the new opf methodologies in smart grids are addressed.
bioinformatics	background: variants of unknown significance (vuss) have been identified in brca1 and brca2 and account for the majority of all identified sequence alterations. notably, vuss occur disproportionately in people of african descent hampering breast cancer (bca) management and prevention efforts in the population. our study sought to identify and characterize mutations associated with increased risk of bca at young age. methods: in our study, the spectrum of mutations in brca1 and brca2 was enumerated in a cohort of 31 african american women of early age at onset breast cancer, with a family history of breast or cancer in general and/or with triple negative breast cancer. to improve the characterization of the brca1 and brca2 variants, bioinformatics tools were utilized to predict the potential function of each of the variants. results: using next generation sequencing methods and in silico analysis of variants, a total of 197 brca1 and 266 brca2 variants comprising 77 unique variants were identified in 31 patients. of the 77 unique variants, one (1.3%) was a pathogenic frameshift mutation (rs80359304; brca2 met591ile), 13 (16.9%) were possibly pathogenic, 34 (44.2%) were benign, and 29 (37.7%) were vuss. genetic epidemiological approaches were used to determine the association with variant, haplotype, and phenotypes, such as age at diagnosis, family history of cancer and family history of breast cancer. there were 5 brca1 snps associated with age at diagnosis; rs1799966 (p=. 045; log additive model), rs16942 (p=. 033; log additive model), rs1799949 (p=. 058; log additive model), rs373413425 (p=. 040 and.023; dominant and log additive models, respectively) and rs3765640 (p=. 033 log additive model). additionally, a haplotype composed of all 5 snps was found to be significantly associated with younger age at diagnosis using linear regression modeling (p=.023). specifically, the haplotype containing all the variant alleles was associated with older age at diagnosis (or= 5.03 95% ci=. 91-9.14). conclusions: knowing a patient 's brca mutation status is important for prevention and treatment decision-making. improving the characterization of mutations will lead to better management, treatment, and bca prevention efforts in african americans who are disproportionately affected with aggressive bca and may inform future precision medicine genomic-based clinical studies.
operational_amplifier	negative feedback technique employing high dc gain operational amplifier (op-amp) is one of the most important techniques in analog circuit design. however, high dc gain op-amp is difficult to realize in scaled technology due to a decrease of intrinsic gain. in this paper, high dc gain op-amp using common-gate topology with high power efficiency is proposed. to achieve high dc gain, large output impedance is required but input transistors' drain conductance decreases output impedance of conventional topology such as folded cascode topology with complementary input. this is because bias current of the output side transistors is not separated from the bias current of the input transistors. on the other hand, proposed circuit can suppress a degradation of output impedance by inserting common-gate topology between input and output side. this architecture separates bias current of the input transistors from that of the output side, and hence the effect of the drain conductance of input transistors is reduced. as the result, proposed circuit can increase dc gain about 10 db compared with the folded cascode topology with complementary input in 65 nm cmos process. moreover, power consumption can be reduced because input nmos and pmos share bias current. according to the simulation results, for the same power consumption, in the proposed circuit gain-bandwidth product (gbw) is improved by approximately 30% and noise is also reduced in comparison to the conventional topology.
signal-flow_graph	traditional design for testability (dft) is arduous and time-consuming because of the iterative process of testability assessment and design modification. to improve the dft efficiency, a dft process based on test point allocation is proposed. in this process, the set of optimal test points will be automatically allocated according to the signal reachability under the constraints of testability criteria. thus, the iterative dft process will be completed by computer and the test engineers will be released to concentrate on the system design rather than the repetitive modification process. to perform test point allocation, the dependency matrix of signal to potential test point (sp-matrix) is defined based on multi-signal flow graph. then, genetic algorithm (ga) is adopted to search for the optimal test point allocation solution based on the sp-matrix. at last, experiment is carried out to evaluate the effectiveness of the algorithm.
pid_controller	a heating, ventilation, and air-conditioning (hvac) system is a multi-variable strongly coupled large-scale system that is composed of several sub-systems. considerable research, simulations, and experiments have been conducted on hvac control. the optimization control of an hvac system is now the popular issue. the ultimate goal of this paper was to achieve minimum energy consumption and improve system efficiency. multi-zone variable air volume and variable water volume air-conditioning systems were developed. the dynamic models of hvac sub-systems were built by the adaptive directional forgetting method. control strategies such as the gearshift integral proportional-integral-derivative (pid) controller and self-tuning pid controller were studied in the platform to improve the dynamic characteristics of the hvac system. system performance was improved. the system saved 18.2% of energy with the integration of iterative learning control and sequential quadratic programming based on the steady-state hierarchical optimization control scheme.
digital_control	this paper presents a three-dimensional (3-d) space vector pulse width modulation (svpwm) technique via a 4 x 4 orthonormal transformation matrix that has been used as a new approach in controlling a three-phase four-leg voltage source inverter (vsi). a fully optimal digital control scheme for the closed-loop regulation of the three-phase four-leg vsi has been used to synthesize a sinusoidal waveform with the help of the proposed method. discrete-time modelling of each phase has been obtained independently in abc reference frame, and its optimal controller has been designed using a predefined performance index. a dsp-based controlled three-phase four-leg prototype vsi has been designed to verify the proposed discrete time modelling and the control scheme. the simulations and the real-time experiments show that satisfactory results have been obtained for the modelling of the three-phase four-leg vsi in abc reference frame and the 3-d svpwm technique via 4 x 4 orthonormal transformation matrix at 20 khz switching frequency.
digital_control	in grid-connected converter control, grid voltage feedforward is usually introduced to suppress the influence of grid voltage distortion on the converter 's grid-side ac current. however, owing to the time-delay in control systems, the suppression effect of the grid voltage distortion is seriously affected. in this paper, the positive effects of the grid voltage feedforward control are analyzed in detail, and the time-delay caused by the low-pass filter (lpf) in the voltage filtering circuits and digital control are summarized. in order to reduce the time-delay effect on the performance of the feedforward control, a voltage feedforward control strategy with time-delay compensation is proposed, in which, a leading correction of the feedforward voltage is used. the optimal leading step used in this strategy is derived from analyzing the phase-frequency characteristics of a lpf and the implementation of digital control. by using the optimal leading step, the delay in the feedforward path can be further counteracted so that the performance of the feedforward control in terms of suppressing the influence of grid voltage distortion on the converter output current can be improved. the validity of the proposed method is verified through simulation and experiment results.
electrical_network	isolated electrical systems lack electrical interconnection to other networks and are usually placed in geographically isolated areas-mainly islands or locations in developing countries. until recently, only diesel generators were able to assure a safe and reliable supply in exchange for very high costs for fuel transportation and system operation. transmission system operators (tsos) are increasingly seeking to replace traditional energy models based on large groups of conventional generation units with mixed solutions where diesel groups are held as backup generation and important advantages are provided by renewable energy sources. the grid codes determine the technical requirements to be fulfilled by the generators connected in any electrical network, but regulations applied to isolated grids are more demanding. in technical literature it is rather easy to find and compare grid codes for interconnected electrical systems. however, the existing literature is incomplete and sparse regarding isolated grids. this paper aims to review the current state of isolated systems and grid codes applicable to them, specifying points of comparison and defining the guidelines to be followed by the upcoming regulations.
system_identification	a novel adaptive filter combining the affine projection algorithm (apa) and the affine projection sign algorithm (apsa) is proposed using an impulsive noise indicator. this indicator is proposed to use the apa as the component filter in impulsive noise environments, and it is easily obtained with convex combination schemes. from this, the proposed algorithm achieves robustness against impulsive noise regardless of the convergence state. in addition, the proposed algorithm exhibits a fast convergence rate of the apa for various noise environments. simulation results verify that the proposed algorithm adequately combines the advantages of the two component filters for system identification scenarios. (c) 2016 elsevier b.v. all rights reserved.
computer_programming	this paper analyzes the advantages and trends of holographic projection technology and the characteristics of large sports performance arrangement using the method of literature, aiming at providing new ideas for the performance arrangement, thus facilitating new artistic system of large sports performance in modern times. results show that the technology of holographic projection gets rid of the tedious steps in the past computer programming, overcomes the design flaws of 3d computer graphic simulation with its unique 360 - degree holographic imaging, and presents a more realistic three - dimensional image whose effect is closer to actual practice. it provides with a better idea of arrangement of large opening and closing ceremonies as well as large sports performances.
cryptography	a new secure key distribution scheme based on the dynamic chaos synchronization of two cascaded semiconductor laser systems (cslss) subject to common chaotic injection and random phase-modulated optical feedback is demonstrated. in this scheme, alice and bob adopt two independent random sequences to control the phase modulators of cslss, which induces a dynamic perturbation to the chaos synchronization. we thoroughly investigate the chaos synchronization performance under different phase-shift conditions with cross-correlation function, and systematically discuss the feasibility and security of the system. the results show that, with proper injection and feedback strength, the correlation coefficient gap between phase shift match and mismatch is clear and robust to the parameter mismatches in the cslss and those between the two cslss. based on this, high-quality key distribution can be performed by picking out the identical random bits from the two independent random sequences according to the computational correlation. moreover, the investigations on the information theoretic security and rate of the key distribution show that the security of the key distribution scheme can be further enhanced by properly increasing the number of layers in the cslss or employing highorder modulation format.
computer_vision	understanding continuous human actions is a non-trivial but important problem in computer vision. although there exists a large corpus of work in the recognition of action sequences, most approaches suffer from problems relating to vast variations in motions, action combinations, and scene contexts. in this paper, we introduce a novel method for semantic segmentation and recognition of long and complex manipulation action tasks, such as ""preparing a breakfast"" or ""making a sandwich"". we represent manipulations with our recently introduced ""semantic event chain"" (sec) concept, which captures the underlying spatiotemporal structure of an action invariant to motion, velocity, and scene context. solely based on the spatiotemporal interactions between manipulated objects and hands in the extracted sec, the framework automatically parses individual manipulation streams performed either sequentially or concurrently. using event chains, our method further extracts basic primitive elements of each parsed manipulation. without requiring any prior object knowledge, the proposed framework can also extract object-like scene entities that exhibit the same role in semantically similar manipulations. we conduct extensive experiments on various recent datasets to validate the robustness of the framework.
pid_controller	this paper focuses on the quality improvements on clinching joints using a servo press with a radial basis function neural network and a sliding mode (rbfs) control strategy. bottom thickness, which is affected by the press punch position, is usually used to monitor clinching joint quality. traditional clinching presses are driven by pneumatic pistons or motors that provide feedback on punch force or motor position. however, this feedback is indirectly related to the joint bottom thickness. clinching workers who set the control parameters on these presses depend on tests and statistics. thus, this paper presents a servo press system that utilizes punch position feedback to directly control the joint bottom thickness. transmission errors are considered for the movement accuracy of the servo press. a mathematical model of the servo press is established for analyzing. an algorithm, which combines rbf neural network and sliding mode, is proposed and applied for press position tracking. this algorithm adopts an rbf neural network to approximate the nominal model of the press system. the update law of the algorithm is based on the lyapunov function used to prove the stability of a closed-loop system. the sliding mode controller compensates for the neural network error and disturbance. finally, experiments are executed on the servo press with an rbfs controller. to evaluate the performance of the proposed method, a fuzzy pid controller is also applied to the press for comparison. the results indicate that the servo clinching press system with rbfs efficiently and accurately control the clinching jointing process.
operational_amplifier	this article deals with an electronic implementation of a 3-d dynamical system that comprises multiple scrolls and is regarded as unstable dissipative system. such a system is dissipative in one of its components but unstable in the other two. the proposed electronic circuit is implemented with resistors, capacitors and comparators and has the capability to generate two or three scrolls
software_engineering	a plethora of multi agent systems (mas) development methodologies exists and all compete for prominence. this paper advocates unification of best of breed activities from these methodologies and examines two existing approaches for unifying access to them. it proposes an alternative approach that focusses on the use of domain knowledge through ontologies as offering the best potential for unifying access to them. the reliance on ontologies will provide flexibility in the process and workproducts use within the methodology. the focus on domain knowledge will reduce the number of mandatory methodological tasks and at the same time create scope for reuse with respect to both system designs and components. the paper will further sketch and argue for a full software development lifecycle for mas where ontologies expressing domain knowledge are the central artifacts.
bioinformatics	background: tuberculosis remains a major global threat. two billion of the world 's population is latently infected with mycobacterium tuberculosis and is at the risk of progression to active disease. bacillus calmette-guerin (bcg), as the only licensed vaccine, has prophylaxis strategy, which protects children from disseminated form of tuberculosis. therefore, postexposure vaccine strategy, which targets individuals with latent tuberculosis infection, is an important strategy to control this disease globally. objectives: in the present study, we designed a novel postexposure multi-epitope dna construct based on 3 latency-associated antigens of rv2029c, rv2031c, and rv2627c and microtubule-associated protein light chain 3 (lc3) as a hallmark protein of the autophagy system. methods: a mouse construct was designed based on predicted mhc class i-and class ii-restricted t-cell epitopes that fused together tandemly. mhc class i-and class ii-restricted epitopes were linked by aay and gpgpg motifs, respectively. lc3 directly fused to the mhc class ii-restricted epitopes at the c-terminus of the peptide. the varieties of expressed construct features were analyzed by bioinformatics tools. finally, construct codons were optimized and mrna structure of optimized construct was analyzed. results: mhc class i-and class ii-predicted epitopes showed a high potential to binding to human hlas alleles, with global broad-spectrum population coverage. the construct had no allergenicity, and the analysis indicated a desirable antigenicity of the construct. the construct had several posttranslational modifications, no signal peptide, and cytoplasmic localization with high score. also, mrna analysis showed low delta g which demonstrated high stability and efficient translation. conclusions: the results revealed that the novel multi-epitope dna construct could be an effective candidate in tuberculosis vaccine development, and it is qualified to investigate its potential to induce cd4 and cd8 t-cell immune response in the experimental animal model.
operating_systems	operating systems interface between hardware and the user, random numbers are useful for security and simulation, and file systems form the program access to them in a modern operating system. blending these items into a remotely accessed infrastructure forms the basis for supporting operating systems projects. this work describes the hardware, software, and communication infrastructure to support student projects by sharing remote hardware to acquire background radiations events with a geiger counter, transforming those events into random numbers, and providing those numbers through a custom file system. collectively, the hardware and software provide an inexpensive remote laboratory experience for computing students.
control_engineering	complex dynamic engineering systems i.e. radar, gimbal, missile, infrared sensors, land vehicles, aircraft, ships, power plants become challenges for classical fault diagnostic system. they are modular consisting of modules or line replaceable units (lru). each module has its own bit circuit that is linked with the system level bit through the bit architecture. the performance characteristic of the diagnostic system i.e. sensitivity and specificity is usually poor. fault diagnostic for these systems are plagued with conditions known as false alarm (fa), missed detection, cannot duplicate (cnd) and retest ok (rtok) that have adverse impacts in performance, reliability, maintainability, availability, safety and affordability. these costly elusive problems may be due to many reasons; some of them are: absence or lack of fault modeling during the threshold design, absence or lack of test verticality, unobservable and uncontrollable modes of state variables in the system state space model. where do signal detection theory techniques (sdtt) fit in the general scheme of classical fault diagnostic i.e. bit threshold design? signal detection theory models lend themselves readily to numerical computations suitable for solution on a computer that is applicable to classical bit testability threshold design. nevertheless, several mathematical strategies must be used before one can apply sdtt into bit detection. since sdtt has been very reliable in many fields, in radar detection application, in medicine diagnostic tests, in biometrics, it can as well be a valuable tool in bit threshold design with a few mathematical manipulations. this paper presents the foundations of sdtt in radar target detection theory in a coherent manner easy to follow and in a way to advance the bit diagnostic threshold design while at the same time emphasizes the underlying physics. these techniques make use of gaussian distribution and bayesian statistics. some of the most important performance measures are sensitivity, specificity, prevalence. this paper addresses as well the test verticality issue and will introduce the unobservable and uncontrollable state variable issues. however, state observability and state controllability are beyond the scope of this paper and should be fully addressed in a control engineering model-based fault diagnostic research task.
electricity	salinity gradient solar ponds act as an integrated thermal solar energy collector and storage system. the temperature difference between the upper convective zone and the lower convective zone of a salinity gradient solar pond can be in the range of 40-60a degrees c. the temperature at the bottom of the pond can reach up to 90a degrees c. low-grade heat (< 100a degrees c) from solar ponds is currently converted into electricity by organic rankine cycle engines. thermoelectric generators can operate at very low temperature differences and can be a good candidate to replace organic rankine cycle engines for power generation from salinity gradient solar ponds. the temperature difference in a solar pond can be used to power thermoelectric generators for electricity production. this paper presents an experimental investigation of a thermoelectric generators heat exchanger system designed to be powered by the hot water from the lower convective zone of a solar pond, and cold water from the upper convective zone of a solar pond. the results obtained have indicated significant prospects of such a system to generate power from low-grade heat for remote area power supply systems.
operating_systems	memory diagnostics are important to improving the resilience of dram main memory. as bit cell size reaches physical limits, dram memory will be more likely to suffer both transient and permanent errors. memory diagnostics that operate online can be a component of a comprehensive strategy to allay errors. this paper presents a novel approach, asteroid, to integrate online memory diagnostics during workload execution. the approach supports diagnostics that adapt at runtime to workload behavior and resource availability to maximize test quality while reducing performance overhead. we describe asteroid 's design and how it can be efficiently integrated with a hierarchical memory allocator in modern operating systems. we also present how the framework enables control policies to dynamically configure a diagnostic. using an adaptive policy, in a 16-core server, asteroid has modest overhead of 1-4 % for workloads with low to high memory demand. for these workloads, asteroid 's adaptive policy has good error coverage and can thoroughly test memory.
data_structures	graphs are considered to be one of the best studied data structures in discrete mathematics and computer science. hence, data mining on graphs has become quite popular in the past few years. the problem of finding frequent itemsets in conventional data mining on transactional databases, thus transformed to the discovery of subgraphs that frequently occur in the graph dataset containing either single graph or multiple graphs. most of the existing algorithms in the field of frequent subgraph discovery adopts an apriori approach based on generation of candidate set and test approach. the problem with this approach is the costlier candidate set generation, particularly when there exist more number of large subgraphs. the research goals in frequent subgraph discovery are to evolve (i) mechanisms that can effectively generate candidate subgraphs excluding duplicates and (ii) mechanisms that find best processing techniques that generate only necessary candidate subgraphs in order to discover the useful and desired frequent subgraphs. in this paper, a two phase approach is proposed by integrating apriori algorithm on graphs to frequent subgraph (fs) tree to discover frequent subgraphs in graph datasets.
microcontroller	in this paper realization of the low-power, portable, low-cost multi-sensor system for air and water quality monitoring is described. developed system is batterypowered with solar panel-based charger unit, and it is intended for use in remote environmental monitoring by collecting information about air temperature (t) and relative humidity (rh), presence of volatile organic compounds (voc) as well as water temperature and ph level. the hardware of the system is based on the atmega128 microcontroller which acquires the sensors data and coordinates the work of all peripherals. to establish full standalone operation, peripherals such a tft color lcd display, embedded keypad and sd card for data storage are included. air quality parameters are collected with sht11 (t and rh) and mq-135 (voc) sensors, while water temperature is monitored with encapsulated lm35 sensor. for ph level monitoring, tio2-based thick film ph resistive sensor was fabricated and characterized. the ph sensor readout electronics, based on the integrated circuit ad5933, is designed in such way to ensure reliable in-situ measurements. discussion of the applications of the proposed system in the more complex, a cloud-based, system for air and water quality monitoring in real-time, with the ibm watson iot platform is given as well.
electrical_network	the resistance distance between any two vertices of a connected graph g is defined as the effective resistance between them in the electrical network constructed from g by replacing each edge of g with unit resistor. the kirchhoff index of a graph g is defined as the sum of the resistance distances between all pairs of vertices of g. l-n,l-p* denote a specified class of graphs with n vertices, which obtained by identifying the vertex u(i) of the complete graph k-p with the root v(i) of the tree t-i, respectively, where i=1,2, ... ,r and 1 <= r <= p. we obtain some ordering relations of kirchhoff indices for four graph transformations, and thus determine the graphs with the first-smallest to the fifth-smallest kirchhoff indices as well as the maximal kirchhoff index of l-n,l-p*, respectively.
software_engineering	one of the most important parts in developing any kind of software is to check the sustainability of the software which is done by the software testing by the software engineers. a varied number of test cases have been taken into account and the test is done by using the unified modelling language (uml). by using the combination of the hybrid revised genetic algorithm along with the bee colony optimization, the test has come out to be in the favour of finding the maximum and the minimum coverage. this novel approach has been tested over the application of a smart card users/security token user. in order to increase the security of the smart card/security token (sc/st), a novel approach for smart card/security token (sc/st) has been proposed,is a decision making structure for self- organising systems based on software engineering. by this secured details can be obtained from the total number of smart card users. by this approach, the total flaws present in the system can be easily detected along with the maximum possible paths. the novel technique for software testing guarantees that minimum time has been considered for maximum coverage. (c) 2016 elsevier ltd. all rights reserved.
electric_motor	this paper introduces the course construction in order to cultivate the students' engineering ideal and the practical ability. teachers adjust teaching methods and teaching devices according to the students' feedback information. the project teaching of dc motor help students to understand the engineering application, and this content of stepper motor break the barriers between the courses. the course information construction is constantly improving.
bioinformatics	background: autophagy is a conserved molecular pathway involved in the degradation and recycling of cellular components. it is active either as response to starvation or molecular damage. evidence is emerging that autophagy plays a key role in the degradation of damaged cellular components and thereby affects aging and lifespan control. in earlier studies, it was found that autophagy in the aging model podospora anserina acts as a longevity assurance mechanism. however, only little is known about the individual components controlling autophagy in this aging model. here, we report a biochemical and bioinformatics study to detect the protein-protein interaction (ppi) network of p. anserina combining experimental and theoretical methods. results: we constructed the ppi network of autophagy in p. anserina based on the corresponding networks of yeast and human. we integrated paatg8 interaction partners identified in an own yeast two-hybrid analysis using atg8 of p. anserina as bait. additionally, we included age-dependent transcriptome data. the resulting network consists of 89 proteins involved in 186 interactions. we applied bioinformatics approaches to analyze the network topology and to prove that the network is not random, but exhibits biologically meaningful properties. we identified hub proteins which play an essential role in the network as well as seven putative sub-pathways, and interactions which are likely to be evolutionary conserved amongst species. we confirmed that autophagy-associated genes are significantly often up-regulated and co-expressed during aging of p. anserina. conclusions: with the present study, we provide a comprehensive biological network of the autophagy pathway in p. anserina comprising ppi and gene expression data. it is based on computational prediction as well as experimental data. we identified sub-pathways, important hub proteins, and evolutionary conserved interactions. the network clearly illustrates the relation of autophagy to aging processes and enables further specific studies to understand autophagy and aging in p. anserina as well as in other systems.
electric_motor	energy efficiency in pumping is affected by the motor efficiency. this paper studies the applicability of common electric motor types to an industrial pumping system by comparing the motor efficiency characteristics with each other, and by analysing how the motor efficiency and sizing affect the resulting pumping system energy consumption with a standard load profile. the objective of the paper is to provide guidance on the motor sizing, so the most energy efficient alternative will be selected to the given pumping system.
machine_learning	clustering is one of the basic tasks in data mining and machine learning which aims at discovering hidden structure in the data. for many real-world applications, there often exist many different yet meaningful clusterings while most of existing clustering methods only produce a single clustering. to address this limitation, multiple clustering, which tries to generate clusterings that are high quality and different from each other, has emerged recently. in this paper, we propose a novel alternative clustering method that generates non-redundant multiple clusterings sequentially. the algorithm is built upon nonnegative matrix factorization, and we take advantage of the nonnegative property to enforce the non-redundancy. specifically, we design a quadratic term to measure the redundancy between the reference clustering and the new clustering, and incorporate it into the objective. the optimization problem takes on a very simple form, and can be solved efficiently by multiplicative updating rules. experimental results demonstrate that the proposed algorithm is comparable to or outperforms existing multiple clustering methods.
computer_vision	motion segmentation and non-rigid structure from motion are two challenging computer vision problems that have attracted numerous research interests. while the previous works handle these two problems separately, we present a general motion segmentation framework in this paper for solving these two seemingly different problems in a unified manner. at the heart of our general motion segmentation framework is a model selection mechanism based on finding the minimal basis subspace representation, by seeking the joint sparse representation of the data matrix. however, such formulation is np-hard and we solve the convex proxy instead. unlike other compressive sensing related works, this convex proxy solution is insufficient for our problem. the convex relaxation artefacts and noise yield multiple subspace representations, making identification of the exact number of motion subspaces challenging. we solve for the right number of subspaces by transforming this problem into a facility location problem with global cost and solve the factor graph formulation using max product belief propagation message passing.
cryptography	in this paper, we propose a new public key scheme, which is a combination of rsa variant namely the drsa and the generalization of generalized discrete logarithm problem (generalized gdlp). the security of this scheme depends equally on the integer factorization of n and the discrete logarithm problem (dlp) on z(n)*, where n is the product of two large primes and z(n)* is the multiplicative group modulo n. the scheme is a randomized algorithm. it is at least as secure as the drsa and elgamal schemes. we also compare the encryption-decryption performance of the proposed scheme with the rsa and drsa schemes.
pid_controller	we study a system of two parabolic nonlinear reaction-diffusion equations subject to a nonlocal boundary condition. this system of nonlinear equations is used for mathematical modeling of biosensors and bioreactors. the integral-type nonlocal boundary condition links the solution on the system boundary to the integral of the solution within the system inner range. this integral plays an important role in the nonlocal boundary condition and in the general formulation of the boundary value problem. the solution at boundary points is calculated using the integral combined with the proportional-integral-derivative controller algorithm. the mathematical model was applied for the modeling and control of drug delivery systems when prodrug is converted into active form in the enzyme-containing bioreactor before the delivering into body. the linear, exponential, and stepwise protocols of drug delivery were investigated, and the corresponding mathematical models for the prodrug delivery were created.
distributed_computing	the suites of numerical models used for simulating climate of our planet are usually run on dedicated high-performance computing (hpc) resources. this study investigates an alternative to the usual approach, i.e. carrying out climate model simulations on commercially available cloud computing environment. we test the performance and reliability of running the cesm (community earth system model), a flagship climate model in the united states developed by the national center for atmospheric research (ncar), on amazon web service (aws) ec2, the cloud computing environment by amazon.com, inc. starcluster is used to create virtual computing cluster on the aws ec2 for the cesm simulations. the wall-clock time for one year of cesm simulation on the aws ec2 virtual cluster is comparable to the time spent for the same simulation on a local dedicated high-performance computing cluster with infiniband connections. the cesm simulation can be efficiently scaled with the number of cpu cores on the aws ec2 virtual cluster environment up to 64 cores. for the standard configuration of the cesm at a spatial resolution of 1.9 degrees latitude by 2.5 degrees longitude, increasing the number of cores from 16 to 64 reduces the wall-clock running time by more than 50% and the scaling is nearly linear. beyond 64 cores, the communication latency starts to outweigh the benefit of distributed computing and the parallel speedup becomes nearly unchanged.
network_security	this paper designs and implements an embedded security gateway based on double-homed structure which composed of software and hardware parts. the core of hardware platform is based on two s3c6410 processors and one ep1c18f4620 fpga. the software is based on reduced linux kernel 3.0.1. the gateway uses net-filter/ip-tables firewall, ipsec vpn and network isolation technologies. and it can effectively reduce the risk of transmitting information by public network and improve the defensive capability. so it can be applied to the business with high security level.
operating_systems	latency jitter is a pressing problem in virtual reality (vr) applications. this paper analyzes latency jitter caused by typical interprocess communication (ipc) techniques commonly found in today 's computer systems used for vr. test programs measure the seal ability and latencies for various ipc techniques, where increasing number of threads are performing the same task concurrently. we use four different implementations on a vanilla linux kernel as well as on a real-time (rt) linux kernel to further assess if a rt variant of a multiuser multiprocess operating system can prevent latency spikes and how this behavior would apply to different programming languages and ipc techniques. we found that linux rt can limit the latency jitter at the cost of throughput for certain implementations. further, coarse grained concurrency should be employed to avoid adding up of scheduler latencies, especially for native system space ipc, while actor systems are found to support a higher degree of concurrency granularity and a higher level of abstraction.
electrical_network	the article present the problems of improving access to electrical network for new customers. it characterizes the influence of terms and costs of connection to distribution network on favorable investment climate. the aspects of the grid companies' network connection activities in russian federation and different countries were studied. it summarized the connection charge formation principles and methods used by government regulators in different jurisdictions are summarized. finally the proposals and recommendations improving the russian federation electricity distribution network connection are suggested.
microcontroller	this paper describes the implementation of a real-time, speaker-independent isolated speech recognition system using hidden markov models on a 32-bit arm cortex-m4f microcontroller. we introduce the theory, the requirements and details of the embedded implementation. the evaluation was made using a multi-speaker isolated-digit corpus of argentinian spanish, and its performance in terms of accuracy, speed and required memory was compared against a baseline dynamic time warping recognizer, implemented previously on the same architecture. test results show that the proposed hmm system outperforms the baseline system, and exhibits a recognition accuracy of 96.21% under a clean acoustic environment.
operational_amplifier	this paper deals with low offset operational amplifiers. it shows an innovative approach to design an operational amplifier (opamp) which combines two different techniques that make it able to handle both the technological and the radio frequency interference (rfi) induced offset.
symbolic_computation	in this type functional variable method has been used to private type of nonlinear fractional differential equations. the main property of the method demonstrate in its flexibility and ability to solve nonlinear equations accurately, efficiency and conveniently. the fractional derivatives are described in the modified riemann-liouville sense. three examples, are presented to show the application of the present technique. as a result, periodic and hyperbolic solutions are obtained.
image_processing	nucleic acids are responsible for the storage, transfer and realization of genetic information in the cell, which provides correct development and functioning of organisms. dna interaction with ligands ensures the safety of this information. over the past 10 years, advances in electron microscopy and image processing allowed to obtain the structures of key dna-protein complexes with resolution below 4 a. however, radiation damage is a limiting factor to the potentially attainable resolution in cryo-em. the prospect and limitations of studying protein-dna complex interactions using cryo-electron microscopy are discussed here. we reviewed the ways to minimize radiation damage in biological specimens and the possibilities of using radiation damage (so-called 'bubblegrams') to obtain additional structural information. (c) 2017 elsevier ltd. all rights reserved.
computer_vision	clinical decisions are sometimes based on a variety of patient 's information such as: age, weight or information extracted from image exams, among others. depending on the nature of the disease or anatomy, clinicians can base their decisions on different image exams like mammographies, positron emission tomography scans or magnetic resonance images. however, the analysis of those exams is far from a trivial task. over the years, the use of image descriptors-computational algorithms that present a summarized description of image regions-became an important tool to assist the clinician in such tasks. this paper presents an overview of the use of image descriptors in healthcare contexts, attending to different image exams. in the making of this review, we analyzed over 70 studies related to the application of image descriptors of different natures-e.g., intensity, texture, shape-in medical image analysis. four imaging modalities are featured: mammography, pet, ct and mri. pathologies typically covered by these modalities are addressed: breast masses and microcalcifications in mammograms, head and neck cancer and alzheimer 's disease in the case of pet images, lung nodules regarding cts and multiple sclerosis and brain tumors in the mri section.
computer_vision	salmon gelatin and boldine as a natural antioxidant were used to prepare edible films by a cold casting method. the concentration of each component was optimised by applying a box-behnken experimental design (bbd) with the goal of maximising radical scavenging capacity of film forming suspensions (ffs) measured by the 2,2-dipheny1-1-picrylhydrazyl (dpph) free radical assay. the results showed synergistic effect between gelatin and boldine for the antioxidant capacity (radical scavenging of over 80%) and antimicrobial activity of gelatin against escherichia coli atcc 25922 and listeria monocytogenes isp 6508. the release of boldine into the food simulant was faster for films containing 2 % gelatin than for those containing 4 %. kinetic data for boldine release from films fitted to the weibull model (r = 0,99). possible molecular interactions between gelatin and boldine were observed in the ftir spectrum of the composite films. within the range of 1638 to 1628 cm(-1) a strong interference caused by boldine in the hydrogen bonding between water and imide residues was observed. owing to the simultaneous antioxidant and antimicrobial activities displayed for the gelatinboldine films, there is potential for application in the preservation of some perishable fresh food such as fish, meat and cheese. (c) 2016 elsevier ltd. all rights reserved.
analog_signal_processing	in this paper, a new vlsi implementable hopf oscillator with dynamic plasticity is proposed for next-generation portable signal processing application. a circuit-realizable piece-wise linear function has been used to govern the frequency adaptation characteristic of the proposed oscillator. furthermore, a straightforward method is suggested to extract the frequency component of the input signal. mathematical model of the oscillator is derived and it is shown, using vhdl-ams model, that despite using a new nonlinear function, the oscillator exhibits the same characteristics and learning behavior as the original one with improved learning time. subsequently, an equivalent circuit model and transistor level implementation for the oscillator is suggested and the mathematical model is confirmed with system and circuit level simulations. capability of such oscillator to extract frequency futures without doing explicit signal processing is shown with examples of both synthetic and real-life emg signals.
computer_vision	the proliferation of large number of images has made it necessary to develop systems for indexing and organizing images for easy access. this has made content-based image retrieval (cbir) an important area of research in computer vision. this paper proposes a combination of features in multiresolution analysis framework for image retrieval. in this work, the concept of multiresolution analysis has been exploited through the use of wavelet transform. this paper combines local binary pattern (lbp) with legendre moments at multiple resolutions of wavelet decomposition of image. first, lbp codes of discrete wavelet transform (dwt) coefficients of images are computed to extract texture feature from image. the legendre moments of these lbp codes are then computed to extract shape feature from texture feature for constructing feature vectors. these feature vectors are used to search and retrieve visually similar images from large database. the proposed method has been tested on five benchmark datasets, namely, corel-1k, olivia-2688, corel-5k, corel-10k, and ghim-10k, and performance of the proposed method has been measured in terms of precision and recall. the expetimental results demonstrate that the proposed method outperforms some of the other state-of-the-art methods in terms of precision and recall. (c) 2016 elsevier inc. all rights reserved.
pid_controller	this paper investigates and compares the energetic and ergonomic performance of three different control logics (on-off, pid, fuzzy), used to regulate the emission of the heating system of an energy-efficient building. tests were carried out on an experimental building, equipped with three electric radiators and a sensor network mapping internal, external and surface thermal conditions. the building-technical system ensemble was evaluated in real time for a monitoring period of five/six days of non-occupancy, winter/midseason weather and mediterranean climate. all controllers were assessed with regard to thermal comfort and energy consumption in order to return an exhaustive scenario of possible strengths and weaknesses. the comparison showed that fuzzy logic, properly configured, outperformed both pid and on/off controllers reducing energy consumption of 30-70% and maintaining thermal dissatisfaction between comfort limits for all the monitoring period. (c) 2016 elsevier b.v. all rights reserved.
relational_databases	supply chain management is a critical domain for fast moving consumer goods (fmcgs). this domain is known for its complexity. new standards and regulations regarding energy efficiency and environmental aspects in general, as well as customer demand, make the analysis, modeling and design of the supply chain more and more complicated. partners involved in these processes are numerous and of diverse background. to help solving this problem, common understanding of the domain and exchange of information among partners involved in the supply chain is of high importance. an ontology capturing the knowledge of the domain was created. to achieve maximum efficiency of the domain operations in terms of cost, quality of service and environmental impact, concept definitions from multiple sources were gathered. an advanced software solution that leverages semantic web technologies, enables users to link data from multiple excel spreadsheets and relational databases together in real-time for data collection, collaboration, and reporting. in this framework, a new way for collaboration throughout the supply chain with the use of an underlying ontology, semantic technologies and visualization technics is introduced. the proposed approach is applied in the context of the fp7 european project e-save. (c) 2015 the authors. published by elsevier ltd.
data_structures	we describe a general framework c2i for generating an invariant inference procedure from an invariant checking procedure. given a checker and a language of possible invariants, c2i generates an inference procedure that iteratively invokes two phases. the search phase uses randomized search to discover candidate invariants and the validate phase uses the checker to either prove or refute that the candidate is an actual invariant. to demonstrate the applicability of c2i , we use it to generate inference procedures that prove safety properties of numerical programs, prove non-termination of numerical programs, prove functional specifications of array manipulating programs, prove safety properties of string manipulating programs, and prove functional specifications of heap manipulating programs that use linked list data structures.
operating_systems	in the new era of cyber-physical systems, software must adapt itself to ever-changing environmental conditions and situations. this is currently not reflected in the design of embedded operating systems, since they are primarily optimized for fixed usage scenarios with tight resource constraints. we discuss the idea of interpreted operating system kernels, which can form a new foundation for highly reconfigurable embedded systems. the paper elaborates reasonable use cases, shows comparable approaches from the past and sketches an implementation strategy that is based on a bare-metal python interpreter.
symbolic_computation	in this article, the prolongation structure technique is applied to a generalised inhomogeneous gardner equation, which can be used to describe certain physical situations, such as the stratified shear flows in ocean and atmosphere, ion acoustic waves in plasmas with a negative ion, interfacial solitary waves over slowly varying topographies, and wave motion in a non-linear elastic structural element with large deflection. the lax pairs, which are derived via the prolongation structure, are more general than the lax pairs published before. under the painleve conditions, the linear-damping coefficient equals to zero, the quadratic non-linear coefficient is proportional to the dispersive coefficient c(t), the cubic non-linear coefficient is proportional to c(t), leaving no constraints on c(t) and the dissipative coefficient d(t). we establish the prolongation structure through constructing the exterior differential system. we introduce two methods to obtain the lax pairs: (a) based on the prolongation structure, the lax pairs are obtained, and (b) via the lie algebra, we can derive the pfaffian forms and lax pairs when certain parameters are chosen. we set d(t) as a constant to discuss the influence of c(t) on the pfaffian forms and lax pairs, and to discuss the influence of d(t) on the pfaffian forms and lax pairs, we set c(t) as another constant. then, we get different prolongation structure, pfaffian forms and lax pairs.
distributed_computing	cloud computing which uses outsourcing and remote processing of applications first appeared about ten years ago. cloud computing built on research in virtualization, distributed computing, utility computing, and web services. it reduces the information technology overhead for starting a new business and it can be accessed from anywhere. one of the concepts used for constructing cloud computing is virtualization, which has its own security risks, but they are not specific to the cloud. the key drawback to adopting cloud computing is security since clients use someone else 's cpu and hard disk for processing and storing data. this paper proposes a security framework to secure virtual machine images in a virtualization layer in the cloud environment. securing the virtual machine image is significant as it will most probably affect the security of cloud computing.
data_structures	we study the problem of indexing a text t[1...n] such that whenever a pattern p[1...p] and an interval [alpha, beta] come as a query, we can report all pairs (i, j) of consecutive occurrences of p in t with alpha <= j - i <= beta. we present an o (n logn) space data structure with optimal o (p + k) query time, where k is the output size. (c) 2016 elsevier b.v. all rights reserved.
cryptography	in this paper, we propose two new algorithms and their hardware implementations for the normal basis multiplication over gf(p(m)), where p is an element of {2, 3}. in this case, the proposed multipliers are designed using serial and digit-serial hardware architectures. the normal basis multipliers over gf(2(m)) and gf(3(m)) are based on two proposed algorithms to compute the multiplication matrices t-k in order to speed-up the execution time and to reduce the area resources. it can be seen that the new hardware architecture for the nb multiplier over gf(2(m)) has the best characteristics of area complexity presented by reyhani [16] and time complexity presented by azarderakhsh and reyhani [31]. the proposed hardware architectures for the normal basis multipliers over gf(2(163)), gf(2(233)), gf(2(283)), gf(2(409)), gf(3(89)) and gf(3(233)) were described in vhdl, and simulated and synthesized using modelsim and quartus prime v16, respectively.
operating_systems	many-core architectures trade single-thread performance for a larger number of cores. scalable throughput can be attained only by a high degree of parallelism and minimized synchronization. whilst this is achievable for many applications, the operating system still introduces bottlenecks through non-local sharing, synchronization, and message passing. a particular challenge for highly dynamic applications, for example invasive hpc applications and elastic compute clouds, is the management of short-living application threads and processes. this paper discusses os architecture choices based on microkernel, multikernel and distributed systems designs and our development experience in the context of the mythos project. initial experiments show a much faster thread creation and activation compared to monolithic systems like linux while providing a more flexible protection and threading model that is better suited for dynamic scenarios. however, despite significant progress in the overall domain of operating systems, the design space for scalable many-core operating systems is yet to be fully explored.
electric_motor	this paper presents the personalized satellite radio, a novel satellite-based radio concept, capable of providing radio services to vehicular terminals. this paper describes the technical solution proposed, which overcomes the classical streaming approach used for traditional radio. the main concept behind it is that individual audio and multimedia files are broadcast to the mobile users instead of transmitting a number of continuous streams. the received files are stored in a large cache located in the receiver of each mobile terminal and are sequentially played to generate a service similar to traditional radio/entertainment programmes. the resulting file-based radio approach makes, in particular, use of higher-layer coding at the transport layer and smart techniques to build up an audible programme with no interruptions and full audio quality based oil the available files. this paper also presents the results of extensive trials that were conducted with a system prototype developed in the framework of an european space agency funded project. copyright (c) 2008 john wiley & sons, ltd.
network_security	against multipoint eavesdropping attack in elastic optical networks, new objective criterion, security strategy and extended routing and spectrum allocation algorithm is proposed the simulation results shows that better security guarantee and resource utilization are provided.
state_space_representation	although there are many successful applications of neural networks (nns), however, there are still some drawbacks in using neural networks (nns) in any control scheme. in this study an nn-based model is applied for a tension leg platform (tlp) system. a linear differential inclusion (ldi) state-space representation is constructed to represent the dynamics of the nn model. control performance is achieved by using the parallel distributed compensation (pdc) scheme to ensure the stability of tlp systems subjected to an external wave force. in terms of the stability analysis, the linear matrix inequality (lmi) conditions are derived using the lyapunov theory to guarantee the robustness design and stability of the tlp system. a simulation example based on practical data is given to demonstrate the feasibility of the proposed fuzzy control approach. in the end, we discuss a practical application with field data on the wave properties and structural characteristics. the results indicate the efficiency and robustness of the proposed nn based approach. (c) 2012 published by elsevier b.v.
control_engineering	this paper presents the idea about how to combine a set of software and hardware resources available in literature to be used as support to control engineering education. the available tools allow to mix topics related to programming, communications, operating systems, and control theory. the well-known raspberry pi board is used as platform to exploit the di_erent proposed concepts. scipy, matplotlib, and numpy libraries, which are python-based open-source libraries for scienti_c computing and graphical representation, are used to perform matlab-like simulations and to implement classical control loops. on the other hand, virtual processes developed in easy java simulations are adapted to be controlled through the network from a controller implemented on the raspberry pi with python. this option is very useful from a teaching point of view since time-based, networked-based, or event-based control approaches can be easily introduced on this proposed architecture. furthermore, once students know how to implement control loops on the raspberry pi using python, external real processes can be easily controlled by using the gpio interface available in the this electronic board. then, a project based on these tools and ideas is motivated and presented in this paper to control a two-tank level process (c) copyright ifac 2015. (c) 2015, ifac international federation of automatic control) hosting by elsevier ltd. all rights reserved.
operational_amplifier	the paper presents a high-voltage integrated-circuit driver capable of producing analog voltages up to 300 v, using dalsa 's 0.8-mu m hv cmos/dmos process, suitable for mems and medical systems. the ic driver includes a hv operational amplifier (op-amp) with a class-b output stage, and hv analog switches with improved off-isolation performance. in contrast to previous frequency compensation schemes, where only one dominant pole occurs below the unity-gain bandwidth, the hv op-amp employs a novel frequency compensation topology with three poles and two zeros located within the unity-gain bandwidth, and is capable of driving large capacitive loads from 100 pf to 10 nf. theoretical analysis of off-isolation of the hv analog switches is also reported and confirms the improvement in off-isolation performance.
electric_motor	purpose: - the purpose of the paper is to introduce a novel design topology for an electric motor, which has essentially none of the normal sources of magnetic alternating force. design/methodology/approach: - two-dimensional (2d) and three-dimensional (3d) finite element methods are used to analyze the electromagnetic performance of the proposed machine. 3d integral equations are used to calculate the scalar potentials. detailed manufacturing process and the results of the testing are presented. findings - the new design will eliminate core vibrations, slot passing frequency vibrations and torque pulsations. the motor also has the property that the external magnetic field is controllable and tunable after the construction. social implications - this approach increases the motor efficiency. originality/value: - the proposed machine has low field and vibration, so it can be used where low exterior fields are required.
system_identification	attempts are being made to improve mechanical design by using nonlinearity rather than eliminating it, especially in the area of vibration control and in energy harvesting. in such systems, there is a need to both predict the dynamic behavior and to estimate the system properties from measurements. this paper concerns an experimental investigation of a simple identification method, which is specific to systems in which the behavior is known to be similar to that of a duffing-type system. it involves the measurement of jump-down frequencies and the amplitudes of displacement at these frequencies. the theoretical basis for the method is briefly described as, is an experimental investigation on a beam-shaker system. the results are comparable with those determined by the restoring force surface method. the method described in this article has the advantage that the data can be collected and processed more easily than the restoring force surface method and can be potentially more suitable for the engineering community than existing identification measures.
distributed_computing	this paper presents a cloud-based system framework based on bigtable and mapreduce as the data storage and processing paradigms for providing a web-based service for viewing, storing, and analyzing massive building information models (bims). cloud and web 3d technologies were utilized to develop a bim data center that can handle the big data of massive blms using multiple servers in a distributed manner and can be accessed by multiple users to concurrently submit and view bims online in 3d. traditional bim include only static information such as the geometric parameters, physical properties, and spatial relations for modeling a physical space. in this study, bim was extended to dynamic bim, which includes dynamic data such as historical records from the monitoring of the facility environment and usage. owing to this extension, a dynamic bim became a parametric model, which can be used to simulate user behaviors. on the client side, this study applied webgl in the web interface development to achieve the display of bims in 3d on browsers. users can access the services via various online devices anytime and anywhere to view the 3d model online. on the server side, this study used apache hadoop, which can utilize multiple servers to provide mass storage spaces in a distributed manner with bigtable-like structured storage, to establish the bim data center. a schema for storing the big data of massive dynamic bims in bigtables was proposed. mapreduce, a hadoop component for the parallel processing of large data sets, was utilized to process big data from dynamic bims. a big data analysis framework to effectively retrieve and calculate required information from dynamic bims in the data center for various applications by mapreduce distributed computing was proposed this study. we provide principle and architecture of the proposed framework along with its experimental assessment. the results confirmed that scalable and reliable management of massive bims can be achieved using the proposed framework. (c) 2016 elsevier b.v. all rights reserved.
electricity	residential domestic hot water energy consumption represented 16% of the eu household heating demand in 2013. with the improvement of the building insulation envelope, domestic hot water contribution to energy consumption is expected to increase significantly, with values between 20% and 32% in single family buildings, and between 35% to almost 50% in multifamily buildings. this energy, currently lost to the environment, can be recovered by waste water heat recovery systems inside buildings (in building solutions). while most publications in this field focus on shower heat recovery and on waste water as heat source for heat pumps, the detailed impact of waste water heat recovery at a city scale by aggregating building data has not been addressed yet. furthermore, waste water heat recovery potential and relevance was not yet quantified as a function of the specific inhabitant and household numbers, end-use occurrence, and building type and age. a method to quantify the building-specific energy cost and energy saving potentials, based on pinch analysis, at the urban scale of in-building waste water heat recovery systems is therefore proposed. a complementary method to spatially allocate and characterise grey water streams as to thermal load and temperature levels in function of the building specificities is also developed. these methods are applied in two case studies, first as retrofitting solution in a city in luxembourg and, second, as optimisation measure for high efficiency residential buildings. grey water heat recovery would reduce the residential fuel consumption of the city by 63%. an integrated approach combining grey water heat recovery for hot water preheating and a heat pump yields up to 28% and 41% electricity savings for passive single family houses and multifamily buildings, respectively. with the detailed characterisation of various grey water streams as a function of inhabitant number and end -use occurrence, the quantification of the energy savings and costs through heat recovery is improved. the outcomes of urban energy and cost assessments concerning grey water heat recovery are more specific, as the results at building level are aggregated to the considered geographical scope. the proposed method therefore complements current urban energy and cost assessments with the detailed integration of in -building grey water heat recovery systems. (c) 2017 published by elsevier ltd.
machine_learning	in medical decision support systems, both the accuracy (i.e., the ability to adequately represent the decision making processes) as well as the transparency and interpretability (i.e., the ability to provide a domain user with compact and understandable explanation and justification of the proposed decisions) play essential roles. this paper presents an approach for automatic design of fuzzy rule-based classification systems (frbcss) from medical data using multi-objective evolutionary optimization algorithms (moeoas). our approach generates, in a single run, a collection of solutions (medical frbcss) characterized by various levels of accuracy-interpretability trade-off. we propose a new complexity-related interpretability measure and we address the semantics-related interpretability issue by means of efficient implementation of the so-called strong fuzzy partitions of attribute domains. we also introduce a special coding-free representation of the rule base and original genetic operators for its processing as well as we implement our ideas in the context of well-known and one of the presently most advanced moe0a5, i.e., non-dominated sorting genetic algorithm ii (nsga-ii). an important part of the paper is devoted to a broad comparative analysis of our approach and as many as 26 alternative techniques arranged in 32 experimental set-ups and applied to three well-known benchmark medical data sets (breast cancer wisconsin (original), pima indians diabetes, and heart disease (cleveland)) available from the uci repository of machine learning databases (http://archive.ics.uci.edu/ml). a number of useful in medical applications performance measures including accuracy, sensitivity, specificity, and several interpretability measures are employed. the results of such a broad comparative analysis demonstrate that our approach significantly outperforms the alternative methods in terms of the interpretability of the obtained frbcss while remaining either competitive or superior in terms of their accuracy. it is worth stressing that the overwhelming majority of the existing medical classification methods concentrate almost exclusively on the accuracy issues. (c) 2016 elsevier ltd. all rights reserved.
bioinformatics	chinese herbal medicine (chm) plays a significant role in breast cancer treatment. we conduct the study to ascertain the relative molecular targets of effective chinese herbs in treating stage iv breast cancer. survival benefit of chm was verified by kaplan-meier method and cox regression analysis. a bivariate correlation analysis was used to find and establish the effect of herbs in complex chm formulas. a network pharmacological approach was adopted to explore the potential mechanisms of chm. patients in the chm group had a median survival time of 55 months, which was longer than the 23 months of patients in the non-chm group. cox regression analysis indicated that chm was an independent protective factor. correlation analysis showed that 10 herbs were strongly correlated with favorable survival outcomes (p<0.01). bioinformatics analyses suggested that the 10 herbs might achieve anti-breast cancer activity primarily through inhibiting hsp90, er alpha and top-ii related pathways.
operational_amplifier	in this paper a new cmos operational amplifier using a darlington pair based gain boosted technique has been enunciated. the proposed opamp shows high gain as well as high ugb using capacitor compensation technique and proper biasing circuit. it is operated on rail to rail power supply of +/- 900mv. this amplifier is highly useful for wireless communications due to low power consumption, high bandwidth, high gain and high noise immunity. the designed operational amplifier gain is 89db, bandwidth is 4.40 ghz and phase margin is 67(o), and slew rate is 991.6v/mu s. this circuit is designed using cadence analog & digital system design tools of gpdk45nm technology.
bioinformatics	decidualization of endometrial stromal cells is an important feature of implantation and pregnancy. the molecular mechanism underlying decidualization remains unclear, particularly regarding the microrna (mirna/mir) regulation of this process. the present study revealed the temporal and spatial distribution of mmu-mir-96 in the mouse uterus during early pregnancy by reverse transcription-quantitative polymerase chain reaction and in situ hybridization. in addition, primary stromal cells were isolated from the mouse uterus and used to explore the role of mmu-mir-96 in decidualization. the results demonstrated that mmu-mir-96 was highly expressed in stromal cells during pregnancy, and was upregulated at implantation sites. in addition, mmu-mir-96 was strongly expressed during decidualization, which indicates that it may serve a role in the decidualization of stromal cells. based on existing reports, mmu-mir-96 participates in apoptosis; therefore the present study investigated its effects on the apoptosis of primary endometrial stromal cells. the results indicated that overexpression of mmu-mir-96 may induce apoptosis of stromal cells. in further studies regarding the underlying mechanism, the target genes of mmu-mir-96 were screened by bioinformatics analysis, and it was confirmed that b-cell lymphoma 2, an anti-apoptotic gene, was the target of mmu-mir-96, as determined using a reporter gene assay. in conclusion, the present study suggested that mmu-mir-96 participates in the decidualization of endometrial stromal cells in mice, thereby serving a key role in pregnancy.
network_security	protecting control planes in networking hardware from high rate packets is a critical issue for networks under operation. one common approach for conventional networking hardware is to offload expensive functions onto hard-wired offload engines as asics. this approach is inadequate for openflow networks because it restricts a certain amount of flexibility for network control that openflow tries to provide. therefore, we need a control plane protection mechanism in openflow switches as a last resort, while preserving flexibility for network control. in this paper, we propose a mechanism to filter out packet-in messages, which include packets handled by the control plane in openflow networks, without dropping important ones for network control. switches record values of packet header fields before sending packet-in messages, and filter out packets that have the same values as the recorded ones. the controllers set the header fields in advance whose values must be recorded, and the header fields are selected based on controller design. we have implemented and evaluated the proposed mechanism on a prototype software switch, concluding that it dramatically reduces cpu loads on switches while passes important packet-in messages for network control.
symbolic_computation	through symbolic computation with maple, the rational solutions and the lump solutions of the generalized (3 + 1)-dimensional shallow water-like equation are presented by using the generalized bilinear operator when the parameter p = 3. it is pointed that these rational solutions are classified into five classes because they are obtained mainly by depending on the polynomial solutions. the resulting lump solutions which are rationally localized in all directions in the space are acquired by making use of the quadratic function. however, not every nonlinear partial differential equation has the lump solutions, if any, the quantity of the lump solutions is fewer than the rational solutions. only one class of lump solutions of the generalized (3 + 1)-dimensional shallow water-like equation is gotten and three 3d plots with specific values of the involved parameters are plotted. (c) 2016 elsevier ltd. all rights reserved.
system_identification	an approach for universal modeling and tracker design for input-constrained unknown nonlinear input time-delay stochastic sampled-data systems is newly proposed in this paper. first, the improved observer/kalman filter identification (okid) method, which uses the current output measurement to estimate the current state, is newly proposed in this paper and it is shown that it outperforms the traditional okid method. in addition, it is shown that the newly proposed current output-based kalman filter is a well-performed output estimator in the extreme case, in which it is not a filter anymore, becoming a universal way of formulating an artificial system model of a real physical process without disturbing its normal operation. consequently, the proposed artificial system model has the following advantages: (i) it is capable of quantifying the stochastic and deterministic characteristics of the dynamical system of interest; (ii) it is capable of carrying out the analyses of various control-design methodologies to achieve the performance specifications in the pre-study phase; and (iii) it is capable of estimating missing and/or abnormal output measurements during the testing and/or practical operating phases. furthermore, an alternative re-designed current output-based observer is newly proposed in this paper, in order to develop a modified observer-based model predictive control (mpc) with input constraints to improve the performance of the unknown nonlinear time-delay stochastic system. when the proposed artificial system model is used together with the proposed constrained mpc, a long-time prediction of future input-output sets in a closed-loop setting can be carried out. finally, the operation of a temperature controlled real nonlinear input time-delay blast furnace process is presented as a case study in this paper, to show the effectiveness of the proposed mechanism. (c) 2016 elsevier inc. all rights reserved.
image_processing	in this study, the temperature and viscosity-dependent methods were used to identify the main heat conduction mechanism in nanofluids. three sets of experiments were conducted to investigate the effects of brownian motion and aggregation. image processing approach was used to identify detailed configurations of different nanofluids microstructures. the thermal conductivity of the nanofluids was measured with respect to the dynamic viscosity in the temperature range between 0 and 55 degrees c. the results clearly indicated that the nanoparticle brownian motion did not play a significant role in heat conduction of nanofluids, which was also supported by the observation that a more viscous sample rendered a higher thermal conductivity. moreover, the microscopic pictures and the differences in the viscosity between theoretical and experimental values suggested the major role of particle aggregation and clustering. (c) 2017 elsevier ltd. all rights reserved.
distributed_computing	attention is a very important cognitive and behavioral process, by means of which an individual is able to focus on a single aspect of information, while ignoring others. in a time in which we are drawn in notifications, beeps, vibrations and blinking messages, the ability to focus becomes increasingly important. this is true in many different domains, from the workplace to the classroom. in this paper we present a non-intrusive distributed system for monitoring attention in teams of people. it is especially suited for teams working at the computer. the presented system is able to provide real-time information about each individual as well as information about the team. it can be very useful for team managers to identify potentially distracting events or individuals, as well as to detect the onset of mental fatigue or boredom, which significantly influence attention. in the overall, this tool may prove very useful for team managers to implement better human resources management strategies.
bioinformatics	the ex vivo challenge assay is being increasingly used as an efficacy endpoint during early human clinical trials of hiv prevention treatments. there is no standard methodology for the ex vivo challenge assay, although the use of different data collection methods and analytical parameters may impact results and reduce the comparability of findings between trials. in this analysis, we describe the impact of data imputation methods, kit type, testing schedule and tissue type on variability, statistical power, and ex vivo hiv growth kinetics. data were p24 antigen (pg/ml) measurements collected from clinical trials of candidate microbicides where rectal (n = 502), cervical (n = 88), and vaginal (n = 110) tissues were challenged with hiv-1(bal) ex vivo. imputation of missing data using a nonlinear mixed effect model was found to provide an improved fit compared to imputation using half the limit of detection. the rectal virus growth period was found to be earlier and of a relatively shorter duration than the growth period for cervical and vaginal tissue types. on average, only four rectal tissue challenge assays in each treatment and control group would be needed to find a one log difference in p24 to be significant (alpha = 0.05), but a larger sample size was predicted to be needed for either cervical (n = 21) or vaginal (n = 10) tissue comparisons. overall, the results indicated that improvements could be made in the design and analysis of the ex vivo challenge assay to provide a more standardized and powerful assay to compare efficacy of microbicide products.
operating_systems	configuration options are widely used for customizing the behavior and initial settings of software applications, server processes, and operating systems. their distinctive property is that each option is processed, defined, and described in different parts of a software project - namely in code, in configuration file, and in documentation. this creates a challenge for maintaining project consistency as it evolves. it also promotes inconsistencies leading to misconfiguration issues in production scenarios. we propose an approach for detection of inconsistencies between source code and documentation based on static analysis. our approach automatically identifies source code locations where options are read, and for each such location retrieves the name of the option. inconsistencies are then detected by comparing the results against the option names listed in documentation. we evaluated our approach on multiple components of apache hadoop, a complex framework with more than 800 options. our tool orplocator was able to successfully locate at least one read point for 93% to 96% of documented options within four hadoop components. a comparison with a previous state-of-the-art technique shows that our tool produces more accurate results. moreover, our evaluation has uncovered 4 previously unknown, real-world inconsistencies between documented options and source code.
analog_signal_processing	this paper describes the theoretical background of electromagnetic induction from metal objects modelling. the response function of a specific case of object shape - a homogenous sphere from ferromagnetic and non-ferromagnetic material is introduced. experimental data measured by a metal detector excited with a linearly frequency-swept signal are presented. as a testing target various spheres from different materials and sizes were used. these results should lead to better identification of the buried object.
symbolic_computation	the algebraic and algorithmic study of integro-differential algebras and operators has only started in the past decade. integro-differential operators allow us in particular to study initial value and boundary problems for linear odes from an algebraic point of view. differential operators already provide a rich algebraic structure with a wealth of results and algorithmic methods. adding integral operators and evaluations, many new phenomena appear, including zero devisors and non-finitely generated ideals. in this tutorial, we give an introduction to symbolic methods for integro-differential operators and boundary problems developed over the last years. in particular, we discuss normal forms, basic algebraic properties, and the computation of polynomial solutions for ordinary integro-differential equations with polynomial coefficients. we will also outline methods for manipulating and solving linear boundary problems and illustrate them with an implementation.
pid_controller	this study investigates the application of the sliding mode controller (smc) for induction motor drive variable-displacement pressure-compensated pump (vdpc) system powered by an isolated wind/storage unit. the variable-speed wind turbine (wt) is proposed to drive a permanent magnet synchronous generator (pmsg) which, feeds a storing energy unit and stand-alone dynamic load. energy storage systems are required for power balance quality in isolated wind power systems. initially, the holistic model of the entire system is achieved, including the pmsg, the uncontrolled rectifier, the buck converter, the storage system, induction machine and the vdpc pump. the power absorbed by the connected loads can be effectively delivered and supplied by the proposed wt and energy storage systems, subject to sliding mode control. the main purposes are to supply 220 v/50 hz through a three-phase inverter and adjust the im speed and vdpc pump flow rate. the performance of the proposed system is compared with the neural network control and the conventional pid control. the simulation results show that the proposed system with the smc and neural network controllers has good performance and good prediction of the electrical parameter waveforms compared with the case of the conventional pid controller.
software_engineering	the energy consumption of computer systems has become an important economic and environmental issue. many researchers have focused on the energy consumption of hardware, but what about the software? software energy consumption is widely adopted for green computation of practical experimentation in research laboratories. but current researchers fail to build a consistent concept base for software energy consumption of critical applications. while branch coverage and concolic testing are very critical practices to validate the safety critical systems, very little effort is given to measure their energy consumption. the computation of the energy consumption of these techniques is an important issue in green it and green software engineering. the contribution of this paper is to automate the computation and analysis of the energy consumption of the testing technique while enhancing the branch coverage using concolic testing. we implement our proposed automation framework in a tool, named green analysis of branch coverage enhancement. the empirical study with forty java programs and the evaluation results show that our developed tool achieves an average increase of 13.5 % in branch coverage. the average energy consumption of our automated tool is approximately 5.6 kj to compute the branch coverage for all the forty experimental programs.
computer_vision	bacterial nanocellulose (bnc) is an emerging nanomaterial with a morphologic structure of a 3-d network and unique properties produced by several species of bacteria. the objective of the present work was to evaluate whether the addition of bnc improved the baking quality of wheat flours, making a change in the viscoelastic behavior of the mass. a study of the rheological behavior of wheat bread dough containing bnc was performed by thermo-rheological and isothermal dynamic oscillatory experiments. the baking response and bread quality parameters were also analyzed. bnc increased specific volume, and moisture retention, decreasing browning index. although bnc produced both raw and heat-treated doughs with more elastic characteristics, textural studies revealed that the addition of bnc reduced firmness of bread crumb. confocal laser scanning microscopy observations showed differences in gluten filaments between control and bnc crumb samples that could explain the larger average porous size of bnc crumb. bnc could be used as improver in the bread-making performance. (c) 2017 elsevier ltd. all rights reserved.
electric_motor	an x17.2 solar flare occurred on 2003 october 28, accompanied by multi-wavelength emissions and a high flux of relativistic particles observed at 1 au. we present the analytic results of the trace, soho, rhessi, ace, goes, hard x-ray (integral satellite), radio (onderejov radio telescope), and neutron monitor data. it is found that the inferred magnetic reconnection electric field correlates well with the hard x-ray, gamma-ray, and neutron emission at the sun. thus the flare 's magnetic reconnection probably makes a crucial contribution to the prompt relativistic particles, which could be detected at 1 au. since the neutrons were emitted a few minutes before the injection of protons and electrons, we propose a magnetic-field evolution configuration to explain this delay. we do not exclude the effect of cme-driven shock, which probably plays an important role in the delayed gradual phase of solar energetic particles.
electricity	state-of-energy (soe) is an important index for batteries in electric vehicles and it provides the essential basis of energy application, load equilibrium and security of electricity. to improve the estimation accuracy and reliability of soe, a novel multi-model fusion estimation approach is proposed against uncertain dynamic load and different temperatures. the main contributions of this work can be summarized as follows: (1) through analyzing the impact on the estimation accuracy of soe due to the complexity of models, the necessity of redundant modeling is elaborated. (2) three equivalent circuit models are selected and their parameters are identified by genetic algorithm offline. linear matrix inequality (lmi) based h-infinity state observer technique is applied to estimate soes on aforementioned models. (3) the concept of fusion estimation is introduced. the estimation results derived by different models are merged under certain weights which are determined by bayes theorem. (4) batteries are tested with dynamic load cycles under different temperatures to validate the effectiveness of this method. the results indicate the estimation accuracy and reliability on soe are elevated after fusion. (c) 2016 elsevier ltd. all rights reserved.
digital_control	a number of measures to increase the quality of data recorded with an improved balzers eldigraph kd-g2 gas-phase electron diffractometer are discussed. the beam-stop has been decoupled from the sector enabling us recording the current of the primary beam and scattered electrons during the experiment. different beam-stops were tested for use in the present setup. modifications of the nozzle tip of an earlier described medium temperature nozzle are reported. the measures lead to reduced exposure times and reduced amount of sample necessary for complete data collection.
cryptography	we have realized a multifunctional aerial display. an aerial image of a polarization-processing display is formed through aerial imaging by retro-reflection. by changing the polarization modulation patterns, we can switch between a three-layered display and a secure display.
electric_motor	a power operated detrasher was developed for removal of green top as well as dry trash from the harvested sugarcane stalks. it consisted of mechanisms for cane feeding, detrashing and delivery. it separates the top from the cane by breaking it from the natural weak point at the joint of immature top with mature cane stalks. it can be transported on three point linkage of the tractor and operated by an electric motor, diesel engine or tractor pto. performance of the equipment was evaluated by feeding different varieties of harvested canes, with their tops first, to the detrashing rollers through the feeding chute. the trash left on the cane after passing through the detrasher varied from 1.5 to 6.6 %. trash removal efficiency varied from 77.5 to 94.5 % depending upon the variety. the output of the detrasher was 2.4 t/h. there was a saving of about 17 % in cost of operation and 84 % in labour requirement using the detrasher as compared to manual method.
pid_controller	for decades, pid (proportional + integral + derivative)-like controllers have been successfully used in academia and industry for many kinds of plants. this is thanks to its simplicity and suitable performance in linear or linearized plants, and under certain conditions, in nonlinear ones. a number of pid controller gains tuning approaches have been proposed in the literature in the last decades; most of them off-line techniques. however, in those cases wherein plants are subject to continuous parametric changes or external disturbances, online gains tuning is a desirable choice. this is the case of modular underwater rovs (remotely operated vehicles) where parameters (weight, buoyancy, added mass, among others) change according to the tool it is fitted with. in practice, some amount of time is dedicated to tune the pid gains of a rov. once the best set of gains has been achieved the rov is ready to work. however, when the vehicle changes its tool or it is subject to ocean currents, its performance deteriorates since the fixed set of gains is no longer valid for the new conditions. thus, an online pid gains tuning algorithm should be implemented to overcome this problem. in this paper, an auto-tune pid-like controller based on neural networks (nn) is proposed. the nn plays the role of automatically estimating the suitable set of pid gains that achieves stability of the system. the nn adjusts online the controller gains that attain the smaller position tracking error. simulation results are given considering an underactuated 6 dof (degrees of freedom) underwater rov. real time experiments on an underactuated mini rov are conducted to show the effectiveness of the proposed scheme.
pid_controller	an improved proportional-integral-derivative (pid) controller based on predictive functional control (pfc) is proposed and tested on the chamber pressure in an industrial coke furnace. the proposed design is motivated by the fact that pid controllers for industrial processes with time delay may not achieve the desired control performance because of the unavoidable model/plant mismatches, while model predictive control (mpc) is suitable for such situations. in this paper, pid control and pfc algorithm are combined to form a new pid controller that has the basic characteristic of pfc algorithm and at the same time, the simple structure of traditional pid controller. the proposed controller was tested in terms of set-point tracking and disturbance rejection, where the obtained results showed that the proposed controller had the better ensemble performance compared with traditional pid controllers. (c) 2016 isa. published by elsevier ltd. all rights reserved.
pid_controller	process control courses usually have a section of the course focused on the building of block diagrams for modeling, simulation, and analysis of open and closed loop processes. for this purpose, students are often oriented to build models using simulink or xcos because of the versatility of these powerful tools in the easy construction of mathematical models using the concept of block-oriented programming. in this paper we propose a model library built in the software emso that allows the user to create block diagrams for process control studies. emso is a powerful tool for process modeling, dynamic simulation and optimization, freely available for academic purpose. with the developed library, analysis of systems responses, even for complex processes, can be carried out and pid controller tuning tasks are made easier and less time-consuming to the students, allowing them to advance in the study of more complex control strategies such as ratio, cascade, override, feed forward, among others. students valued the developed tool as a very useful and practical one to favor a control course learning process and between equivalent and advantageous tool when compared with simulink and xcos. (c) 2016 institution of chemical engineers. published by elsevier b.v. all rights reserved.
system_identification	reliable and accurate short-term subway passenger flow prediction is important for passengers, transit operators, and public agencies. traditional studies focus on regular demand forecasting and have inherent disadvantages in predicting passenger flows under special events scenarios. these special events may have a disruptive impact on public transportation systems, and should thus be given more attention for proactive management and timely information dissemination. this study proposes a novel multiscale radial basis function (msrbf) network for forecasting the irregular fluctuation of subway passenger flows. this model is simplified using a matching pursuit orthogonal least squares algorithm through the selection of significant model terms to produce a parsimonious msrbf model. combined with transit smart card data, this approach not only exhibits superior predictive performance over prevailing computational intelligence methods for non-regular demand forecasting at least 30 min prior, but also leverages network knowledge to enhance prediction capability and pinpoint vulnerable subway stations for crowd control measures. three empirical studies with special events in beijing demonstrate that the proposed algorithm can effectively predict the emergence of passenger flow bursts. (c) 2017 elsevier ltd. all rights reserved.
electrical_circuits	in this paper the electronic implementation of fitzhugh-nagumo (f-n) neurons via monolithic microwave integrated circuits (mmic) based upon a resonant tunneling diode (rtd) nonlinear transmission line (nltl) using a coplanar waveguide (cpw) is considered. the goals are twofold. in the framework of electrical equivalent circuit emulating nonlinear active wave propagation effects, it is shown, on one hand, how different physical mechanisms are responsible for the time evolution of given input signals. a key result is that this medium supports stable and stationary pulse propagation that is only determined by the parameters of the rtd-nltl and is independent of the boundary conditions. on the other hand, the influence of specific line elements on the output signal waveform is discussed in a most systematic manner. this leads, for the first time, to a more physical interpretation of the properties of the rtd-nltl and, furthermore, to interesting technical applications at multi-ghz frequencies and on picosecond time scales. as a result, physically based ways are elucidated regarding how the technical design of those compact neuromorphic electrical circuits can be optimized by numerical simulations and performed using standard mmic technologies.
network_security	cyber-physical embedded systems (cpess) are distributed embedded systems integrated with various actuators and sensors. when it comes to the issue of cpes security, the most significant problem is the security of embedded sensor networks (esns). with the continuous growth of esns, the security of transferring data from sensors to their destinations has become an important research area. due to the limitations in power, storage, and processing capabilities, existing security mechanisms for wired or wireless networks cannot apply directly to esns. meanwhile, esns are likely to be attacked by different kinds of attacks in industrial scenarios. therefore, there is a need to develop new techniques or modify the current security mechanisms to overcome these problems. in this article, we focus on intrusion detection (id) techniques and propose a new attack-defense game model to detect malicious nodes using a repeated game approach. as a direct consequence of the game model, attackers and defenders make different strategies to achieve optimal payoffs. importantly, error detection and missing detection are taken into consideration in intrusion detection systems (idss), where a game tree model is introduced to solve this problem. in addition, we analyze and prove the existence of pure nash equilibrium and mixed nash equilibrium. simulations show that the proposed model can both reduce energy consumption by up to 50% compared with the existing all monitor (am) model and improve the detection rate by up to 10% to 15% compared with the existing cluster head (ch) monitor model.
relational_databases	in this paper, we consider restricted data sharing between a set of parties that wish to provide some set of online services requiring such data sharing. each party is assumed to store its data in private relational databases, and is given a set of mutually agreed set of authorization rules that specify access to attributes over individual relations or joins over relations owned by one or more parties. the access restrictions introduce significant additional complexity in rule enforcement and query planning as compared with a traditional distributed database environment. we examine the problem of minimum cost rule enforcement which simultaneously checks for the enforceability of each rule and generation of minimum cost plan of its execution. however, the paper is not focused on specific cost functions, but instead of efficient methods for enforcing rules in the face of access restrictions and inter-party data transfer needs. we propose an efficient heuristic algorithm for this minimal enforcement since the exact problem is np-hard. in some cases, it is not possible to enforce the rules with the regular parties only. in such cases, we need help of trusted third parties (tps). if all parties trust a single tp, such a party can enforce all unenforced rules, but it is desirable to use the tp minimally. we also consider the extended case where multiple tps are required since not every regular party can trust a single tp.
parallel_computing	a review and comparative analyses of methods for restricting the range of molecular interactions within the concept of atom-atom potentials are presented. emphasis is placed on the problem of calculating the electrostatic energy in models with periodic boundary conditions. numerous calculations of the thermodynamic and structural characteristics of water using parallel monte carlo computations have shown that the use of functional forms simulating the electric potentials of ""screened charges"" provides very good results.
computer_vision	computer vision-based human activity recognition (har) has become very famous these days due to its applications in various fields such as smart home healthcare for elderly people. a video-based activity recognition system basically has many goals such as to react based on people 's behavior that allows the systems to proactively assist them with their tasks. a novel approach is proposed in this work for depth video based human activity recognition using joint-based motion features of depth body shapes and deep belief network (dbn). from depth video, different body parts of human activities are segmented first by means of a trained random forest. the motion features representing the magnitude and direction of each joint in next frame are extracted. finally, the features are applied for training a dbn to be used for recognition later. the proposed har approach showed superior performance over conventional approaches on private and public datasets, indicating a prominent approach for practical applications in smartly controlled environments.
control_engineering	online laboratories are useful and valuable resources in high education, especially in engineering studies. this work presents a methodology to create effective laboratories for learning that interact with a learning management system (lms) to achieve advanced integration. it is based on pedagogical aspects and considers not only the laboratory application itself but also related resources that complement it. the methodology is flexible, covers all possible cases, and it is structured in stages that can be used with any system architecture, standards, or type of online laboratory (virtual, remote, or hybrid) because it abstracts technical aspects at a high level. this methodology facilitates the creation of new online labs so that any teacher, even those without specialized knowledge, can clarify many of the questions that may arise and gain understanding of how to implement an effective online laboratory with lms integration to assist learning. as an example and validation of the methodology, this work describes a laboratory developed as a shared content object reference model (scorm) package which is hosted in the institutional lms at the university of jaen. the laboratory was presented to 338 students taking an industrial automation class, and student evaluations were quite positive.
computer_programming	this article introduces the educational functions of a computer program developed and put into practice for the computer-aided instruction of the finite element method. an interactive simulation with graphical visualization is used as a tool to teach and learn the concepts and procedures related to the construction and solution of finite element stiffness equations. the tool encompasses the stages of processing finite element equations from element modeling to equation solving. any operation of this educational tool is not an emulation of computational processes, but an actual execution of finite element processing. thus, instructors of the finite element method may use this educational program as a tool to present complex computational aspects in comprehensible graphic images. students may experience and explore each stage of the computation using the interactive simulation, and attain a better understanding of the concepts and procedures of the stiffness method, bypassing manual calculation or computer programming. the instructional tool has been implemented as a part of a finite element analysis program. (c) 2013 wiley periodicals, inc. comput appl eng educ 23:157-169, 2015; view this article online at ; doi
system_identification	the present paper takes from the original outputonly identification approach named full dynamic compound inverse method (fdcim), recently published on this journal by the authors, and proposes an innovative, much enhanced version, in the description of more general forms of structural damping, including for classically adopted rayleigh damping. this has led to an extended fdcim formulation, which offers superior performance, on all the targeted identification parameters, namely: modal properties, rayleigh damping coefficients, structural features at the element-level and input seismic excitation time history. synthetic earthquake-induced structural response signals are adopted as input channels for the fdcim approach, towards comparison and validation. the identification algorithm is run first on a benchmark 3-storey shear-type frame, and then on a realistic 10-storey frame, also by considering noise added to the response signals. consistency of the identification results is demonstrated, with definite superiority of this latter fdcim proposal.
state_space_representation	the goal of the present study is to show how it is possible to estimate online the individual torques applied at each wheel of an automotive vehicle by using an unknown input observer together with a simple nonlinear state-space model. the necessary measurements are the steering angle, the usual rotation speed of each wheel plus the vertical load at the centre of each wheel. by doing this, this study anticipates the affordability of a new generation of wheel bearing with embedded measurements of transmitted forces. successful simulated experimentations using a realistic simulator are shown. validations are done using classical case studies of longitudinal, lateral and coupled dynamics. the present limits and some possible improvements of the proposed method are also discussed.
analog_signal_processing	this paper brings attention to a new nonlinear mathematical model of a hydro-turbine governing system with a surge tank. the nonlinear mathematical model, which is described by state-space equations, is composed of francis turbine system, electrical generator system, conduit system and governor system. furthermore, the nonlinear dynamical behaviors of the system with different parameters are studied exhaustively including bifurcation diagrams, time waveforms, phase orbits, poincare maps, spectrograms and power spectrums. fortunately, some interesting phenomenons are found from numerical simulation results. more important, all of the above analyses supply some theory bases for designing and running of a hydro-turbine governing system. (c) 2013 elsevier inc. all rights reserved.
operational_amplifier	a simple voltage-to-frequency converter (vfc) with modulated duty cycles is proposed. the proposed vfc is composed of an operational amplifier, a voltage-to-current circuit, a charge and discharge circuit, a comparator, and a schmitt trigger. the 50% duty cycle signal is always obtained at the output of the schmitt trigger and multiple duty cycles can be obtained at the output of the comparator by simply adjusting an external voltage level. due to its simplicity, the proposed vfc circuit can be easily combined with other circuitry to extend its practical application. the errors caused by the circuit non-idealities are investigated to quantify the trade-offs between performance and cost. the proposed vfc, which features modulated duty cycles, is realized in a standard 0.18-m 1p6m complementary metal-oxide-semiconductor (cmos) technology, and an active area of 210mx190m is occupied. experimental results show that the proposed converter is useful for output frequency ranges from 315khz to 2.53mhz with an input voltage range of 0.2-1.6v and a power consumption of 0.8mw.
system_identification	experimental modal analysis aims at identifying the modal properties (e.g., natural frequencies, damping ratios, mode shapes) of a structure using vibration measurements. two basic questions are encountered when operating in the frequency domain: is there a mode near a particular frequency? if so, how much spectral data near the frequency can be included for modal identification without incurring significant modeling error? for data with high signal-to-noise (s/n) ratios these questions can be addressed using empirical tools such as singular value spectrum. otherwise they are generally open and can be challenging, e.g., for modes with low sin ratios or close modes. in this work these questions are addressed using a bayesian approach. the focus is on operational modal analysis, i.e., with 'output-only' ambient data, where identification uncertainty and modeling error can be significant and their control is most demanding. the approach leads to 'evidence ratios' quantifying the relative plausibility of competing sets of modeling assumptions. the latter involves modeling the 'what-if-not' situation, which is non-trivial but is resolved by systematic consideration of alternative models and using maximum entropy principle. synthetic and field data are considered to investigate the behavior of evidence ratios and how they should be interpreted in practical applications. (c) 2016 elsevier ltd. all rights reserved.
system_identification	parkinson 's disease (pd) is a progressive neurodegenerative disease characterized by rigidity, bradykinesia, resting tremor, and postural instability. rigidity, defined as an increased resistance to passive movement of a joint, progresses faster than other motor signs in pd. rigidity is attributable to both exaggerated neural reflex and altered muscle mechanical properties. however, little is known about the contributions of individual components to rigidity. further, there is no evidence regarding the effects of dopaminergic medication on individual components. objectives of this study were to quantify the contributions of neural reflexes and intrinsic muscle properties to rigidity and investigate the effects of medication on each contributing component. joint torque and muscle activities of the wrist in 14 patients and 14 controls were measured during externally induced movements. each subject with pd was tested in off- and on-medication states. a system identification technique was applied to differentiate and quantify the neural reflex and intrinsic mechanical components. a mixed model of anova was performed to compare the differences between the two components of rigidity for both groups, and to compare between the off- and on-medication states for patients. the results showed that reflex and intrinsic components are comparable (p >0.05), and both are enhanced in subjects with pd than in the controls (p < 0.05). medication decreased the reflex component of rigidity (p < 0.01). it is concluded that both reflex and intrinsic factors are responsible for rigidity. present findings are clinically significant as they may provide guidance in development of effective therapeutic interventions.
computer_programming	sorting is one of the important algorithms in computer programming. the ordinary 6 sorting algorithms are analyzed and compare from the algorithmic time complexity and stability. the executive efficiency of 6 sorting algorithms is verified by java program. the costing time and stability of 6 sorting algorithms are compared to provide certain reference for sorting algorithm.
symbolic_computation	in this paper, we construct soliton solutions for a generalized variable-coefficient coupled hirota-maxwell-bloch system, which can describe the ultrashort optical pulse propagation in a nonlinear, dispersive fiber doped with two-level resonant atoms. under certain transformations and constraints, one- and two-soliton solutions are obtained via the hirota method and symbolic computation, and soliton collisions are graphically presented and analyzed. one soliton is shown to maintain its amplitude and shape during the propagation. soliton collision is elastic, while bright two-peak solitons and dark two-peak solitons are also observed. we discuss the influence of the coefficients for the group velocity, group-velocity dispersion (gvd), self-phase modulation, distribution of the dopant, and stark shift on the soliton propagation and collision features, with those coefficients are set as some constants and functions, respectively. we find the group velocity and self-phase modulation can change the solitons' amplitudes and widths, and the solitons become curved when the gvd and distribution of the dopant are chosen as some functions. when the stark shift is chosen as a certain constant, the two peaks of bright two-peak solitons and dark two-peak solitons are not parallel. in addition, we observe the periodic collision of the two solitons.
electrical_network	the power loss reduction is one of the main targets for any electrical energy distribution company. in this paper the problem of the joint optimization of both topology and network parameters in a real smart grid is faced. a portion of the italian electric distribution network managed by the acea distribuzione s. p. a. located in rome is considered. it includes about 1200 user loads, 70 km of mv lines, 6 feeders, a thyristor voltage regulator and 6 distributed energy sources (5 generator sets and 1 photovoltaic plant). the power factor correction (pfc) is performed tuning the 5 generator sets and setting the state of the breakers in order to perform the distributed feeder reconfiguration (dfr). about the dfr, in this paper we introduce a simplified graph representation of the electrical network and we propose a new algorithm to find all the radial network configurations. the pfc and the dfr optimization is faced by defining and solving a suited multi-objective optimization problem adopting a genetic algorithm. tests have been performed by feeding the simulation environment with real data concerning dissipated and generated active and reactive power values. first results are very interesting, showing that considering all the possible admissible network configurations can help the optimization procedure in finding better solutions.
voltage_law	a new sub-space max-monomial modeling scheme for cmos transistors in sub-micron technologies is proposed to improve the modeling accuracy. major electrical parameters of cmos transistors in each sub-space from the design space are modeled with max-monomials. this approach is demonstrated to have a better accuracy for sub-micron technologies than singlespace models. sub-space modeling based geometric programming power optimization has been successfully applied to three different op-amps in 0.18 mu m technology. hspice simulation results show that sub-space modeling based gp optimization can allow efficient and accurate analog design. computational effort can be managed to an acceptable level when searching sub-spaces for transistors by using practical constraints. an efficient scheme in dealing with non-convex constraint inherent in kirchhoff 's voltage law is suggested in this paper. by using this scheme, the nonconvex constraint, such as posynomial equality, can be relaxed to a convex constraint without affecting the result.
electric_motor	a new topology of single-phase two stage ac to dc sepic converter in step down configuration with high efficiency at extremely low voltage gain is proposed with high input power factor and low input current total harmonic distortion. in this work, proposal has be given to modify conventional two stage ac to dc sepic converter introducing a switched capacitor branch in between the stages. the input current thd is kept low. the input power factor is high with two-loop feedback control. the proposed schemes can be used in the application of battery charging of electric motor vehicles.
computer_programming	computer programming is essential in engineering education. we are developing a programming education support tool pgtracer in order to facilitate learning process of computer programming. pgtracer utilizes fill-in-the-blank question composed of a pair of a source program and a trace table. we propose a set of feedback functions for the students in this paper. pgtracer automatically collects learning log of the students when they fill a blank. the feedback functions provide various analysis result of the collected log so that students can easily understand their achievement level and weak points. many students highly appreciate the feedback functions through an experimental evaluation of the functions.
digital_control	this paper explores the large-signal and small-signal dynamics of a series-capacitor (sc) buck-type converter and introduces an optimal closed-loop control scheme to accommodate both the steady-state and transient modes. as opposed to a conventional buck converter, where time-optimal control is realized by a single on-off cycle, in the sc-buck topology there is a need to distribute the switching phases to satisfy the charge-balance of the flying capacitor. the new control method hybrids a voltage-mode small-signal controller for steady-state operation and a non-linear, state-plane based transient-mode control scheme for load transients. a detailed principle of operation of the sc-buck converter is provided and explained through an average behavioral model and state-plane analysis. the operation of the controller is experimentally verified on a 12w 12v-to-1.5v converter, demonstrating voltage-mode control operation as well as time-optimal response for load transients.
computer_programming	in this paper, we describe the development of a support system that facilitates the process of learning computer programming through the reading of computer program source code. reading code consists of two steps: reading comprehension and meaning deduction. in this study, we developed a tool that supports the comprehension of a program 's reading. the tool is equipped with an error visualization function that illustrates a learner 's mistakes and makes them aware of their errors. we conducted experiments using the learning support tool and confirmed that the system is effective.
electrical_circuits	stationary modes and their possible bifurcations in nonautonomous electrical circuits with nonlinear resistive elements, the voltage-current characteristic of which cannot be satisfied to known conditions of convergence, are investigated. the main result of this article is description of current modes in a single and three-phase circuit with asymmetric voltage-current characteristics. the most interesting result of investigation of these transient and steady current modes in nonlinear electrical circuits is the possibility of the quasi-periodical process with low-frequency component, values and significance of which can be modulated by modification of amplitude of external high-frequency three-phase voltage.
computer_graphics	we present a method for computing ambient occlusion (ao) for a stack of images of a lambertian scene from a fixed viewpoint. ambient occlusion, a concept common in computer graphics, characterizes the local visibility at a point: it approximates how much light can reach that point from different directions without getting blocked by other geometry. while ao has received surprisingly little attention in vision, we show that it can be approximated using simple, per-pixel statistics over image stacks, based on a simplified image formation model. we use our derived ao measure to compute reflectance and illumination for objects without relying on additional smoothness priors, and demonstrate state-of-the art performance on the mit intrinsic images benchmark. we also demonstrate our method on several synthetic and real scenes, including 3d printed objects with known ground truth geometry.
electric_motor	this paper aims to carry out an analysis of the way in which the turbulence of the testing explosive mixture, turbulence induced by the high speed rotation movement of the shaft of the motor, as well as the rotation of the interior cooling fan, influences the maximum explosion pressures recorded, when carrying out the type tests of electrical rotating machines, when running. the paper also presents the most important results obtained in the specific laboratory of insemex, during a research project carried out recently. even if electric motors for environments with explosion hazards are designed and manufactured following the same principles as the ones used for other electric machinery, they have certain particularities related to their field of use. from here the required type of protection is resolved, with a series of restrictions imposed to electric motor projects [3]. as widely known, in case of flameproof electric motors as well as in case of most of the technical equipment in general, design and manufacture exceeded long time ago the stage when the manufacturers used to apply their own design methods.
symbolic_computation	fractional derivatives are powerful tools in solving the problems of science and engineering. in this paper, an analytical algorithm for solving fractional differential-difference equations in the sense of jumarie 's modified riemann-liouville derivative has been described and demonstrated. the algorithm has been tested against time-fractional differential-difference equations of rational type via symbolic computation. three examples are given to elucidate the solution procedure. our analyses lead to closed form exact solutions in terms of hyperbolic, trigonometric, and rational functions, which might be subject to some adequate physical interpretations in the future. copyright (c) 2013 john wiley & sons, ltd.
analog_signal_processing	an original analog function synthesizer circuit with increased accuracy will be presented, allowing to implement a multitude of important continuous mathematical functions. the accuracy of the proposed structure is excellent and the range of the input variable is strongly extended as a result of the third-order approximation of the implemented functions. the circuit performance is expected to be stable against process corners as all functions exclusively depend on current ratios. the great advantages of the increased modularity and controllability and of the associated reduced design costs per function represent an immediate consequence of the multiple functions realized by the proposed structure. the function synthesizer circuit is designed for implementing in 0.18 mu m cmos technology and it is supplied at 1.8v. the spice simulations confirm the estimated theoretical results, showing an approximating error smaller than 0.01% for the composing squaring block and smaller than 0.013% for the composing multiplier/divider block.
relational_databases	data provenance is the history associated with that data. it constitutes the origin, creation, processing, and archiving of data. in today 's internet era, it has gained significant importance for database analytics. most of the provenance models store provenance information in relational databases for further querying and analysis. although, querying of provenance in relational databases is very efficient for small data sets, it becomes inefficient as the provenance data grows and traversal depth of provenance query increases. this is mainly due to increase in number of join operations to search the entire provenance data. graph databases provide an alternative to rdbmss for storing and analyzing provenance data as it can scale to billions of nodes and at the same time traverse thousands of relationships efficiently. in this paper, we propose efficient multi-depth querying of provenance data using graph databases. the proposed solution allows efficient querying of provenance of current as well as historical queries. a comparison between relational and graph databases is presented for varying provenance data size and traversal depths. graph databases are found to scale well with increasing depth of provenance queries, whereas in relational databases the querying time increases exponentially.
image_processing	composite data sets measured on different objects are usually affected by random errors, but may also be influenced by systematic (genuine) differences in the objects themselves, or the experimental conditions. if the individual measurements forming each data set are quantitative and approximately normally distributed, a correlation coefficient is often used to compare data sets. however, the relations between data sets are not obvious from the matrix of pairwise correlations since the numerical value of the correlation coefficient is lowered by both random and systematic differences between the data sets. this work presents a multidimensional scaling analysis of the pairwise correlation coefficients which places data sets into a unit sphere within low-dimensional space, at a position given by their cc* values [as defined by karplus & diederichs (2012), science, 336, 1030-1033] in the radial direction and by their systematic differences in one or more angular directions. this dimensionality reduction can not only be used for classification purposes, but also to derive data-set relations on a continuous scale. projecting the arrangement of data sets onto the subspace spanned by systematic differences (the surface of a unit sphere) allows, irrespective of the random-error levels, the identification of clusters of closely related data sets. the method gains power with increasing numbers of data sets. it is illustrated with an example from low signal-to-noise ratio image processing, and an application in macromolecular crystallography is shown, but the approach is completely general and thus should be widely applicable.
electric_motor	between may 1995 and june 1999 we equipped 81 barren-ground grizzly bears (ursus arctos) with satellite radio-collars within a study area of 235,000 km(2), centred 400 km northeast of yellowknife, northwest territories. we estimated 71 annual ranges of radio-tracked animals (greater than or equal to 38 locations years) using the 95% fixed kernel technique with least squares cross-validation. annual ranges of males ((x) over bar= 7,245 km(2), se = 1,158, n = 26) were larger than ranges of females ((x) over bar = 2,100 km(2), se = 279, n = 45). ranges increased in size as the proportional amount of exposed bedrock and other marginal habitats in the environment increased. annual ranges are the largest reported for grizzly bears in north america.
electricity	while several studies have examined the effect of renewable portfolio standard laws on renewable generation in states, previous literature has not assessed the potential for spatial dependence in these policies. using recent spatial panel methods, this paper estimates a number of econometric models to examine the impact of rps policies when spatial autocorrelation is taken into account. consistent with previous literature, we find that rps laws do not have a significant impact on renewable generation within a state. however, we find evidence that state rps laws have a significant positive impact on the share of renewable generation in the nerc region as a whole. these findings provide evidence that electricity markets are efficiently finding the lowest-cost locations to serve renewable load in states with more stringent rps laws. in addition, our results suggest that rps laws may be more effective tools for environmental policy than for economic development.
system_identification	this research proposed novel development of a 2-dof h infinity loop shaping structured controller based on particle swarm optimization (pso) that considers the closed-loop dynamic response, robustness, stability, and minimal control input in design criteria to control position of 3-dof pneumatic surgical robot. unlike other conventional h infinity controllers, the proposed controller offers robustness, high performance, but cost-effective simple structure, which has recently received attention from several researchers and preferred in industrial applications. the proposed technique is simulated and experimented on a nonlinear system of a pneumatic 3-dof surgical robot for a minimally invasive surgery (mis). mechanical design, dynamics modeling, and system identification of the surgical robot are conducted. the simulation results verify that the proposed controller can gain a better h infinity sub-optimal solution than the conventional 2-dof h infinity loop shaping controller. also, the experiments confirm that the proposed controller is capable to tolerate the perturbed conditions and can be alternative to the conventional controllers in pneumatic controlled system. (c) 2017 elsevier ltd. all rights reserved.
symbolic_computation	in this paper, the fractional derivatives in the sense of modified riemann-liouville derivative and the exp-function method, the (g'/g)-expansion method and the generalized kudryashov method are used to construct exact solutions for (3 + 1)-dimensional space-time fractional modified kdv-zakharov-kuznetsov equation. this fractional equation can be turned into another nonlinear ordinary differential equation by fractional complex transformation and then these three methods are applied to solve it. as a result, some new exact solutions are obtained. the three methods demonstrate power, reliability and efficiency. (c) 2016 elsevier ltd. all rights reserved.
parallel_computing	in the industry 4.0, factories around the world grow automated and intelligent, and where smart camera plays an important role. smart camera is equipped with processor, memory, communication interface, and operating system, so it can process large amounts of data in advance to assist follow-up automatic inspection and judgment. additionally, since smart camera is an independent system, it will not affect the original system of factories, which is an immense advantage in troubleshooting. besides, thanks to technology breakthroughs in recent years, using graphics processing unit (gpu) to implementing tons of parallel computing helps to significantly boost the overall efficiency. therefore, when a rising number of factories consider improving production capacity of production lines, how to use gpu to assist the improvement is an important issue. based on this scenario, this paper used nvidia tegra tx1 platform with 256 gpu cuda cores and quad-core arm cortex a57 processor and basler usb 3.0 industrial camera to simulate a smart industrial camera, which has gpu and can perform a myriad of complex computations. this paper designed how to recognize and count objects in a real time manner in a highspeed industrial inspection environment with large volumes of data, so as to verify the concept (smart camera with gpu cores) we proposed. the experimental results proved our ideas, and the software design architecture provided in this paper is a simple and efficient design. in the future application in the internet of things or the internet of everything, this structure can be a valuable reference.
analog_signal_processing	in this paper we study the control of the power and the frequency of the turbo generator couple to the power grid. these are developed linear mathematical models for steam turbine and electrical generator. used in power control system design. the dynamic control system was simulated using matlab simulink.
system_identification	the paper presents a general agent-based system identification framework as potential solution for data-driven models of building systems that can be developed and integrated with improved efficiency, flexibility and scalability, compared to centralized approaches. the proposed method introduces building sub-system agents, which are optimized independently, by solving locally a maximum likelihood estimation problem. several models are considered for the sub-system agents and a systematic selection approach is established considering the root mean square error, the parameter sensitivity to output trajectory and the parameter correlation. the final model is integrated from selected models for each agent. two different approaches are developed for the integration; the negotiated-shared parameter model, which is a distributed method, and the free-shared parameter model based on a decentralized method. the results from a case-study for a high performance building indicate that the model prediction accuracy of the new approach is fairly good for implementation in predictive control.
signal-flow_graph	in this paper, a unified algebraic transformation approach is presented for designing parallel recursive and adaptive digital filters and singular value decomposition (svd) algorithms. the approach is based on the explorations of some algebraic properties of the target algorithms' representations. several typical modern digital signal processing examples are presented to illustrate the applications of the technique. they include the cascaded orthogonal recursive digital filter, the givens rotation-based adaptive inverse qr algorithm for channel equalization, and the qr decomposition-based svd algorithms. all three examples exhibit similar throughput constraints. there exist long feedback loops in the algorithms' signal flow graph representation, and the critical path is proportional to the size of the problem, applying the proposed algebraic transformation techniques, parallel architectures are obtained for all three examples, for cascade orthogonal recursive filter, retiming transformation and orthogonal matrix decompositions (or pseudo-commutativity) are applied to obtain parallel filter architectures with critical path of five givens rotations. for adaptive inverse qr algorithm, the commutativity and associativity of the matrix multiplications are applied to obtain parallel architectures with critical path of either four givens rotations or three givens rotations plus two multiply-add operations, whichever turns out to be larger. for svd algorithms, retiming and associativity of the matrix multiplications are applied to derive parallel architectures with critical path of eight givens rotations. the critical paths of all parallel architectures are independent of the problem size as compared with being proportional to the problem size in the original sequential algorithms. parallelism is achieved at the expense of slight increase (or the same for the svd case) in the algorithms' computational complexity.
analog_signal_processing	the evolution, design and test results of a novel permanent magnet generator for use in direct-drive wind turbines are presented. this generator topology is based on steel c-core modules (which make up the rotor) and an air-cored stator winding. this topology allows a reduction in structural mass for large diameter generators, which can lead to lightweight generators. copyright (c) 2009 john wiley & sons, ltd.
microcontroller	tropical soils are major players on co2 emissions and c cycling on earth. however, it is in tropical countries where scientists can have the most limited access to analytical tools needed for research on these processes. this paper describes the construction and test of a less than us 50 chamber for monitoring of multiple soil gas emissions. the system consisted on an array of three mq series gas sensors placed into an airtight container, a pic microcontroller and a custom-built software developed for data capture and visualization running on a laptop. a modified multiplexing of sensors was also incorporated in order to allow the parallel analysis in up to eight samples. the chamber, hereafter called senose (short for soil electric nose), was tested in two separate experiments. the first study used the three sensor array system in soil samples from colombia and ecuador, which were separated into two groups in order to study their gas emission patterns in d(+) glucose induced respiration tests. for a second experiment using a multiplexed sensor array in a different set of colombian soil samples, gas emission patterns were obtained from autoclaved soil with reduced microbial activity, which were further contaminated with diesel oil as c source. during the first study, in replicated 22 h continuous runs senose clearly showed differences in soil respiration patterns of these soil samples, and a prominent timing differential increase in gas production after spiking d(+) glucose, a proxy for organic c, as a substrate. results of the second study showed a clearly different pattern of gas emissions in diesel oil contaminated samples, when microbial activity was reduced by soil autoclaving. moreover, two groups of non-autoclaved soil subsamples differing only in diesel oil addition could also be differentiated with basis on their respiration patterns after some hours of gas tracking. based on these results we foresee a great potential from the use of this low cost system in fields such as soil microbiology, fertility, biotechnology and environmental sciences, where processes such as microbial activity, plant nutrient availability or soil pollutant turnover are tracked by monitoring their gas emission patterns. (c) 2016 elsevier b.v. all rights reserved.
machine_learning	in many research and application areas, such as information retrieval and machine learning, we often encounter dealing with a probability distribution that is mixed by one distribution that is relevant to our task in hand and the other that is irrelevant and that we want to get rid of. thus, it is an essential problem to separate the irrelevant distribution from the mixture distribution. this article is focused on the application in information retrieval, where relevance feedback is a widely used technique to build a refined query model based on a set of feedback documents. however, in practice, the relevance feedback set, even provided by users explicitly or implicitly, is often a mixture of relevant and irrelevant documents. consequently, the resultant query model (typically a term distribution) is often a mixture rather than a true relevance term distribution, leading to a negative impact on the retrieval performance. to tackle this problem, we recently proposed a distribution separation method (dsm), which aims to approximate the true relevance distribution by separating a seed irrelevance distribution from the mixture one. while it achieved a promising performance in an empirical evaluation with simulated explicit irrelevance feedback data, it has not been deployed in the scenario where one should automatically obtain the irrelevance feedback data. in this article, we propose a substantial extension of the basic dsm from two perspectives: developing a further regularization framework and deploying dsm in the automatic irrelevance feedback scenario. specifically, in order to avoid the output distribution of dsm drifting away from the true relevance distribution when the quality of seed irrelevant distribution (as the input to dsm) is not guaranteed, we propose a dsm regularization framework to constrain the estimation for the relevance distribution. this regularization framework includes three algorithms, each corresponding to a regularization strategy incorporated in the objective function of dsm. in addition, we exploit dsm in automatic (i.e., pseudo) irrelevance feedback, by automatically detecting the seed irrelevant documents via three different document reranking methods. we have carried out extensive experiments based on various trec datasets, in order to systematically evaluate the proposed methods. the experimental results demonstrate the effectiveness of our proposed approaches in comparison with various strong baselines.
data_structures	we present a new version of the core structural package of our application programming interface, apinetworks, for the treatment of complex networks in arbitrary computational environments. the new version is written in java and presents several advantages over the previous c++ version: the portability of the java code, the easiness of object-oriented design implementations, and the simplicity of memory management. in addition, some additional data structures are introduced for storing the sets of nodes and edges. also, by resorting to the different garbage collectors currently available in the jvm the java version is much more efficient than the c++ one with respect to memory management. in particular, the g1 collector is the most efficient one because of the parallel execution of g1 and the java application. using g1, apinetworks java outperforms the c++ version and the well-known networkx and jgrapht packages in the building and bfs traversal of linear and complete networks. the better memory management of the present version allows for the modeling of much larger networks.
machine_learning	energy prediction of machine tools can deliver many advantages to a manufacturing enterprise, ranging from energy-efficient process planning to machine tool monitoring. physics-based energy prediction models have been proposed in the past to understand the energy usage pattern of a machine tool. however, uncertainties in both the machine and the operating environment make it difficult to predict the energy consumption of the target machine reliably. taking advantage of the opportunity to collect extensive, contextual, energy-consumption data, we discuss a data-driven approach to develop an energy prediction model of a machine tool in this paper. first, we present a methodology that can efficiently and effectively collect and process data extracted from a machine tool and its sensors. we then present a data-driven model that can be used to predict the energy consumption of the machine tool for machining a generic part. specifically, we use gaussian process (gp) regression, a nonparametric machine-learning technique, to develop the prediction model. the energy prediction model is then generalized over multiple process parameters and operations. finally, we apply this generalized model with a method to assess uncertainty intervals to predict the energy consumed by any part of the machine using a mori seiki nvd1500 machine tool. furthermore, the same model can be used during process planning to optimize the energy-efficiency of a machining process.
network_security	we address the issue of large scale network security. it is known that traditional game theory becomes intractable when considering a large number of players, which is a realistic situation in today 's networks where a centralized administration is not available. we propose a new model, based on mean field theory, that allows us to obtain optimal decentralised defence policy for any node in the network and optimal attack policy for an attacker. in this way we settle a promising framework for the development of a mean field game theory of large scale network security. we also present a case study with experimental results.
digital_control	this paper proposes a dimmable energy-efficient light-emitting diode (led) driver for applications in interior lighting. high efficiency is achieved by an adaptive voltage regulation, which minimizes power losses in the linear current regulator. a digital control mechanism employing a resistive digital-to-analog converter for feeding the analog feedback input of a dc-dc converter is introduced. it is shown that the digital control methodology gives maximum design flexibility and enhances control over regulation speed and stability. in an experimental setup, the proposed concept is verified and evaluated. operating at an input voltage of 24 v, the led driver provides a relatively wide output voltage range of 3.5-38 v. output current is regulated to 700 ma with a steady-state precision of more than 98.8%, whereas pulsewidth modulation dimming with a frequency of 1 khz and shortest on-time of 4 mu s is employed. a peak efficiency of the complete system of 93.9% is achieved.
computer_programming	this article addresses the problem of testing the difference between two correlated agreement coefficients for statistical significance. a number of authors have proposed methods for testing the difference between two correlated kappa coefficients, which require either the use of resampling methods or the use of advanced statistical modeling techniques. in this article, we propose a technique similar to the classical pairwise t test for means, which is based on a large-sample linear approximation of the agreement coefficient. we illustrate the use of this technique with several known agreement coefficients including cohen 's kappa, gwet 's ac(1), fleiss 's generalized kappa, conger 's generalized kappa, krippendorff 's alpha, and the brenann-prediger coefficient. the proposed method is very flexible, can accommodate several types of correlation structures between coefficients, and requires neither advanced statistical modeling skills nor considerable computer programming experience. the validity of this method is tested with a monte carlo simulation.
electrical_circuits	the problem of existence of metzler matrices with given spectra is addressed for positive stable continuous-time linear systems and electrical circuits. necessary and sufficient conditions for the existence of the metzler matrices are established. it is shown that positive and stable electrical circuits have real eigenvalues. an open problem for positive electrical circuits is formulated. the considerations are illustrated by numerical examples of linear systems and positive electrical circuits.
software_engineering	the goal of software testing should go beyond simply finding defects. ultimately, testing should be focused on increasing customer satisfaction. defects that are detected in areas of the software that the customers are especially interested in can cause more customer dissatisfaction. if these defects accumulate, they can cause the software to be shunned in the marketplace. therefore, it is important to focus on reducing defects in areas that customers consider valuable. this article proposes a value-driven v-model (v-2 model) that deals with customer values and reflects them in the test design for increasing customer satisfaction and raising test efficiency.
software_engineering	the successful use of intelligent agents in healthcare has attracted researchers to apply this emerging software engineering paradigm in more advanced and complex applications. main success factor is the natural mapping of real world medical problems into cyber world. multi-agent architecture can easily model the heterogeneous, distributed and autonomous health care systems. the multi agent systems have been applied from single healthcare activity like knowledge based medical system to complex, multi-component based systems like complete healthcare unit. the use of multi agent systems in health care domain has also opened the ways to find out new applications like personalized and socialized health care systems. this versatile use of multi agent systems has also posed new problems for researchers like; security, communication, and different social issues. this work reviews recent years' research and applications of multi agent systems in healthcare published in different research journals, international conferences, and implemented practically. we reviewed five subdomains and three systems in each subdomain. a set of common parameters of these systems has been extracted and compared to analyze systems' merits and deficiencies. based on our analysis, we have provided recommendations for multi agent systems applied in healthcare domain. future research directions for interested researchers and practitioners are also discussed. as our own future research work, we intend to study healthcare and multi agent systems in e-commerce.
operational_amplifier	in this paper, a low-power and precise electrical stimulator is introduced in which no operational amplifier (opamp) is used. for electrical stimulations that have low pulse width, an opamp with high slew rate is needed which is power consuming. in this work, the opamp is substituted with a digital circuitry. a 100 khz clock is also used to update the current of the stimulator in the stimulation phases in order to make the stimulator accurate enough. producing such a clock needs only few micro watts. this stimulator is simulated in a 0.18 mu m cmos process, as well. the simulation results shows that this stimulator has only 0.056% charge mismatch in 1 ma stimulation current with a pulse width of 32 mu s.
machine_learning	bioinformatics has grown very quickly for the last 20 years, and it will grow even faster in the future. one of the long-standing open challenges in bioinformatics is biomarker identification and cancer diagnosis from gene expression. in this paper, the authors propose a novel hybrid wrapper/filter feature selection approach to identify the most informative genes for cancer diagnosis, named hwf-gs. it handles selection through two steps. the first one is an iterative filter-based mechanism to generate potential subsets of genes. the second step is the aggregation of the best-selected subsets by means of a wrapper-based consensus process that relies on a particle swarm optimization adapted to feature selection. an ensemble of classifiers (svm and knn) is employed to evaluate the selected genes. experiments on nine publicly available cancer dna microarray datasets have shown that hwf-gs selects robust signatures with high classification accuracy and competes with and even outperforms other methods in the literature.
bioinformatics	introduction: the aim of this study was to clarify the microrna (mirna) expression profiles of raw264.7 macrophages infected by candida albicans to elucidate the roles of differentially expressed mirnas and to further explore the mechanisms underlying the immune response to c. albicans infection. methods: high-throughput mirna microarray analysis was performed to detect differentially expressed mirnas in control and c. albicans-infected raw264.7 cells. quantitative real-time pcr analysis was used to verify the microarray results. target genes of differentially expressed mirnas were predicted with bioinformatics software. the cell biological processes and signaling pathways of these mirna-targeted genes involved in c. albicans infection were predicted by gene ontology (go) enrichment and pathway analyses. results: significant upregulation of eight mirnas (mmu-mir-140-5p, mmu-mir-96-5p, mmu-mir-8109, mmu-mir-466i-3p, mmu-mir-222-5p, mmu-mir-301b-3p, mmu-mir-466g, and mmu-mir-7235-5p) and downregulation of eight mirnas (mmu-mir-3154, mmu-mir-223-3p, mmu-mir-494-3p, mmu-mir-6908-5p, mmu-mir-188-5p, mmu-mir-6769b-5p, mmu-mir-7002-5p, and mmu-mir-1224-5p) were observed, as compared with the control (fold change >= 2.0 and p<0.05). go analysis revealed that both mmu-mir-140-5p and mmu-mir-223-3p participated in immune responses, inflammatory reactions, and cell apoptosis in c. albicans infection. also, the mapk signaling pathway was found to play an important role in the immune response against c. albicans infection. conclusions: this study revealed comprehensive expression and functional profiles of differentially expressed mirnas in macrophage raw264.7 cells infected by c. albicans. these findings should help to further elucidate the mechanisms underlying the immune response to c. albicans infection.
distributed_computing	a mapreduce algorithm can be described by a mapping schema, which assigns inputs to a set of reducers, such that for each required output there exists a reducer that receives all the inputs participating in the computation of this output. reducers have a capacity that limits the sets of inputs they can be assigned. however, individual inputs may vary in terms of size. we consider, for the first time, mapping schemas where input sizes are part of the considerations and restrictions. one of the significant parameters to optimize in any mapreduce job is communication cost between the map and reduce phases. the communication cost can be optimized by minimizing the number of copies of inputs sent to the reducers. the communication cost is closely related to the number of reducers of constrained capacity that are used to accommodate appropriately the inputs, so that the requirement of how the inputs must meet in a reducer is satisfied. in this work, we consider a family of problems where it is required that each input meets with each other input in at least one reducer. we also consider a slightly different family of problems in which each input of a list, x, is required to meet each input of another list, y, in at least one reducer. we prove that finding an optimal mapping schema for these families of problems is np-hard, and present a bin-packing-based approximation algorithm for finding a near optimal mapping schema.
bioinformatics	background: translational researchers need robust it solutions to access a range of data types, varying from public data sets to pseudonymised patient information with restricted access, provided on a case by case basis. the reason for this complication is that managing access policies to sensitive human data must consider issues of data confidentiality, identifiability, extent of consent, and data usage agreements. all these ethical, social and legal aspects must be incorporated into a differential management of restricted access to sensitive data. methods: in this paper we present a pilot system that uses several common open source software components in a novel combination to coordinate access to heterogeneous biomedical data repositories containing open data ( open access) as well as sensitive data ( restricted access) in the domain of biobanking and biosample research. our approach is based on a digital identity federation and software to manage resource access entitlements. results: open source software components were assembled and configured in such a way that they allow for different ways of restricted access according to the protection needs of the data. we have tested the resulting pilot infrastructure and assessed its performance, feasibility and reproducibility. conclusions: common open source software components are sufficient to allow for the creation of a secure system for differential access to sensitive data. the implementation of this system is exemplary for researchers facing similar requirements for restricted access data. here we report experience and lessons learnt of our pilot implementation, which may be useful for similar use cases. furthermore, we discuss possible extensions for more complex scenarios.
symbolic_computation	with the help of the symbolic computation system maple, the riccati equation mapping approach and a linear variable separation approach, a new family of complex solutions for the (2+1)-dimensional boiti-leon-pempinelli system (blp) is derived. based on the derived solitary wave solution, some novel complex wave localized excitations are obtained.
computer_vision	libcoopt is an open-source matlab code library which provides a general and convenient tool to approximately solve the combinatorial optimization problems on the set of partial permutation matrices, which are frequently encountered in computer vision, bioinformatics, social analysis, etc. to use the library, the user needs only to give the objective function and its gradient function associated with the problem. two typical problems, the subgraph matching problem and the quadratic assignment problem, are employed to illustrate how to use the library and also its flexibility on different types of problems.
signal-flow_graph	a system for measuring the dielectric propel-ties of cereal grains from 1 to 350 mhz with a coaxial sample holder is presented. several polar alcohols were used to calibrate and verify permittivity measurements obtained with a signal-flow graph model from the full two-part s-parameter measurements. at the lowest frequencies (1-25 mhz), where the phase measurements are less accurate, a lumped parameter model was used for the dielectric loss factor measurements. the system was calibrated with measurements on air and decanol and verified with measurements on octanol, hexanol, and pentanol. the standard error for the polar alcohols used for verification was 2.3% for the dielectric constant and 7.6% for the dielectric loss factor. although measurements were taken on static samples, the sample holder is designed to accommodate flowing grain. dielectric properties measurements at 25 degrees c were taken on four hard red winter wheat cultivars ranging in moisture content from about 9% to 21% with bulk densities varying from 0.66 to 0.83 g/cm(3). most of the data agreed with measurements reported in the literature.
computer_vision	x-ray screening systems have been used to safeguard environments in which access control is of paramount importance. security checkpoints have been placed at the entrances to many public places to detect prohibited items, such as handguns and explosives. generally, human operators are in charge of these tasks as automated recognition in baggage inspection is still far from perfect. research and development on x-ray testing is, however, exploring new approaches based on computer vision that can be used to aid human operators. this paper attempts to make a contribution to the field of object recognition in x-ray testing by evaluating different computer vision strategies that have been proposed in the last years. we tested ten approaches. they are based on bag of words, sparse representations, deep learning, and classic pattern recognition schemes among others. for each method, we: 1) present a brief explanation; 2) show experimental results on the same database; and 3) provide concluding remarks discussing pros and cons of each method. in order to make fair comparisons, we define a common experimental protocol based on training, validation, and testing data (selected from the public gdxray database). the effectiveness of each method was tested in the recognition of three different threat objects: 1) handguns; 2) shuriken (ninja stars); and 3) razor blades. in our experiments, the highest recognition rate was achieved by methods based on visual vocabularies and deep features with more than 95% of accuracy. we strongly believe that it is possible to design an automated aid for the human inspection task using these computer vision algorithms.
image_processing	deep learning (dl) is a powerful state-of-the-art technique for image processing including remote sensing (rs) images. this letter describes a multilevel dl architecture that targets land cover and crop type classification from multitemporal multisource satellite imagery. the pillars of the architecture are unsupervised neural network (nn) that is used for optical imagery segmentation and missing data restoration due to clouds and shadows, and an ensemble of supervised nns. as basic supervised nn architecture, we use a traditional fully connected multilayer perceptron (mlp) and the most commonly used approach in rs community random forest, and compare them with convolutional nns (cnns). experiments are carried out for the joint experiment of crop assessment and monitoring test site in ukraine for classification of crops in a heterogeneous environment using nineteen multitemporal scenes acquired by landsat-8 and sentinel-1a rs satellites. the architecture with an ensemble of cnns outperforms the one with mlps allowing us to better discriminate certain summer crop types, in particular maize and soybeans, and yielding the target accuracies more than 85% for all major crops (wheat, maize, sunflower, soybeans, and sugar beet).
analog_signal_processing	carbon nanotubes dispersed in polymer matrix have been aligned in the form of fibers and interconnects and cured electrically and by uv light. conductivity and effective semiconductor tunneling against reverse to forward bias field have been designed to have differentiable current-voltage response of each of the fiber/channel. the current-voltage response is a function of the strain applied to the fibers along axial direction. biaxial and shear strains are correlated by differentiating signals from the aligned fibers/channels. using a small doping of magnetic nanoparticles in these composite fibers, magneto-resistance properties are realized which are strong enough to use the resulting magnetostriction as a state variable for signal processing and computing. various basic analog signal processing tasks such as addition, convolution and filtering etc. can be performed. these preliminary study shows promising application of the concept in combined analog-digital computation in carbon nanotube based fibers. various dynamic effects such as relaxation, electric field dependent nonlinearities and hysteresis on the output signals are studied using experimental data and analytical model.
signal-flow_graph	in this paper, the mathematical modeling of cuk converter operating in continuous conduction mode (ccm), is done by using the signal flow graph (sfg) method and meyson gain formula. by using the obtained model, the output voltage to input voltage transfer function and also the output control transfer function are extracted. moreover, the effects of equivalent series resistors (esrs) on stability and frequency response of cuk converter are investigated in four different states, the roots location and bode diagram of each state have been studied by using related obtained transfer function. the simulation results are presented to verify the sfg performance and also the effects of the inductors and capacitor resistances on stability and frequency response.
signal-flow_graph	this article presents methods to translate a behavioral-level analog description into a field programmable analog array (fpaa) implementation. the methods consist of several steps that are referred to as function decomposition, macrocell synthesis, placement and routing, and postplacement simulation. the focus of this article is on the first three steps. the function decomposition step deals with decomposing a high-order system function into a set of lower-order functions. we present an efficient procedure for searching for an optimal solution. this procedure is based on first formally demonstrating the equivalence of two previously used optimization criteria. the objective of the macrocell synthesis step is to generate a hardware realization. a modified signal flow graph is introduced to represent fpaa circuits and graph transformations are used to identify the realizations that comply with the fpaa hardware constraints. the modified signal flow graph also allows scaling of capacitor values due to the limited set of allowable values in an fpaa. for the placement and routing step, an efficient method to estimate the circuit performance degradation due to parasitic effects is given. using performance degradation as the cost function, an algorithm for finding an optimal fpaa placement and routing configuration is given. the efficacy of the methods developed is demonstrated by direct measurements on a set of filters.
software_engineering	the use of computers and complex software is pervasive in archaeology, yet their role in the analytical pipeline is rarely exposed for other researchers to inspect or reuse. this limits the progress of archaeology because researchers cannot easily reproduce each other 's work to verify or extend it. four general principles of reproducible research that have emerged in other fields are presented. an archaeological case study is described that shows how each principle can be implemented using freely available software. the costs and benefits of implementing reproducible research are assessed. the primary benefit, of sharing data in particular, is increased impact via an increased number of citations. the primary cost is the additional time required to enhance reproducibility, although the exact amount is difficult to quantify.
software_engineering	we theorize a two-mind model of design thinking. mind 1 is about logical design reasoning, and mind 2 is about the reflection on our reasoning and judgments. the problem solving ability of mind 1 has often been emphasized in software engineering. the reflective mind 2, however, has not received much attention. in this study, we want to find out if mind 2, or reflection, can improve design discourse, a prerequisite of design quality. we conducted multiple case studies with 12 student groups, divided into test groups and control groups. we provided external reflections to the test groups. no reflections were given to the control groups. we analyzed the quality of the design discourse in both groups. we found that reflection (mind 2) improves the quality of design discourse (mind 1) under certain preconditions. the results highlight the significance of reflection as a mean to improve the quality of design discourse. we conclude that software designers need both mind 1 and mind 2 to obtain a higher quality design discourse, as a foundation for a good design. copyright (c) 2016 john wiley & sons, ltd.
signal-flow_graph	using the signal-flow graph approach, a general synthesis method for the realisation of high-order voltage transfer functions is presented and a current conveyor filter is obtained. the resulting filter contains a minimum number of capacitors, at most 2n+3 resistors, as well as n+2 current conveyors of plus type, all of which operate in current-mode.
state_space_representation	this article discusses filtering, prediction and simulation in univariate and multivariate noncausal processes. a closed-form functional estimator of the predictive density for noncausal and mixed processes is introduced that provides prediction intervals up to a finite horizon h. a state-space representation of a noncausal and mixed multivariate vector autoregressive process is derived in two ways-by the partial fraction decomposition or from the real jordan canonical form. a recursive bhhh algorithm for the maximization of the approximate log-likelihood function is proposed, which calculates the filtered values of the unobserved causal and noncausal components of the process. the new methods are illustrated by a simulation study involving a univariate noncausal process with infinite variance.
distributed_computing	determination of conserved regions that plays vital roles on regulation of transcription and translation processes is one of the most challenging problems in bioinformatics. however, with the increasing power of distributed computing systems, solving these types of combinatorial problems by utilizing parallelized brute force or exhaustive search algorithms recently has gained popularity. in this paper, we investigated the parallelized implementation of a search tree based brute force technique to find motifs with different lengths. experimental studies showed that parallelization of the brute force techniques with less communication overhead is significantly increased the usability of them to analyze long nucleotide sequences.
pid_controller	this paper presents fuzzy-pid (fpid) control scheme for a blood glucose control of type 1 diabetic subjects. a new metaheuristic cuckoo search algorithm (csa) is utilized to optimize the gains of fpid controller. csa provides fast convergence and is capable of handling global optimization of continuous nonlinear systems. the proposed controller is an amalgamation of fuzzy logic and optimization which may provide an efficient solution for complex problems like blood glucose control. the task is to maintain normal glucose levels in the shortest possible time with minimum insulin dose. the glucose control is achieved by tuning the pid (proportional integral derivative) and fpid controller with the help of genetic algorithm and csa for comparative analysis. the designed controllers are tested on bergman minimal model to control the blood glucose level in the facets of parameter uncertainties, meal disturbances and sensor noise. the results reveal that the performance of csa-fpid controller is superior as compared to other designed controllers.
signal-flow_graph	this paper presents a systematic development of unified signal flow graph model for an interleaved buck converter system operating in continuous inductor current mode. from this signal flow graph small, large-signal and steady-state models are developed, which are useful to study the converter dynamic and steady-state behaviour. converter performance expressions like steady-state voltage gain, efficiency expressions and other small-signal characteristic transfer functions are derived. development of unified signal flow graph is explained for a 3-cell interleaved converter system. derivation of large, small-signal and steady-state models from the unified signal flow graph is demonstrated by considering a 2-cell interleaved buck converter system. large signal model was programmed in tutsim simulator, and the large-signal responses against supply, load disturbances were predicted. signal flow graph analysis results are validated with psim simulations. further, the mathematical models obtained from the signal flow graph modelling are in agreement with those obtained from the state-space averaging technique. copyright (c) 2003 john wiley sons, ltd.
parallel_computing	hypergraph partitioning is commonly used in solving very large scale integration (vlsi) placement problem, data mining, sparse matrix multiplication, and parallel computing. this paper presents a novel heuristic for hypergraph partitioning based on nonlinear programming. in our approach we consider adjacent one-dimensional bins. since the reduction of cuts is equivalent to reducing the net length across the two bins, the vertices are moved across the bins in such a way that the density of vertices in each bin is balanced as per the partitioning requirement and reduction in the wirelength. for the walshaw partitioning benchmarks, our tool naps' results are consistently comparable to that obtained by chaco. our tool nap produces better cuts than chaco on 22 instances out of 29 graph samples.
microcontroller	wearable heaters have been increasingly attracting researchers' great interest due to their efficient utility in maintaining warmth and in thermotherapy. nowadays carbon nanomaterials and metallic nanowires tend to become the mainstream heating elements in wearable heaters considering their excellent electrical and mechanical properties. though considerable progress has been made, there still exist challenging issues that need to be addressed in practical applications, including bad breathability and poor endurance to mechanical deformations. here, we devise a copper nanowire based composite fiber with a unique hierarchical structure. this fiber possesses not only excellent heating performance, but also fantastic tolerance to mechanical impact, such as bending, twisting, and stretching. we further weave these fibers into a wearable heating fabric and realize smart personal heating management through an android phone by integrating with a microcontroller unit. two practical applications are demonstrated including a heating kneepad for articular thermotherapy and a heating coat on an infant model for maintaining warmth.
electrical_network	the emergence of many non-linear loads causes severe disturbances in the present power system. it affects the power quality thereby decreasing the overall efficiency. the important issue among the power quality is harmonics that becomes the major concern in the power system network. this survey mainly discusses the causes and effects of harmonics in the electrical network. it also discusses the various detection techniques that detects and analyzes the presence of harmonics in the system. in addition to this, this survey also discusses the new technique called pan tompkins algorithm to detect the harmonics with the communication protocol as cloud computing.
system_identification	we study the modeling of lagrangian systems with multiple degrees of freedom. based on system dynamics, canonical parametric models require ad hoc derivations and sometimes simplification for a computable solution; on the other hand, due to the lack of prior knowledge in the system 's structure, modern nonparametric models in machine learning face the curse of dimensionality, especially in learning large systems. in this paper, we bridge this gap by unifying the theories of lagrangian systems and vector-valued reproducing kernel hilbert space. we reformulate lagrangian systems with kernels that embed the governing euler-lagrange equation-the lagrangian kernels-and show that these kernels span a subspace capturing the lagrangian 's projection as inverse dynamics. by such property, our model uses only inputs and outputs as in machine learning and inherits the structured form as in system dynamics, thereby removing the need for the mundane derivations for new systems as well as the generalization problem in learning from scratches. in effect, it learns the system 's lagrangian, a simpler task than directly learning the dynamics. to demonstrate, we applied the proposed kernel to identify the robot inverse dynamics in simulations and experiments. our results present a competitive novel approach to identifying lagrangian systems, despite using only inputs and outputs.
symbolic_computation	for a given septic bezier curve with a distinct ordered sequence of control points, how to determine whether it is a ph curve via exact symbolic computation in theory. this problem motivated the study of a necessary and sufficient condition for a planar septic bezier curve to possess a pythagorean hodograph (ph). based on the definition of a ph curve and the complex representation of a planar curve, we develop geometric conditions in terms of the leg-lengths and angles of a control polygon that must be separated to guarantee the ph property. the relation between the compatibility of solutions with respect to the complex coefficients of ph equations and geometric constraints is analyzed. moreover, ph septic curves with inflections are extended to construct s-shaped transition curves. (c) 2015 elsevier b.v. all rights reserved.
parallel_computing	mpj express is a messaging system that allows application developers to parallelize their compute-intensive sequential java codes on high performance computing clusters and multicore processors. in this paper, we extend mpj express software to provide two new communication devices. the first device-called hybrid-enables mpj express to exploit hybrid parallelism on cluster of multicore processors by sitting on top of existing shared memory and network communication devices. the second device-called native-uses jni wrappers in interfacing mpj express to native mpi implementations like mpich and open mpi. we evaluate performance of these devices on a range of interconnects including 1g/10g ethernet, 10g myrinet and 40g infiniband. in addition, we analyze and evaluate the cost of mpj express buffering layer and compare it with the performance numbers of other java mpi libraries. our performance evaluation reveals that the native device allows mpj express to achieve comparable performance to native mpi libraries-for latency and bandwidth of point-to-point and collective communications-which is a significant gain in performance compared to existing communication devices. the hybrid communication device-without any modifications at application level-also helps parallel applications achieve better speedups and scalability by exploiting multicore architecture. our performance evaluation quantifies the cost incurred by buffering and its impact on overall performance of software. we witnessed comparative performance as both new devices improve application performance and achieve upto 90 % of the theoretical bandwidth available without application rewriting effort-including nas parallel benchmarks, point-to-point and collective communication.
state_space_representation	our focus is on realistically modeling and forecasting dynamic networks of face-to-face contacts among individuals. important aspects of such data that lead to problems with current methods include the tendency of the contacts to move between periods of slow and rapid changes, and the dynamic heterogeneity in the actors' connectivity behaviors. motivated by this application, we develop a novel method for locally adaptive dynamic (lady) network inference. the proposed model relies on a dynamic latent space representation in which each actor 's position evolves in time via stochastic differential equations. using a state-space representation for these stochastic processes and polya-gamma data augmentation, we develop an efficient mcmc algorithm for posterior inference along with tractable procedures for online updating and forecasting of future networks. we evaluate performance in simulation studies, and consider an application to face-to-face contacts among individuals in a primary school.
electricity	microgrids assisted by renewable energy resources are complex man made systems of various interconnected components. a number of real life scenarios relating to resource management in microgrids are modeled as multi-objective optimization formulations where multiple objectives may or may not conflict with each other. while considering the type of application, input and output of the problem, the nature of optimization problem changes. to address various types of optimization problems relating to microgid design, planning and operation, there exist a number of optimization solution types. we investigate the existing literature to classify different optimization objectives with respect to designing, planning and operation of microgrids. some mathematical formulations for commonly used objectives relating to resource management in microgrids have been tabulated. we also classified the optimization types being used to address various optimization problems relating to resource management in microgrids. various types of solution approaches along with the relevant simulation tools are also presented. we also reviewed the multicriteria optimization for different application areas of smart grid. the article can serve as a foundation for further research in the area of multicriteria decision making relating to resource management in micrgorids.
microcontroller	in this paper we proposed, designed and evaluated a novel decentralized and self-learning framework to support both high reliability and energy-efficiency for periodic traffic applications in wsns. our autonomous framework comprises three main components: estimation and identification of periodic flows, dynamic wakeup-sleep scheduling and asynchronous channel hopping. with asynchronous channel hopping the frequency hopping pattern is determined by each source node autonomously, and forwarders have to identify and follow the pattern. we also propose a light and efficient controller to eliminate the collision caused by multi-flow overlap at forwarders. we present design and evaluation of our autonomous framework using realistic trace-based simulation. the results show that our asynchronous channel hopping solution improves the packet reception rate compared to the single channel solutions without the need of an expensive signaling and time synchronization overhead. we also show that with this scheme the average energy consumption yields a 50 % lower than the single channel solutions. furthermore, we analyze in detail the energy consumption characteristics of our autonomous framework when operated with a popular transceiver, the chipcon cc2420 and texas instruments msp430 microcontroller. we analyze how much various factors contribute to the overall energy consumption. these insights provide valuable guidance on where to start with any effort geared towards saving energy.
digital_control	fault detection in induction machines is commonly realized through motor current signature analysis. in case of wound-rotor induction machine rotor faults, the amplitude of the inverse sequence harmonic component -sf of the rotor current space-vector is monitored in order to sense its variation. however, motor current signature analysis is limited by some drawbacks. in fact, under transient operating conditions an efficient fast fourier transform cannot be made, since slip or frequency vary, and so the amplitude of the harmonic component -sf. in this paper, a new technique based on the square current space-vector signature analysis (scssa) is proposed for rotor fault detection in wound-rotor induction machines operating under time-varying conditions. the performance of the proposed approach is confirmed by simulation and experimental results. the proposed technique can be easily embedded in the digital control system for modern wind power plants.
algorithm_design	vibrations with unknown and/or time-varying frequencies significantly affect the achievable performance of control systems, particularly in precision engineering and manufacturing applications. this paper provides an overview of disturbance-observer-based adaptive vibration rejection schemes; studies several new results in algorithm design; and discusses new applications in semiconductor manufacturing. we show the construction of inverse-model-based controller parameterization and discuss its benefits in decoupled design, algorithm tuning, and parameter adaptation. also studied are the formulation of recursive least squares and output-error-based adaptation algorithms, as well as their corresponding scopes of applications. experiments on a wafer scanner testbed in semiconductor manufacturing prove the effectiveness of the algorithm in high-precision motion control. copyright (c) 2015 john wiley & sons, ltd.
network_security	the development of wireless vehicular ad-hoc network (vanet) aimed to enhance road 's safety and provide comfortable driving environment by delivering early warning and infotainment messages. intentional jamming attacks target at undermining such a goal by disrupting wireless communications. while detecting jamming attacks is important towards enhancing road safety, it is challenging because vanet operates in outdoor environment (highly changeable road conditions and atmospheric phenomena), and encompasses volatile topology and high mobility of vehicles (traveling speed and directions). to overcome these challenges, in this work, we study jamming attack mobility and behaviors in ieee802.11p networks. in particular, we focus on analyzing jamming impact based on jammers behaviors, and mobility patterns. thus, in order to achieve reliable detection, first we identify the impact of vehicles' density on network performance. then, we study jamming effectiveness when adopting different mobility patterns (stationary, random, or targeting) and behaviors (constant, random, and reactive). finally, we propose a two phase detection algorithm and evaluate it in a simulation environment. our approach shows promising results to detect different types of jammers accurately in ieee802.11p networks.
relational_databases	due to the fact that existing database systems are increasingly more difficult to use, improving the quality and the usability of database systems has gained tremendous momentum over the last few years. in particular, the feature of explaining why some expected tuples are missing in the result of a query has received more attention. in this paper, we study the problem of explaining missing answers to top-k queries in the context of sql (i.e., with selection, projection, join, and aggregation). to approach this problem, we use the query-refinement method. that is, given as inputs the original top-k sql query and a set of missing tuples, our algorithms return to the user a refined query that includes both the missing tuples and the original query results. case studies and experimental results show that our algorithms are able to return high quality explanations efficiently.
computer_graphics	making decisions using judgements of multiple non-deterministic indicators is an important task, both in everyday and professional life. learning of such decision making has often been studied as the mapping of stimuli (cues) to an environmental variable (criterion); however, little attention has been paid to the effects of situation-by-person interactions on this learning. accordingly, we manipulated cue and feedback presentation mode (graphic or numeric) and task difficulty, and measured individual differences in working memory capacity (wmc). we predicted that graphic presentation, fewer cues, and elevated wmc would facilitate learning, and that person and task characteristics would interact such that presentation mode compatible with the decision maker 's cognitive capability (enhanced visual or verbal wmc) would assist learning, particularly for more difficult tasks. we found our predicted main effects, but no significant interactions, except that those with greater wmc benefited to a larger extent with graphic than with numeric presentation, regardless of which type of working memory was enhanced or number of cues. our findings suggest that the conclusions of past research based predominantly on tasks using numeric presentation need to be reevaluated and cast light on how working memory helps us learn multiple cue-criterion relationships, with implications for dual-process theories of cognition.
network_security	with the popularization and application of internet technology, it has brought great opportunities, challenges and has a significant change to various industries, which entered the internet age. computer network is double-edged sword, bringing convenience to people at the same time there are some security risks, seriously affecting the information security of the internet age. therefore, this article is to explore the main computer network security risks and to lower the risks of computer security management measures, thus providing an important guarantee for computer network security.
microcontroller	continuous monitoring of environmental parameters provides farmers with useful information, which can improve the quality and productivity of crops grown in greenhouses. the objective of this study was to develop a greenhouse environment measurement system using a low-cost microcontroller with open-source software. greenhouse environment parameters measured were air temperature, relative humidity, and carbon dioxide (co2) concentration. the ranges of the temperature, relative humidity, and co2 concentration were -40 to 120 degrees c, 0 to 100%, and 0 to 10,000 ppm, respectively. a 128 x 64 graphic lcd display was used for real-time monitoring of the greenhouse environments. an arduino uno r3 consisted of a usb interface for communicating with a computer, 6 analog inputs, and 14 digital input/output pins. a temperature/relative humidity sensor was connected to digital pins 2 and 3. a co2 sensor was connected to digital pins 12 and 13. the lcd was connected to digital pin 1 (tx). the sketches were programmed with the arduino software (ide). a measurement system including the arduino board, sensors, and accessories was developed (totaling $244). data for the environmental parameters in a venlo-type greenhouse were obtained using this system without any problems. we expect that the low-cost microcontroller using open-source software can be used for monitoring the environments of plastic greenhouses in korea.
pid_controller	in feedback control of mechatronic systems, sensor signals are usually noisy and uncertain because of measurement errors and environmental disturbances. such uncertainty and noise of feedback signals may cause instability of the controlled systems. this paper presents a new model-free discrete-time sliding mode filter for effectively removing noise by balancing the tradeoff between the filtering smoothness and the suppression of delay. the presented filter is an extension of a sliding mode filter (jin et al. real-time quadratic sliding mode filter for removing noise. adv. robot., 2012) by including an adaptive gain, of which value is determined in a similar way to that of a first-order adaptive windowing filter (janabi-sharifi et al. discrete-time adaptive windowing for velocity estimation. ieee trans. control syst. technol., 2000). the effectiveness of the presented filter is validated through numerical examples and experiments.
analog_signal_processing	wing-wave is an ocean, alternative energy system to convert the circular motion of ocean waves as they propagate through the sea into electrical energy. the system consists of planes, called ""wings"". the wings are mounted on the sea floor and move in a radial motion as a result of the passing waves. the mechanical energy is translated into electrical energy by means of an electrical generator. three wing-wave prototype systems were built at florida institute of technology (florida tech) and deployed november 17th, 2010, june 23rd, 2011, and june 6th, 2012, respectively. each deployment provided valuable information that lead to modifications in subsequent versions and deployment techniques, culminating in the demonstration of a fully functioning and feasible alternative, renewable, electrical energy producing subsea system.
parallel_computing	purpose: this paper studies the influence of information and communication technologies on human reasoning and decision making. it investigates the potential impact of ambient intelligence on change in pedestrian mobility behavior, using a large city-scale scenario. methods: this work establishes an interplay between social and technological aspects of awareness by augmenting a model-driven framework of a realistic information eco-system. a distributed multi-agent system is developed to model a real-life urban mobility environment. the model is then simulated using a large scale parallel computing platform. results: evaluation results revealed that the quality of information in ambient-assisted environments increases when compared with those without ambient intelligence. conclusion: we conclude that there is a positive correlation between the extent of information being shared in a socially-inspired information eco-systems and the level of collective awareness in an urban mobility scenario.
analog_signal_processing	a fuzzy sets intersection procedure to select the optimum sizes of analog circuits composed of metal-oxidesemiconductor field-effect-transistors (mosfets), is presented. the cases of study are voltage followers (vfs) and a current-feedback operational amplifier (cfoa), where the width (w) and length (l) of the mosfets are selected from the space of feasible solutions computed by swarm or evolutionary algorithms. the evaluation of three objectives, namely: gain, bandwidth and power consumption; is performed using hspice (tm) with standard integrated circuit (ic) technology of 0.35 mu m for the vfs and 180nm for the cfoa. therefore, the intersection procedure among three fuzzy sets representing ""gain close to unity"", ""high bandwidth"" and ""minimum power consumption"", is presented. the main advantage relies on its usefulness to select feasible w/l sizes automatically but by considering deviation percentages from the desired target specifications. basically, assigning a threshold to each fuzzy set does it. as a result, the proposed approach selects the best feasible sizes solutions to guarantee and to enhance the performances of the ics in analog signal processing applications.
bioinformatics	an important problem in the field of bioinformatics is to identify interactive effects among profiled variables for outcome prediction. in this paper, a logistic regression model with pairwise interactions among a set of binary covariates is considered. modeling the structure of the interactions by a graph, our goal is to recover the interaction graph from independently identically distributed (i.i.d.) samples of the covariates and the outcome. when viewed as a feature selection problem, a simple quantity called influence is proposed as a measure of the marginal effects of the interaction terms on the outcome. for the case when the underlying interaction graph is known to be acyclic, it is shown that a simple algorithm that is based on a maximum-weight spanning tree with respect to the plug-in estimates of the influences not only has strong theoretical performance guarantees, but can also outperform generic feature selection algorithms for recovering the interaction graph from i.i.d. samples of the covariates and the outcome. our results can also be extended to the model that includes both individual effects and pairwise interactions via the help of an auxiliary covariate.
electrical_circuits	unexpected faults occurring in certain conditions on renewable energy sources connected to the power grid may result in severe damages, if capacitive load exists and consequently inductive power factor correction is applied with shunt coils. the paper presents some investigations on a case study.
cryptography	the domain name system (dns) is a core internet infrastructure that translates names to machine-readable information, such as ip addresses. security flaws in dns led to a major overhaul, with the introduction of the dns security (dnssec) extensions. dnssec adds integrity and authenticity to the dns using digital signatures. dnssec, however, has its own concerns. it suffers from availability problems due to packet fragmentation and is a potent source of distributed denial-of-service attacks. in earlier work, we argued that many issues with dnssec stem from the choice of rsa as default signature algorithm. a switch to alternatives based on elliptic curve cryptography (ecc) can resolve these issues. yet switching to ecc introduces a new problem: ecc signature validation is much slower than rsa validation. thus, switching dnssec to ecc imposes a significant additional burden on dns resolvers, pushing load toward the edges of the network. therefore, in this paper, we study the question: will switching dnssec to ecc lead to problems for dns resolvers, or can they handle the extra load? to answer this question, we developed a model that accurately predicts how many signature validations dns resolvers have to perform. this allows us to calculate the additional cpu load ecc imposes on a resolver. using real-world measurements from four dns resolvers and with two open-source dns implementations, we evaluate future scenarios where dnssec is universally deployed. our results conclusively show that switching dnssec to ecc signature schemes does not impose an insurmountable load on dns resolvers, even in worst case scenarios.
bioinformatics	histih3d gene encodes histone h3.1 and is involved in gene-silencing and heterochromatin formation. hist1h3d expression is upregulated in primary gastric cancer tissue. in this study, we explored the effects of hist1h3d expression on lung cancer, and its mechanisms. hist1h3d expression was measured by immunohistochemistry and rt-pcr in lung cancer tissues and human lung cancer cell lines. cell proliferation was assessed by mtt assay. flow cytometric analysis was used to determine cell cycle distribution and apoptosis. levels of related proteins were detected by western blotting. bioinformatics analysis was performed to investigate related signaling pathways. cdna microarray analysis was performed to identify differentially expressed genes following hist1h3d knockdown. hist1h3d expression was upregulated in lung cancer tissue samples and the h1299 human lung cancer cell line (p<0.01). regulation of hist1h3d expression in nucleus of cells in lung cancer tissues was significant associated with tumor stage (p=0.02) and lymph node metastases (p=0.04). downregulation of hist1h3d expression led to suppression of proliferation and colony forming ability, cell cycle arrest at the go/g, phase, and promotion of cell apoptosis. the microarray data revealed 522 genes that were differentially expressed after hist1h3d knockdown in h1299 cells. these genes were shown to be linked to numerous pathways, including the cell cycle, p53 signaling, and mcm. western blot analysis confirmed upregulated expression of the thbs1 and tp53i3 genes, and downregulated expression of the cdk6, cdkn1 and ccne2 genes. in conclusion, our results suggest that hist1h3d is highly expressed in lung cancer cell lines and tissues. furthermore, hist1h3d may be important in cell proliferation, apoptosis and cell cycle progression, and is implicated as a potential therapeutic target for lung cancer.
analog_signal_processing	development of new ways to provide clean onboard electric energy is a key feature for the sailing boat industry and sail race teams. this is why marine turbines (mt), are considered to provide onboard energy. these turbines can be used to harness kinetic energy of the water flow related to the ship motion. in this paper we propose to study an unconventional design of such a turbine where the electrical generator is located in the periphery of the blades and where the magnetic gap is water filled. this kind of solution called ""rim driven"" structure allows to increase the compactness and the robustness of the system. due to the strong interaction of the multi physical phenomena, an electromagnetic model and a thermal model of the pm generator are associated with a hydrodynamic model of the blades and of the water flow in the underwater air gap. these models are used in a global coupled design approach in order to optimize, under constraints, the global efficiency of the system. this solution allows to optimize the system design.
relational_databases	despite the huge amount of work devoted to the treatment of time within the relational context, few relevant temporal phenomena still remain to be addressed. one of them is the treatment of ""nearly periodic events"", i.e., events/facts that occur in intervals of time which repeat periodically (e.g., a meeting occurring twice each monday, possibly not at regular times). nearly periodic events are quite frequent in everyday life, and thus in many applicative contexts. their treatment within the relational model is quite challenging, since it involves the integrated treatment of three aspects: (i) the number of repetitions, (ii) their periodicity, and (iii) temporal indeterminacy. coping with this problem requires an in-depth extension of current temporal relational database techniques. in this paper, we introduce a new data model, and new definitions of relational algebraic operators coping with the above issues. we ascertain the properties of the new model and algebra, with emphasis on the expressiveness of our representation model, on the reducibility property, and on the correctness of the algebraic operators.
electrical_circuits	purpose - the purpose of this paper is to propose a method to reduce the non-linear distortion of a transistor to its input and output ports to aid distortion contribution analysis (dca). this is especially needed when the internal structure of a device model is complex. design/methodology/approach - the non-linear distortion generated by all non-linear sources inside a device model are reduced to transistor i/o ports by lmse fitting techniques. simulations of an ldmos power transistor are used to compare the reduced distortion results with the actual non-linear sources. findings - it is shown, that device models where the current sources are split by intermediate nodes cause superficial results, when distortion contributions are calculated as a superposition of contributions from individual non-linear sources. the proposed iterative fitting technique works. research limitations/implications - some non-quasistatic effects and the transfer functions from external terminals to internal controlling nodes are not covered. practical implications - the analysis is a step toward a generic non-linear distortion contribution simulation tool that would aid the designers to develop more linear analog circuits. originality/value - the concept of dca itself is fairly new. this paper makes a step to represent the distortion sources in a canonical way.
parallel_computing	earthquake-induced landslides are serious natural hazards that shocked us with tremendous casualties and great economic losses in many mountainous areas around the world. however, predicting and preventing the earthquake-induced landslides is very difficult due to the complicated relationship between seismic dynamics and coseismic landsliding. comprehensive understanding of earthquake-induced landslides from the perspective of seismic dynamic mechanism remains inadequate at present. this study employs an elastoplastic spectral element method incorporating parallel computing and represents a realistic three-dimensional slope model via a semi-structured hexahedral mesh to investigate the dynamic failure characteristics of earthquake-induced landslides. dynamic behaviours of slopes are simulated using a continuumbased approach with a mohr-coulomb yield criterion. displacement fields are calculated using the shear strength reduction technique. pseudo-static seismic loading is performed to assess the slope stability quantitatively and complex topography is taken into consideration. the xinzhong landslide that occurred in beichuan country is one of destructively collapsing landslides triggered by the wenchuan earthquake and is therefore selected as a case study for discussion. three-dimensional visualization of the calculated results quantitatively demonstrated that the three-dimensional numerical model well reproduced the coseismic landsliding response and its essential dynamic failure pattern, which could not be purely captured by geographic information systems (gis) and remote sensing (rs) technologies and calculated using simply two-dimensional numerical model. the numerical results also showed that tensile and shear fractures had significant influences on the nature of the failed surface development. in addition, the presence of seismic loading in the slope could cause obvious disturbances for the slope stability. comparative analysis indicated that the shear surface of the earthquake-induced slope was shorter and the tension crack surface was deeper than that of the normal gravity condition. moreover, the landslide mainly occurred in the transition from the upper to lower part of the slope, indicating that the slope topography was one of the crucial factors resulting in slope failure. although the model was constructed without the presence of a pre-existing failure surface, comparative analysis addressed that the failure surface obtained by the numerical simulation was in close agreement with that by the post-failure investigations. the results could provide insight into better understanding of the relationship between landslide and seismic dynamic mechanism. the study has practical significance for the effective prevention and mitigation of earthquake-induced landslide hazards.
pid_controller	proportional-integral-derivative (pid) control has been widely used in industrial equipment. however, the transient response obtained is poor when the fixed pid controller is used for nonlinear systems. moreover, a hydraulic excavator consists of a nonlinear system with a derivative element. in this case, the system output does not track the reference signal because the integral element in the controller is canceled out by the derivative element in the system. in order to improve the transient response and the tracking performance, a data-driven pid control for tuning and updating pid gains has been proposed. however, the data-driven pid control method could not improve the tracking performance. in this paper, the controller design scheme based on a data-driven approach for the hydraulic excavator is proposed. moreover, the control parameters of the proposed scheme are updated in an off-line manner by using fictitious reference iterative tuning. the effectiveness of this controller is verified by simulating the control behavior of a hydraulic excavator.
relational_databases	nosql databases are designed to address performance and scalability requirements of web based application which cannot be addressed by traditional relational databases. due to their contrast in priorities and architecture to conventional relational databases using sql, these databases are referred as ""nosql"" databases since they incorporate lots of additional features in addition to the features of conventional databases. the relational databases strongly follow the acid (atomicity, consistency, isolation, and durability) properties while the nosql databases follow base (basically available, soft state, eventual consistency) principles. this survey paper is an analytical study on base features of some of nosql databases. (c) 2015 elsevier b.v. all rights reserved.
computer_programming	the present work addresses the development of a finite element formulation for handling bending, buckling, and post buckling analysis of composite laminated structures with damage. the inverse hyperbolic shear deformation theory (ihsdt) was applied in the finite element formulation. the effect of damage is analyzed for thin composite plates. an anisotropic damage formulation was used to simulate the damage, which is based on the concept of stiffness reduction. computer programming is developed in the matlab environment. the excellent agreement of the results obtained in the present method with those from references shows that the technique is effective and precise. parametric studies in the buckling behavior of a damaged composite plate are presented. critical buckling temperatures are computed for a damaged plate using the present model. thermal post buckling equilibrium paths are traced for various parametric variations for composite plates with mild damage and compared the results with that of undamaged cases. the validation of ihsdt has been demonstrated for buckling analysis in thermal environment for composite plates with an internal flaw. the present work is worthwhile compared with previous works due to the choice of finite element method and inverse hyperbolic shear deformation theory for analyzing the influence of damage on buckling and post buckling behavior of laminated plates. (c) 2016 the institution of structural engineers. published by elsevier ltd. all rights reserved.
electrical_circuits	electrical analogy, which is used to solve numerical problems in fluid mechanics, is used here to solve the classical problem of couette flow between two parallel plates, hagen-poiseuille flow in a pipe and the transient free convection flow along a semi-infinite vertical wall. the nonlinear system of partial differential equations is numerically solved by the network simulation method, based on thermo-electric analogy. a simulator of electrical devices, permits the direct visualization of the local and/or integrated transport variables (temperatures, velocities, concentrations, and fluxes) at any point or section of the medium. at the same time, the solution for both transient and steady-state problems is obtained, the only requirement being finite-difference schemes for the spatial variable. this educational tool is seen to be very useful for solving numerical problems in engineering and can be used to graduate in the university. (c) 2011 wiley periodicals, inc. comput appl eng educ 21: 748-757, 2013
data_structures	partial match queries constitute the most basic type of associative queries in multidimensional data structures such as -d trees or quadtrees. given a query where s of the coordinates are specified and are left unspecified (), a partial match search returns the subset of data points in the data structure that match the given query, that is, the data points such that whenever . there exists a wealth of results about the cost of partial match searches in many different multidimensional data structures, but most of these results deal with random queries. only recently a few papers have begun to investigate the cost of partial match queries with a fixed query . this paper represents a new contribution in this direction, giving a detailed asymptotic estimate of the expected cost for a given fixed query . from previous results on the cost of partial matches with a fixed query and the ones presented here, a deeper understanding is emerging, uncovering the following functional shape for <(l.o.t. lower order terms, throughout this work) in many multidimensional data structures, which differ only in the exponent and the constant , both dependent on s and k, and, for some data structures, on the whole pattern of specified and unspecified coordinates in as well. although it is tempting to conjecture that this functional shape is ""universal"", we have shown experimentally that it seems not to be true for a variant of -d trees called squarish -d trees.
symbolic_computation	in this paper, multiple exp-function method is employed to investigate exact multiple wave solutions for (2 + 1)-dimensional potential kadomtsev-petviashvili equation and (3 + 1)dimensional jimbo-miwa equation. not only already known multiple wave solutions are recovered, but also several new or more general multiple wave solutions are obtained. (c) 2014 elsevier ltd. all rights reserved.
image_processing	in this letter, a highly reconfigurable crossbar transmission line switch matrix for magnetic resonance imaging (mri) system is proposed. unlike the conventional m x n crossbar switch configuration, the proposed structure can manipulate 2m x n matrix without doubling the area occupancy. also, the proposed structure includes the signal loss-compensation circuitry based on inductor banks to enhance signal-to-noise ratio (snr). thus, for any required numbers of input and output channels, the proposed structure can reduce the overall size, the number of required component, and even increase the quality of mr images by snr enhancement. the proposed structure was implemented and verified at 4-tesla (170 mhz) mr system through the comparison of rf path loss, snr and phantom test image qualities.
software_engineering	software engineering predictive modeling involves construction of models, with the help of software metrics, for estimating quality attributes. recently, the use of search-based techniques have gained importance as they help the developers and project-managers in the identification of optimal solutions for developing effective prediction models. in this paper, we perform a systematic review of 78 primary studies from january 1992 to december 2015 which analyze the predictive capability of search-based techniques for ascertaining four predominant software quality attributes, i.e., effort, defect proneness, maintainability and change proneness. the review analyses the effective use and application of search-based techniques by evaluating appropriate specifications of fitness functions, parameter settings, validation methods, accounting for their stochastic natures and the evaluation of developmental models with the use of well-known statistical tests. furthermore, we compare the effectiveness of different models, developed using the various search-based techniques amongst themselves, and also with the prevalent machine learning techniques used in literature. although there are very few studies which use search-based techniques for predicting maintainability and change proneness, we found that the results of the application of search-based techniques for effort estimation and defect prediction are encouraging. hence, this comprehensive study and the associated results will provide guidelines to practitioners and researchers and will enable them to make proper choices for applying the search-based techniques to their specific situations.
signal-flow_graph	this paper reports the design and development of reconfigurable (up to 8192-point), data parallel, constant geometry fast fourier transform (cg-fft) architectures based on network-on-chip (noc) paradigm. twiddle factor multiplications have been realized using pipelined cordic rotators in the proposed architecture in order to ensure its high throughput. mapping of fft functions to cores has been done by considering the proposed signal flow graph (sfg) for cg-fft architecture, which helps in optimizing the design of network components (routers and network interfaces) and reducing the latency of fft computation. the proposed input-size aware architecture can withstand faults in other processing elements (pes) as it can accomplish the entire fft computation using only one pe as well. when mapped onto mesh based noc, the proposed architectures could achieve reduction in latency by 5 x, compared to several existing, fft architectures on noc. hardware realization of the pe and the network components of the proposed architectures have been done using xilinx kintex-7 family field-programmable gate array (fpga) device. the maximum operating frequency of a pe in the proposed architecture has been found to be 184.010 mhz, which meets the timing specifications of several application standards, such as dvb-t/h, dab, 802.11a/n and uwb. in addition to the fpga-prototype, the proposed architectures have also been synthesized in asic design flow to obtain area and power results. (c) 2015 elsevier b.v. all rights reserved.
analog_signal_processing	this paper presents a laboratory set-up to be used as wind turbine emulator. the emulator can be used for research applications to drive an electrical generator in a similar way as a wind turbine, by reproducing the torque developed by a wind turbine for a given wind velocity. also, it can be used as an educational tool to teach the behaviour, operation and control of a wind turbine. in this work, the turbine torque is reproduced by a dc drive. a control program reads wind velocities from an input file and calculates torque reference to the dc drive. a commercial dc drive with torque control is used to apply the commanded torque to the shaft of the electrical generator. both, stall wind turbines and pitch controlled wind turbines can be emulated in the laboratory set-up. the emulator reproduced not only the mean torque of the turbine but also the oscillating torque due to wind shear and tower shadow. this functionality of the emulator can be used to investigate the effect of these phenomena in power quality. experimental results are given which show that the emulator is an useful tool for the purposes already mentioned.
control_engineering	in this paper the role of control history in control engineering education is discussed. a possible web based approach to historical aspects in control education is presented. the paper approaches fundamentals of creating traditional webquests, as well as the author 's approach to creation of learning tools. the suggested approach is to reject use of the internet resources and to use local ones, to simplify system of performance evaluation, to add self-assessment tests for each variant and a final test. (c) 2015, ifac (international federation of automatic control) hosting by elsevier ltd. all rights reserved.
machine_learning	background and objective: to safely select the proper therapy for ventricullar fibrillation (vf) is essential to distinct it correctly from ventricular tachycardia (vt) and other rhythms. provided that the required therapy would not be the same, an erroneous detection might lead to serious injuries to the patient or even cause ventricular fibrillation (vf). the main novelty of this paper is the use of time-frequency (t-f) representation images as the direct input to the classifier. we hypothesize that this method allow to improve classification results as it allows to eliminate the typical feature selection and extraction stage, and its corresponding loss of information. methods: the standard aha and mit-bih databases were used for evaluation and comparison with other authors. previous to t-f pseudo wigner-ville (pwv) calculation, only a basic preprocessing for denoising and signal alignment is necessary. in order to check the validity of the method independently of the classifier, four different classifiers are used: logistic regression with l2 regularization (l2 rlr), adaptive neural network classifier (annc), support vector machine (ssvm), and bagging classifier (bagg). results: the main classification results for vf detection (including flutter episodes) are 95.56% sensitivity and 98.8% specificity, 88.80% sensitivity and 99.5% specificity for ventricular tachycardia (vt), 98.98% sensitivity and 97.7% specificity for normal sinus, and 96.87% sensitivity and 99.55% specificity for other rhythms. conclusion: results shows that using t-f data representations to feed classifiers provide superior performance values than the feature selection strategies used in previous works. it opens the door to be used in any other detection applications. (c) 2017 elsevier b.v. all rights reserved.
electrical_network	this work proposed a new real time monitoring system in distribution transformer with communication through a zigbee network. it obtains the voltage, current, power, energy and frequency of all loads connected at the distribution transformer. the information collected in the measurements are send to a server through a zigbee network for safe the information. the new real time system build a wireless network with low energy consumption and a large transmission distance with enough conditions to work in an urban distribution electric network. this system make possible a low cost infrastructure to do a task of save electric magnitude as well as possible diagnostic of the electrical network.
relational_databases	nowadays many applications must process events at a very high rate. these events are processed on the fly, without being stored. complex event processing technology (cep) is used to implement such applications. some of the cep systems, like apache storm the most popular ceps, lack a query language and operators to program queries as done in traditional relational databases. this paper presents paas-cep, a cep language that provides a sql-like language to program queries for cep and its integration with data stores (database or key-value store). our current implementation is done on top of apache storm however, the cep language can be used with any cep. the paper describes the architecture of the paas-cep, its query language and the algebraic operators. the paper also details the integration of the cep with traditional data stores that allows the correlation of live streaming data with the stored data.
electrical_network	this article presents a methodology for optimal distributed generation (dg) allocation and sizing in distribution systems, in order to minimize the electrical network losses and keep acceptable voltage profiles. the optimization problem considered equality and inequality constrains, 24 hours power load levels, operational voltage limits, conventional power flow, dg placement with binary variables and sizing of active and reactive power. the optimization problem is solved by mixed integer nonlinear programming (minpl) using knitro solver.
system_identification	background: many healthcare organizations have developed disclosure policies for large-scale adverse events, including the veterans health administration (va). this study evaluated va 's national large-scale disclosure policy and identifies gaps and successes in its implementation. methods: semi-structured qualitative interviews were conducted with leaders, hospital employees, and patients at nine sites to elicit their perceptions of recent large-scale adverse events notifications and the national disclosure policy. data were coded using the constructs of the consolidated framework for implementation research (cfir). results: we conducted 97 interviews. insights included how to handle the communication of large-scale disclosures through multiple levels of a large healthcare organization and manage ongoing communications about the event with employees. of the 5 cfir constructs and 26 sub-constructs assessed, seven were prominent in interviews. leaders and employees specifically mentioned key problem areas involving 1) networks and communications during disclosure, 2) organizational culture, 3) engagement of external change agents during disclosure, and 4) a need for reflecting on and evaluating the policy implementation and disclosure itself. patients shared 5) preferences for personal outreach by phone in place of the current use of certified letters. all interviewees discussed 6) issues with execution and 7) costs of the disclosure. conclusions: cfir analysis reveals key problem areas that need to be addresses during disclosure, including: timely communication patterns throughout the organization, establishing a supportive culture prior to implementation, using patient-approved, effective communications strategies during disclosures; providing follow-up support for employees and patients, and sharing lessons learned.
data_structures	we propose a differential versioning based data storage (divers) architecture for distributed storage systems, which relies on a novel erasure coding technique that exploits sparsity across versions. the emphasis of this work is to demonstrate how sparsity exploiting codes (sec), originally designed for i/o optimization, can be extended to significantly reduce storage overhead in a repository of versioned data. in addition to facilitating reduced storage, we address some key reliability aspects for divers such as (i) mechanisms to deploy the coding technique with arbitrarily varying size of data across versions, and (ii) investigating the right allocation strategy for the encoded blocks over a network of distributed nodes across different versions so as to achieve the best fault tolerance. we also discuss system issues related to the management of data structures for accessing and manipulating the files over the differential versions. (c) 2016 elsevier b.v. all rights reserved.
computer_vision	dense motion field estimation is a key computer vision problem. many solutions have been proposed to compute small or large displacements, narrow or wide baseline stereo disparity, or non-rigid surface registration, but a unified methodology is still lacking. the authors introduce a general framework that robustly combines direct and feature-based matching. the feature-based cost is built around a novel robust distance function that handles keypoints and weak features such as segments. it allows us to use putative feature matches to guide dense motion estimation out of local minima. the authors' framework uses a robust direct data term. it is implemented with a powerful second-order regularisation with external and self-occlusion reasoning. their framework achieves state-of-the-art performance in several cases (standard optical flow benchmarks, wide-baseline stereo and non-rigid surface registration). their framework has a modular design that customises to specific application needs.
software_engineering	maze is an extension of the object-z specification language supporting the specification and development of multi-agent systems (mas). following recommendations from the agent-oriented software engineering community, it supports three distinct levels of abstraction: (i) the macro level which focusses on the system 's overall, global behaviour, independently of how the agents of the system operate and interact, (ii) the meso level which focusses on agent interactions, and (iii) the micro level which focusses on the operation of individual agents. object-z 's high-level support for component based specification, which is well suited to modelling mas, is complemented in maze with support for action refinement to facilitate the top-down development process from the macro to micro level, and with a number of syntactic conventions aimed at abstractly specifying the low-level mechanisms required for dealing with asynchronous communication and timing constraints at the micro level. the latter are shorthands for existing object-z notation and so require no redefinition of object-z 's semantics. in this paper, we provide an overview of maze and illustrate its use on a non-trivial case study: a swarm robotic algorithm for self-assembly. (c) 2016 elsevier b.v. all rights reserved.
machine_learning	presbyacusis, or age-related hearing loss, can be characterized in humans as metabolic and sensory phenotypes, based on patterns of audiometric thresholds that were established in animal models. the metabolic phenotype is thought to result from deterioration of the cochlear lateral wall and reduced endocochlear potential that decreases cochlear amplification and produces a mild, flat hearing loss at lower frequencies coupled with a gradually sloping hearing loss at higher frequencies. the sensory phenotype, resulting from environmental exposures such as excessive noise or ototoxic drugs, involves damage to sensory and non-sensory cells and loss of the cochlear amplifier, which produces a 50-70 db threshold shift at higher frequencies. the mixed metabolic + sensory phenotype exhibits a mix of lower frequency, sloping hearing loss similar to the metabolic phenotype, and steep, higher frequency hearing loss similar to the sensory phenotype. the current study examined audiograms collected longitudinally from 343 adults 50-93 years old (n = 686 ears) to test the hypothesis that metabolic phenotypes increase with increasing age, in contrast with the sensory phenotype. a quadratic discriminant analysis (qda) was used to classify audiograms from each of these ears as (1) older-normal, (2) metabolic, (3) sensory, or (4) metabolic + sensory phenotypes. although hearing loss increased systematically with increasing age, audiometric phenotypes remained stable for the majority of ears (61.5 %) over an average of 5.5 years. most of the participants with stable phenotypes demonstrated matching phenotypes for the left and right ears. audiograms were collected over an average period of 8.2 years for ears with changing audiometric phenotypes, and the majority of those ears transitioned to a metabolic or metabolic + sensory phenotype. these results are consistent with the conclusion that the likelihood of metabolic presbyacusis increases with increasing age in middle to older adulthood.
electricity	studies on the implications of population density on energy consumption in small and medium-sized cities in low- and middle-income countries are limited. this paper estimates and analyses energy consumption, using a diverse set of methods, to compare two medium-sized cities in thailand with similar urban forms and socioeconomic characteristics but different population densities - namely, the less dense city chaiyaphum and denser city roi et. the results reveal that the annual household electricity consumption per capita of these two cities is similar, showing no implications of density. however, private transport energy consumption per capita in chaiyaphum is 22 per cent higher, supporting the hypothesis that a less dense city will have higher transport energy consumption. the key factor identified is the greater distance travelled by households located in the peri-urban areas in the less dense city. this has important policy implications for urban planning and urban development practices in thailand.
relational_databases	now-related temporal data play an important role in many applications. clifford et al. 's approach is a milestone to model the semantics of 'now' in temporal relational databases. several relational representation models for now-related data have been presented; however, the semantics of such representations has not been explicitly studied. additionally, the definition of a relational algebra to query now-related data is an open problem. we propose the first integrated approach that provides both a neat semantics for now-related data and a compact 1nf representation (data model and relational algebra) for them. additionally, our approach also extends current approaches to consider (i) domains where it is not always possible to know when changes in the world are recorded in the database and (ii) now-related data with a bound on their persistency in the future. to do so, we explicitly model the notion of temporal indeterminacy in the future for now-related data. the properties of our approach are also analyzed both from a theoretical (semantic correctness and reducibility of the algebra) and from an experimental point of view. experiments show that, despite the fact that our approach is a major extension to current temporal relational approaches, no significant overhead is added to deal with 'now'.
operational_amplifier	memristor is a nano device that exhibits unique iv pinched hysteresis loop with switching mechanism and has ability to remember its last state. these interesting memristor characteristics encourage researchers to understand the new device and develop its potential applications. the problem is memristor has not yet available in current market due to the cost and technical difficulties in fabrication nanoscale device. thus, the only way is develop model for memristor. in this paper, few spice memristor models are selected and their i-v behaviors are compared to a physical memristor to verify model similarity with actual device. next a new approach of cmos memristor application is proposed. an interfacing circuit between spice memristor model and cmos circuit is presented. the interfacing circuit is composed by write circuit (to program memristor resistance) and read circuit (to read memristor current) using operational amplifier and current mirror. this interfacing circuit is very important to incorporate memristor into cmos for cmos-memristor application studies.
system_identification	a novel adaptive weight online sequential extreme learning machine (awos-elm) is proposed for predicting time series problems based on an online sequential extreme learning machine (os-elm) in this paper. in real-world online applications, the sequentially coming data chunk usually possesses varying confidence coefficients, and the data chunk with a low confidence coefficient tends to mislead the subsequent training process. the proposed awos-elm can improve the training process by accessing the confidence coefficient adaptively and determining the training weight accordingly. experiments on six time series prediction data sets have verified that the awos-elm algorithm performs better in generalization performance, stability, and prediction ability than the os-elm algorithm. in addition, a real-world mechanical system identification problem is considered to test the feasibility and efficacy of the awos-elm algorithm.
state_space_representation	this paper studies the estimation of the frictional torque of the synchromesh during the gear shifting operation in an electric vehicle equipped with a clutchless automated manual transmission (amt). the clutchless drivetrain of the electric vehicle is discussed and the dynamical model of the powertrain from the electric traction motor to the synchromesh system of a two-speed amt is developed. in order to estimate the frictional torque of the synchromesh, which is indeed an unknown input to the dynamical system, it is assumed to be generated by a fictitious autonomous system. thereafter, the augmented state- space representation of the actual and fictitious state variables, which forms the basis for the observer design, is provided and the observability of this augmented system is discussed. a deterministic luenberger observer and a stochastic kalman-bucy filter are designed in order to estimate the frictional torque of the synchromesh. the estimation is based on the measuring angular velocities of the electric motor and synchro ring together with the known electromagnetic torque of the traction motor. the performance of the observers is assessed experimentally by means of a test rig. the results demonstrate the satisfactory performance of the stochastic observer when the system encounters process and measurement noise which are likely to happen in practice.
algorithm_design	a multistage graph is center problem of computer science, many coordination and consistency problems can be convert into multistage graph problem. we obtained the fitness function by coding the vertex of multistage graph, and designed the genetic algorithm for solving multistage graph problem. experiment results show that this algorithm is very effective and feasible.
parallel_computing	the elastodynamic boundary integral equation method (biem) in real space and in the temporal domain is an accurate semi-analytical tool to investigate the earthquake rupture dynamics on non-planar faults. however, its heavy computational demand for a historic integral generally increases with a time complexity of o(mn3)for the number of time steps n and elements m due to volume integration in the causality cone. in this study, we introduce an efficient biem, termed the 'fast domain partitioning method' (fdpm), which enables us to reduce the computation time to the order of the surface integral, o(mn2), without degrading the accuracy. the memory requirement is also reduced to o(m-2) from o((mn)-n-2). fdpm uses the physical nature of green 's function for stress to partition the causality cone into the domains of the p and s wave fronts, the domain in-between the p and s wave fronts, and the domain of the static equilibrium, where the latter two domains exhibit simpler dependences on time and/or space. the scalability of this method is demonstrated on the large-scale parallel computing environments of distributed memory systems. it is also shown that fdpm enables an efficient use of memory storage, which makes it possible to reduce computation times to a previously unprecedented level. we thus present fdpm as a powerful tool to break through the current fundamental difficulties in running dynamic simulations of coseismic ruptures and earthquake cycles under realistic conditions of fault geometries.
computer_vision	many computer vision problems involve exploring the synthesis and classification models that map images from the observed source space to a target space. recently, one popular and effective method is to transform images from both source and target space into a shared single sparse domain, in which a synthesis model is established. motivated by such a technique, this research attempts to explore an effective and robust linear function that maps the sparse representatio ns of images from the source space to the target space, and simultaneously develop a linear classifier on such a coupled space with both supervised and semi-supervised learning. in order to capture the sparse structure shared by each class, we represent this mapping using a linear transformation with the constraint of sparsity. the performance of our proposed method is evaluated on several benchmark image datasets for low-resolution faces/digits classification and super-resolution, and the experimental results verify the effectiveness of the proposed method.
software_engineering	problem-based learning (pbl) has often been seen as an all-or-nothing approach, difficult to apply in traditional curricula based on traditional lectured courses with exercise and lab sessions. aalborg university has since its creation in 1974 practiced pbl in all subjects, including computer science and software engineering, following a model that has become known as the aalborg model. following a strategic decision in 2009, the aalborg model has been reshaped. we first report on the software engineering program as it was in the old aalborg model. we analyze the programme wrt competence levels according to bloom 's taxonomy and compare it with the expected skills and competencies for an engineer passing a general software engineering 4-year program with an additional 4 years of experience as defined in the ieee software engineering body of knowledge (swebok) [abran et al. 2004]. we also compare with the graduate software engineering 2009 curriculum guidelines for graduate degree programmes in software engineering (gswe2009) [pyster 2009]. we then describe the new curriculum and draw some preliminary conclusions based on analyzing the curriculum according to bloom 's taxonomy and the results of running the program for 2 years. as the new program is structured to be compliant with the bologna process and thus presents all activities in multipla of 5 european credit transfer system points, we envision that elements of the program could be used in more traditional curricula. this should be especially easy for programs also complying with the bologna process.
analog_signal_processing	the first fully integrated 2d cmos imaging sensor with on-chip signal processing for applications in laser doppler blood flow (ldbf) imaging has been designed and tested. to obtain a space efficient design over 64 x 64 pixels means that standard processing electronics used off-chip cannot be implemented. therefore the analog signal processing at each pixel is a tailored design for ldbf signals with balanced optimization for signal-to-noise ratio and silicon area. this custom made sensor offers key advantages over conventional sensors, viz. the analog signal processing at the pixel level carries out signal normalization; the ac amplification in combination with an anti-aliasing filter allows analog-to-digital conversion with a low number of bits; low resource implementation of the digital processor enables on-chip processing and the data bottleneck that exists between the detector and processing electronics has been overcome. the sensor demonstrates good agreement with simulation at each design stage. the measured optical performance of the sensor is demonstrated using modulated light signals and in vivo blood flow experiments. images showing blood flow changes with arterial occlusion and an inflammatory response to a histamine skin-prick demonstrate that the sensor array is capable of detecting blood flow signals from tissue.
cryptography	we propose a quantum public-key encryption (qpke) protocol for an unknown multi-qubit state based on qubit-wise teleportation. the private-key is a computational boolean function, whereas the public-key is a pair of a random bit string and a quantum state. a private-key corresponds to an exponential number of public-keys. security analysis showed that the proposed protocol has information-theoretic security from attacks for the private-key and the encryption. a multi-partite quantum secret state sharing protocol is presented based on the proposed multi-qubit-oriented qpke protocol. such secret state sharing protocol is information-theoretically secure.
electric_motor	this paper focuses on the variability in vibration from electromagnetic origin for an electric motor. the multiphysics modeling is introduced by the magnetic force density computation and by the coupling of the 2d electromagnetic and 3d structural dynamic finite element models. the modal stability procedure (msp) and the monte carlo simulation (mcs) are associated for the variability calculation of natural frequencies and frequency response functions (frfs) of finite element systems with material random parameters. the msp formulations are developed for 8-node solid hexahedron element modeling the electric stator. the mcs-msp approach only requires a single finite element analysis, leading to a fast monte carlo simulation using msp formulation. the validation of mcs-msp is investigated, the uncertainty propagation is discussed and the computational costs of mcs-msp are presented. this non intrusive method provides an evaluation of frequencies and frfs variability for industrial-size models with a large number of degrees of freedom, a large number of random variables and a low or moderate variability level. (c) 2016 elsevier b.v. all rights reserved.
algorithm_design	the exemplar breakpoint distance problem is motivated by finding conserved sets of genes between two genomes. it asks to find respective exemplars in two genomes to minimize the breakpoint distance between them. if one genome has no repeated gene (called trivial genome) and the other has genes repeating at most twice, it is referred to as the (1, 2)-exemplar breakpoint distance problem, ebd(1, 2) for short. little has been done on algorithm design for this problem by now. in this article, we propose a parameter to describe the maximum physical span between two copies of a gene in a genome, and based on it, design a fixed-parameter algorithm for ebd(1, 2). using a dynamic programming approach, our algorithm can take o(4(s)n(2)) time and o(4(s)n) space to solve an ebd(1, 2) instance that has two genomes of n genes where the second genome has each two copies of a gene spanning at most s copies of the genes. our algorithm can also be used to compute the maximum adjacencies between two genomes. the algorithm has been implemented in c++. simulations on randomly generated data have verified the effectiveness of our algorithm. the software package is available from the authors.
analog_signal_processing	a microstrip shunt open-stub overlapping a shorted slotline is presented and used to design a novel wideband dispersive delay line. the inherent periodic transmission zeros due to the resonances of an open-stub and a shorted slotline can be removed by using the complementary configuration. moreover, the phase response of the complementary stub is frequency dependant which is used to design a dispersive delay line. the group delay profile of the complementary stub is smooth and continuous while at the same time maintaining a flat magnitude response over an ultra-wide bandwidth. several units can be cascaded to obtain a desired group delay profile. this configuration can be used in analog signal processing or to reduce the signal distortion from other wideband components.
network_security	gpu is widely used in various applications that require huge computational power. in this paper, we contribute to the cryptography and high performance computing research community by presenting techniques to accelerate symmetric block ciphers (aes-128, cast-128, camellia, seed, idea, blowfish and threefish) in nvidia gtx 980 with maxwell architecture. the proposed techniques consider various aspects of block cipher implementation in gpu, including the placement of encryption keys and t-box in memory, thread block size, cipher operating mode, parallel granularity and data copy between cpu and gpu. we proposed a new method to store the encryption keys in registers with high access speed and exchange it with other threads by using the warp shuffle operation in gpu. the block ciphers implemented in this paper operate in ctr mode, and able to achieve high encryption speed with 149 gbps (aes-128), 143 gbps (cast-128), 124 gbps (camelia), 112 gbps (seed), 149 gbps (idea), 111 gbps (blowfish) and 197 gbps (threefish). to the best of our knowledge, this is the first implementation of block ciphers that exploits warp shuffle, an advanced feature in nvidia gpu. on the other hand, block ciphers can be used as pseudorandom number generator (prng) when it is operating under counter mode (ctr), but the speed is usually slower compare to other prng using lighter operations. hence, we attempt to modify idea and blowfish in order to achieve faster prng generation. the modified idea and blowfish manage to pass all nist statistical test and testu01 smallcrush except the more stringent tests in testu01 (crush and bigcrush).
pid_controller	investigation of vibration is an important topic for the purposes of ride investigation of control vibration is an important topic for the purposes of ride comfort in railway engineering. the vibration of rail vehicles becomes very complex because it is affected by the condition of vehicles, including suspensions and wheel profile, condition of track sections, including rail profile, rail irregularities, cant and curvature. the present study deals with the modeling and control for lateral rail vehicle active suspension by pid-zn controller. for this, a numerical simulation of the dynamic behavior is made based on the lagrangian approach in order to study the effect of vehicle speed in response to imperfections in the tracks. a model of 17 degrees of freedom is adopted which consists of one car body 2 bogies and 4 wheel-sets. a sperling ride index (iso2631) is calculated using filtered rms accelerations in order to evaluate the ride comfort. which allowing at the same time the evaluation of the dynamic behavior of the car body and the level of passenger comfort by analyzing the accelerations at the center of mass of the car body.
algorithm_design	this paper presents the software framework established to facilitate cloud-hosted robot simulation. the framework addresses the challenges associated with conducting a task-oriented and real-time robot competition, the defense advanced research projects agency (darpa) virtual robotics challenge (vrc), designed to mimic reality. the core of the framework is the gazebo simulator, a platform to simulate robots, objects, and environments, as well as the enhancements made for the vrc to maintain a high fidelity simulation using a high degree of freedom and multisensor robot. the other major component used is the cloudsim tool, designed to enhance the automation of robotics simulation using existing cloud technologies. the results from the vrc and a discussion are also detailed in this work. note to practitioners-advances in robot simulation, cloud hosted infrastructure, and web technology have made it possible to accurately and efficiently simulate complex robots and environments on remote servers while providing realistic data streams for human-in-the-loop robot control. this paper presents the software and hardware frameworks established to facilitate cloud-hosted robot simulation, and addresses the challenges associated with conducting a task-oriented robot competition designed to mimic reality. the competition that spurred this innovation was the vrc, a precursor to the darpa robotics challenge, in which teams from around the world utilized custom human-robot interfaces and control code to solve disaster response-related tasks in simulation. winners of the vrc received both funding and access to atlas, a humanoid robot developed by boston dynamics. the gazebo simulator, an open source and high fidelity robot simulator, was improved upon to met the needs of the vrc competition. additionally, cloudsim was created to act as an interface between users and the cloud-hosted simulations. as a result of this work, we have achieved automated deployment of cloud resources for robotic simulations, near real-time simulation performance, and simulation accuracy that closely mimics real hardware. these tools have been released under open source licenses and are freely available, and can be used to help reduce robot and algorithm design and development time, and increase robot software robustness.
software_engineering	developing distributed applications, particularly those for distributed, real-time and embedded (dre) systems, is a difficult and complex undertaking due to the need to address four major challenges: the complexity of programming interprocess communication, the need to support a wide range of services across heterogeneous platforms and promote reuse, the need to efficiently utilize resources, and the need to adapt to changing conditions. the first two challenges are addressed to a large extent by standardized, general-purpose middleware (e.g. corba, dcom and java rmi) through the use of a ""black-box"" approach, such as the object-oriented paradigm (frameworks and design patterns). the need to support a large variety and range of applications and application domains has resulted in very feature-rich implementations of these standardized middleware. however, such a feature-richness acts counteractive to resolving the remaining two challenges; instead it incurs excessive memory footprint and performance overhead, as well as increased cost of testing and maintenance. to address the four challenges all at once while leveraging the benefits of general-purpose middleware requires a scientific approach to specializing the middleware. software engineering techniques, such as aspect-oriented programming (aop), feature-oriented programming (fop), and reflection make the specialization task simpler, albeit still requiring the dre system developer to manually identify the system invariants, and sources of performance and memory footprint bottlenecks that drive the specialization techniques. specialization reuse is also hampered due to a lack of common taxonomy to document the recurring specializations, and assess the strengths and weaknesses of these techniques. to address these requirements, this paper presents a case for an automated, multi-stage, feature-oriented middleware specialization process that improves both middleware developer productivity and middleware performance. three specific contributions are made in this paper. first, contemporary middleware specialization research is framed in terms of a three-dimensional taxonomy. second, the principles of separation of concerns are used in the context of this taxonomy to define six stages of a middleware specialization process lifecycle. finally, a concrete implementation of the six stage, automated middleware specialization process is presented along with empirical data illustrating the benefits accrued using the framework.
parallel_computing	a wide variety of large-scale data have been produced in bioinformatics. in response, the need for efficient handling of biomedical big data has been partly met by parallel computing. however, the time demand of many bioinformatics programs still remains high for large-scale practical uses because of factors that hinder acceleration by parallelization. recently, new generations of storage devices have emerged, such as nand flash-based solid-state drives (ssds), and with the renewed interest in near-data processing, they are increasingly becoming acceleration methods that can accompany parallel processing. in certain cases, a simple drop-in replacement of hard disk drives by ssds results in dramatic speedup. despite the various advantages and continuous cost reduction of ssds, there has been little review of ssd-based profiling and performance exploration of important but time-consuming bioinformatics programs. for an informative review, we perform in-depth profiling and analysis of 23 key bioinformatics programs using multiple types of devices. based on the insight we obtain from this research, we further discuss issues related to design and optimize bioinformatics algorithms and pipelines to fully exploit ssds. the programs we profile cover traditional and emerging areas of importance, such as alignment, assembly, mapping, expression analysis, variant calling and metagenomics. we explain how acceleration by parallelization can be combined with ssds for improved performance and also how using ssds can expedite important bioinformatics pipelines, such as variant calling by the genome analysis toolkit and transcriptome analysis using rna sequencing. we hope that this review can provide useful directions and tips to accompany future bioinformatics algorithm design procedures that properly consider new generations of powerful storage devices.
analog_signal_processing	the paper is devoted to the innovative device consisting of the frees-winging piston internal or external combustion engine and oscillating rotary electrical generator. advantages and possibilities of such unit are presented to compare with shortcomings of the conventional units, as well as with units of the linear free-piston internal combustion engine and oscillating linear generator. principles of modelling an simulation of the considered device are presented too. usage of the proposed unit as a source of energy in the hybrid electric vehicles enables to create competitive hybrid vehicle.
image_processing	an enhanced version of a segmentation algorithm applied in x-ray images using a prior shape and a straightened boundary image (sbi) is proposed. in the sbi method, the boundary of the target object is extracted with a constant width along the prior shape and transformed to a rectangular image in which the edges are straightened. a new minimal path algorithm is proposed and applied to sbi minimising a cost function to select the best path corresponding to the edges of the target object. the cost function is calculated based on all possible paths from each pixel to the beginning of the image while lowering the computational complexity. comparing with previous methods, the proposed method removes artefacts and provides clearer and smoother edges even when the prior shape is far from the target object. the method is also less sensitive to the initial positioning of the prior shape model.
digital_control	using a field-programmable gate array (fpga) development board, a digital signal processor (dsp) builder, and the phase-to-amplitude conversion principle, a low-cost system for measuring the amplitude-to-amplitude (am/am) and amplitude-to-phase (am/pm) distortion curves of radio frequency (rf) power amplifiers (pas) is presented. the state of the art based on the measurements and preliminary studies of am/am and am/pm distortion curves is discussed. a full digital control of the test bed simulated/emulated in matlab/simulink is introduced to recalculate the known am/am and am/pm measurements stored as look-up table (lut). finally, the low-cost system comprises the memory polynomial model (mpm) that involves the nonlinearity order and memory effects of real pas. (c) 2015 elsevier b.v. all rights reserved.
microcontroller	this paper proposes a wireless photovoltaic (pv) visualization monitoring, evaluation, and fault detection system based on the stm32f4discovery board with bluetooth data transmission in the matlab/simulink platform. all of the irradiance, the cell temperature, voltage, and current of pv devices are acquired through the microcontroller-based daq board. these measurements data are transferred to a host computer by both bluetooth slave module and bluetooth master one built in a laptop. these measurement data are visually displayed in the form of dashboard in the matlab/simulink environment and are simultaneously input to pv model for theoretical simulation. the functions of evaluation and fault detection for pv modules under practical working conditions are conducted and displayed at the same software platform. the proposed system has been proved with sufficient accuracy and confidence in the functions of visualization monitoring, evaluation, and fault detection. as compared with the well-developed ones, the proposed system has the advantages such as: reduce both cable and hardware configuration and integrate the all visualization monitoring, evaluation, and fault detection solely in the matlab/simulink environment. (c) 2016 elsevier ltd. all rights reserved.
algorithm_design	this study designed a path planning method based on fuzzy algorithm and genetic fuzzy algorithm for the security patrol robot. firstly, the fuzzy algorithm design of path planning was introduced, it included making the obstacle avoidance control strategy, establishing fuzzy language and its membership function of input and output, establishing fuzzy control rules for path planning, and carrying on fuzzy reasoning and defuzzification for path planning. although the fuzzy logic algorithm can avoid obstacle well for path planning, it need the membership function and control rules accurately, and affecting the application of fuzzy reasoning. therefore, genetic algorithm was used to optimize the fuzzy algorithm, it included description of model, determining the range of variation of each parameter, encoding scheme, algorithm flow, and designing of fuzzy logic controller based on genetic algorithm optimization. finally, in order to verify the effectiveness of the designed genetic fuzzy algorithm, the simulation was carried out.
signal-flow_graph	this paper presents a generalized mixed-radix decimation-in-time (dit) fast algorithm for computing the modified discrete cosine transform (mdct) of the composite lengths n=2 x q(m), m >= 2, where q is an odd positive integer. the proposed algorithm not only has the merits of parallelism and numerical stability, but also needs less multiplications than that of type-iv discrete cosine transform (dct-iv) and type-ii discrete cosine transform (dct-ii) based mdct algorithms due to the optimized efficient length-(n/q) modules. the computation of mdct for composite lengths n=q(m) x 2(n), m >= 2, n >= 2, can then be realized by combining the proposed algorithm with fast radix-2 mdct algorithm developed for n=2(n). the combined algorithm can be used for the computation of length-12/36 mdct used in mpeg-1/-2 layer iii audio coding as well as the recently established wideband speech and audio coding standards such as g.729.1, where length-640 mdct is used. the realization of the inverse mdct (imdct) can be obtained by transposing the signal flow graph of the mdct. (c) 2011 elsevier b.v. all rights reserved.
system_identification	this paper studies the stochastic behavior of the signed variants of the lms algorithm for a system identification framework when the input signal is a cyclostationary white gaussian process. three algorithms are studied: the signed regressor, the signed error, and the sign-sign algorithms. the input cyclostationary signal is modeled by a white gaussian random process with periodically time-varying power. the system parameters vary according to a random-walk. mathematical models are derived for the mean and mean-square-deviation behavior of the adaptive weights with the input cyclostationarity. these models are used to derive new results concerning the performance of the algorithms. some of these results are surprising. monte carlo simulations of the three algorithms provide strong support for the theory.
algorithm_design	most of the recent mobile robot researchers focus on obstacle avoidance and path tracking in unknown environment. this paper presents a new algorithm using straight-line equation adaptation mechanism that makes robotino reaching its destination accurately, also to enable it to detect and to avoid static or dynamic obstacles using nine infrared sensors. a brief robotino dynamic description is discussed to help in understanding the proposed control algorithm. a detailed algorithm design procedure is evaluated. the simulation results showed the effectiveness of the proposed algorithm in the sense of avoiding obstacles without collision through robotino predefined path.
computer_vision	saliency modeling has played an important part in computer vision studies over the past 30 years. many state-of-the-art models adopted complex mathematical and machine learning theories. in this paper, a simple and effective visual attention model is proposed. we find that a single fixed template is enough for saliency map generation; this idea is inspired by the receptive field of the human visual system. all that is needed is to convolve the input image with this template with additional post-processing. experiments show that our model is extremely fast and performs better than state-of-the-art models in human eye fixation prediction.
control_engineering	the manufacturing industry currently faces the big challenges of global competition dealing with the increasing costs of energy and raw materials on the one hand, and with the increasing quality requirements for high product technology and innovation expectations of the customer on the other hand. in the next decade, the overall progress of the technology will demand new strategies to increase the international acceptance and positive management of the increasing competition in the global market. this paper is a proposal to establish a strategic approach of an advanced, intelligent and networked measurement technique with automated measurement and evaluation processes as well as the highest accuracy and the smallest uncertainty of the measurement processes for both research, higher education and at the same time for the manufacturing industry. using an example application, the development of modeling, construction and implementation of the experiments in an inter-university network are demonstrated. thereby, the cooperation and implementation of the working steps in two remote research laboratories, namely the nanotechnology laboratory aum at the vienna university of technology in austria and the control engineering laboratory utn-frba in argentina are described.
system_identification	process measurements are of vital importance for monitoring and control of industrial plants. when we consider offshore oil production platforms, wells that require gas-lift technology to yield oil production from low pressure oil reservoirs can become unstable under some conditions. this undesirable phenomenon is usually called slugging flow, and can be identified by an oscillatory behavior of the downhole pressure measurement. given the importance of this measurement and the unreliability of the related sensor, this work aims at designing data-driven soft-sensors for downhole pressure estimation in two contexts: one for speeding up first-principle model simulation of a vertical riser model; and another for estimating the downhole pressure using real-world data from an oil well from petrobras based only on topside platform measurements. both tasks are tackled by employing echo state networks (esn) as an efficient technique for training recurrent neural networks. we show that a single esn is capable of robustly modeling both the slugging flow behavior and a steady state based only on a square wave input signal representing the production choke opening in the vertical riser. besides, we compare the performance of a standard network to the performance of a multiple timescale hierarchical architecture in the second task and show that the latter architecture performs better in modeling both large irregular transients and more commonly occurring small oscillations. (c) 2016 elsevier ltd. all rights reserved.
cryptography	two new protocols for quantum binary voting are proposed. one of the proposed protocols is designed using a standard scheme for controlled deterministic secure quantum communication (cdsqc), and the other one is designed using the idea of quantum cryptographic switch, which uses a technique known as permutation of particles. a few possible alternative approaches to accomplish the same task (quantum binary voting) have also been discussed. security of the proposed protocols is analyzed. further, the effciencies of the proposed protocols are computed, and are compared with that of the existing protocols. the comparison has established that the proposed protocols are more efficient than the existing protocols.
electric_motor	satellite radio posed a new question for canadian policy-makers: how to take advantage of a transnational radio service while ensuring cultural identity was not lost within channel offerings that are predominately american. comparing the initial licensing of satellite radio in canada (2005) to the merger of the services (2011) and the post-merger license renewal (2012) highlights a shift in the spatial understanding of satellite radio, from being determined by a satellite 's footprint to that of what i call 'cultural lifelines,' the various mobile devices and services that enable one to maintain connection to cultural content. alongside shifting spatial considerations of satellite radio, canadian content has increasingly been packaged as a brand or genre, catering to fragmented taste preferences and individual, mobile listening practices.
machine_learning	psychiatry research has long experienced a stagnation stemming from a lack of understanding of the neurobiological underpinnings of phenomenologically defined mental disorders. recently, the application of computational neuroscience to psychiatry research has shown great promise in establishing a link between phenomenological and pathophysiological aspects of mental disorders, thereby recasting current nosology in more biologically meaningful dimensions. in this review, we highlight recent investigations into computational neuroscience that have undertaken either theory- or data-driven approaches to quantitatively delineate the mechanisms of mental disorders. the theory-driven approach, including reinforcement learning models, plays an integrative role in this process by enabling correspondence between behavior and disorder-specific alterations at multiple levels of brain organization, ranging from molecules to cells to circuits. previous studies have explicated a plethora of defining symptoms of mental disorders, including anhedonia, inattention, and poor executive function. the data-driven approach, on the other hand, is an emerging field in computational neuroscience seeking to identify disorder-specific features among high-dimensional big data. remarkably, various machine-learning techniques have been applied to neuroimaging data, and the extracted disorder-specific features have been used for automatic case-control classification. for many disorders, the reported accuracies have reached 90% or more. however, we note that rigorous tests on independent cohorts are critically required to translate this research into clinical applications. finally, we discuss the utility of the disorder-specific features found by the data-driven approach to psychiatric therapies, including neurofeedback. such developments will allow simultaneous diagnosis and treatment of mental disorders using neuroimaging, thereby establishing theranostics' for the first time in clinical psychiatry.
electrical_circuits	this article deals with chua 's circuit characterization from the point of view of a filter based on the concept of piecewise linear functions. furthermore, experiments are developed for teaching electronic systems that can be used for novel filtering concepts. the frequency range in which they are tested is from 20 hz to 20 khz, due to the audio spectrum comprised in this frequency range. the node associated with the capacitor and chua 's diode is used as input, and the node for another capacitor and the coil is used as output, thereby establishing one input-output relationship for each system case given by the piecewise linear functions. the experimental result shows that chua 's circuit behaves as a bandpass filter-amplifier, with a maximum frequency around 3 khz and bandwidth between 1.5 khz and 5.5 khz. the results presented in this paper can motivate engineering students to pursue applications of novel electrical circuits based on topics that are of potential interest in their future research studies.
electric_motor	population sizes of ice-associated pinnipeds have often been estimated with visual or photographic aerial surveys, but these methods require relatively slow speeds and low altitudes, limiting the area they can cover. recent developments in infrared imagery and its integration with digital photography could allow substantially larger areas to be surveyed and more accurate enumeration of individuals, thereby solving major problems with previous survey methods. we conducted a trial survey in april 2003 to estimate the number of pacific walruses (odobenus rosmarus divergens) hauled out on sea ice around st. lawrence island, alaska. the survey used high altitude infrared imagery to detect groups of walruses on strip transects. low altitude digital photography was used to determine the number of walruses in a sample of detected groups and calibrate the infrared imagery for estimating the total number of walruses. we propose a survey design incorporating this approach with satellite radio telemetry to estimate the proportion of the population in the water and additional low-level flights to estimate the proportion of the hauled-out population in groups too small to be detected in the infrared imagery. we believe that this approach offers the potential for obtaining reliable population estimates for walruses and other ice-associated pinnipeds.
electric_motor	cycling induced by automatic control of functional electrical stimulation provides a means of therapeutic exercise and functional restoration for people affected by paralysis. during cycling induced by functional electrical stimulation, various muscle groups are stimulated according to the cycle crank angle; however, because of kinematic constraints on the cycle-rider system, stimulation is typically only applied in a subsection of the crank cycle. therefore, these systems can be considered as switched control systems with autonomous, state-dependent switching with potentially unstable modes. previous studies have included an electric motor in the system to provide additional control authority, but no studies have considered the effects of switched control in the stability analysis of the motorized functional electrical stimulation cycling system. in this paper, a model of the motorized cycle-rider system with functional electrical stimulation is developed that includes the effects of a switched control input. a novel switching strategy for the electric motor is designed to only provide assistance in the regions of the crank cycle where the kinematic effectiveness of the rider 's muscles is low. a switched sliding-mode controller is designed, and global, exponentially stable tracking of a desired crank trajectory is guaranteed via lyapunov methods for switched systems, despite parametric uncertainty in the nonlinear model and unknown, time-varying disturbances. experimental results from five able-bodied, passive riders are presented to validate the control design, and the developed control system achieves an average cadence tracking error of revolutions per minute for a desired trajectory of 50 revolutions per minute. note to practitioners-autonomous systems designed for rehabilitation and functional assistance for people with disabilities such as paralysis have the potential to maximize rehabilitative outcomes and improve the quality of life for millions of people. disorders such as paralysis drastically reduce a person 's ability to complete tasks due to a loss of neuromuscular control. functional electrical stimulation can activate paralyzed muscles, restoring functional ability through automated application of electric current to the neuromuscular system, and, when applied to a task such as cycling, is both rehabilitative and empowering. however, cycling induced by functional electrical stimulation is limited by the capability of the rider 's muscles, so an electric motor is typically added to accommodate the rider 's ability and to support stability. the response by muscle to electrical stimulation is uncertain, time-varying, and nonlinear, and switching the control input across multiple muscle groups and between the rider and an electric motor make guaranteeing stability and performance challenging. this paper presents a novel approach to the challenge of controlling motorized cycling systems with functional electrical stimulation that considers the switching effects and guarantees exponentially stable tracking of a desired crank trajectory, and experimental results indicate how the control system may be applied to a rehabilitative cycling task. directions for future research are aimed at implementation of the developed control system in patient populations with paralysis to quantify its impact on therapeutic outcomes such as muscle function and neuroplasticity.
digital_control	repetitive control strategies have been commonly applied in pulse-width-modulated (pwm) voltage source inverters (vsis) for many industrial applications. this paper presents a repetitive controller for voltage harmonic mitigation of vsi-based islanded microgrids. the phase delay in the overall control system, e.g., the delay caused by the digital duty cycle calculation, pwm generation, and repetitive controller, has to be compensated by elaborately designed phase lead filters in order to prevent control performance deterioration and system instability. nevertheless, quantificational analysis and practical design of the time advance unit in such filters are hardly found in existing literature works. in view of this, this paper proposes an explicit analysis of the phase lead filters and a novel design method of the time advance unit in repetitive controllers to ensure system stability. moreover, with the help of the proposed method, the overall system stability margin is predictable and improved controller performance is achieved as well. the proposed method is implemented experimentally to show the accurate stability margin calculation as well as the excellent steady state and dynamic performances of the repetitive control scheme.
electric_motor	this work focuses on a development of an accurate finite element method (fem) model to predict the reed critical frequency (rcf) of an electric motor and a study of the influence of the fixation base on the deviations from the numerical to the experimental results. ideally, the base for experimental tests needs to be sized in a way to avoid any deflection or displacement in the attachment position of the motor. in order to evaluate the fem model and the influence of the base characteristics in the rcf results, three testing bases were used to test the same electric motor. the relation of the masses of the bases to the mass of the motor are nearly eight times, twenty seven times and ninety eight times, respectively.
image_processing	rapid transport of water and solutes through desiccation soil cracks can lead to crop water and nutrient stress. the challenge of irrigation management of cracking soils is to take advantage of the rapid water intake rate of a dry, cracked soil, while keeping plant water stress at a minimum. therefore, mitigation not suppression of desiccation cracks is imperative and considered our objective of this study. a laboratory experiment was carried out to investigate the effects of sugarcane pith additive on mitigating desiccation cracks, the volumetric shrinkage strain, the total porosity, and water retention at field capacity of clay soils. the clay soil was treated with the sugarcane pith at dosages of 1, 2, 3, 4 and 5% on dry weight basis. various experimental methods were used to determine the variations in volumetric shrinkage, total porosity and water retention at field capacity. the characteristics of crack patterns were studied using an image processing technique. compared with the untreated soil, the results showed that the sugarcane pith can increase the total porosity and water content at field capacity, while reducing volumetric shrinkage strain, and consequently, mitigating the development of desiccation cracks. therefore, results suggested that the modification of clayey soil by the addition of the sugarcane pith by rates up to 2% on dry weight basis can be a viable and innovative method to mitigate the development of desiccation cracks. in addition, this application will enhance recycling efforts by converting sugarcane pith waste into usable amendment to mitigate cracks in clayey soil. (c) 2017 elsevier b.v. all rights reserved.
electric_motor	a new model of power-assisted bicycle has been designed, set up and tested. the main innovative solutions for the pedelec prototype are described in the present paper: the electric motor position; the new mechanical transmission; the low cost measurement system of the driving torque; the special test rig. differently from a common approach, in which the electric motor is located on one of the three hubs of the bicycle, the idea of the pedelec prototype consists of an electrical motor in the central position that, by means of a bevel gear, transmits the torque on the central hub. the other innovative solution is represented by the motion transmission from the motor to the pedal shaft, achieved by two different gearboxes: the first one is a planetary gearbox and the second one is a simple bevel gear. the pedelec prototype contains also a new low cost measurement system of the driving torque based on a strain gauge load cell located on one side of the rear wheel, between the hub and the frame. moreover, a commercial cycling simulator has been suitably modified in order to properly install the different sensors for the measurement of the performance of the pedelec. the test rig is able to reproduce an aforethought route or paths acquired during road tests, to measure the performance of the e-bike in terms of instantaneous power and speed. the experimental test rig can simulate the resistant torque of a predetermined track and it aims to test and to optimize the control strategy available on the electronic control unit. the authors have also conducted an environmental analysis of the developed pedelec, in particular comparing the e-bike with a thermal moped, in terms of environmental impact. (c) 2016 the authors. published by elsevier ltd. this is an open access article under the cc by-nc-nd license.
operational_amplifier	this paper proposes a method that analog multiplier and current feedback operational amplifier have been used to form second-order voltage-controlled multifunctional filter. the designed circuit has been achieved theoretical analysis, pspice simulation and actual measurement. it can simultaneously realize low-pass, high pass and band pass filter function. results show that the pass band can be adjusted with the frequency range of the input signal, and can be used in the field of frequency characteristic analysis, harmonic analysis, frequency measurement, signal detection. furthermore, it shows more importance in theoretical significance and application prospects.
control_engineering	for the abstract and general theory of ""control engineering fundamental"", the traditional teaching methods of the course has been facing difficulties which the teachers find it difficult to teach and the students feel it hard to learn for a long time. in order to improve teaching efficiency and quality of the course, the virtual experiment method was applied in the teaching practice of the course. the new method relies on matlab/simulink and virtual experiment platform to realize the combination of real experiment and virtual experiment, furthermore provides an open self-learning platform for students. experimental study on the teaching of the course for three years was carried out by using equal group test method to verify the effect of virtual experiment. the results show that virtual experiment can not only play a very good role in the course teaching and significantly improve the teaching effect, but also promote students' professional quality and the ability of independent innovation.
electrical_circuits	aiming the problem of parking information release is large flow, and release information is not timely and not accurately, the internet of vehicle (iov) of the urban traffic parking system is proposed based on the parking lot sensor network and sensor combination and its electrical control circuits. this system will be use the core technology of internet of things (iot) and combinate the timer and elastic pressure switch with a pressure sensor and its electrical circuits to realize the parking information acquisition, release, query, reservation and parking navigation with reliable and accurately. experimental results shows the electrical control circuits will be better management the parking information with accurately and the car user uses the vehicle terminal to search the target parking lot and to receive the parking information. this system will be to alleviate the urban traffic and improve the utilization efficiency of urban parking lot, for the future of the city and social development to provide better technical support and basis.
control_engineering	the paper presents an extended structure for a minimum variance adaptive control system of an induction generator, which aims to improve its operating behavior under electrical short-circuit conditions. the basic design idea is to limit the control to physically achievable values, and thus increasing the robustness of the control system and avoiding an instability regime. a control limiting block is proposed and used for this purpose. moreover, a short-circuit detector enables an on-line setting of the control penalty factor, improving the quality of the controlled output. all these additional customizations of the control system, implemented to keep the plant operational under and after a short-time short-circuit fault (acting as an abnormal perturbation), must also provide good performance in the normal operating mode.
operating_systems	background: next-generation sequencing (ngs) has revolutionized how research is carried out in many areas of biology and medicine. however, the analysis of ngs data remains a major obstacle to the efficient utilization of the technology, as it requires complex multi-step processing of big data demanding considerable computational expertise from users. while substantial effort has been invested on the development of software dedicated to the individual analysis steps of ngs experiments, insufficient resources are currently available for integrating the individual software components within the widely used r/bioconductor environment into automated workflows capable of running the analysis of most types of ngs applications from start-to-finish in a time-efficient and reproducible manner. results: to address this need, we have developed the r/bioconductor package systempiper. it is an extensible environment for both building and running end-to-end analysis workflows with automated report generation for a wide range of ngs applications. its unique features include a uniform workflow interface across different ngs applications, automated report generation, and support for running both r and command-line software on local computers and computer clusters. a flexible sample annotation infrastructure efficiently handles complex sample sets and experimental designs. to simplify the analysis of widely used ngs applications, the package provides pre-configured workflows and reporting templates for rna-seq, chip-seq, var-seq and ribo-seq. additional workflow templates will be provided in the future. conclusions: systempiper accelerates the extraction of reproducible analysis results from ngs experiments. by combining the capabilities of many r/bioconductor and command- line tools, it makes efficient use of existing software resources without limiting the user to a set of predefined methods or environments. systempiper is freely available for all common operating systems from bioconductor (http://bioconductor.org/packages/devel/systempiper).
electrical_network	frequency response analysis (fra) is a technique used to diagnose the mechanical integrity of a transformer winding; such diagnostic tools can be of enormous value since power transformers are a critical asset within any electrical network. to minimize the probability of an unexpected outage, or prevent a catastrophic failure, maintenance and monitoring of power transformers is essential for utilities. over the past couple of decades, fra has been utilized as an off-line diagnosis method. however, with the recent development in smart grid systems, there is now a growing interest in the development of on-line fra techniques. this paper proposes a technique for in-service monitoring of power transformer winding deformation, which uses a broad frequency sine wave voltage excitation signal and high frequency current transformers (ct) in conjunction with the bushings test taps. experiments using this system were conducted and then validated on a single-phase 22kv/110v voltage transformer.
electricity	the light emitting diode (led) based visible light communication (vlc) system can provide lighting and communication simultaneously. it has attracted much attenuation recently. as the photovoltaic cell (also known as solar cell) is physically flexible, low cost, and easily available, it could be a good choice for the vlc receiver (rx). furthermore, besides acting as the vlc rx, the solar cell can convert vlc signal into electricity for charging up the rx devices. hence, it could be a promising candidate for the future internet-of-thing (iot) networks. however, using solar cell as vlc rx is challenging, since the response of the solar cell is highly limited and it will limit the vlc data rate. in this work, we propose and demonstrate for the first time using pre-distortion manchester coding (mc) signal to enhance the signal performance of solar cell rx based vlc. the proposed scheme can significantly mitigate the slow response, as well as the direct-current (dc) wandering effect of the solar cell; hence 50 times increase in data rate can be experimentally achieved.
machine_learning	the quantitative simulation of forest fire spreading plays an essential role in designing quick risk management and implementing effective suppression policies. as a preferable modelling approach, the cellular automaton (ca) has been used to simulate the complex mechanisms of fire spreading. however, in traditional ca models, comprehensive studies on the physical principles of forest fires are needed to define the local transition rules. instead of defining transition rules, the extreme learning machine (elm) was applied in this study. by integrating the elm with the traditional forest fire ca framework, a new cellular automaton modelling approach was proposed. after that, its performance was validated using data collected from five fires in the west of united states. results show that the elm performed well in predicting each cell 's igniting probability. the impact of wind velocity on fire spreading pattern can be effectively described by the proposed modelling approach. furthermore, the validation against actual fire behavior observations shows that its simulation performance is acceptable and in most cases is better than that of the previously reported studies.(c) 2017 elsevier b.v. all rights reserved.
computer_programming	computer programming is regarded as a difficult skill to learn both by researchers and often by learners themselves. metacognition has been identified as an important factor to be a successful learner in learning computer programming. metacognitive in educational psychology is generally described as monitoring and controlling activities of one 's cognition. the researchers have examined the metacognitive awareness inventory om to identify how it relates to student academic achievement at school and universities. in this research work, an empirical research is conducted using the mai inventory with the objective to examine the correlation between the metacognitive awareness with the grade point average (gpa) performance of the introductory programming course at universities in malaysia. the experiment result indicates a positive relationship between metacognitive awareness with the learning success of introductory programming course at universities.
symbolic_computation	in this paper, the generalized unified method is used to construct multi-rational wave solutions of the ()-dimensional kadomtsev-petviashvili equation with variable coefficients. this is an extension of the previous work that was given by the same author in osman and abdel-gawad (epj plus 130(10):1-11, 2015). the (2 1)-dimensional kadomtsev-petviashvili equation with variable coefficients can be used to characterize many nonlinear phenomena in fluid dynamics, plasma physics and some other nonlinear science when the inhomogeneities of media and non-uniformities of boundaries are taken into consideration. to give more physical insight into the obtained solutions, we present graphically their representative structures by setting the arbitrary functions in the solutions as specific functions. moreover, the influences of the variable coefficient functions and interaction properties of solitary waves are discussed for physical interests and possible applications.
operating_systems	computer-based control systems, especially if they run under general-purpose operating systems, often exhibit variance of the scan period of processing inputs and outputs. although this fact is usually not taken into account when discrete control algorithms are used, it can cause worse performance of the control loop in comparison to the theoretical case. in this paper we describe a modified discrete lq control algorithm that takes disturbances of the scan period into account and partially compensates their influence. we also show that such a controller can be implemented even on low-performance hardware platforms, if they are equipped with a sufficient amount of memory.
machine_learning	in the field of weapon system of systems (wsos) simulation, various indicators are widely used to describe the capability of wsos, but it is always difficult to describe the comprehensive capability of wsos quickly and intuitively by visualization of multi-dimensional indicators. a method of machine learning and visualization is proposed, which can display and analyze the capabilities of different wsos in a two-dimensional plane. the analysis and comparison of the comprehensive capability of different components of wsos is realized by the method, which consists of six parts: multiple simulations, key indicators mining, three spatial distance calculation, fusion project calculation, calculation of individual capability density, and calculation of multiple capability ranges overlay. binding a simulation experiment, the collaborative analysis of six indicators and 100 possible kinds of red wsos are achieved. the experimental results show that this method can effectively improve the quality and speed of capabilities analysis, reveal a large number of potential information, and provide a visual support for the qualitative and quantitative analysis model.
operational_amplifier	three novel differential amplifier topologies using double gate a-igzo tfts on flexible substrate are presented in this paper. the designs exploit positive feedback and a load with self-biased top gate to achieve the highest static gain in single stage a-igzo amplifiers reported to date. after fabrication, the three amplifiers exhibit respectively a static gain of 14 db, 21.5 db, and 30 db, with a bandwidth of 2 khz, 400 hz, and 150 hz. also, for each circuit the input referred noise has been measured to be 420 mu v-rms, 195 mu v-rms, and 146 mu v-rms, respectively. based on these results, the a-igzo amplifier providing the highest gain is suitable as front-end for heart rate measurements and, with some further optimization verified in simulation, can also be used for other bio-potential applications, like electro hysterogram and electro cardiogram.
electricity	this paper addresses electricity transmission planning under the new industry and institutional structure of the mexican electricity market, which has engaged in a deep reform process after decades of a state-owned vertically -integrated-non-competitive-closed industry. under this new structure, characterized by a nodal pricing system and an independent system operator (iso), we analyze welfare-optimal network expansion with two modeling strategies. in a first model, we propose the use of an incentive price-cap mechanism to promote the expansion of mexican networks. in a second model, we study centrally-planned grid expansion in mexico by an iso within a power-flow model. we carry out comparisons of these models which provide us with hints to evaluate the actual transmission planning process proposed by mexican authorities (prodesen). we obtain that the prodesen plan appears to be a convergent welfare-optimal planning process.
electric_motor	the problem of vehicle lateral stability control for fully electric vehicles is addressed in this paper using two different approaches. one of them is a novel integrated lateral stability control (ilsc) system and the second one is a regenerative braking based lateral stability control system (rb-lsc). the proposed ilsc system is based on corrective yaw moment calculation, braking torque distribution and electric motor torque reduction. the proposed second method - rb-lsc - is a simpler method than the ilsc system. in this method, electric motor torque is regulated according to the vehicle side slip error and/or the vehicle yaw rate error. the performances of the proposed methods are evaluated under severe road conditions and extreme maneuvers using the commercially available carsim vehicle dynamics software. the results show that the proposed control systems improve vehicle lateral stability significantly.
electrical_circuits	the accurate and reliable identification of damage in modern engineered structures is essential for timely corrective measures. vibration-based damage prediction has been studied extensively by virtue of its global damage detection ability and simplicity in practical implementation. however, due to noise and damping effects, the accuracy of this method is inhibited when direct peak detection (dpd) is utilized to determine resonant frequency shifts. this research investigates an alternative method to detect frequency shifts caused by structural damage based on the utilization of strongly nonlinear bifurcation phenomena in bistable electrical circuits coupled with piezoelectric transducers integrated with the structure. it is shown that frequency shift predictions by the proposed approach are significantly less susceptible to error than dpd when realistic noise and damping levels distort the shifting resonance peaks. as implemented alongside adaptive piezoelectric circuitry with tunable inductance, the new method yields damage location and severity identification that is significantly more robust and accurate than results obtained following the dpd approach.
image_processing	an image processing technique using the proper orthogonal decomposition (pod) of infrared thermal data was developed to improve the speed of assessment of 2d heat source fields accompanying mechanical transformation. this method involved the generation of a reduced orthonormal basis to approximate thermal fields prior to heat source estimation. the robustness of the method was first assessed using a penalising benchmark test. this test involved artificially setting several tricky situations that arise in practice (high diffusivity, low signal-to-noise ratio, complex heat source distribution, etc.). application of the method to several experimental temperature fields obtained by an infrared focal plane array camera is then presented. the error between the pod approximated solution in terms of heat sources and a reference solution, computed via a local least squares fitting method, was found to be negligible, thus confirming the efficiency and advantages of the pod preprocessing technique - the method enabled us to obtain a reliable estimate of heat sources while drastically reducing the computation cost in terms of cpu time.
state_space_representation	this paper presents an optimal method to tune the proportional, integral and derivative (pid) controller for a hydraulic turbine coupled with the corresponding transient droop compensator (tdc). the proposed methodology is based on the desired time response specification (dtrs) of the input guide vane servomotor that includes typical rate limiters and gain saturation in power plants. therefore, the problem consists of adjusting both the parameters of the controller and compensator such as the time response remains close to the specified one. to avoid suboptimal solutions at local minimum points, it is necessary to solve the resulting non linear problem in two steps: (i) firstly, solve a linear programming (lp) to determine the values of pid&tdc block using state space representation to match the input and output time responses specifications and (ii) determine the final values of the pid and tdc parameters using the previous results in a new non linear programming. the proposed methodology has presented the advantage of tuning the pid coordinated with the tdc spending low computational time. the results show that the performance of the method covers a wide range of operating conditions of the system. comparisons were also made with existing methods in the literature to show the effectiveness of the proposed methodology. (c) 2014 elsevier ltd. all rights reserved.
computer_graphics	natural phenomena simulation attracts a lot of research attention and interest in virtual reality. the simulation for liquid has become a research focus in both computer graphics and computational physics, because of the difficulties in dynamic modelling and high computational complexity. we introduce the main research achievements in recent years with regard to liquids, which is a common natural phenomenon. a hybrid modelling approach for dynamic liquid simulation is proposed, followed by a surface reconstruction method using simulated results. in particle-based fluid simulation, surface construction is one procedure to contour the implicit function which determines an isosurface in a scalar field. we describe an adaptive polygonisation approach, by adaptively constructing an unconstrained octree structure, to reduce excessive subdivision which is required by traditional methods like marching cubes. dual marching cubes is then applied to perform surface extraction on a new grid which is topologically dual to the octree structure. experiment shows the advantages of our approach in generating satisfactory effects without excessively fine-grained grid structure. satisfactory visual effect is achieved and this application can be used in computer games, movie making and virtual simulation in medical areas.
state_space_representation	the uncertainty of neural model influences the effectiveness of the neural model-based fdi and ftc systems. the application of the gmdh approach to the state-space neural model structure selection allows reducing the model uncertainty. the state-space representation of the neural model enables to develop a new technique of estimation of the neural model inputs based on the ruif. this result enables performing robust fault detection and isolation of the actuators.
parallel_computing	the bootstrap is a popular and powerful method for assessing precision of estimators and inferential methods. however, for massive datasets that are increasingly prevalent, the bootstrap becomes prohibitively costly in computation and its feasibility is questionable even with modern parallel computing platforms. recently, kleiner and co-authors, proposed a method called blb (bag of little bootstraps) for massive data, which is more computationally scalable with little sacrifice of statistical accuracy. building on blb and the idea of fast double bootstrap, we propose a new resampling method, the subsampled double bootstrap, for both independent data and time series data. we establish consistency of the subsampled double bootstrap under mild conditions for both independent and dependent cases. methodologically, the subsampled double bootstrap is superior to blb in terms of running time, more sample coverage, and automatic implementation with less tuning parameters for a given time budget. its advantage relative to blb and bootstrap is also demonstrated in numerical simulations and a data illustration. supplementary materials for this article are available online.
operational_amplifier	a constant-gm, rail-to-rail operational amplifier circuit topology is presented in this paper. the amplifier input stage is realized using single nmos pair at 0.13 mu m bulk-cmos process technology. the overall gain variation is within the range of +/- 2.338% for the rail-to-rail common mode input range. the proposed design is able to reject the common mode input response with 115db of common mode rejection ratio (cmrr). high slew rate is achieved and the simulated value is +19/-43 (v/mu s) of an unity gain buffer op-amp at 5pf of cl. the variation in overall gm and gain are also simulated at different corner temperatures. the circuit simulation is done in tanner eda at 1.8v of power supply which dissipates the power of 6.1mw.
state_space_representation	high-frequency (hf) models of electrical motors and power converters are greatly important for electromagnetic compatibility characterization of electrical drives and for electromagnetic interference (emi) filter design. in this paper, an accurate and effective method for the characterization and tuning of hf models (150 khz-30 mhz) for induction motors has been proposed based on experimental measurements of the motor impedance. impedance measurements have been taken in three different configurations: between all the six winding terminals which are shorted and grounded; between the three input terminals which are shorted and grounded (common mode); and between one input terminal and the other two which are shorted (differential mode). once an hf motor model structure has been chosen and modeled using a state-space representation, its parameters have been tuned using genetic algorithm to match the real impedance in each corresponding configuration. comparison between the experimental impedance measurements and the model impedance estimate are shown for all the tested configurations, in order to validate the model within the frequency range of interest for emi.
electrical_network	more and more maritime applications as marine vessels and offshore platforms need an adaptive protection power system. however, the adaptive protection is yet to be implemented in the maritime sector. usually, the adaptive protection implies the existence of a central control unit that monitors the entire electrical network and changes the relay settings accordingly, but this approach is not adequate for the maritime power systems. this paper propose a decentralized adaptive protection method, where each protection relay is able to identify by itself the network status without the need of a central control unit. the new adaptive protection method is based on communication between the overcurrent relays and the equipment that could affect the protection system, such as circuit breakers and generators. using pscad, the proposed method is implemented in a test medium voltage maritime power system that possess some of the characteristics of the maritime applications, as variable generation and network reconfiguration.
analog_signal_processing	the paper aims to perform a comparative analysis regarding the testing results achieved on an experimental model of counter rotating wind turbine with a rated power of 1 kw for a wind velocity of 10 m/s. the experimental model is consisted of a system of two rotors which rotate in opposite directions - one rotor is rotating in clockwise direction and the other in counter-clockwise direction - and one unique electrical generator, which adds-up the rotation of both wind rotors. the ratio between the two diameters is 1.08, the up-wind rotor being slightly larger than the down-wind one. the experimental model is provided with a three-phase synchronous electric generator with counter rotating armatures, having the power of 1.6 kw, 3x24 v, at 750 rpm. this type of generator is characterized by a reduced size, increased rotational speed and no losses due to movement transmission. the experiments on the wind turbine system have been performed both in a wind tunnel as well as in situ, in a location nearby iasi city, romania, where the turbine has been installed. the paper focuses on investigating the operation of the system both in controlled test conditions and in real conditions, when wind changes its velocity and direction. in order to determine the effect of these variations, the wind turbine system has been tested at different wind velocities, up to 10.5 m/s in the wind tunnel and up to 8.7 m/s in free air stream. the in situ testing has been performed also in order to validate the results obtained on the experimental model of counter rotating wind turbine system within the wind tunnel. there has been noticed a good consistency between the two sets of experiments, resulting that the procedure is suitable to be further applied in designing a 10 kw wind turbine prototype.
computer_vision	the paper develops a general regression framework for the analysis of manifold-valued response in a riemannian symmetric space (rss) and its association with multiple covariates of interest, such as age or gender, in euclidean space. such rss-valued data arise frequently in medical imaging, surface modelling and computer vision, among many other fields. we develop an intrinsic regression model solely based on an intrinsic conditional moment assumption, avoiding specifying any parametric distribution in rss. we propose various link functions to map from the euclidean space of multiple covariates to the rss of responses. we develop a two-stage procedure to calculate the parameter estimates and determine their asymptotic distributions. we construct the wald and geodesic test statistics to test hypotheses of unknown parameters. we systematically investigate the geometric invariant property of these estimates and test statistics. simulation studies and a real data analysis are used to evaluate the finite sample properties of our methods.
state_space_representation	the adequate representation of states in the construction of intelligent agents is fundamental for allowing them to achieve a satisfactory performance, principally for those that actuate in a competitive environment that possesses a high state space. one particular type of representation that is very appropriate for these situations is the netfeaturemap, which describes by means of features the relevant aspects that are inherent to the environment where the agent actuates. in renowned intelligent agents, such features are manually selected, which certainly leads to inadequate choices. in this way, the main contribution of this paper is to propose a new approach, based on association rules, that automatically selects these features. under the intent of investigating the efficacy of such a proposal, the authors utilize the domain of checkers player agents as their study laboratory. the best performance of the association rules-based agents proves the efficacy of the present proposal.
software_engineering	bayesian networks (bn) have been used for decision making in software engineering for many years. in other fields such as bioinformatics, bns are rigorously evaluated in terms of the techniques that are used to build the network structure and to learn the parameters. we extend our prior mapping study to investigate the extent to which contextual and methodological details regarding bn construction are reported in the studies. we conduct a systematic literature review on the applications of bns to predict software quality. we focus on more detailed questions regarding (1) dataset characteristics, (2) techniques used for parameter learning, (3) techniques used for structure learning, (4) use of tools, and (5) model validation techniques. results on ten primary studies show that bns are mostly built based on expert knowledge, i.e. structure and prior distributions are defined by experts, whereas authors benefit from bn tools and quantitative data to validate their models. in most of the papers, authors do not clearly explain their justification for choosing a specific technique, and they do not compare their proposed bns with other machine learning approaches. there is also a lack of consensus on the performance measures to validate the proposed bns. compared to other domains, the use of bns is still very limited and current publications do not report enough details to replicate the studies. we propose a framework that provides a set of guidelines for reporting the essential contextual and methodological details of bns. we believe such a framework would be useful to replicate and extend the work on bns.
electricity	compressed air energy storage technologies can improve the supply capacity and stability of the electricity grid, particularly when fluctuating renewable energies are massively connected. while incorporating the combined cooling, heating and power systems into compressed air energy storage could achieve stable operation as well as efficient energy utilization. in this paper, a novel combined cooling, heating and power based compressed air energy storage system is proposed. the system combines a gas engine, supplemental heat exchangers and an ammonia-water absorption refrigeration system. the design tradeoff between the thermodynamic and economic objectives, i.e., the overall exergy efficiency and the total specific cost of product, is investigated by an evolutionary multi-objective algorithm for the proposed combined system. it is found that, with an increase in the exergy efficiency, the total product unit cost is less affected in the beginning, while rises substantially afterwards. the best trade-off solution is selected with an overall exergy efficiency of 53.04% and a total product unit cost of 20.54 cent/kwh, respectively. the variation of decision variables with the exergy efficiency indicates that the compressor, turbine and heat exchanger preheating the inlet air of turbine are the key equipment to cost-effectively pursuit a higher exergy efficiency. it is also revealed by an exergoeconomic analysis that, for the best trade-off solution, the investment costs of the compressor and the two heat exchangers recovering compression heat and heating up compressed air for expansion should be reduced (particularly the latter), while the thermodynamic performance of the gas engine need to be improved significantly. (c) 2017 elsevier ltd. all rights reserved.
analog_signal_processing	a new active element for analog signal processing, namely the current inverter buffered differential input transconductance amplifier (cibdita), is proposed it combines some features of the well-known current differencing buffered and transconductance amplifiers, simplifies their current input stage, and increases their universality by introducing an additional voltage-type input. the usefulness of this new element is demonstrated on the example of a 2(nd)-order filter which employs only one active element, two grounded capacitors, and one resistor.
pid_controller	in order to ensure that a robotic hand can successfully grasp objects without damaging them, an active compliance control can be a very useful technique to provide a safe grasping. in particular, this paper establishes a direct force control for a 3-finger adaptive robot gripper by using a pid control. a modified fsr force sensor where a plastic cover is used to ensure the contacted force during grasping can be measured and recorded. a series of grasping tests were performed to observe the performance of pid control. the experimental results show that the pid control can be a simple and reliable control scheme to provide an active compliance control through direct force control. in addition, different compliance level is feasible particularly for a stiff spongy ball.
analog_signal_processing	the potential of electric power generation from marine tidal currents is enormous. tidal currents are being recognized as a resource to be exploited for the sustainable generation of electrical power. the high load factors resulting from the fluid properties and the predictable resource characteristics make marine currents particularly attractive for power generation and advantageous when compared to other renewable energies. moreover, international treaties related to climate control have triggered resurgence in development of renewable ocean energy technology. therefore, several demonstration projects in tidal power are scheduled to capture the tidal generated coastal currents. regarding this emerging and promising area of research, this paper reviews marine tidal power fundamental concepts and main projects around the world. it also report issues regarding electrical generator topologies associated to tidal turbines. moreover, attempts are made to highlight future issues so as to index some emerging technologies mainly according to relevant works that have been carried out on wind turbines and on ship propellers.
analog_signal_processing	converting infrared radiation in the form of heat into electricity is one of the interesting energy conversion approaches. this can be simply accomplished through thermoelectric effect with the well-known device called thermoelectric cooler (tec). in this paper, we briefly overview tec-based concepts, demonstrations, and products for converting heat into electricity. we then propose our own portable tec-based heat-to-electricity converting module. experimental proof of concept is also highlighted showing a promising output voltage of 5vdc and 0.224a suitable for low voltage applications. future work relates to design optimization, engineering improvement, and testing in real world scenario
machine_learning	machine learning algorithms applied to text categorization mostly employ the bag of words (bow) representation to describe the content of the documents. this method has been successfully used in many applications, but it is known to have several limitations. one way of improving text representation is usage of wikipedia as the lexical knowledge base - an approach that has already shown promising results in many research studies. in this paper we propose three path-based measures for computing document relatedness in the conceptual space formed by the hierarchical organization of a wikipedia category graph (wcg). we compare the proposed approaches with the standard path length method to establish the best relatedness measure for the wcg representation. to test overall wcg efficiency, we compare the proposed representations with the bow method. the evaluation was performed with two different types of clustering algorithms (optics and k-means), used for categorization of keyword-based search results. the experiments have shown that our approach outperforms the standard path length approach, and the wcg representation achieves better results than bow.
analog_signal_processing	the paper will present a converter with multiple sources for energy harvest of internal combustion engine vehicle. the energy sources include solar panel, regeneration energy during braking and thermal electrical generator. since these three energy sources have different power rating, a power distribution control method is proposed in this paper. the proposed power distribution control provides effectively specific power distribution control while requiring less feedback signals and thereby reducing the cost of ad converter etc. the specifications of the converter include: input voltage ranging extends from 16 v to 60 v, output power is around 1.32 kw and output voltage is 12 v. details of the controller design, simulation and experimental results will be presented to confirm the effectiveness of the proposed multi-source converter and power distribution control method. the results show that the output voltage can be well regulated. all the power distributions among different energy sources can be achieved. the prototype is designed and experimental results are included for confirmation.
pid_controller	this paper concerns the dynamical decoupling and feed-forward control of magnetically-levitated planar actuators (mlpas) with moving coils when the moving stage 's center-of-mass (cm) deviates from the geometric center (gc). based on the direct wrench-current decoupling, the factors that affect the continuity of current are emphatically analyzed for a more stable current control, and the propulsion works at cm is converted at gc with newton-euler dynamic equation. by inverting the system dynamics, 6 degrees-of-freedom (dof) individual control is realized and the system is simplified from mimo to siso. based on the decoupling, an acceleration feed-forward controller with pid control is designed. by studying the coupling parameter relating to feed-forward inputs and white noise, the acceleration amplification coefficient is achieved and the pid parameters will be optimized based on comparing the actual variance with the minimum achievable variance. last, the simulation results indicate that the feed-forward compound controller applying to mlpas system has a better performance than the general pid controller.
digital_control	a hydrokinetic smart grid (ksg) concept powered by modules of hydrokinetic microturbines arranged in rows is proposed in this work. a complete description of each module: mechanical design, hydropower characteristics, power electronics and control strategies have been included. a complete dynamic simulation of an example of a ksg has been performed. it considers microturbine modules, power loads, energy storage modules and a grid tie inverter that interface with the mains using a single connection. additionally, the control and power stages of a hydrokinetic microturbine has been validated. the satisfactory technical results obtained in addition with the acceptable results of an investment analysis, encourage future implementations of ksgs.
control_engineering	after a short discussion of the goldi remote lab infrastructure, the new experiment control panel (ecp) and the integrated graphical interactive finite state machine toolset (gift) main focus of the paper is the interconnection of multiple remote labs (based on the goldi infrastructure) to a remote lab cloud. within two running tempus projects ten remote labs in four countries can be used worldwide. based on this cloud structure it is necessary to adapt the complex goldi access control system. with this new reservation system possibilities for an effective worldwide experiment management will be available, which will be described in the article.
electricity	utility sector reform spread across the developing world in the 1980s and 1990s. in egypt, as in many cases, the pace and nature of reform has been challenged by a state-owned national incumbent. however, in the egyptian telecommunications sector, rapid growth in the cellular market has overtaken the archaic fixed-line system. hence, the national monopoly provider, telecom egypt (te), has been stripped of its market power as the market diversified. the implemented public sector reform and privatization placed efficiency pressures on te resulting in improved outcomes for a range of stakeholders, consumers, workers, and the government, including reduced prices, increased access, and improved service quality. this experience offers lessons for policy makers and researchers about liberalization in the face of entrenched state interests. however, there are nuances in the findings relating to market type, that is, fixed-line versus cellular, residential versus non-residential, and national versus international. despite attempted improvements, direct competition in its retail market has led to deterioration in te 's financial performance, although this has been partially offset by its monopoly supply of an essential input and a degree of protection provided by the regulator sympathetic to te. the evidence from this case study supports the concept of a staggered introduction of competition. however, protecting inefficient market insiders, be it firms or workers, is always at the expense of potentially more efficient outsiders. (c) 2016 the author. published by elsevier ltd.
network_security	the economic situation highlights the significant role of the application of computer in human society since the 21st century, especially since 2015. this thesis probes into the security risk propagation of immune mechanism under complex network background. focusing on the issue of network security under network background, the thesis deploys the analysis by adopting the mechanism model of immune mechanism, immunizing parts of the nodes, establishing stochastic immune mechanism of security risk and introducing stochastic immune mechanism propagation model of security risk. to further study the security risk propagation of immune mechanism under complex network background, the thesis presents the model rules, introduces the security risk acquaintance immune mechanism and establishes models of acquaintances immune mechanism. finally, attributing to the simulation experiments, the simulation results, the characteristics of security risk propagation model, and the study of stochastic immune mechanism propagation model and acquaintance immune mechanism stochastic model, the thesis reaches the conclusion that at the initial stage of propagation, the die-out rate of the security risk is inversely proportional to the propagation rate.
electricity	to find a balance between food and energy security, this research presents the design of an energy self-sufficient farm in electricity, heat and bioethanol, which is produced by energy crops and agricultural residues. the farm proposed is evaluated by two models: land optimization and cost optimization. due to the food-fuel debate over land and the detriment of food security, this research proposes utilizing the current abandoned land and increasing the food self-sufficiency ratio (fssr) of the crops analyzed (rice, wheat and maize). the farm is optimized for several food and fuel demands, with a maximum farm unit size of 100 ha. the result is a myriad of farms of different sizes, each optimized for a certain demand. subsequently, the amount and variety of such farms are optimized maximizing the food and fuel produced for each city of the case study (miyagi prefecture, japan). the results suggest that the establishment of energy self-sufficient farms in the abandoned land can stimulate the biofuel industry and increase food security simultaneously. the fssr of maize and wheat can be improved in approximately 10-25 and 7-9 %, respectively. the estimated bioethanol potential is 3.2-3.8 ml. additionally, a surplus of electricity and heat, approximately 61-65 gwh and 60-165 mj, respectively, is obtained. as the land optimization model proposed is sensitive to crop yields, a simultaneous evaluation is recommended. the results also suggest that the farms must be larger than 8 ha to achieve self-sufficiency; therefore, the policies involved need further evaluation.
operational_amplifier	in this paper, a new pulse width modulation (pwm) converter is proposed. this structure converts the analog input signal to a pwm waveform using only inverters/charge-pumps in combination with passive elements. thus, the proposed pwm converter does not need any operational amplifier. the added feedback path current can be used to adjust the required duty-cycle of the pwm conversion based on the dynamic range of the input signal. the behavior of the proposed pwm converter is formulated and simulated in a 0.13 mu m cmos technology. from the simulation results, the proposed pwm converter achieves 74db linearity and draws only 1.0ma at 500mhz from 1.0v supply in a 0.13 mu m process.
electrical_circuits	this paper proposes a new method of decoupling and subdividing electrical circuits, containing power-electronics devices, in order to achieve fast and accurate real-time simulation. in this technique, each state variable can be discretized using different discretization methods. combining implicit and explicit ode solvers, state-space equations are decoupled while remaining accurate and stable. unlike most traditional decoupling techniques previously proposed, the proposed one does not require artificial delay or supplementary states to be added in order to decouple the system. furthermore, this technique is meant to be implemented with commercially available simulation software. by doing so, a large and complex circuit containing several hundreds of state variables can be easily and accurately simulated with minor modification to the existing models. finally, stability and accuracy of the proposed technique are thoroughly demonstrated in a numerical example during steady state and under faulty conditions.
analog_signal_processing	in this paper, a novel translinear loop based, high performance complementary metal-oxide-semiconductor (cmos) second-generation differential current conveyor (dccii) is introduced. by using super source follower transistors, very low equivalent impedances are obtained at input terminals x(n) and x(p). in addition, new voltage-mode (vm) and current-mode (cm) first-order all-pass filters (apfs) are proposed to highlight the performance of the designed cmos dccii. the designed cmos implementation is simulated with hspice using ams 0.35 mu m real process parameters. it consumes only 1.3 mw power with using +/- 1.25 v power supply voltages. the simulation results of the proposed cmos dcii circuit and the experimental results for designed vm apf are in very good agreement with the theoretical ones.
algorithm_design	although the problem of k-area coverage has been intensively investigated for dense wireless sensor networks (wsns), how to arrive at a k-coverage sensor deployment that optimizes certain objectives in relatively sparse wsns still faces both theoretical and practical difficulties. moreover, only a handful of centralized algorithms have been proposed to elevate 2-d area coverage to 3-d surface coverage. in this paper, we present a practical algorithm, i.e., the autonomous deployment for load balancing k-surface coverage (apollo), to move sensor nodes toward k-surface coverage, aiming at minimizing the maximum sensing range required by the nodes. apollo enables purely autonomous node deployment as it only entails localized computations. we prove the termination of the algorithm and the (local) optimality of the output. we also show that our optimization objective is closely related to other frequently considered objectives for 2-d area coverage. therefore, our practical algorithm design also contributes to the theoretical understanding of the 2-d k-area coverage problem. finally, we use extensive simulation results to both confirm our theoretical claims and demonstrate the efficacy of apollo.
operating_systems	virtual desktop infrastructure (vdi) solutions seek to provide a satisfactory user experience at the client side when accessing remote desktop applications, even from mobile devices with limited capabilities. this paper presents a new approach, improving on previous work by the authors, in which a combination of virtual network computing (vnc) and streaming protocols allowed efficient remote web access to virtualized applications within a cloud architecture. the new approach simplifies virtual machine templates, from which virtual machine instances are deployed, by centralizing software modules, greatly simplifying their management. our new contribution consists of an integrated solution with specific webm video encoding modules in charge of application visual output processing, an hypertext transfer protocol (http) streaming server, and a vnc server. the solution can be installed in the hypervisor of the host machines instead of replicating the servers and modules throughout the guest (virtual) machines that run the virtualized applications. consequently, their implementations are unique and independent of the operating system of the virtual machines. in short, it is not necessary to provide different implementations for different operating systems, which reduces the complexity of virtual machine templates and greatly simplies platform management. to demonstrate our solution, we have modified the quick emulator (qemu)-kernel-based virtual machine (kvm) hypervisor source code accordingly. we also present qualitative and quantitative analyses that demonstrate that the new approach is advantageous in terms of software management and quality of experience, compared with our previous work and other well-known thin clients, contributing to the enhancement of vdi systems. copyright (c) 2015john wiley & sons, ltd.
electric_motor	a challenging strategy to reuse 3d-printer structures for laboratory training, related to automation and positioning, is presented. the laboratory course is meant to be presented to students within ""digital systems and microcontrollers"" and ""automatisms and control"" courses.
distributed_computing	distributed denial of service attacks produce large volumes of spoofed network data. manual analysis of gigabytes of network logs to determine source of the attacks, victim ips and vulnerability exploitation is time- consuming and error prone. cloud computing has recently emerged as a promising technology which allows everyday users to harness the massively parallel processing capabilities of commodity machines as a payas- you- go utility service. the contribution of this work is the conceptualization, design and implementation of a distributed ddos analysis framework that uses the power of the cloud via the mapreduce paradigm to perform an entropy based clustering and security analysis of the key features of attack traffic. we have evaluated our framework on two large and publicly available ddos attack datasets. moreover, we achieve 86% speedup in analysis with a modestly sized cluster of ten nodes.
data_structures	the study of tumor growth biology with computer-based models is currently an area of active research. different simulation techniques can be used to describe the complexity of any real tumor behavior, among these, ""cellular automata""-based simulations provide an accurate tumor growth graphical representation while, at the same time, keep simpler the implementation of the automata as computer programs. several authors have recently published relevant proposals, based on the latter approach, to solve tumor growth representation problem through the development of some strategies for accelerating the simulation model. these strategies achieve computational performance of cellular-models representation by the appropriate selection of data types, and the clever use of supporting data structures. however, as of today, multithreaded processing techniques and multicore processors have not been used to program cellular growth models with generality. this paper presents a new model that incorporates parallel programming for multi and manycore processors, and implements any synchronization requirement necessary to implement the solution. the proposed parallel model has been proved using java and c++ program implementations on two different platforms: chipset intel i5-4440 and one node of 16-processors cluster of our university. the improvement resulting from the introduction of parallelism into the model is analyzed in this paper, comparing it with the standard sequential simulation model currently used by researchers in mathematical oncology.
machine_learning	generating synthetically mixed data from library spectra provides a direct means to train empirical regression models for subpixel mapping. in order to best represent the subpixel composition of image data, the generation of synthetic mixtures must incorporate a multitude of mixing possibilities. this can lead to an excessive amount of training samples. we show that increasing mixing complexity in the training set improves model performance when quantifying urban land cover with support vector regression (svr). to cope with the challenging increase in the number of training samples, we propose the use of ensemble learning based on bootstrap aggregation from synthetically mixed training data. the workflow is tested on simulated spaceborne imaging spectrometer data acquired over berlin, germany. comparisons to svr without bagging and multiple endmember spectral mixture analysis reveal the usefulness of the methodology for quantitative urban mapping.
microcontroller	by the deployment of internet of things, embedded systems using microcontroller are nowadays under threats through the network and incorporating security measure to the systems is highly required. unfortunately, microcontrollers are not so powerful enough to execute standard security programs and need light-weight, high-speed and secure cryptographic libraries. in this paper, we port nacl cryptographic library to arm cortex-m0(m0+) microcontroller, where we put much effort in fast and secure implementation. through the evaluation we show that the implementation achieves about 3 times faster than avr nacl result and reduce half of the code size.
analog_signal_processing	direct drive wave energy converters are characterized by a direct conversion of the wave energy into electricity with no intermediate mechanical conversion system. for this reason, optimization methods for maximizing the absorbed power have to be designed for acting on the electrical generator. besides, this type of system requires power electronics to be connected to the grid. this paper evaluates three different current control strategies applied to a boost-rectifier in the ac-dc stage as part of an optimization method. the system is implemented and simulated in matlab/simulink with real random waves. in direct drive wave energy conversion, unlike the original application of these controllers, the input electrical power is highly variable, both in amplitude and frequency. the controllers are assessed under these conditions and their advantages and disadvantages are presented.
lorentz_force_law	we consider the nonlinear klein-gordon-maxwell system derived from the lagrangian integral(-1/4 f(mu nu)f(mu nu) + 1/2- nu(phi) - ea(mu)j(mu)(b)) on four-dimensional minkowski space-time, where phi is a complex scalar field and f(mu nu) = partial derivative(mu)a(nu) - partial derivative(nu)a(mu) is the electromagnetic field. for appropriate nonlinear potentials nu, the system admits soliton solutions which are gauge invariant generalizations of the non-topological solitons introduced and studied by lee and collaborators for pure complex scalar fields. in this article, we develop a rigorous dynamical perturbation theory for these solitons in the small e limit, where e is the electromagnetic coupling constant. the main theorems assert the long time stability of the solitons with respect to perturbation by an external electromagnetic field produced by the background current j(b), and compute their effective dynamics to o(e). the effective dynamical equation is the equation of motion for a relativistic particle acted on by the lorentz force law familiar from classical electrodynamics. the theorems are valid in a scaling regime in which the external electromagnetic fields are o(1), but vary slowly over space-time scales of o(1/delta), and delta = e(1-k) for k is an element of (0, 1/2) as e ->0. we work entirely in the energy norm, and the approximation is controlled in this norm for times of o(1/e).
data_structures	the finnish patient data repository is a nationwide electronic health record (ehr) system collecting patient data from all healthcare providers. the usefulness of the large amount of data stored in the system depends on the underlying data structures, and thus a solid understanding of these structures is in focus in further development of the data repository. this study seeks to improve that understanding by a systematic literature review. the review takes the physician 's perspective to the use and usefulness of the data structures. the articles included in this review study data structures intended to be used in the actual care process. secondary use and nursing aspects have been covered in separate reviews. after applying the predefined inclusion and exclusion criteria only 40 articles were included in the review. the research on widespread systems in everyday use was especially scarce, most studies concentrated on narrow fields. majority of these studies were primarily developed for specialist use in secondary care units. most structures or applications studied were at an early stage of development. in many applications the use of structured data was found to improve the completeness of the documented data and facilitate its automated use. however, there seem to be some applications where narrative text cannot be easily replaced by structured data. usability results regarding structured representation were conflicting. the scattered nature and paucity of research hinders the generalizability of the findings, and from the system design or implementation point of view the practical value of the scientific literature reviewed is limited.
bioinformatics	the hla-g molecule presents immunomodulatory properties that might inhibit immune responses when interacting with specific natural killer and t cell receptors, such as kir2dl4, ilt2 and ilt4. thus, hla-g might influence the outcome of situations in which fine immune system modulation is required, such as autoimmune diseases, transplants, cancer and pregnancy. the majority of the studies regarding the hla-g gene variability so far was restricted to a specific gene segment (i.e., promoter, coding or 3' untranslated region), and was performed by using sanger sequencing and probabilistic models to infer haplotypes. here we propose a massively parallel sequencing (ngs) with a bioinformatics strategy to evaluate the entire hla-g regulatory and coding segments, with haplotypes inferred relying more on the straightforward haplotyping capabilities of ngs, and less on probabilistic models. then, hla-g variability was surveyed in two admixed population samples of distinct geographical regions and demographic backgrounds, cyprus and brazil. most haplotypes (promoters, coding, 3'utr and extended ones) were detected both in brazil and cyprus and were identical to the ones already described by probabilistic models, indicating that these haplotypes are quite old and may be present worldwide. (c) 2017 elsevier ltd. all rights reserved.
system_identification	the objective of structural model updating is to reduce inherent modeling errors in finite element (fe) models due to simplifications, idealized connections, and uncertainties of material properties. updated fe models, which have less discrepancies with real structures, give more precise predictions of dynamic behaviors for future analyses. however, model updating becomes more difficult when applied to civil structures with a large number of structural components and complicated connections. in this paper, a full-scale fe model of a major long-span bridge has been updated for improved consistency with real measured data. two methods are applied to improve the model updating process. the first method focuses on improving the agreement of the updated mode shapes with the measured data. a nonlinear inequality constraint equation is used to an optimization procedure, providing the capability to regulate updated mode shapes to remain within reasonable agreements with those observed. an interior point algorithm deals with nonlinearity in the objective function and constraints. the second method finds very efficient updating parameters in a more systematic way. the selection of updating parameters in fe models is essential to have a successful updating result because the parameters are directly related to the modal properties of dynamic systems. an in-depth sensitivity analysis is carried out in an effort to precisely understand the effects of physical parameters in the fe model on natural frequencies. based on the sensitivity analysis, cluster analysis is conducted to find a very efficient set of updating parameters. (c) 2016 elsevier ltd. all rights reserved.
signal-flow_graph	advances in nano-electronics vlsi manufacturing technology and the rapid downscaling of the size of logic circuits have made them more prone to errors. this has led to the need for fast circuit reliability evaluation of large logic circuits. in this paper a new method for reliability analysis of vlsi logic circuits based on a modified form of mason 's rule is proposed. utilizing matrix sparsity significantly increases the speed and reduces the required memory of the proposed approach. in addition, an approach is introduced to mitigate the effect of reconvergent paths. simulation results indicate that the proposed method is scalable and runs 4x faster than previously proposed schemes. (c) 2014 published by elsevier ltd.
cryptography	with reference to a distributed architecture consisting of sensor nodes connected by wireless links in an arbitrary network topology, we consider a segment-oriented implementation of the single address space paradigm of memory reference. in our approach, applications consist of active entities called components, which are distributed in the network nodes. a component accesses a given segment by presenting a handle for this segment. a handle is a form of pointer protected cryptographically. handles allow an effective implementation of communications between components, and key replacement. the number of messages generated by the execution of the communication primitives is independent of the network size. the key replacement mechanism is well suited to reliable application rekeying over an unreliable network.
machine_learning	heterogeneous computing, combining devices with different architectures such as cpus and gpus, is rising in popularity and promises increased performance combined with reduced energy consumption. opencl has been proposed as a standard for programming such systems and offers functional portability. however, it suffers from poor performance portability, because applications must be retuned for every new device. in this paper, we use machine learning-based auto-tuning to address this problem. benchmarks are run on a random subset of the tuning parameter spaces, and the results are used to build a machine learning-based performance model. the model can then be used to find interesting subspaces for further search. we evaluate our method using five image processing benchmarks, with tuning parameter space sizes up to 2.3 m, using different input sizes, on several devices, including an intel i7 4771 (haswell) cpu, an nvidia tesla k40 gpu, and an amd radeon hd 7970 gpu. we compare different machine learning algorithms for the performance model. our model achieves a mean relative error as low as 3.8% and is able to find solutions on average only 0.29% slower than the best configuration in some cases, evaluating less than 1.1% of the search space. the source code of our framework is available at https://github.com/acelster/ml-autotuning.
algorithm_design	this paper investigates the physical-layer security of a multiuser peer-to-peer (mup2p) relay network for amplify-and-forward (af) protocol, where a secure user and other unclassified users coexist with a multi-antenna eavesdropper and the eavesdropper can wiretap the confidential information in both two cooperative phases. our goal is to optimize the transmit power of the source and the beamforming weights of the relays jointly for secrecy rate maximization subject to the minimum signal-to-interference-noise-ratio (sinr) constraint at each user, and the individual and total power constraints. mathematically, the optimization problem is non-linear and non-convex, which does not facilitate an efficient resource allocation algorithm design. as an alternative, a null space beamforming scheme is adopted at the relays for simplifying the joint optimization and eliminating the confidential information leakage in the second cooperative phase, where the relay beamforming vector lies in the null space of the equivalent channel of the relay to eavesdropper links. although the null space beamforming scheme simplifies the design of resource allocation algorithm, the considered problem is still non-convex and obtaining the global optimum is very difficult, if not impossible. employing a sequential parametric convex approximation (spca) method, we propose an iterative algorithm to obtain an efficient solution of the non-convex problem. besides, the proposed joint design algorithm requires a feasible starting point, we also propose a low complexity feasible initial points searching algorithm. simulations demonstrate the validity of the proposed strategy.
distributed_computing	this paper presents a novel frequency-domain approach for distributed harmonic analysis (dha) of a multi-area interconnected electric power system within restructured environment. the proposed approach is based on a decentralized structure in which harmonic analysis of an area is independently conducted, even with limited available data, via local computing resources. the large-change sensitivity (lcs) concept is then applied in a secure platform to account for the effects of whole network to each single area of the interconnected power system. frequency-dependent models of system elements accompanied by any existent harmonic assessment method can be utilized for harmonic penetration calculation. the proposed dha approach is capable of finding exact values as those of the interconnected system using tcp/ip communication facility. moreover, it allows operator of a utility to independently conduct dha within a restructured power network. the developed method is implemented in an existing software package and applied to several networks including the ieee 118-bus test system. (c) 2016 elsevier b.v. all rights reserved.
network_security	recent variants of distributed denial-of-service (ddos) attacks leverage the flexibility of application-layer protocols to disguise malicious activities as normal traffic patterns, while concurrently overwhelming the target destination with a large request rate. new countermeasures are necessary, aimed at guaranteeing an early and reliable identification of the compromised network nodes (the botnet). in this work we introduce a formal model for the aforementioned class of attacks, and we devise an inference algorithm that estimates the botnet hidden in the network, converging to the true solution as time progresses. notably, the analysis is validated over real network traces.
pid_controller	in this paper, a novel hybrid many optimizing liaisons (mol) and teaching-learning based optimization(tlbo) i.e. mol-tlbo based optimization of integrated hybrid renewable energy sources (ihres) is proposed for techno-economic-socio analysis. ihres consists of pv, wind turbine, battery storage banks and diesel generator. the methodology was constructed by using meteorological data from renewable energy laboratory of electrical engineering department, manit, bhopal situated in madhya pradesh, india. optimal sizing of ihres is done on the basis of solar irradiation, wind speed, demand load, reliability index, loss of load probability (lolp) and co2 emission through diesel generator. three different crystalline silicon pv modules are considered: ase-300(mi-si based efg), kyocera-120(mc-si based wafer) and astro-power ap-120(thin-film si). results show that ap-120 gives better result as compared with other two for pv-wind-battery-dg combination. annual cost of the system (acs) is evaluated by using the proposed hybrid mol and tlbo (mol-tlbo) algorithm. supremacy of the suggested mol-tlbo hybrid method for optimal sizing of hybrid system is proved by comparing the results with other optimization techniques i.e. tlbo, itlbo, pso, mol and sga. finally it is seen that mol-tlbo based techno-economicsocio analysis for ihres exhibit superior performance and fast as compared to sga, pso, tlbo, itlbo and mol. (c) 2016 elsevier b.v. all rights reserved.
pid_controller	this paper focuses on the stabilization problem for the floated inertial platform experimental system. based on the moment analysis of the platform and the mode of the main moment, the dynamic equation of the stabilized platform rotating around its center is derived in consideration of some disturbances. to solve the system model uncertainty, measurement noise, three-axial coupling and unmodeled disturbances, the auto disturbances rejection controller (adrc) is proposed. in addition, the time delay problem, caused by system wireless transmission, is addressed using an improved adrc controller. three-axial stabilized control system model of floated inertial platform experimental system is built by matlab/simulink. simulations indicate that the adrc controller is better than the traditional pid controller. this controller can stabilize the platform more quickly, more accurately, more robustly and without overshoot. improved smith predicting adrc controller can eliminate the influence of transmission time delay of the system to realize the stability control real-timely. by virtue of this improved controller, this platform can provide an effective inertial reference for the vehicle.
operating_systems	as one of the most developed intelligent operating systems on mobile devices, android has taken the most part of the cell phone market. a rapid increase in the number of mobile applications make them more and more relevant to people 's daily lives than ever before. due to android 's security mechanism and the validation lack of publishing android apps, android malware detection still remains to be a critical issue. to solve this problem, this paper found that the statistical information of android components (mainly activity) from the manifest file cannot be ignored, based on the traditional method of android permission detection. in this paper, a new feature vector is extracted from the androidmanifest file, which combines the permission information and the component information of the android application. we combine the naive bias classification algorithm, and propose a malicious application detection method based on androidmanifest file information. the experimental results show that the new method performance better than that of the traditional permission detection.
operating_systems	the aim of this work is to propose a methodology that seeks to discover how, when and as the increased performance of the algorithms and how the configuration parameters can influence each other, and finally, discover using statistical methods which settings of virtual environment achieve the best results on average. the experimental design is a preestablished set of tests using scientific and statistical criteria mainly, in order to determine the influence of various factors on the results (metric) of a system or process, identifying and observing the reasons that led to change in the expected value. the planning that was used is factorial planning 3(4), where each factor (core, memory, operating system and virtual machine) were varied in three levels. tested operating systems were ubuntu 14.04 64bit, centos 7.0 64bit and windows 8.0 64bit; and virtual machines were tested kvm, xen and vmware. data were collected and analyzed using analysis of variance. the results show that the major analyzed factors changes the algorithm performance, but they cannot be analyzed separately because there are also significant interactions belonging to these factors. at a 5% significance level, analysis of variance showed that the core interactions: memory, memory with os, memory with vm and os with vm, all these factors impact the runtime of the analyzed algorithm.
pid_controller	a novel global pid control scheme for nonlinear mimo systems is proposed and implemented for a robot as study case, this scheme is called awfpid from its adaptive wavelet fuzzy pid control structure. basically, it identifies inverse error dynamics using a radial basis neural network with daughter rasp1 wavelets activation function; its output is in cascaded with an infinite impulse response (iir) filter to prune irrelevant signals and nodes as well as to recover a canonical form. then, online adaptive fuzzy tuning of a discrete pid regulator is proposed, whose closed-loop guarantees global regulation for nonlinear dynamical plants. the wavelet network includes a fuzzy inference system for online tuning of learning rates. a real-time experimental study on a three degrees of freedom haptic interface, the phantom premium 1.0a, highlights the regulation with smooth control effort without using the mathematical model of the robot. (c) 2015 elsevier b.v. all rights reserved.
digital_control	this paper introduces a new voltage regulator module (vrm) that merges a highly efficient switched-inductor converter as the main unit with a load-side switched-capacitor-based converter to assist during load transient events. the resulting hybrid-vrm exhibits improved dynamic performance for both loading and unloading transient events, while maintaining a compact design with reduced output capacitance and lower components stress. the hybrid controller that has been developed allows operation that is based on output voltage measurement alone, further reducing the circuit complexity. a power processing efficiency analysis that has been carried out shows efficiency improvement in favor of the hybrid-vrm when compared to time-optimal control under varying load conditions. the operation of the vrm is verified on a 20-w, 12v-to-1.5-v prototype with peak power conversion efficiency of 93%, demonstrating near-ideal transient recovery.
control_engineering	millions of workers worldwide are exposed to noise levels that increase their risk of hearing impairment. noise exposure can cause several risks for the safety and health of workers, however the condition can be prevented by preventive measures. in many countries hearing loss prevention programmes (hlpps) are mandatory, which are considered an effective means to prevent noise induced hearing loss. the awareness of the industry to keep noise control engineering programs, training programs inserted into an effective hearing conservation program is essential to protect the worker. the objective of this work is search about the effectiveness of hearing loss prevention interventions about hearing education programs, hearing protection devices and workers noise perception. this paper presents the systematic review about this topic, was reports in order to identify papers published in constant journals on databases with appropriate keywords combinations. it was conclude that studies about conservation program evaluation have been used in relatively few studies, mainly the relation with the effects of these programs on employees' health and safety.
image_processing	although recent laboratory tests are showing promising progresses in the materials and production technologies of photovoltaic (pv) devices, the commercial pv modules do not show analogous impressive improvements. therefore, a diagnostic approach, able to check the current state of health of already installed pv systems, as well as their trend of ageing, assumes a strategic importance. in this scenario, we introduce a thermography-based diagnostics able to provide a detailed, clear, and unambiguous information, thanks to a computer-aided investigation that is much deeper than the today available infrared analysis. the proposed approach allows a numerical and qualitative evaluation of each cell of the pv device. this part i-framework introduces the methodology, based on two main analyses. the first one (cell analysis) studies each single cell, while the second one (cluster analysis) focuses the attention on groups of pv cells. the framework is also characterized by a preprocessing in which the region of interest is extracted from the infrared image in order to focus the successive processing and analyses only on this area. the part ii-platform and results shows the cloud platform implementing the workflow (it automatically generates a comprehensive and detailed report), and discusses also several significant cases of study.
operating_systems	positron emission tomography (pet) images are degraded by a phenomenon known as the partial volume effect (pve). approaches have been developed to reduce pves, typically through the utilisation of structural information provided by other imaging modalities such as mri or ct. these methods, known as partial volume correction (pvc) techniques, reduce pves by compensating for the effects of the scanner resolution, thereby improving the quantitative accuracy. the petpvc toolbox described in this paper comprises a suite of methods, both classic and more recent approaches, for the purposes of applying pvc to pet data. eight core pvc techniques are available. these core methods can be combined to create a total of 22 different pvc techniques. simulated brain pet data are used to demonstrate the utility of toolbox in idealised conditions, the effects of applying pvc with mismatched point-spread function (psf) estimates and the potential of novel hybrid pvc methods to improve the quantification of lesions. all anatomy-based pvc techniques achieve complete recovery of the pet signal in cortical grey matter (gm) when performed in idealised conditions. applying deconvolution-based approaches results in incomplete recovery due to premature termination of the iterative process. pvc techniques are sensitive to psf mismatch, causing a bias of up to 16.7% in gm recovery when overestimating the psf by 3 mm. the recovery of both gm and a simulated lesion was improved by combining two pvc techniques together. the petpvc toolbox has been written in c++, supports windows, mac and linux operating systems, is open-source and publicly available.
computer_vision	the ability to present effectively is essential for professionals; therefore, oral communication courses have become part of the curricula for higher education studies. however, speaking in public is still a challenge for many graduates. to tackle this problem, driven by the recent advances in computer vision techniques and prosody analysis, multimodal tools have been designed to support the development of public speaking skills. one of these tools is the presentation trainer, a research prototype able to provide learners with real-time feedback on a set of nonverbal communication aspects. despite initial positive evaluations, the application still lacks grounding in a valid assessment model for nonverbal communication aspects in the context of presentations. to come up with such a model, we conducted semi-structured interviews with experts in the public speaking domain. furthermore, the objective of these interviews was also to have a formative evaluation of the presentation trainer, analysing how it suits with common practices for teaching and learning public speaking skills. the results of this study identify 131 nonverbal communication practices that affect the quality of a presentation and summarize experts' points of view regarding multimodal public speaker instructors.
data_structures	a gradient-statistic-based diagnostic measure is developed in the context of the generalized linear mixed models. its performance is assessed by some real examples and simulation studies, in terms of ability in detecting influential data structures and of concordance with the most used influence measures.
symbolic_computation	in order to monitor carbon monoxide in industrial production, we developed a passive gas radiation measurement system based on fourier transform infrared spectroscopy and carried out infrared radiation measurement experiment of carbon monoxide detection in simulated industrial production environment by this system. the principle, condition, device and data processing method of the experiment are introduced in this paper. in order to solve the problem of light path jitter in the actual industrial field, we simulated the noise in the industrial environment. we combine the advantages of mathematica software in the aspects of graph processing and symbolic computation to data processing to improve the signal noise ratio and noise suppression. based on the hitran database, the nonlinear least square fitting method was used to calculate the concentration of the co spectra before and after the data processing. by comparing the calculated concentration, the data processed by mathematica is reliable and necessary in the industrial production environment.
digital_control	while digital control has achieved success in various power electronic applications, data conversion remains a primary challenge and limitation compared to conventional analog methods. in particular, tradeoffs among resolution, switching frequency, and power consumption of digital pulse-width modulation (dpwm) blocks limit performance, particularly in high conversion-ratio applications. analog-digital conversion is also challenging when line-voltage feedforward techniques are applied as it requires high speed, accuracy, and in some cases exposure to voltages exceeding the rating of deep-submicron cmos technologies. this work explores tradeoffs in power consumption of counter/delay-line dpwm circuits, implemented in cmos, and derives an optimization method to segment the bit allocation among the counter and delay line components. a method for line-voltage feedforward is also presented that can instrument and quantize transients on the supply voltage without direct exposure of low voltage devices to the supply. an automotive 48v:7v application is considered.
signal-flow_graph	star-delta transformations are popular in electrical engineering. of late they have also been tried in reliability analysis. techniques are presented here to transform a star (delta) to a delta (star) in a signal flow graph. this allows us to simplify some non-series-parallel graphs using a series parallel framework. unlike the case of electrical circuits, these transformations are not always possible. it is shown that a star-to-delta transformation is always possible. but a delta can be transformed into a star if and only if a certain loop condition is satisfied. an important advantage of these techniques is that they can be used even when there are directed loops, whereas this is not the case with standard series parallel techniques.
relational_databases	the physical design of data storage is a critical administrative factor for optimizing system performance. improved system performance can be achieved by building indices. it must be noted that, although indices can improve system performance, creating many random indices may have a negative impact on system performance, and result in wasted space. selecting indices properly is a fundamental aspect of system design optimization, but it is often a complex task. index-selection optimization techniques have been widely studied in database management system (dbmss). however, they have not been get the same study in mapreduce relational-databases. this paper focuses on the index-selection process in hadoop-database hybrid systems. the main contribution is the utilization of data mining techniques to develop a tool for determining optimal index-set configurations. an overall evaluation shows that the index configurations recommended by the developed tool achieved an average performance gain of up to 48% in total analytical tasks performed.
electrical_network	distribution systems are naturally unbalanced as a consequence of unbalanced loads and the electrical network itself, where the use of single-phase or two-phase sections is not uncommon. in addition, a detailed representation of a typical distribution system can have tens of thousands of nodes, depending on the area selected for study and whether a three-phase representation is employed. this contrasts with transmission systems, where typical sizes in terms of number of nodes are much smaller and where a balanced (single-phase) representation is sufficient in most situations. thus, transmission and distribution systems have traditionally been studied separately, but this approach is becoming increasingly inadequate for various reasons. this paper then proposes a methodology that integrates transmission and distribution systems into a common electrical model. at the core of the methodology there are 1) single-and three-phase models for each component (branches, transformers, loads, etc.) and 2) interchangeable balanced and unbalanced network equivalents that allow for analyzing specific areas of a given complete network. potential gains brought about by the proposed methodology are illustrated through its application in a real-world electric system.
analog_signal_processing	the thermo-acoustic generators offer a unique means of converting thermal energy into mechanical energy without any moving parts and without fluid circulation. they are comparable to the stirling engine with the advantage of much greater simplicity. they are therefore natural candidates for special uses where interventions are limited. the problem to solve is transforming the mechanical energy into electrical energy. mhd generators offer excellent opportunities in this area, particularly by using the mechanisms of induction. the work concerns the combination of a thermo-acoustic generator with an induction generator of a new concept for obtaining electric current with adjustable voltage and current strength, delivered at the thermo-acoustic wave frequency. the system has been subjected to numerical simulation. however, an experimental program is being studied in collaboration with industrial and academic partners. the exploitation of the process by using a solar collector (parabolic or cylindrically-parabolic) is envisaged with the aim to produce electricity, for example, in isolate villages (c) 2010 published by elsevier ltd. selection and/or peer-review under responsibility of [name organizer]
relational_databases	this paper proposes a novel approach for building a natural language interface to a relational database (nli-rdb) using conversational agent (ca), information extraction (ie) and object relational mapping (orm) framework. the ca will help in disambiguating the user 's queries and guiding the user interaction. ie will play an important role in named entities extraction in order to map natural language queries into database queries. the orm framework i.e. the hibernate framework resolves the impedance mismatch between the object oriented paradigms (oop) and relational databases (rdbs) i.e. oop concepts differ from rdb concepts, thus it reduces the complexity in generating sql statements. also, by utilizing orm framework, the rdbs entities are mapped into real world objects, which bring the rdbs a step closer to the user. in addition, the orm framework simplify the interaction between oop and rdbs. the developed nli-rdb system allows the user to interact with objects directly in natural language and through navigation, rather than by using sql statements. this direct interaction tends to be easier and more acceptable for humans whom are nor technically orientated and have no sql knowledge. the nli-rdb system also offers friendly and interactive user interface in order to refine the query generated automatically. the nli-rdb system has been evaluated by a group of participants through a combination of qualitative and quantitative measures. the experimental results show good performance of the prototype and excellent user 's satisfaction.
operating_systems	this paper develops an internet-of-things data highway embracing end sensors, sensor nodes, databases, big data processors, web connections, and high-end statistics engines. it is aiming at automatic, pseudo real-time, and integrative sensor stream processing, fully benefitting from the capability of sophisticated statistics packages supporting a variety of artificial intelligence and data mining libraries. specifically, raspberry pi nodes capture signals from attached sensors via gpio interfaces and insert into a remote mysql database table using its connector utility. in the linux machine, the table entry is purged at each fixed time and dumped to a text file for a later batch analysis using hadoop. the r package running in a windows pc periodically downloads the sensor stream from the database table via the implementation of a library extension invoking relevant operating systems calls. in the r space, even a spatial analysis and visualization can be provided comprehensively.
symbolic_computation	the main aim is to present recent developments in applications of symbolic computing in probabilistic and stochastic analysis, and this is done using the example of the well-known maple system. the key theoretical methods discussed are (i) analytical derivations, (ii) the classical monte-carlo simulation approach, (iii) the stochastic perturbation technique, as well as (iv) some semi-analytical approaches. it is demonstrated in particular how to engage the basic symbolic tools implemented in any system to derive the basic equations for the stochastic perturbation technique and how to make an efficient implementation of the semi-analytical methods using an automatic differentiation and integration provided by the computer algebra program itself. the second important illustration is probabilistic extension of the finite element and finite difference methods coded in maple, showing how to solve boundary value problems with random parameters in the environment of symbolic computing. the response function method belongs to the third group, where interference of classical deterministic software with the non-linear fitting numerical techniques available in various symbolic environments is displayed. we recover in this context the probabilistic structural response in engineering systems and show how to solve partial differential equations including gaussian randomness in their coefficients.
relational_databases	this paper describes the design and implementation of a tool to extract the imdb dataset files and import them into a database. this approach differs from other published tools or research in that the previous work used relational databases. this tool uses document oriented data structures, and allows others to augment the code to change structures based on their needs. the project development required the use of technologies currently in demand for web developers and software engineers, which allows other developers to fork a copy of the work and utilize in their own work. in addition, it provided the project team an opportunity to develop additional marketable skills. finally, a web interface to perform queries against the import data to validate the import process was also developed. these queries include searching by people 's names, searching by movie/tv titles, or viewing specific data on an individual person or movie/tv title..
cryptography	dramatic technology progress in data manipulation induced several attempts of baleful and illegal processing. in this regard, several protection techniques, including cryptography, steganography, and watermarking have been used to avoid the illegal production and distribution of data online. on the other side, the attacks are still a major problem that limits the effectiveness of watermarking techniques. the geometric attacks involve displacement of pixels. therefore, they induce synchronization errors between the original and attacked image that complicates the watermark recovery process. so in order to solve the de-synchronization problem, we propose to use a robust meshing technique between different geometrical data of the image to correct the geometric distortion. in this work, we propose a novel geometrically invariant digital image watermarking approach based on the geometrical feature of the cover image and the defragmented delaunay triangulation on respecting the three constraints of watermarking approaches (imperceptibility of embedded watermark, embedding capacity, and robustness). the aim idea of this work is to propose a blind, imperceptible, and robust digital image watermarking scheme based on defragmented delaunay tessellation and weber 's law. the defragmented triangulation provides a best synchronization of the embedded data after attacks application. the weber 's law is used to propose an auto-thresholding algorithm to compute the optimal embedding gain factor for each watermark 's bit in order to ensure the imperceptibility of the hidden data. firstly, the invariant features in the host gray scale image are extracted by using the canny edge detector. then, the delaunay tessellation of the saved keys points set is generated and defragmented to select the optimal robust triangles for watermark embedding. simulation results illustrate the imperceptibility of the embedded data and the robustness of the proposed approach against intentional and unintentional geometrical attacks are presented in the finally section. copyright (c) 2017 john wiley & sons, ltd.
microcontroller	monitoring vital signs, which include breathing, is often used both in clinical practice and at home. the paper presents a novel low power system that can be used to control breathing frequency and detect apnea, which uses a condenser-type humidity sensor supplied with input bias current of an operational amplifier. the new configuration of the sensor, which compensates for the amplifier saturation state during the exhalation phase, increases breath detection effectiveness. the presented system is energy efficient, consumes approx. 50 mu a and operates over a wide range of supply voltages, 1.8 divided by 18 v dc. it enables to detect even very weak breathing. the concept of the integrated system has also been presented. this system can work directly with digital circuits without converting the electric signal. the presented system is characterized by a very simple construction and offers a new solution both in the field of sensor technology and for the use of operational amplifiers. (c) 2016 elsevier b.v. all rights reserved.
control_engineering	absolute stability attracted much attention in the 1960s. several stability conditions for loops with slope restricted nonlinearities were developed. results such as the circle criterion and the popov criterion form part of the core curriculum for students of control. moreover, the equivalence of results obtained by different techniques, specifically lyapunov and popov 's stability theories, led to one of the most important results in control engineering: the kyp lemma. for luryel systems this work culminated in the class of multipliers proposed by o'shea in 1966 and formalized by zames and falb in 1968. the superiority of this class was quickly and widely accepted. nevertheless the result was ahead of its time as graphical techniques were preferred in the absence of readily available computer optimization. its first systematic use as a stability criterion came 20 years after the initial proposal of the class. a further 20 years have been required to develop a proper understanding of the different techniques that can be used. in this long gestation some significant knowledge has been overlooked or forgotten. most significantly, o'shea 's contribution and insight is no longer acknowledged; his papers are barely cited despite his original parameterization of the class. this tutorial paper aims to provide a clear and comprehensive introduction to the topic from a user 's viewpoint. we review the main results: the stability theory, the properties of the multipliers (including their phase properties, phase-equivalence results and the issues associated with causality), and convex searches. for clarity of exposition we restrict our attention to continuous time multipliers for single-input single-output results. nevertheless we include several recent significant developments by the authors and others. we illustrate all these topics using an example proposed by o'shea himself. (c) 2015 european control association. published by elsevier ltd. all rights reserved.
image_processing	a suitable piece of software is presented to connect abaqus, a sophisticated finite element package, with matlab, the most comprehensive program for mathematical analysis. this interface between these well-known codes not only benefits from the image processing and the integrated graph-plotting features of matlab but also opens up new opportunities in results post-processing, statistical analysis and mathematical optimization, among many other possibilities. the software architecture and usage are appropriately described and two problems of particular engineering significance are addressed to demonstrate its capabilities. firstly, the software is employed to assess cleavage fracture through a novel 3-paranieter weibull probabilistic framework. then, its potential to create and train neural networks is used to identify damage parameters through a hybrid experimental-numerical scheme, and model crack propagation in structural materials by means of a cohesive zone approach. the source code, detailed documentation and a large number of tutorials can be freely downloaded from www.abaqus2matlab.com. (c) 2017 elsevier ltd. all rights reserved.
analog_signal_processing	a novel topology suitable for emulating fractional-order capacitors and inductors using current excitation is achieved using a fractional-order differentiator/integrator block and appropriately configured operational transconductance amplifiers. the scheme is capable of emulating both fractional-order capacitors and fractional-order inductors without any modifications to its structure. this implementation allows for electronic tuning of the order, capacitance/inductance, and bandwidth of operation by modification of only the bias current. post-layout simulation results of the impedance magnitude and phase confirm the correct emulated behavior of both fractional-order capacitors and inductors. two examples highlight the applications of this topology in i) realizing a fractional-order bandpass filter and ii) emulating a cole impedance model for biological applications. for both examples the characteristics of each circuit are validated in simulation. (c) 2016 elsevier ltd. all rights reserved.
state_space_representation	this note addresses parameterization issues of nonlinear observer-based fault detection (fd) systems which are composed of a residual generator, a residual evaluator and a threshold. our study consists of two steps. in the first step, with the aid of nonlinear factorization and input-output operator techniques, we prove that any stable residual generator can be parameterized by a cascade connection of the process kernel representation and a post-filter that represents the parameter system. in the second step, based on the state-space representation of the parameterized residual generators, we investigate the so-called l-infinity- and l-2-classes of observer-based fd systems. this leads to the parameterization of the threshold settings for both classes of fd systems and, associated with them, to the characterization of the existence conditions.
bioinformatics	accumulating evidence suggests that ribosomal proteins may have extraribosomal functions in various physiological and pathological processes, including cancer. we analyzed the expression of the cirh1a ribosomal protein in colorectal carcinoma and para-carcinoma samples by bioinformatics analyses of data extracted from the cancer genome atlas and in colorectal cancer cell lines in vitro by qpcr. cirh1a was highly expressed in carcinoma samples and colorectal cancer cells. we also transduced the rko colorectal cancer (crc) cell line with lentivirus-mediated small interfering rnas (sirnas) and studied the impact that this knockdown of cirh1a expression had on cell growth. rna interference (rnai)-mediated inhibition of cirh1a expression significantly suppressed proliferation and increased apoptosis of transduced cells, and tended to arrest them in g(1) phase. our data suggest that cirh1a plays a critical role in the proliferation, cell cycle distribution, and apoptosis of human malignant colorectal cells, and might therefore be a potential target for therapeutic strategies.
algorithm_design	the rapid increase of information and accessibility in recent years has activated a paradigm shift in algorithm design for artificial intelligence. recently, deep learning (a surrogate of machine learning) have won several contests in pattern recognition and machine learning. this review comprehensively summarises relevant studies, much of it from prior state-of-the-art techniques. this paper also discusses the motivations and principles regarding learning algorithms for deep architectures.
digital_control	the development of a non-human primate (nhp) model of spinal cord injury (sci) based on mechanical and computational modeling is described. we scaled up from a rodent model to a larger primate model using a highly controllable, friction-free, electronically-driven actuator to generate unilateral c6-c7 spinal cord injuries. graded contusion lesions with varying degrees of functional recovery, depending upon pre-set impact parameters, were produced in nine nhps. protocols and pre-operative magnetic resonance imaging (mri) were used to optimize the predictability of outcomes by matching impact protocols to the size of each animal 's spinal canal, cord, and cerebrospinal fluid space. post-operative mri confirmed lesion placement and provided information on lesion volume and spread for comparison with histological measures. we evaluated the relationships between impact parameters, lesion measures, and behavioral outcomes, and confirmed that these relationships were consistent with our previous studies in the rat. in addition to providing multiple univariate outcome measures, we also developed an integrated outcome metric describing the multivariate cervical sci syndrome. impacts at the higher ranges of peak force produced highly lateralized and enduring deficits in multiple measures of forelimb and hand function, while lower energy impacts produced early weakness followed by substantial recovery but enduring deficits in fine digital control (e.g., pincer grasp). this model provides a clinically relevant system in which to evaluate the safety and, potentially, the efficacy of candidate translational therapies.
control_engineering	with the direction of the study outcomes and job requirements for postgraduate students, outcome-based education is implemented in the curriculum group design and application for control engineering discipline in wuhan university of science and technology, which is based on the demand analysis of master of full-time professional degree. combined with the demand of society and enterprises, the system structure of the curriculum group pays more emphasis on the practical ability of student, and it is driven by the students' final study outcome. the curriculum group for control engineering discipline has three blocks: basic curriculums, core curriculums and expanding curriculums and the educational quality is evaluated by the variety of student outcomes.
analog_signal_processing	this paper proposes a spiral-shaped dispersive delay structure (spiral-dds) composed of vertically stacked spiral coils and vertical vias. this all-pass network architecture can produce a large group delay peak at a certain frequency in a few ghz range. basic performance of the spiral-dds are studied theoretically, and the group delay with more than 6 ns was successfully generated by a compact multilayered architecture with dimensions of 6.0 x 6.0 x 1.18 mm (3). this paper also reports that the most of losses occurred in dds comes from conductor loss, not from dielectric loss.
electrical_circuits	the paper deals with a technique for the simulation of higher-order electrical circuits with parameters varying randomly. the principle consists in the utilization of the theory of stochastic differential equations (sde), namely the vector form of the ordinary sdes. random changes of both excitation voltage and some parameters of passive circuit elements are considered, and circuit responses are analyzed. the voltage and/or current responses are computed and represented in the form of the sample means accompanied by their confidence intervals to provide reliable estimates. the method is applied to analyze responses of the circuit models of optional orders, specially those consisting of a cascade connection of the rlgc networks. to develop the model equations the state-variable method is used, afterwards a corresponding vector sde is formulated and a stochastic euler numerical method applied. to verify the results the deterministic responses are also computed by the help of the pspice simulator or the numerical inverse laplace transforms (nilt) procedure in matlab (r), while removing random terms from the circuit model.
analog_signal_processing	the majority of wind turbines currently in operation have the conventional danish concept design-that is, the three-bladed rotor of such turbines is indirectly coupled with an electrical generator via a gearbox. recent technological developments have enabled direct drive wind turbines to become economically feasible. potentially, direct drive wind turbines may enjoy higher levels of availability due to the removal of the gearbox from the design. however, this is only a theory: so far not substantiated by detailed analytic calculation. by providing such a calculation, this paper enables us to quantitatively evaluate technical and economic merits of direct drive and gearbox-driven wind turbines.
pid_controller	a control method for improving tracking performance with respect to a reference trajectory has been developed. the proposed control system has an inner/outer control structure. the inner control system is the existing control system based on a conventional pid controller, which is designed in advance and is independent of the outer control system. in order to improve tracking performance, the outer control system is designed based on optimal preview control theory and is added to the outside of the inner control system. a polynomial trajectory is used as the reference trajectory and is fed to the outer control system. the reference trajectory is modified online to minimize tracking error. the modified reference trajectory is derived as a control input signal from the outer control system and is fed to the inner control system. the effectiveness of the proposed control method is confirmed using numerical simulations in a benchmark problem for hard disk drives (hdds).
operating_systems	in this paper, we introduce software asset analyzer (saa), a system that monitors and detects potentially vulnerable software asset modifications in end devices, and can be used to guide patch management. software patching is a complex and failure-prone process that, on enterprise networks, requires triage. accurate inventories of software (applications and operating systems) improve patching efficiency, which is a significant concern for security analysts. by generating asset baselines, the saa identifies and reports abnormal deviations in individual end-devices, which allows security analysts to identify vulnerable devices and further enforce security patching. this system is also suited for detecting vulnerable software installs and remediation process verification. saa is a low-cost and efficient method that yields accurate and complete inventories of assets on end-devices, reducing the potential loss from new vulnerabilities.
pid_controller	being complex, non-linear and coupled system, the robotic manipulator cannot be effectively controlled using classical proportional-integral-derivative (pid) controller. to enhance the effectiveness of the conventional pid controller for the nonlinear and uncertain systems, gains of the pid controller should be conservatively tuned and should adapt to the process parameter variations. in this work, a mix locally recurrent neural network (mlrnn) architecture is investigated to mimic a conventional pid controller which consists of at most three hidden nodes which act as proportional, integral and derivative node. the gains of the mix locally recurrent neural network based pid (mlrnnpid) controller scheme are initialized with a newly developed cuckoo search algorithm (csa) based optimization method rather than assuming randomly. a sequential learning based least square algorithm is then investigated for the online adaptation of the gains of mlrnnpid controller. the performance of the proposed controller scheme is tested against the plant parameters uncertainties and external disturbances for both links of the two link robotic manipulator with variable payload (tl-rmwvp). the stability of the proposed controller is analyzed using lyapunov stability criteria. a performance comparison is carried out among mlrnnpid controller, csa optimized nnpid (optnnpid) controller and csa optimized conventional pid (optpid) controller in order to establish the effectiveness of the mlrnnpid controller. (c) 2016 isa. published by elsevier ltd. all rights reserved.
data_structures	we present a technique for representing bounded-degree planar graphs in a succinct fashion while permitting i/o-efficient traversal of paths. using our representation, a graph with n vertices, (in this paper denotes ) each with an associated key of bits, can be stored in bits and traversing a path of length k takes i/os, where b denotes the disk block size. by applying our construction to the dual of a terrain represented as a triangular irregular network, we can represent the terrain in the above space bounds and support path traversals on the terrain using i/os, where k is the number of triangles visited by the path. this is useful for answering a number of queries on the terrain, such as reporting terrain profiles, trickle paths, and connected components.
cryptography	storing and retrieving data in cloud are important in today 's environment. it also adds insecurity as data sharing in cloud would be affected by hacking or modifying the original content of the data. for secure data transmission, encryption and decryption are the most followed methods. this existing method demands the authentication, security keys from a third party cannot be considered safe because the entire network becomes questionable when such party is not trustworthy. this paper proposes a method, where encrypting the public keys and decrypting the private keys would be generated from cloud node itself, not by a separate trusted authority. this paper also uses the attribute real-time parameters taken for building security keys for each requesting nodes in time dependent manner. since attributes are real-time parameters and changes on random deployment add to security to the contributing nodes. furthermore, some parameters like busy state help to route data and ensure good packet delivery and client data storage.
computer_programming	in this note, we present a novel approach in using visual programming languages and in treating specific language impairments (sli). starting from the characteristics of sli, in particular of syntactic impairment, and from the need to develop metalinguistic awareness, assuming that the latest researches in computer programming assessing it as a language are right, we show the theoretical possibility to treat linguistic impairments, for what concerns linguistic and social difficulties, through the use of visual programming, in particular of scratch. this study does not have an application in the field yet, but we believe in the importance of sharing these ideas.
data_structures	conventional multilevel modeling works well with purely hierarchical data; however, pure hierarchies rarely exist in real datasets. applied researchers employ ad hoc procedures to create purely hierarchical data. for example, applied educational researchers either delete mobile participants' data from the analysis or identify the student only with the last school attended while including an explanatory variable indicating whether a student is mobile. this simulation study compared the parameter and standard error estimates of these two ad hoc procedures for handling and assessing the influence of mobility on outcomes with results based on use of the multiple membership random effects model. substantial bias was found for some parameters when multiple membership data structures were ignored.
data_structures	multiversion databases store both current and historical data. rows are typically annotated with timestamps representing the period when the row is/was valid. we develop novel techniques to reduce index maintenance in multiversion databases, so that indexes can be used effectively for analytical queries over current data without being a heavy burden on transaction throughput. to achieve this end, we re-design persistent index data structures in the storage hierarchy to employ an extra level of indirection. the indirection level is stored on solid-state disks that can support very fast random i/os, so that traversing the extra level of indirection incurs a relatively small overhead. the extra level of indirection dramatically reduces the number of magnetic disk i/os that are needed for index updates and localizes maintenance to indexes on updated attributes. additionally, we batch insertions within the indirection layer in order to reduce physical disk i/os for indexing new records. in this work, we further exploit ssds by introducing novel deltablock techniques for storing the recent changes to data on ssds. using our deltablock, we propose an efficient method to periodically flush the recently changed data from ssds to hdds such that, on the one hand, we keep track of every change (or delta) for every record, and, on the other hand, we avoid redundantly storing the unchanged portion of updated records. by reducing the index maintenance overhead on transactions, we enable operational data stores to create more indexes to support queries. we have developed a prototype of our indirection proposal by extending the widely used generalized search tree open-source project, which is also employed in postgresql. our working implementation demonstrates that we can significantly reduce index maintenance and/or query processing cost by a factor of 3. for the insertion of new records, our novel batching technique can save up to 90 % of the insertion time. for updates, our prototype demonstrates that we can significantly reduce the database size by up to 80 % even with a modest space allocated for deltablocks on ssds.
operational_amplifier	bicmos bandgap reference (bgr) has advantage over mos based bgr in terms of its accuracy at its reference output and very less temperature coefficient (tc). this paper presents bandgap reference circuit with folded cascode operational amplifier (op-amp) in order to improve the stability of final v-ref output. the temperature stability of output can be improved by using trimming circuit in voltage mode architecture of bandgap reference operating with less power consumption. using only first order temperature compensation technique, the proposed circuit gives output voltage of 1.181v with 0 degrees c to 100 degrees c temperature variations that corresponds to tc of 19ppm/ degrees c. the output reference voltage exhibits line variations of 2.4mv/v with supply range of 1.62v to 1.98v at typical process corner. a single stage folded cascode op-amp that is included in the proposed bandgap improves the stability of output voltage in closed loop, power supply rejection ratio (psrr) of bgr and input common mode range. the proposed circuit includes start-up circuit to avoid start-up problem because of closed loop, the reference current for op-amp is generated from bgr current mirror and impact of its tc on final v-ref is negligible. the simulation results shows that psrr of proposed bgr is -43db from dc to 30khz frequency, phase margin (pm) is 70 degrees, input offset of op-amp is 1.96 mu v and closed loop gain of op-amp in bgr is 118db. the total current for overall bgr is 12 mu a and total power consumption is 18.4 mu w. the proposed bandgap reference is simulated using mentor-graphics pyxis tool, eldo-spice simulator in 130nm cmos technology. the proposed bgr output is used in low-drop-out (ldo) regulator circuit that is operating at 3.3v supply and gives regulated output of 1.8v.
image_processing	generalized linear image processing systems have been developed from physical image formation models, human visual perception models, and mathematical models. although there have been many papers on the extension, parameterization, and symmetrization of some of these systems, what is lacking is a unified framework such that the development and study of such systems can be performed based on a common ground. in this paper, we propose a conceptual image sensor which models how the light energy is converted into the sensor data. in the proposed sensor model, the input energy is regarded as a random variable and the conversion is through the cumulative distribution function. based on the sensor model, we suggest a statistical framework by which new systems can be derived, and existing and seemingly unrelated systems can be studied from a unified perspective. the proposed statistical framework not only provides a principled way to symmetrizing systems through the even extension of the probability distribution function (pdf) and a natural way for the parameterization of systems through parameters of pdf. in this paper, we demonstrate new applications of the statistical framework through a numerical approximation of the lower incomplete gamma function, through the enhancement of the dynamic range and manipulation of the sharpness of images by using the scalar multiplication operation of the parametric system, through an application of a new system in fusion of multi-exposure images, and through an application of the three new systems for the correction of incorrect exposure.
computer_graphics	despite the fact that numerous online 3d virtual worlds (3dvws) are implemented as elearning and e-training platforms, mainly in academic milieus, these environments are still employed for research purposes and not as a current practice. the present paper presents a synthetic evaluation of an experimental online multi-user 3dvw for teaching and learning computer graphics classes and discusses findings against results from an evaluation of similar activities performed on a moodle lms platform. the paper concludes on different aspects, such as the usability, pedagogical efficacy and technology acceptance, and gives recommendations for good practices in designing educational 3dvws.
signal-flow_graph	the vernier operation with signal flow graph (sfg) is a graphical approach for analyzing the intricate photonic circuits mathematically and quick calculation of optical transfer function. analysis of a cascaded microring resonators (cmrr) made of ingaasp/inp semiconductor is presented using the signal flow graph (sfg) method which enables modelling the transfer function of the passive cmrr. these passive filters are mostly characterized by their frequency response. the theoretical calculations of the system is performed by the vernier effects analysis. two mrrs with radius of 100 mu m which are vertically coupled together are used to generate resonant peaks. here, the phase, dispersion and group delay of the generated signals are analyzed.
signal-flow_graph	this paper discusses the multi-signal flow graph model and the testability analysis method based on this model. the modeling process of the multi-signal model, the dependency matrix generation method of the failure-test and the details of the testability analysis are illustrated by use of several examples. the results got in the testability analysis are also validated. it is demonstrated that the testability analysis method based on multi-signal model is easy to be implemented in computer-aided analysis, which helps to develop the testability analysis software tool in future.
relational_databases	with the ever-increasing usage of internet, the availability of digital data is in tremendous demand. in this context, it is essential to protect the ownership of the data and to be able to find the guilty user. in this paper, a fingerprinting scheme is proposed to provide protection for numeric relational database (rdb), which focuses on challenges like: 1. minimum distortion in numeric database, 2. usability preservation, 3. non-violation of the requirement of blind decoding. when the digital data in concern is numeric in nature the usability of data needs to be keenly preserved, this is made possible by achieving minimum distortion.
state_space_representation	herein, a study on the hydrodynamic modelling of pontoon bridges is presented, with the bergsoysund bridge as a representative example. the model relies on the finite element method and linearized potential theory. the primary emphasis is placed on the stochastic response analysis within the framework of the power spectral density method. the quadratic eigenvalue problem is solved using a state-space representation and an iterative algorithm. the contribution of the fluid structure interaction to the overall modal damping is investigated. response effects due to changes in the sea state are studied. a frequency independent approximation of the hydrodynamic coefficients is presented and discussed. (c) 2016 elsevier ltd. all rights reserved.
computer_graphics	one of the methods for obtaining the curve and the surface of complex shape in the engineering geometry, computer graphics, including area of computer vision multi-view geometry, multi-view stereo reconstruction is chaikin algorithm, suggested in 1974. unfortunately, the algorithm works with broken lines so at each step we get a continuous, but not a smooth curve or surface. the current article (paper, work) aims to generalize known in engineering geometry chaikin algorithm for modeling of curves and surfaces of arbitrary smoothness class. we have proved that chaikin 's algorithm is a special case of the wavelet recovery of b-spline curve, or b-spline surface smoothness of class c-1. using a filterbank constructed on the basis of b-splines of arbitrary order for spline wavelets, we suggested a generalization of the chaikin algorithm for modeling of curves and surfaces of arbitrary smoothness class. the generalized chaikin algorithm proposed is a set of theoretical tools for computer-aided design, computer vision systems.
computer_programming	the courses of computer programming language are important basic specialty courses for majors of science and technology in universities. these courses are often both highly abstract and practical, and many works involved in the teaching process are worth exploring and researching. focusing on teaching methods of "" c++ programming language"" course, this paper presents our ideas and practice in performing teaching work in the course. in the paper, we discusses some important works in different teaching links, including textbook selection, courseware preparation, classroom teaching, practical ability training. our practice has proved that, by adopting appropriate teaching methods to adapt to the actual situation in the teaching process, the teachers can control teaching process flexibly and improve teaching effectiveness and quality.
system_identification	recently, online input selection has gained an increasing attention in evolving fuzzy models. in this paper, we proposed a new evolving fuzzy system referred to as evolving heterogeneous fuzzy inference system (ehfis), which can simultaneously perform local input selection and system identification in an evolving and integrative manner. the introduced ehfis is structured by some fuzzy rules with different effective input variables. this was achieved through inclusion of some parameters (local input selectors) in the structure of the takagi-sugeno system. an online learning algorithm is proposed to identify the ehfis, where 1) the premise parameter learning and rule evolution take place with the usage of an incremental and evolving clustering for partitioning the data space; 2) a local input selection strategy based on switching to a neighboring model is adopted, and then, all fuzzy rules with the same input structure form a new category; and 3) for each category, the parameters of linear models, in consequent parts, are updated by weighted recursive fuzzily weighted least-squares estimator. the performance of the proposed ehfis is evaluated and compared through several simulations on hand made as well as real-life datasets.
operational_amplifier	the input offset voltage is a quit important performance parameter for operational amplifiers, and the low frequency l/f noise has a great effect on the offset voltage. in this paper, chopping technology which is an efficient approach to decrease the l/f noise and offset voltage of cmos amplifiers is adopted. in the low pass filter, the multiplier composed of r and c is used to filter out the modulation noise. the circuit of the presented chopper amplifier is designed and simulated with 45nm cmos process and a 1v supply. simulated results show that the total harmonic distortion of chopper amplifier is 54.1db and the chopper frequency is 10 khz. the input referred noise is 2.54 nv/root hz @1khz, and the average power consumption is 65.5 mu w. the proposed technology has a pleasurable preference.
operating_systems	in this paper, we introduce the analysis and the design of a new web-based interactive software tool, called webubu, which has been developed to serve the undergraduate students' needs related to linux operating system (os) issues. the aim of this software development was twofold: on the one hand to familiarize students with ubuntu os environment and, on the other hand to promote the self-learning related to this linux distribution, in the context of everyday os classrooms. wbubu software can be used only for interactive demonstration of features of linux during lectures and to support instructors for evaluation of students' skills in the lab. for other tasks such as long term studying of linux-based os 's physical' linux must be used. our software is essentially a website that simulates ubuntu operating system inside a web browser. undergraduate students can easily explore both graphical user interface (gui) and command line of ubuntu 's environment. additionally, students can ascertain the acquired knowledge through an automated examination process and learn from their mistakes as they shown automatically by the software in real time. educator can manage students' performances that are stored in a database system and assess the individual 's cognitive progress resulting from the software contribution. however, webubu will give students the chance for practice and self assessment when they not involved in the university 's educational process or physical' linux is unavailable. that software intends to complement the existing teaching and learning methods concerning operating systems. (c) 2015 wiley periodicals, inc.
computer_vision	object detection is one of the most important tasks of computer vision. it is usually performed by evaluating a subset of the possible locations of an image, that are more likely to contain the object of interest. exhaustive approaches have now been superseded by object proposal methods. the interplay of detectors and proposal algorithms has not been fully analyzed and exploited up to now, although this is a very relevant problem for object detection in video sequences. we propose to connect, in a closed-loop, detectors and object proposal generator functions exploiting the ordered and continuous nature of video sequences. different from tracking we only require a previous frame to improve both proposal and detection: no prediction based on local motion is performed, thus avoiding tracking errors. we obtain three to four points of improvement in map and a detection time that is lower than faster regions with cnn features (r-cnn), which is the fastest convolutional neural network (cnn) based generic object detector known at the moment.
electricity	this study investigated the effect of carbon fibers as brush anode materials on the performance of microbial fuel cells (mfcs). two types of carbon fibers with different electrical resistivity and functionality polyacrylonitrile (pan) (rho: 28.0 mu omega m) and pitch (rho: 2.05 mu omega m) were investigated. x-ray photoelectron spectroscopy analysis showed that the pan- and pitch-based carbon fibers presented almost the same surface elements and functional groups, and there was no significant difference in microbial growth on the brush anodes. current interrupt and steady discharging methods demonstrated the pitch-based carbon brush anodes had lower ohmic resistance and generated higher power density. after nitric acid treatment, the power density generated by the pan- and pitch-based anodes increased by 29.3% and 26.7%, achieving 816 and 895 mw m(-2), respectively. using pitch-based carbon fiber brush as anode attained better performance than the widely used pan-based carbon brush. the acid treated pitch-based carbon fibers provide a promising alternative to highly efficient anode materials for the extensive application of mfcs. (c) 2017 elsevier b.v. all rights reserved.
signal-flow_graph	in this paper, we present an efficient algorithm for computing the 2-d discrete cosine transform (dct). first, we arrange the input data matrix in a certain order. second, we formulate the output data matrix to a block-structured matrix-vector multiplication, and show that the block-structured matrix has the same properties as the 1-d dct kernel matrix. therefore, the 2-d dct problem is reduced to the 1-d dct problem. we thus can provide a procedure for computing the 2-d dct which is similar to that of the 1-d dct. the primary appeal of this algorithm lies not only in its low computational cost but also in its regular structure as the transform size increases.
cryptography	non-malleable codes, defined by dziembowski, pietrzak, and wichs (ics '10), provide roughly the following guarantee: if a codeword c encoding some message x is tampered to c' = f (c) such that c' not equal c, then the tampered message x' contained in c' reveals no information about x. the nonmalleable codes have applications to immunizing cryptosystems against tampering attacks and related -key attacks. one cannot have an efficient non-malleable code that protects against all efficient tampering functions f. however, in this paper we show ""the next best thing"": for any polynomial bound s given a -priori, there is an efficient non-malleable code that protects against all tampering functions f computable by a circuit of size s. more generally, for any family of tampering functions of size vertical bar f vertical bar <= 2(s), there is an efficient non-malleable code that protects against all f is an element of f. the rate of our codes, defined as the ratio of message to codeword size, approaches 1. our results are information -theoretic and our main proof technique relies on a careful probabilistic method argument using limited independence. as a result, we get an efficiently samplable family of efficient codes, such that a random member of the family is non-malleable with overwhelming probability. alternatively, we can view the result as providing an efficient non-malleable code in the ""common reference string"" model. we also introduce a new notion of non-malleable key derivation, which uses randomness x to derive a secret key y = h(x) in such a way that, even if x is tampered to a different value x' = f (x), the derived key y' = h(x') does not reveal any information about y. our results for non-malleable key derivation are analogous to those for non-malleable codes. as a useful tool in our analysis, we rely on the notion of ""leakage -resilient storage"" of davi, dziembowski, and venturi (scn '10), and, as a result of independent interest, we also significantly improve on the parameters of such schemes.
parallel_computing	this work focuses on the development of a multiscale computational fluid dynamics (cfd) simulation framework with application to plasma-enhanced chemical vapor deposition of thin film solar cells. a macroscopic, cfd model is proposed which is capable of accurately reproducing plasma chemistry and transport phenomena within a 2d axisymmetric reactor geometry. additionally, the complex interactions that take place on the surface of a-si: h thin films are coupled with the cfd simulation using a novel kinetic monte carlo scheme which describes the thin film growth, leading to a multiscale cfd model. due to the significant computational challenges imposed by this multiscale cfd model, a parallel computation strategy is presented which allows for reduced processing time via the discretization of both the gas-phase mesh and microscopic thin film growth processes. finally, the multiscale cfd model has been applied to the pecvd process at industrially relevant operating conditions revealing non-uniformities greater than 20% in the growth rate of amorphous silicon films across the radius of the wafer.
computer_vision	this article addresses the problem of creating interactive mixed reality applications where virtual objects interact in images of real world scenarios. this is relevant to create games and architectural or space planning applications that interact with visual elements in the images such as walls, floors and empty spaces. these scenarios are intended to be captured by the users with regular cameras or using previously taken photographs. introducing virtual objects in photographs presents several challenges, such as pose estimation and the creation of a visually correct interaction between virtual objects and the boundaries of the scene. the two main research questions addressed in this article include, the study of the feasibility of creating interactive augmented reality (ar) applications where virtual objects interact in a real world scenario using the image detected high-level features and, also, verifying if untrained users are capable and motivated enough to perform ar initialization steps. the proposed system detects the scene automatically from an image with additional features obtained using basic annotations from the user. this operation is significantly simple to accommodate the needs of non-expert users. the system analyzes one or more photos captured by the user and detects high-level features such as vanishing points, floor and scene orientation. using these features it will be possible to create mixed and augmented reality applications where the user interactively introduces virtual objects that blend with the picture in real time and respond to the physical environment. to validate the solution several system tests are described and compared using available external image datasets.
digital_control	with the development of science and technology and the formation of a comprehensive multidisciplinary technology. the emergence of new permanent magnetic actuator and electronic operation of synchronous technology in the field of pressure to achieve a hardware basis. in order to meet the high reliability of the vacuum circuit breaker operation, our country is in-depth study, and gradually promote and electronic control systems match the permanent mechanism. in this article, we have the key technology of digital signal processing theory research motor and motor control. experimental results show the effectiveness of the method, to better reflect the characteristics of the digital control system for digitizing motion brushless dc motor control engineering applications useful to explore and try.
relational_databases	in the article the detection of ""missing"" or ""hidden"" data during the processing of the well-defined queries to database is discussed and on terms of quality the importance is justified, the article also covers organization, processing, and program implementation issues of fuzzy queries to database of information systems. (c) 2016 the authors. published by elsevier b.v.
digital_control	this paper describes the implementation of a second order sliding mode (sosm) controller for a practical point-of-load (pol) power supply with realistic values of output capacitor equivalent series resistance (esr) and equivalent series inductance (esl). the sosm control presented in this paper results in fast transient responses, has a current limiting feature, supports light load operation, and achieves constant frequency steady state operation. experimental results are given for a 2.5 v - 5.5 v input, 0.6 v - 1.5 v output, 3 a prototype.
software_engineering	purpose - software product management (spm) unites disciplines related to product strategy, planning, development, and release. there are many organizational activities addressing technical, social, and market issues when releasing a software product. owing to the high number of activities involved, spm remains a complex discipline to adopt. the purpose of this paper is to understand what are the core and supporting spm activities. design/methodology/approach - the authors adopted the research method of meta-ethnography to present a set of techniques for synthesizing individual qualitative studies to increase the degree of conceptualization. the results obtained from three empirical studies were synthesized using the meta-ethnography approach to enhance, rethink, and create a higher level abstraction of the findings. findings - the results show that the study has both theoretical and practical contribution. as the meta-ethnography synthesis has not been widely applied in software engineering, the authors illustrate how to use this research method in the practice of software engineering research. the practical contribution of the study is in the identification of five core and six supporting spm activities. originality/value - the practical value of this paper is in the identification of core spm activities that should be present in any company practicing spm. the list of supporting spm consists of activities that are not reported to product manager but affect the product success.
electric_motor	a gearless one-motor concept for contra-rotating fans is presented in this article. the rotors are mounted to an electric motor using only one shaft. the coupling between both rotors is realised by utilising the conservation of angular momentum. the contra-rotating fans has a diameter of 200mm at a design speed of 2100min(-1) for the first stage and 1200min(-1) for the second stage. it has been designed and investigated through a series of experiments by the institute of air handling and refrigeration in dresden. the performance map and 2d particle image velocimetry measurements have been conducted. numerical models for 3d quasi-steady state and transient simulations have been implemented and carried out by the institute of mechanics and fluid dynamics. the results show a good agreement between the quasi-steady, the transient simulations and the experiment. however, when close to stall, the time-resolved simulations show a superior performance compared with steady-state computations.
machine_learning	a smart camera is a vision system capable of extracting application-specific information from the captured images. the paper proposes a decentralized and efficient solution for visual parking lot occupancy detection based on a deep convolutional neural network (cnn) specifically designed for smart cameras. this solution is compared with state-of-the-art approaches using two visual datasets: pklot, already existing in literature, and cnrparlc-ext. the former is an existing dataset, that allowed us to exhaustively compare with previous works. the latter dataset has been created in the context of this research, accumulating data across various seasons of the year, to test our approach in particularly challenging situations, exhibiting occlusions, and diverse and difficult viewpoints. this dataset is public available to the scientific community and is another contribution of our research. our experiments show that our solution outperforms and generalizes the best performing approaches on both datasets. the performance of our proposed cnn architecture on the parking lot occupancy detection task, is comparable to the well-known alexnet, which is three orders of magnitude larger. (c) 2016 elsevier ltd. all rights reserved.
software_engineering	software refactoring has been recognized as a valuable process during software development and is often aimed at repaying technical debt. technical debt arises when a software product has been built or amended without full care for structure and extensibility. refactoring is useful to keep technical debt low and if it can be automated there are obvious efficiency benefits. using a combination of automated refactoring techniques, software metrics and metaheuristic searches, an automated refactoring tool can improve the structure of a software system without affecting its functionality. in this paper, four different refactoring approaches are compared using an automated software refactoring tool. weighted sums of metrics are used to form different fitness functions that drive the search process towards certain aspects of software quality. metrics are combined to measure coupling, abstraction and inheritance and a fourth fitness function is proposed to measure reduction in technical debt. the 4 functions are compared against each other using 3 different searches on 6 different open source programs. four out of the 6 programs show a larger improvement in the technical debt function after the search based refactoring process. the results show that the technical debt function is useful for assessing improvement in quality. (c) 2016 elsevier inc. all rights reserved.
computer_graphics	recent years, the stylized draw technology is attracted eyes in non-photorealistic rendering. in this paper, a generation method of an image with chinese ink-wash effect based on blur and edge detection was provided, and implemented in programming on matlab sdk platform. using this method on the platform, a given color image could converse to the picture stylized with chinese ink-wash effect automatically for the user even who has no painting background. the experimental results proved that these methods are effective and satisfied in use, simple, and easy to operate or learn.
distributed_computing	an efficient exploitation of distributed computing infrastructures (dcis) is needed to deal with the data deluge that the scientific community is facing, in particular the astrophysics one due to the emerging square kilometre array (ska) telescope that will reach data rates in the exascale domain. hence, science gateways are being enriched with advanced tools that not only enable the scientists to build their experiments but also to optimize their adaptation to different infrastructures. in this work we present a method, called ""two-level workflow system"", to build this kind of tools and we apply it to a set of analysis tasks of interest for some use applications to the ska. this method uses the software-as-a-service model to keep the scientists insulated from technical complexity of dcis, and the compss programming model to achieve an efficient use of the computing resources.
algorithm_design	a continuous monitoring system (cms) model is presented, having new improved capabilities. the system is based on the actual real-time configuration of the system. existing risk scoring models assume damage potential is estimated by systems' owner, thus rejecting the information relying in the technological configuration. the assumption underlying this research is based on users' ability to estimate business impacts relating to systems' external interfaces which they use regularly in their business activities, but are unable to assess business impacts relating to internal technological components. according to the proposed model systems' damage potential is calculated using technical information on systems' components using a directed graph. the graph is incorporated into the common vulnerability scoring systems' (cvss) algorithm to produce risk scoring measures. framework presentation includes system design, damage potential scoring algorithm design and an illustration of scoring computations.
microcontroller	gait analysis using wearable wireless sensors can be an economical, convenient and effective way to provide diagnostic and clinical information for various health-related issues. in this work, our custom designed low-cost wireless gait analysis sensor that contains a basic inertial measurement unit (imu) was used to collect the gait data for four patients diagnosed with balance disorders and additionally three normal subjects, each performing the dynamic gait index (dgi) tests while wearing the custom wireless gait analysis sensor (wgas). the small wgas includes a tri-axial accelerometer integrated circuit (ic), two gyroscopes ics and a texas instruments (ti) msp430 microcontroller and is worn by each subject at the t4 position during the dgi tests. the raw gait data are wirelessly transmitted from the wgas to a near-by pc for real-time gait data collection and analysis. in order to perform successful classification of patients vs. normal subjects, we used several different classification algorithms, such as the back propagation artificial neural network (bp-ann), support vector machine (svm), k-nearest neighbors (knn) and binary decision trees (bdt), based on features extracted from the raw gait data of the gyroscopes and accelerometers. when the range was used as the input feature, the overall classification accuracy obtained is 100% with bp-ann, 98% with svm, 96% with knn and 94% using bdt. similar high classification accuracy results were also achieved when the standard deviation or other values were used as input features to these classifiers. these results show that gait data collected from our very low-cost wearable wireless gait sensor can effectively differentiate patients with balance disorders from normal subjects in real time using various classifiers, the success of which may eventually lead to accurate and objective diagnosis of abnormal human gaits and their underlying etiologies in the future, as more patient data are being collected.
relational_databases	order dependencies (ods) describe a relationship of order between lists of attributes in a relational table. ods can help to understand the semantics of datasets and the applications producing them. they have applications in the field of query optimization by suggesting query rewrites. also, the existence of an od in a table can provide hints on which integrity constraints are valid for the domain of the data at hand. this work is the first to describe the discovery problem for order dependencies in a principled manner by characterizing the search space, developing and proving pruning rules, and presenting the algorithm order, which finds all order dependencies in a given table. order traverses the lattice of permutations of attributes in a level-wise bottom-up manner. in a comprehensive evaluation, we show that it is efficient even for various large datasets.
analog_signal_processing	a new application-specific integrated circuit (asic), the high-speed charge-to-time converter (qtc) iwatsu clc101, provides three channels, each consisting of preamplifier, discriminator, low-pass filter, and charge integration circuitry, optimized for the waveform of a photomultiplier tube (pmt). this asic detects pmt signals using individual built-in discriminators and drives output timing signals whose width represents the integrated charge of the pmt signal. combined with external input circuits composed of passive elements, the qtc provides full analog signal processing for the detector 's pmts, ready for further processing by time-to-digital converters (tdcs). high-rate ( >1 mhz) signal processing is achieved by short-charge-conversion-time and baseline-restoration circuits. wide-range charge measurements are enabled by offering three gain ranges while maintaining a short cycle time. qtc chip test results show good analog performance, with efficient detection for a single photoelectron signal, four orders of magnitude dynamic range (0.3 mv similar to 3 v; 0.2 similar to 2500 pc). 1% charge linearity, 0.2 pc charge resolution, and 0.1 ns timing resolution. test results on ambient temperature dependence, channel isolation, and rate dependence also meet specifications. (c) 2009 elsevier b.v. all rights reserved.
symbolic_computation	the korteweg-de vries (kdv)-type equations have been seen in fluid mechanics, plasma physics and lattice dynamics, etc. this paper will address the bilinearization problem for some higher-order kdv equations. based on the relationship between the bilinear method and bell-polynomial scheme, with introducing an auxiliary independent variable, we will present the general bilinear forms. by virtue of the symbolic computation, one- and two-soliton solutions are derived.
parallel_computing	increasing availability of multicore systems has led to greater focus on the design and implementation of languages for writing parallel programs. such languages support various abstractions for parallelism, such as fork-join, async-finish, futures. while they may seem similar, these abstractions lead to different semantics, language design and implementation decisions, and can significantly impact the performance of end-user applications. in this paper, we consider the question of whether it would be possible to unify various paradigms of parallel computing. to this end, we propose a calculus, called dag calculus, that can encode fork-join, async-finish, and futures, and possibly others. we describe dag calculus and its semantics, establish translations from the aforementioned paradigms into dag calculus. these translations establish that dag calculus is sufficiently powerful for encoding programs written in prevailing paradigms of parallelism. we present concurrent algorithms and data structures for realizing dag calculus on multicore hardware and prove that the proposed techniques are consistent with the semantics. finally, we present an implementation of the calculus and evaluate it empirically by comparing its performance to highly optimized code from prior work. the results show that the calculus is expressive and that it competes well with, and sometimes outperforms, the state of the art.
system_identification	this paper focuses on the identification of the nonlinear vibration system of power transformers. a hammerstein model is used to identify the system with electrical inputs and the vibration of the transformer tank as the output. the nonlinear property of the system is modelled using a fourier neural network consisting of a nonlinear element and a linear dynamic block. the order and weights of the network are determined based on the lipschitz criterion and the back-propagation algorithm. this system identification method is tested on several power transformers. promising results for predicting the transformer vibration and extracting system parameters are presented and discussed.
network_security	this paper acquaints with a created application for generating rainbow tables and the results of testing rainbow tables, according to the length of the chosen chain. the paper presents a specialized application containing its own algorithms for reduction functions, changing the length of chain, generating rainbow tables and measuring the effectivity of the password search in detail. within the executed tests, the dependence of rainbow tables size on the password length, the affection of the hash search by the size of the chosen chain and their links to collisions, which arise from the principle of using the reduction function, were observed. the results objectively describe the pros and cons of using rainbow tables and show the possibilities and restrictions for their effective usage.
machine_learning	despite marked progress over the past several decades, convective storm nowcasting remains a challenge because most nowcasting systems are based on linear extrapolation of radar reflectivity without much consideration for other meteorological fields. the variational doppler radar analysis system (vdras) is an advanced convective-scale analysis system capable of providing analysis of 3-d wind, temperature, and humidity by assimilating doppler radar observations. although potentially useful, it is still an open question as to how to use these fields to improve nowcasting. in this study, we present results from our first attempt at developing a support vector machine (svm) box-based nowcasting (sbow) method under the machine learning framework using vdras analysis data. the key design points of sbow are as follows: (1) the study domain is divided into many position-fixed small boxes, and the nowcasting problem is transformed into one question, i.e., will a radar echo >35dbz appear in a box in 30min? (2) box-based temporal and spatial features, which include time trends and surrounding environmental information, are constructed. (3) and the box-based constructed features are used to first train the svm classifier, and then the trained classifier is used to make predictions. compared with complicated and expensive expert systems, the above design of sbow allows the system to be small, compact, straightforward, and easy to maintain and expand at low cost. the experimental results show that although no complicated tracking algorithm is used, sbow can predict the storm movement trend and storm growth with reasonable skill.
computer_vision	non-negative matrix factorization (nmf) is a very effective method for high dimensional data analysis, which has been widely used in computer vision. it can capture the underlying structure of image in the low dimensional space using its parts-based representations. however, nonnegative entries are usually required for the data matrix in nmf, which limits its application. besides, it is actually an unsupervised method without making use of prior information of data. in this paper, we propose a novel method called pairwise constrained graph regularized convex nonnegative matrix factorization (pgcnmf), which not only allows the processing of mixed-sign data matrix but also incorporates pairwise constraints generated among all labeled data into convex nmf framework. we expect that images which have the same class label will have very similar representations in the low dimensional space as much as possible, while images with different class labels will have dissimilar representations as much as possible. clustering experiments on nonnegative and mixed-sign real-world image datasets are conducted to demonstrate the effectiveness of the proposed method. (c) 2016 elsevier b.v. all rights reserved.
bioinformatics	male infertility is a multifactorial disorder with impressively genetic basis; besides, sperm abnormalities are the cause of numerous cases of male infertility. in this study, we evaluated the genetic variants in exons 4 and 5 and their intron-exon boundaries in rabl2b gene in infertile men with oligoasthenoteratozoospermia (oat) and immotile short tail sperm (ists) defects to define if there is any association between these variants and human male infertility. to this purpose, dna was extracted from peripheral blood and after pcr reaction and sequencing, the results of sequenced segments were analyzed. in the present study, 30 infertile men with ists defect and 30 oligoasthenoteratozoospermic infertile men were recruited. all men were of iranian origin and it took 3 years to collect patient 's samples with ists defect. as a result, the 50776482 delc intronic variant (rs144944885) was identified in five patients with oligoasthenoteratozoospermia defect and one patient with ists defect in heterozygote form. this variant was not identified in controls. the allelic frequency of the 50776482 delc variant was significantly statistically higher in oligoasthenoteratozoospermic infertile men (p < 0.05). bioinformatics studies suggested that the 50776482 delc allele would modify the splicing of rabl2b pre-mrna. in addition, we identified a new genetic variant in rabl2b gene. according to the present study, 50776482 delc allele in the rabl2b gene could be a risk factor in iranian infertile men with oligoasthenoteratozoospermia defect, but more genetic studies are required to understand the accurate role of this variant in pathogenesis of human male infertility.
electric_motor	electric motors are becoming increasingly popular for the propulsion and control of unmanned systems. in order to optimize power generation and energy use for unmanned systems, it is important to understand the dynamics of electric motors and the corresponding powertrain. this paper provides an early, preliminary study on an electric motor used for unmanned aerial systems (uas'). an electric motor dynamometer is used for collecting data on the motor, and trends are discussed. future work will look at implementing mathematical models in an unmanned ground system built for experimentation.
electricity	in order to attain emissions reduction targets to improve air quality and reduce global warming, electric vehicles (evs) arise as alternatives to conventional vehicles fueled by fossil fuels. in this context, this work presents a comparative study between an ev and its conventional version, a medium-duty, diesel engine powered vehicle, from road tests following a standard cycle in urban driving conditions. the performance parameters evaluated are ev electric energy consumption and carbon dioxide (co2) emissions from electricity generation and, for the conventional vehicle, exhaust co2 emissions and energy consumption calculated from fuel consumption and heating value. five scenarios were built to conduct an economic viability study in terms of payback and net present value (npv). considering the conditions applied, the results from the environmental analysis showed that co2 emissions from the ev was 4.6 times lower in comparison with the diesel vehicle. on the other hand, the economic analysis revealed that the viability of the ev is compromised, mainly due to the imported parts with unfavorably high exchange rates. in the best scenario and not considering revenue from commercial application, the calculated payback period of the ev is 13 years of operation. (c) 2017 elsevier ltd. all rights reserved.
machine_learning	data clustering is a popular analysis tool for data statistics in many fields such as pattern recognition, data mining, machine learning, image analysis, and bioinformatics. the aim of data clustering is to represent large datasets by a fewer number of prototypes or clusters, which brings simplicity in modeling data and thus plays a central role in the process of knowledge discovery and data mining. in this paper, a novel data clustering algorithm based on modified gravitational search algorithm is proposed, which is called bird flock gravitational search algorithm (bfgsa). the bfgsa introduces a new mechanism into gsa to add diversity, a mechanism which is inspired by the collective response behavior of birds. this mechanism performs its diversity enhancement through three main steps including initialization, identification of the nearest neighbors, and orientation change. the initialization is to generate candidate populations for the second steps and the orientation change updates the position of objects based on the nearest neighbors. due to the collective response mechanism, the bfgsa explores a wider range of the search space and thus escapes suboptimal solutions. the performance of the proposed algorithm is evaluated through 13 real benchmark datasets from the well-known uci machine learning repository. its performance is compared with the standard gsa, the artificial bee colony (abc), the particle swarm optimization (pso), the firefly algorithm (fa), k-means, and other four clustering algorithms from the literature. the simulation results indicate that the bfgsa can effectively be used for data clustering.
voltage_law	this letter presents an improved backward/forward sweep algorithm for three-phase load-flow analysis of radial distribution systems. in the backward sweep, kirchhoff 's current law and kirchhoff 's voltage law are used to calculate the upstream bus voltage of each line or a transformer branch. then, the linear proportional principle is adopted to find the ratios of the real and imaginary components of the specified voltage to those of the calculated voltage at the substation bus. in the forward sweep, the voltage at each downstream bus is then updated by the real and imaginary components of the calculated bus voltage multiplying with the corresponding ratio. the procedure stops after the mismatch of the calculated and the specified voltages at the substation is less than a convergence tolerance. the proposed algorithm is tested with three ieee benchmark distribution systems. results show that the algorithm is accurate and computationally efficient in comparing with two other commonly used methods.
symbolic_computation	on the hilbert space the singular integral operator with non-carleman shift and conjugation is considered, where are the cauchy projectors, , , , are continuous functions on the unit circle , u is the shift operator and c is the operator of complex conjugation. we show how the symbolic computation capabilities of the computer algebra system mathematica can be used to explore the dimension of the kernel of the operator k. the analytical algorithm [adimker-noncarleman] is presented; several nontrivial examples are given.
operational_amplifier	in this paper a low power and low output ripple regulator is designed with teaching-learning-based optimization (tlbo) for radio frequency identification applications. in order to decrease the power consumption the voltage of regulator sub-blocks is supplied from elementary stages. in the proposed operational amplifier employed to the regulator, adaptive biasing is used and bandgap reference of the regulator is totally designed by mosfet. to optimize the proposed regulator after modeling the regulator with the help of neural network, tlbo algorithm is used. the outputs of tlbo are output voltage, ripple value and power consumption. by using this algorithm the output voltage is 0.8 v with 2.78 mv ripple and power consumption. also the quiescent current of this design is decreased to 290 na. the chip area of the layout design in cadence software is about . the operation frequency of this circuit is 960 mhz and the simulation is done in cmos technology.
electrical_circuits	methods and materials for liquid encapsulation in thin (19 mu m) silicone membranes are presented in this work. a set of 12 liquids including solvents, oils, silicone pre-polymers and one ionic liquid are experimentally tested. we show that all selected liquids are chemically inert to silicone and that vapor pressure is the key parameter for stable encapsulation. it is demonstrated that encapsulated volume of silicone pre-polymers and ionic liquids can stay stable for more than 1 month. the actuation of dielectric elastomer actuators (deas) in conductive liquids is also investigated. an analysis of the equivalent electrical circuits of immersed deas shows that non-overlapping regions of the electrodes should be minimized. it also provides guidelines to determine when the electrodes should be passivated. the effects of immersion in a conductive liquid are assessed by measuring the actuation strain and capacitance over periodic actuation. the experimental results show no sign of liquid-induced degradation over more than 45k actuation cycles.
cryptography	berta et al 's uncertainty principle in the presence of quantum memory (berta et al 2010 nat. phys. 6 659) reveals uncertainties with quantum side information between the observables. in the recent important work of coles and piani (2014 phys. rev. a 89 022112), the entropic sum is controlled by the first and second maximum overlaps between the two projective measurements. we generalize the entropic uncertainty relation in the presence of quantum memory and find the exact dependence on all d largest overlaps between two measurements on any d-dimensional hilbert space. our bound is rigorously shown to be strictly tighter than previous entropic bounds in the presence of quantum memory, which have potential applications to quantum cryptography with entanglement witnesses and quantum key distributions.
operational_amplifier	the operational amplifiers are the versatile and significant modules in the field of electronic circuits. two-stage op-amp is a multistage amplifier which is widely useful for on-chip applications. the proposed circuit is a two stage operational amplifier designed using differential architecture, implemented in cmos technology. the circuit gives best results such as high gain of 1,960 db and low power consumption of 1.320 mw at 180 nm technology.
system_identification	the problem of discrete-time model identification of industrial processes with time delay was investigated. an iterative and separable method is proposed to solve this problem, that is, the rational transfer function model parameters and time delay are alternately fixed to estimate each other. the instrumental variable technique is applied to guarantee consistent estimation against measurement noise. a noteworthy merit of the proposed method is that it can handle fractional time delay estimation, compared to existing methods commonly assuming that the time delay is an integer multiple of the sampling interval. the identifiability analysis for time delay is addressed and correspondingly, some guidelines are provided for practical implementation of the proposed method. numerical and experimental examples are presented to illustrate the effectiveness of the proposed method.
voltage_law	planar nanoscopic contacts are observed to undergo early electrical breakdown. the authors show that the cause is high field emission capable of triggering electromigration. the phenomenon is well described by an empirical current-voltage law, well different from that usually found in nonflat field emitters; this is attributed to the particular geometry of the contacts. although the mathematical form of the law is always the same, the intensity of breakdown current changes from sample to sample, ranging over several orders of magnitude; this is explained by the nanoscopic roughness of the emitting surfaces. they also show that the occurrence of breakdown may be dependent on the polarity of the applied voltage.
operating_systems	automotive systems are widely used in industry and our daily life. as the reliability of automotive systems is becoming a greater challenge in our community, increasingly more automotive companies are interested in applying formal methods to improve the reliability of automotive systems. we focus on automotive operating systems conforming to the osek/vdx standard. such operating systems are considered as important components to ensure the reliability of the automotive systems. in previous work, we proposed a framework to verify the design models of reactive systems against their specifications. this framework allows us to check whether the design model conforms to the specification based on a simulation relation. this paper shows a case study in which the framework is applied to a real design of the osek/vdx operating system. as a result, we found that we were able to check several important properties of the design model. we show the effectiveness and practicality of the framework based on the results of the case study.
algorithm_design	in the last decade, biology and medicine have undergone a fundamental change: next generation sequencing (ngs) technologies have enabled to obtain genomic sequences very quickly and at small costs compared to the traditional sanger method. these ngs technologies have thus permitted to collect genomic sequences (genes, exomes or even full genomes) of individuals of the same species. these latter sequences are identical to more than 99%. there is thus a strong need for efficient algorithms for indexing and performing fast pattern matching in such specific sets of sequences. in this paper we propose a very efficient algorithm that solves the exact pattern matching problem in a set of highly similar dna sequences where only the pattern can be pre-processed. this new algorithm extends variants of the boyer-moore exact string matching algorithm. experimental results show that it exhibits the best performances in practice.
computer_graphics	with the increasing availability of high-resolution images, videos, and 3d models, the demand for scalable large data processing techniques increases. we introduce a method of sparse dictionary learning for edit propagation of large input data. previous approaches for edit propagation typically employ a global optimization over the whole set of pixels (or vertexes), incurring a prohibitively high memory and time-consumption for large input data. rather than propagating an edit pixel by pixel, we follow the principle of sparse representation to obtain a representative and compact dictionary and perform edit propagation on the dictionary instead. the sparse dictionary provides an intrinsic basis for input data, and the coding coefficients capture the linear relationship between all pixels and the dictionary atoms. the learned dictionary is then optimized by a novel scheme, which maximizes the kullback-leibler divergence between each atom pair to remove redundant atoms. to enable local edit propagation for images or videos with similar appearance, a dictionary learning strategy is proposed by considering range constraint to better account for the global distribution of pixels in their feature space. we show several applications of the sparsity-based edit propagation, including video recoloring, theme editing, and seamless cloning, operating on both color and texture features. our approach can also be applied to computer graphics tasks, such as 3d surface deformation. we demonstrate that with an atom-to-pixel ratio in the order of 0.01% signifying a significant reduction on memory consumption, our method still maintains a high degree of visual fidelity.
computer_programming	novice students (n=99) participated in a lab study in which they learned the fundamentals of computer programming in python using a self-paced computerized learning environment involving a 25-min scaffolded learning phase and a 10-min unscaffolded fadeout phase. students provided affect judgments at approximately 100 points (every 15 s) over the course of viewing videos of their faces and computer screens recorded during the learning session. the results indicated that engagement, confusion, frustration, boredom, and curiosity were the most frequent affective states, while anxiety, happiness, anger, surprise, disgust, sadness, and fear were rare. confusion + frustration and curiosity + engagement were identified as two frequently co-occurring pairs of affective states. an analysis of affect dynamics indicated that there were reciprocal transitions between engagement and confusion, confusion and frustration, and one way transitions between frustration and boredom and boredom and engagement. considering interaction events in tandem with affect revealed that constructing code was the central activity that preceded and followed each affective state. further, confusion and frustration followed errors and preceded hint usage, while curiosity and engagement followed reading or coding. an analysis of affect-learning relationships after partialling out control variables (e. g., scholastic aptitude, hint usage) indicated that boredom (r=-.149) and frustration (r=-.218) were negative correlated with learning while transitions between confusion. frustration (r=.103), frustration. confusion (r=.105), and boredom. engagement (r=.282) were positively correlated with learning. implications of the results to theory on affect incidence and dynamics and on the design of affect-aware learning environments are discussed.
digital_control	digital stabilization of unstable equilibria of linear systems may lead to small amplitude stochastic-like oscillations. we show that these vibrations can be related to a deterministic chaotic dynamics induced by sampling and quantization. a detailed analytical proof of chaos is presented for the case of a pd controlled oscillator: it is shown that there exists a finite attracting domain in the phase-space, the largest lyapunov exponent is positive and the existence of a smale horseshoe is also pointed out. the corresponding two-dimensional micro-chaos map is a multi-baker map, i.e. it consists of a finite series of baker 's maps.
control_engineering	conventional integer order proportional integral derivative (iopid) are the workhorse for the control of almost 90% of the industrial processes due to its structural simplicity. with the application of fractional calculus in the field of control engineering, fractional order (fo) pid controllers are gaining popularity since it requires a slight modification of the integer order pid controller. tuning of the integer order pid controller parameters are by well known techniques like ziegler nichols method, cohen coon method, etc mostly time domain based and few frequency techniques are also available. in the present research work, an attempt has been made to tune the fopi controller using frequency domain specifications. frequency domain specifications considered for the design includes the phase margin specification, gain crossover frequency specification and robustness to gain variations. the proposed control schemes are applied to three interacting tank process represented as third order system and verified under servo, regulatory, servo-regulatory response and robustness conditions. comparison of the time domain performance indices are performed to guarantee the superiority of the proposed scheme
electric_motor	this paper discusses the development of an energy management and supervisory control system (ems) for a hybrid electric vehicle (hev). it is built on national instruments' compactrio embedded controller and labview real-time software platform. the ems functions as the primary vehicle controller whose objective is to achieve optimal operation of the hybrid propulsion system-reduced fuel consumption and selfsustaining energy storage, since the vehicle is a non-plug-in hybrid. the hev derives its propulsion power from two sources -an internal combustion engine (ice) and an electric motor. the ems receives inputs of throttle position, vehicle speed, engine rpm and battery state of charge (soc). based on a certain control algorithm, it then determines the two sources' operation status and power distribution, and charging of battery pack. a graphical driver interface is implemented on a tablet pc with a tcp/ip connection to the ems controller. a labview-based interface appears on a dynamically-controllable html page hosted by the web server function of the compactrio, enabling the driver to monitor and override control of the hybrid vehicle.
state_space_representation	this paper deals with the problem of non-fragile robust finite-time h-infinity control for a class of uncertain nonlinear stochastic ito systems via neural network. first, applying multi-layer feedback neural networks, the nonlinearity is approximated by linear differential inclusion (ldi) under state-space representation. then, a sufficient condition is proposed for the existence of non-fragile state feedback finite-time h-infinity controller in terms of matrix inequalities. furthermore, the problem of non-fragile robust finite-time h-infinity control is reduced to the optimization problem involving linear matrix inequalities (lmis), and the detailed solving algorithm is given for the restricted lmis. finally, an example is given to illustrate the effectiveness of the proposed method.
system_identification	complexity pursuit (cp) has recently been proposed as an elegant and simple solution to blindly (i.e. without measuring the inputs) separate the modal contributions in the vibration responses of a structure. this potentially finds considerable interest in operational modal analysis and related applications. this paper analyses the theoretical ins and outs of the method. it also revises its physical interpretation in the modal analysis context. cp is found to separate components which are the least dispersive (i.e. invariant under linear filtering), a property that well characterizes the modal responses of lightly damped systems. however, it is also found to suffer from the same limitations as other blind source separation methods used in the state-ofthe-art, namely the difficulty to separate strongly coupled modes and to identify complex mode shapes. finally a generalization of cp is proposed which intends to widen its applicability. interestingly, the generalized crep happens to include the well-known sobi algorithm as a particular case.
electricity	recent forecasts suggest that african countries must triple their current electricity generation by 2030. our multicriteria assessment of wind and solar potential for large regions of africa shows how economically competitive and low-environmental-impact renewable resources can significantly contribute to meeting this demand. we created the multicriteria analysis for planning renewable energy (mapre) framework to map and characterize solar and wind energy zones in 21 countries in the southern african power pool (sapp) and the eastern africa power pool (eapp) and find that potential is several times greater than demand in many countries. significant fractions of demand can be quickly served with ""no-regrets"" options-or zones that are low-cost, low-environmental impact, and highly accessible. because no-regrets options are spatially heterogeneous, international interconnections are necessary to help achieve low-carbon development for the region as a whole, and interconnections that support the best renewable options may differ from those planned for hydropower expansion. additionally, interconnections and selecting wind sites to match demand reduce the need for sapp-wide conventional generation capacity by 9.5% in a high-wind scenario, resulting in a 6-20% cost savings, depending on the avoided conventional technology. strategic selection of low-impact and accessible zones is more cost effective with interconnections compared with solutions without interconnections. overall results are robust to multiple load growth scenarios. together, results show that multicriteria site selection and deliberate planning of interconnections may significantly increase the economic and environmental competitiveness of renewable alternatives relative to conventional generation.
computer_programming	game-based learning is considered as a very motivational tool to accelerate active learning of students. as such learning environments usually follow a computer-assisted instruction concept that offers no adaptability to each student, some idea from intelligent tutoring systems (its) are borrowed and applied in educational games to teach introductory programming. thus, we developed a game-based intelligent tutoring system (gits) in the form of a competitive board game. the board game revises the classic table game ""snakes and ladders"" to improve web-based problem solving skills and learning computer programming. moreover, a mini-game, tictac-toe quiz, is applied in gits to update the bayesian network used for the process of decision-making in our proposed system. our future work is to evaluate the gits by conducting an experimental study using novices.
analog_signal_processing	the paper presents a detailed numerical model of the dynamic behaviour of a francis turbine installed in a hydroelectric plant. the model considers in detail the francis turbine with all the electromechanical subsystems, such as the main speed governor, the controller and the servo actuator of the turbine distributor, and the electrical generator. in particular, it reproduces the effects of pipeline elasticity in the penstock, the water inertia and the water compressibility on the turbine behaviour. the dynamics of the surge tank on low frequency pressure waves is also modelled together with the main governor speed loop and the position controllers of the distributor actuator and of the hydraulic electrovalve. model validation has been made by means of experimental data of a 75 mw-470 m hydraulic head-francis turbine acquired during some starting tests after a partial revamping, which also involved the control system of the distributor. (c) 2011 elsevier ltd. all rights reserved.
electrical_network	this paper introduces a simultaneous state and topology estimation method able to process both conventional (scada) and synchrophasor measurements. it is devised to extract from the analog measurements not only estimates for the state variables, but also information concerning the underlying network topology. this can be accomplished by representing selected parts of the electrical network at bus section level, and by using a specialized, multiobjective optimization framework to formulate the joint estimation problem. the multiobjective criterion comprises both the familiar weighted least squares term and an additional least absolute value component that models switching branch statuses. the proposed approach can be seen as a validation step for the outcome produced by network processors, thereby preventing the occurrence of topology errors. the results presented in this paper show that the joint estimation approach can be extended to allow phasor measurement processing capability, and that the whole scheme can draw significant benefits from such an extension.
symbolic_computation	in this article, the novel (g '/ g)-expansion method is successfully applied to construct the abundant travelling wave solutions to the kdv-mkdv equation with the aid of symbolic computation. this equation is one of the most popular equation in soliton physics and appear in many practical scenarios like thermal pulse, wave propagation of bound particle, etc. the method is reliable and useful, and gives more general exact travelling wave solutions than the existing methods. the solutions obtained are in the form of hyperbolic, trigonometric and rational functions including solitary, singular and periodic solutions which have many potential applications in physical science and engineering. many of these solutions are new and some have already been constructed. additionally, the constraint conditions, for the existence of the solutions are also listed.
data_structures	detection of data structures in spectral clustering approaches becomes a difficult task when dealing with complex distributions. moreover, there is a need of a real user prior knowledge about the influence of the free parameters when building the graph. here, we introduce a graph pruning approach, termed kernel alignment based graph pruning (kagp), within a spectral clustering framework that enhances both the local and global data consistencies for a given input similarity. the kagp allows revealing hidden data structures by finding relevant pair-wise relationships among samples. so, kagp estimates the loss of information during the pruning process in terms of a kernel alignment-based cost function. besides, we encode the sample similarities using a compactly supported kernel function that allows obtaining a sparse data representation to support spectral clustering techniques. attained results shows that kagp enhances the clustering performance in most of the cases. in addition, kagp avoids the need for a comprehensive user knowledge regarding the influence of its free parameters. (c) 2015 elsevier b.v. all rights reserved.
image_processing	this study presents the results from the rheological measurement of clay suspensions using vane geometry in a wide gap configuration. it focuses on how measurement of viscosity cannot be effective for two reasons: the limits of the vane geometry itself and the limits of the material depending on its content of solid particles. image analysis of the flow while shearing the material is carried out to relate the flow behavior. several approaches to compute the shear flow curve from torque-rotational velocity data are used. the results demonstrate that the applied setpoint while applying a logarithmic shear rate ramp can be very different from the calculated shear rate from existing theories. depending on the solid volume fraction of the particles in the mixture, we relate the macroscopic behavior using image analysis and the shear flow curves to the rheophysical regime of the flow of the suspensions. therefore, this paper has two simultaneous goals: the first one is to describe the physical phenomena which control macroscopic behavior and the second one is to highlight the limits of the vane geometry for viscosity measurement of mineral suspensions like kaolinite pastes.
relational_databases	over the past few years, reversible watermarking techniques for relational databases have been proposed to provide protection of ownership rights, data tempering, and data integrity. mainly, these techniques ensure original data recovery from watermarked data, whereas irreversible watermarking schemes only protect ownership rights. this characteristic of reversible watermarking has emerged as a candidate solution for the protection of ownership rights of data, intolerable to modifications such as medical data, genetic data, credit card, and bank account data. the main objective of this paper is to make an extensive survey of the state-of-the-art in reversible watermarking techniques for relational databases to reflect recent research progress and to point out the key issues for future research. in order to analyze these techniques, a classification has been performed on the basis of (i) the extent of modifications introduced by the watermarking scheme in the underlying data and (ii) the robustness of the embedded watermark against malicious attacks. copyright (c) 2015 john wiley & sons, ltd.
digital_control	it is shown that the problem of evaluation of states both object and controller arises at digital control. in multi-circuit embedded systems time intervals of residence of system in any state depends on both time complexity of control algorithm and dispatching discipline. two simplest disciplines, of most common use are investigated: the cyclic dispatching and foreground (quasi-stochastic) one. with use the semi-markov process as fundamental theory, models of functioning of control programs under investigated dispatching disciplines are worked out. mathematical relationships for time of return to any state of semi-markov process and time between switches are obtained. the parameters obtained are essential for working out of efficient regimes of data processing in embedded systems.
microcontroller	visual techniques for qualitative assessment of roads, which rank the roads either good or not, have been widely used by the international confederation of transport. although there are quantitative techniques, such as iri (international index roughness), the use of these techniques involves a higher cost technique compared to the visual one due to the fact that there is a need of special and quite expensive equipment. in this work we developed a new quantitative indicator of roads able to evaluate and compare them in terms of its surface quality without relying on visual analysis. a low-cost acquisition system based on an analog 3-axis accelerometer and a microcontroller was developed. also, it was developed an algorithm able to evaluate and rank the road on a scale ranging from 0 to 5. two roads visually rated as good and bad were used as references. it was tested 3 different types of roads, with or without holes. both tests were conducted with a vehicle running at 40, 50 and 60 km/h. the results showed that the greater the amount of holes or unevenness the worst the quality indicator and that this depends on the speed of the vehicle. it was concluded that a quantitative analysis of road might be automatically done by using a low cost measuring system.
electric_motor	this paper presents a method of friction compensation for a linear electric motor in a model in the loop suspension test rig. the suspension consists of a numerically modeled spring and damper, with inputs of suspension motion. the linear motor is force controlled using a force sensor to track the output of the numerical model. the method uses a coulomb friction model and applies a feedforward step signal when velocity zero crossing occurs. velocity zero crossing estimation is achieved using an algorithm based on measured feedback velocity and force. experimental results indicate reduction of force tracking error caused by coulomb friction leading to improved test rig accuracy.
pid_controller	in this paper, an enhanced genetic algorithm (ega) based proportional integral-derivative (pid) controller is presented for control of nonlinear dynamic process. in ega, the crossover and elite offspring are optimized using ant colony optimization (aco) which improves the convergence characteristics and optimization capabilities of traditional genetic algorithm (ga).the proposed algorithm is implemented for closed loop control of continuous stirred tank reactor (cstr) process. the performance of the proposed scheme is validated through the simulation results and by comparing with the conventional counterparts. the integral performance criteria viz., integral square error (ise), integral absolute error (iae), integral time weighted absolute error (itae) of the ega implemented cstr system revealed a reduction of ise equal to 1.5704e-4 at 50-150 sampling interval when compared to conventional ga. the results show that, ega based nonlinear pid is more suitable for servo and regulatory operations.
electrical_circuits	smart textiles have become a dominant trend in future textiles development, especially wearable electronics. however, electronic garment designs often look more 'technical' than 'textile', which is reflected in the slow growth of the market. therefore, a design approach is proposed to design the conductive paths of electric stimulation garments in three steps: modelling, division and conquer, and pattern refinement to enhance the aesthetics. a transcutaneous electrical nerve stimulation (tens) knitwear garment with a refined conductive network was developed and evaluated. the output waveforms and spectrums of the resulting tens knitwear are similar to those of tens signals. the resistance variations are smaller than 16 per cent after optimization, which is largely due to truncation and deformation. this method could provide a feasible and systematic approach to the design of electric stimulation textiles by using conductive fabrics to meet the requirements of both functionality and aesthetics.
operational_amplifier	background: electroencephalography (eeg) is still a widely used imaging tool that combines high temporal resolution with a relatively low cost. ag/agcl metal electrodes have been the gold standard for non-invasively monitoring electrical brain activity. although reliable, these electrodes have multiple drawbacks: they suffer from noise, such as offset potential drift, and usability issues, for example, difficult skin preparation and cross-coupling of adjacent electrodes. new method: in order to tackle these issues a prototype electric potential sensor (eps) device based on an auto-zero operational amplifier was developed and evaluated. the eps is a novel active ultrahigh impedance capacitively coupled sensor. the absence of 1/f noise makes the eps ideal for use with signal frequencies of similar to 10 hz or less. a comprehensive study was undertaken to compare neural signals recorded by the eps with a standard commercial eeg system. results: quantitatively, highly similar signals were observed between the eps and eeg sensors for both free running and evoked brain activity with cross correlations of higher than 0.9 between the eps and a standard benchmark eeg system. comparison with existing method(s): these studies comprised measurements of both free running eeg and event related potentials (erps) from a commercial eeg system and eps. conclusions: the eps provides a promising alternative with many added benefits compared to standard eeg sensors, including reduced setup time and elimination of sensor cross-coupling. in the future the scalability of the eps will allow the implementation of a whole head ultra-dense eps array. (c) 2015 elsevier b.v. all rights reserved.
cryptography	we propose multi-party quantum summation protocols based on single particles, in which participants are allowed to compute the summation of their inputs without the help of a trusted third party and preserve the privacy of their inputs. only one participant who generates the source particles needs to perform unitary operations and only single particles are needed in the beginning of the protocols.
relational_databases	spreadsheets are among the most commonly used applications for data management and analysis. they combine data processing with very diverse supplementary features: statistics, visualization, reporting, linear programming solvers, web queries periodically downloading data from external sources, etc. however, the spreadsheet paradigm of computation still lacks sufficient analysis. in this article, we demonstrate that a spreadsheet can implement all data transformations definable in sql, merely by utilizing spreadsheet formulas. we provide a query compiler, which translates any given sql query into a worksheet of the same semantics, including null values. thereby, database operations become available to the users who do not want to migrate to a database. they can define their queries using a high-level language and then get their execution plans in a plain vanilla spreadsheet. the functions available in spreadsheets impose limitations on the algorithms one can implement. in this paper, we offer o(n log(2) n) sorting spreadsheet, using a non-constant number of rows, and, surprisingly, depth-first-search and breadth-first-search on graphs.
network_security	with the ever growing demand of location-independent access to autonomous decentralized systems (ads), anomaly detection scheme for industrial ethernet, which highly is satisfied with demanding real-time and reliable industrial applications, becomes one of the most pressing subjects in ads. in this paper, we present an innovative approach to build a traffic model based on structural time series model for a chemical industry system. a basic structural model that decomposes time series into four items is established by the stationary analysis of industrial traffic. parameters in the model are identified by the state space model, which is conducted from the training sequence using standard kalman filter recursions and the em algorithm. furthermore, the performance of state space model is evaluated by the experimental results that confirm significant improvement in detection accuracy and the validity of abnormal data localization. (c) 2016 elsevier b.v. all rights reserved.
microcontroller	background: neuroscience research on non-human primates usually requires the animals to sit in a chair. to do this, typically monkeys are fitted with collars and trained to enter the chairs using either a pole, leash and jump cage. animals may initially show resistance and risk injury. we have developed an automated chair-training method that minimizes restraints to ease the animals into their chairs. new method: we developed a method to automatically train animals to enter a primate chair and stick out their heads for neckplate placement. to do this, we fitted the chairs with arduino microcontrollers coupled to a water-reward system and touch-and proximity sensors. results and comparison with existing methods: we found that the animals responded well to the chair, partially entering the chair within hours, sitting inside the chair within days and allowing us to manually introduce a door and neck plate, all within 14-21 sessions. although each session could last many hours, automation meant that actual training person-hours could be as little as half an hour per day. the biggest advantage was that animals showed little resistance to entering the chair, compared to monkeys trained by leash pulling. conclusions: this automated chair-training method can take longer than the standard collar-and-leash approach, but multiple macaques can be trained in parallel with fewer person-hours. it is also a promising method for animal-use refinement and in our case, it was the only effective training approach for an animal suffering from a behavioral pathology. (c) 2016 elsevier b.v. all rights reserved.
distributed_computing	apache hadoop is a widely used distributed computing framework and its file system is hadoop distributed file system (hdfs), which assumes that datanodes in a system are homogeneous in nature. when a cloud system scales up, datanodes are very likely to become heterogeneous. thus, extensive research has been placed on improving performance for heterogeneous hadoop systems, but little attention has been placed on security improvements. this motivates us to investigate a data allocation scheme called the secure hdfs (sechdfs) by integrating the secret sharing technique to improve storage security in a heterogeneous hadoop system. datanodes in a hadoop system are classified into a variety of different types of groups based on their vulnerability characteristics. sechdfs addresses the increased risk issue caused by data replication in hdfs by allocating fragments of a file to as many different types of datanodes as possible and multiple replicas of the same fragment to datanodes of the same type. a storage assurance model is developed to evaluate the quality of security offered by sechdfs. analysis of the assurance model and performance evaluation experiments show that sechdfs does not impact the performance of the hadoop system that much in comparison with the default hdfs, while significantly improving data assurance in a heterogeneous environment.
computer_graphics	in this paper, the authors propose a ""multi modification design model"", as a new type of visual expression. this visual expression by a computer has been unified as so-called computer graphics (cg). today, in most circumstances, visual expression by a computer indicates cg; its main role is to generate a image on the virtual space of a computer and this is an image that is difficult to be drawn or recreated physically. in recent years, expressive abilities by cg have been enhanced. in other words, complicated images and drawings that require much calculation became possible and easy due to the speeding up of computer processing. however this alone cannot broaden the variety of expressivity of visual expression by a computer we need to extend its ability. usually the history of visual expression referred to its cg history and there has not been much progress or innovation in terms of creativity since 1980s when the socalled cg was determined. the author describes ""multi modification design model"", as a new visual expression by a computer which is demonstrated through the actual produced work.
operating_systems	light emitting diode (led) luminaires provide compelling benefits such as long-term cost savings, and safety advantages through longer life and durability. led luminaires have lower maintenance costs, and improved instant restrike capability when compared to legacy luminaire types. in industrial applications, the proven lower total cost of ownership and increased safety for leds are the driving forces for led luminaires to replace traditional light sources. as with any new technology, challenges exist in designing and maintaining an optimal system to withstand the intended application and environmental conditions. common challenges and considerations include luminaire placement, the intensity/dispersion/quality of light, thermal management, material selection, and redundant safety and operating systems. the authors will examine best practices and common misconceptions in the selection and application of led luminaires focusing on process and harsh/hazardous locations. the probability of success in maximizing reliability, safety & efficiency of led technology in such applications is enhanced by utilizing proven design principles & methods. the selection methods and design principles will be explained using actual application examples and case studies.
operating_systems	the object modeling technique, a generally used object-oriented software development technique, comprises the object, dynamic, and functional models to provide three corresponding views that graphically express diverse aspects of software systems. this paper adds security engineering into an object oriented model-driven software development for real life web applications. in this paper, we use mining patterns in web applications. this research paper proposes a unified modeling language based secure software maintenance procedure. the proposed method is applied for maintaining a large-scale software product and real-life product-line products. after modeling we can implement and run this web application, on spf based trusted operating systems. reverse engineering has become a main concern in software development industry because of their complete size and so much difficulty. this difficulty needs to be tackled since the software systems in question are of significant importance to their owners and maintainers. for secure designing of web applications, this paper propose system security performance model for trusted operating system. for re engineering and re-implementation process of web applications, this paper proposes the model driven roundtrip engineering approach.
control_engineering	in many control engineering applications, it is impossible or expensive to measure all the states of the dynamical system and only the system output is available for controller design. in this study, a new dynamic output feedback control algorithm is proposed to stabilize the unstable periodic orbit of chaotic spinning disks with incomplete state information. the proposed control structure is based on the t-s fuzzy systems. this investigation also introduces a new design procedure to satisfy a constraint on the t-s fuzzy dynamic output feedback control signal. this procedure is independent of the exact value of initial states. finally, computer simulations are accomplished to illustrate the performance of the proposed control algorithm. (c) 2015 wiley periodicals, inc.
symbolic_computation	this paper addresses the potential korteweg-de vries equation. the singular 1-soliton solution is obtained by the aid of ansatz method. subsequently, the -expansion method and the exp-function approach also gives a few more interesting solutions. finally, the lie symmetry analysis leads to another plethora of solution to the equation. these results are going to be extremely useful and applicable in applied mathematics and theoretical physics.
operating_systems	this article analyzes dynamic changes in mobile phone popularity based on phone features. the time period, 2004-2013, selected for the study is interesting because many technical innovations took place molding the mobile phone market dramatically. the study utilizes comprehensive phone model and sales data collected in finland, combined with temporally ordered probabilistic models to discover the time behavior of predictivity. more precisely, the tree augmented na ve bayes - classification method is adapted to detect those phone characteristics that best predict the annual phone popularity measured as phone model unit sales. linear regression and the chow test are used to discover potential trends and structural breaks. the strength of the predictivity is measured as kullback-leibler divergence. this kind of systematic longitudinal analysis highlights patterns, which are otherwise not possible to observe. the study discovered that the operating system is clearly the only feature with an increasing strength in predicting popularity over time. in contrast, sixteen features have structural breaks between 2004 and 2013. most such breaks are related to the technical evolution of phones: their display, communication, and camera capabilities. notably, the structural break in 2007-2008 related to the phone manufacturer brand is interpreted as the market turning from hardware to software driven mode, which contributed to nokia 's failure with symbian and windows operating systems, and to google 's success with a hardware independent operating system android. (c) 2016 elsevier ltd. all rights reserved.
computer_vision	breakthrough performances have been achieved in computer vision by utilizing deep neural networks. in this paper we propose to use random forest to classify image representations obtained by concatenating multiple layers of learned features of deep convolutional neural networks for scene classification. specifically, we first use deep convolutional neural networks pre-trained on the large-scale image database places to extract features from scene images. then, we concatenate multiple layers of features of the deep neural networks as image representations. after that, we use random forest as the classifier for scene classification. moreover, to reduce feature redundancy in image representations we derived a novel feature selection method for selecting features that are suitable for random forest classification. extensive experiments are conducted on two benchmark datasets, i.e. mit-indoor and uiuc-sports. obtained results demonstrated the effectiveness of the proposed method. the contributions of the paper are as follows. first, by extracting multiple layers of deep neural networks, we can explore more information of image contents for determining their categories. second, we proposed a novel feature selection method that can be used to reduce redundancy in features obtained by deep neural networks for classification based on random forest. in particular, since deep learning methods can be used to augment expert systems by having the systems essentially training themselves, and the proposed framework is general, which can be easily extended to other intelligent systems that utilize deep learning methods, the proposed method provide a potential way for improving performances of other expert and intelligent systems. (c) 2016 elsevier ltd. all rights reserved.
control_engineering	this paper describes the status, achieved results and future research plans related to a student 's project of an on-line on-board wind estimation system. the system is planned to augment functionality and improve performance of existing small uav flight control system units, developed within students activities at the department of control engineering, faculty of electrical engineering, czech technical university in prague. simulated data are prepared based on realistic flight mechanics models. simple algorithms are adopted from literature and tailored for our case and their sensitivity to measurement errors is carefully analyzed. finally, performance of the algorithms is demonstrated in realistic simulation scenarios. related hardware components are also introduced and discussed in brief and the future plans are elaborated.
digital_control	this paper presents theoretical and practical results about dynamic analysis, frequency response, and control of a llc resonant dc/dc converter operating under wide input voltage and load variations. a nonlinear model for the llc resonant converter was developed using the extended describing function method; then, based on the derived model, a nonlinear observer-based controller was designed and implemented with a digital signal processor. transient responses obtained under input voltage and output load variations show that the proposed controller is capable to stabilize the output effectively. experimental results prove the superiority of the proposed observer-based controller over a conventional pid controller.
bioinformatics	amr h sawalha is professor of internal medicine and marvin and betty danto research professor of connective tissue research at the university of michigan, department of internal medicine, division of rheumatology. he also holds faculty appointments at the center for computational medicine and bioinformatics and the graduate program in immunology at the university of michigan. he was recently appointed as guest professor at central south university in changsha, china. he received his medical degree from jordan university of science and technology and completed his residency training in internal medicine at the university of oklahoma health sciences center, and his fellowship in rheumatology at the university of michigan. his research focus is the genetics and epigenetics of complex autoimmune and inflammatory diseases, including lupus and systemic vasculitis. he has authored over 100 peer-reviewed manuscripts, book chapters and review articles, and is on the editorial board of several journals in his field. he has been elected as a member of the american society for clinical investigation, and has received numerous awards, including the edmund l dubois, md, memorial lectureship award from the american college of rheumatology in recognition for his work in lupus. he is chair of the lupus foundation of america research subcommittee and is a member of the vasculitis foundation medical and scientific advisory board. he also provides clinical care and teaching in the rheumatology outpatient and inpatient services, and he is the director of the nih-funded rheumatology training grant at the university of michigan.
symbolic_computation	in order to develop a computationally efficient implementation of the maximally permissive deadlock avoidance policy (dap) for complex resource allocation systems (ras), a recent approach focuses on the identification of a set of critical states of the underlying ras state-space, referred to as minimal boundary unsafe states. the availability of this information enables an expedient one-step-lookahead scheme that prevents the ras from reaching outside its safe region. the work presented in this paper seeks to develop a symbolic approach, based on binary decision diagrams (bdds), for efficiently retrieving the (minimal) boundary unsafe states from the underlying ras state-space. the presented results clearly demonstrate that symbolic computation enables the deployment of the maximally permissive dap for complex ras with very large structure and state-spaces with limited time and memory requirements. furthermore, the involved computational costs are substantially reduced through the pertinent exploitation of the special structure that exists in the considered problem. note to practitioners-a key component of the real-time control of many flexibly automated operations is the management of the allocation of a finite set of reusable resources among a set of concurrently executing processes so that this allocation remains dead-lock-free. the corresponding problem is known as deadlock avoidance, and its resolution in a way that retains the sought operational flexibilities has been a challenging problem due to: (i) the inability to easily foresee the longer-term implications of an imminent allocation and (ii) the very large sizes of the relevant state spaces that prevent an online assessment of these implications through exhaustive enumeration. a recent methodology has sought to address these complications through the offline identification and storage of a set of critical states in the underlying state space that renders efficient the safety assessment of any given resource allocation. the results presented in this paper further extend and strengthen this methodology by complementing it with techniques borrowed from the area of symbolic computation; these techniques enable a more compressed representation of the underlying state spaces and of the various subsets and operations that are involved in the pursued computation.
electricity	conversion of lignocellulosic biomass to electricity using fuel cell technologies is a promising but challenging research topic for sustainable electricity production. this is because that lignocellulosic biomass generally cannot be directly used as a fuel for electricity generation in a conventional fuel cell with high efficiency. typical fuel cells that can convert lignocellulosic biomass to electricity under mild conditions (< 100 degrees c) include microbial fuel cells (mfc) and novel direct biomass fuel cells (dbfc) such as that mediated by polyoxo-metalates (poms) developed recently. however, the efficiency and power output for these low-temperature fuel cells still need to be improved for practical applications. in this review, we focus on the research advances of electricity generation in fuel cells that can be operated at low temperatures. more specifically, we discussed the progress, challenge and perspectives of biomass-fueled mfcs. recent interesting researches on dbfc were also highlighted in terms of the efficiency, principles, and technological obstacles. as concluded in this work, lignocellulosic biomass is a promising feedstock for fuel cells because it is renewable, carbon neutral, and sustainable. however, the power density of lignocelluose-fueled mfc are usually far below that required for commercial applications. improving fermentable sugar release from lignocellulosic biomass and increasing the cell output power are the main research points. dbfc can obtain a high theoretical exergy recovery; however, it is still in its early stage of development with low efficiency. more research should be focused on the electrode development, cell design, parameter optimization, process integration, as well as understanding fundamental process mechanisms.
operational_amplifier	a very high gain (137 db) two stage cmos operational amplifier having structural simplicity of classical widlar architecture has been presented. the differential input stage of proposed operational amplifier has been modified by incorporating inverse aspect ratio self cascode structures biased to operate in subthreshold region, to minimize the classical compensation capacitor to 0.1 pf and results in considerable saving in occupied chip area. p-spice simulations in 0.25 mu m cmos technology at +/- 1 v supply have been carried out to compare the performance of proposed operational amplifier with previously reported designs. the proposed operational amplifier demonstrated better gain-bandwidth product of 1.37 mhz, low power consumption of 21 mu w and occupied smaller chip area of < 400 (mu m)(2).
machine_learning	a critical aspect of dimensionality reduction is to assess the quality of selected (or produced) feature subsets properly. feature subset assessment in machine learning refers to split a given feature subset into a training set, which is used to estimate the parameters of a classification model, and a test set used to estimate the predictive performance of the model. then, averaging the results of multiple splitting (i.e., cross-validation, cv) is commonly used to decrease the variance of the estimator. but in practice, cv scheme is very computationally expensive. in this paper, we propose a new statistics index method called lw-index for evaluation of feature subset and dimensionality reduction algorithms in general. the proposed method is a type of ""classical statistics"" approach that uses the feature subset to compute an empirical estimate of the quality of feature subset. a large number of performance comparisons with the machine learning approach conducted on fourteen benchmark collections show that the proposed lw index is highly correlated with the external indices (i.e., macrof(1), microf(1)) of svm and centroid-based classifier (cbc) trained by five-fold cv scheme. furthermore, the experimental results indicate that lw index has the same performance as the traditional cv scheme for evaluating the dimensionality reduction algorithms and it is more efficient than the traditional methodology. therefore, one contribution of this paper is to present an alternative methodology, based on an internal index typically used in the unsupervised learning context, that is computationally cheaper than the traditional cv methodology. another contribution is to propose a new internal index that behaves better than other similar indices widely used in clustering and shows high correlation with the results obtained by the traditional methodology. (c) 2017 the authors. published by elsevier b.v.
algorithm_design	the effectiveness of in situ remediation to treat contaminated aquifers is limited by the degree of contact between the injected treatment chemical and the groundwater contaminant. in this study, candidate designs that actively spread the treatment chemical into the contaminant are generated using a multi-objective evolutionary algorithm. design parameters pertaining to the amount of treatment chemical and the duration and rate of its injection are optimized according to objectives established for the remediation - maximizing contaminant degradation while minimizing energy and material requirements. because groundwater contaminants have different reaction and sorption properties that influence their ability to be degraded with in situ remediation, optimization was conducted for six different combinations of reaction rate coefficients and sorption rates constants to represent remediation of the common groundwater contaminants, trichloroethene, tetrachloroethene, and toluene, using the treatment chemical, permanganate. results indicate that active spreading for contaminants with low reaction rate coefficients should be conducted by using greater amounts of treatment chemical mass and longer injection durations relative to contaminants with high reaction rate coefficients. for contaminants with slow sorption or contaminants in heterogeneous aquifers, two different design strategies are acceptable - one that injects high concentrations of treatment chemical mass over a short duration or one that injects lower concentrations of treatment chemical mass over a long duration. thus, decision-makers can select a strategy according to their preference for material or energy use. finally, for scenarios with high ambient groundwater velocities, the injection rate used for active spreading should be high enough for the groundwater divide to encompass the entire contaminant plume. (c) 2016 elsevier b.v. all rights reserved.
computer_graphics	the algorithms of exposure of signals of unknown form are offered in multidimensional time series with subsequent presentation of separate time series from every mining hole as points multidimensional space of parameters of these mining holes. by means of facilities of cognitive machine graphic arts these mining holes form kappa cognitive characters in that evidently as aberrant behavior of parameters of these mining holes can be educed in case of multidimensional terabyte of time series.
analog_signal_processing	recovery of waste heat from the electrical generator into the water preheating circuit of the steam thermal power plants (stpp) is a method frequently used to increase electricity production without additional consumption of primary energy. however, the manufacturers of turbine-generator sets do not explicitly indicate the effect of the method on their performances. using numerical modeling of steam cycle, the paper presents the method 's effects on the stpp performances. it also shows a method, simple, fast, and enough accurate, for estimating these effects, that could be applied when it is not possible to recalculate the whole cycle.
parallel_computing	dynamic simulation for transient stability assessment is one of the most important, but intensive, computational tasks for power system planning and operation. several commercial software tools provide functionality for performing multiple dynamic simulations such as those in contingency analysis simultaneously on parallel computers. nevertheless, a single dynamic simulation is still a time consuming process performed sequentially on one single computing core as the tools were originally designed. modern high performance computing (hpc) holds the promise to accelerate a single dynamic simulation by parallelizing its kernel algorithms without compromising computational accuracy. parallelizing a single dynamic simulation is a much more challenging problem than the contingency-type parallel computing. it requires a good match between simulation algorithms and computing hardware. this paper provides guidance for such a match so as to design and implement parallel dynamic simulation to maximize the utilization of computing hardware and the performance of the simulation. the guidance is derived through comparative implementation of four parallel dynamic simulation schemes in two state-of-the-art hpc environments: 1) message passing interface and 2) open multi-processing. the scalability and speedup performance of parallelized dynamic simulation are thoroughly studied to determine the impact of simulation algorithms and computing hardware configurations. several testing cases are presented to illustrate the derived guidance.
network_security	a darknet monitoring system is developed to grasp malicious activities on the internet in an early stage and to cope with them. the darknet monitoring system consists of network sensors deployed widely on the internet. the sensors capture incoming unsolicited packets. a goal of this system analyzes captured malicious packets and provides effective information for protecting good internet users from malicious activities. to provide effective and reliable information, sensors must be deployed in secret and hidden from outside. on the other hand, attackers intend to detect sensors for evading them. this attempt is known as localization attacks to darknet monitoring systems. if actual location of sensors is revealed to attackers, it is almost impossible to grasp the latest tactics used by attackers. thus in our previous work, we proposed a packet sampling method, which samples incoming packets based on an attribute of packets sender, to increase a tolerance to a localization attack and to keep a high quality of information publicized by the system. as a result, we almost succeeded to counter from a localization attack, which generates spike on the publicized graph to detect a sensor. however in some cases, proposed sampling method works to attacker 's advantage and spikes appear clearly on the graph. therefore, we propose advanced sampling methods, which sample incoming packets based on multiple attributes of packets sender. in this paper, we present our improved methods and show a promising evaluation result obtained from the simulation.
data_structures	given an initial assignment of processes to machines, the machine reassignment problem is to find an assignment that improves the machine usage, subject to several resource and allocation constraints, and considering reassignment costs. we propose a heuristic based on simulated annealing for solving this problem. it uses two neighborhoods, one that moves a process from one machine to another, and a second one that swaps two processes on different machines. we present data structures that permit to validate and execute a move in time where is the number of resources and the number of dependencies of the service the process belongs to. the heuristic runs with two different sets of parameters in parallel until a convergence criterion is satisfied. the machine reassignment problem was subject of the roadef/euro challenge in 2012, and the proposed algorithm ranked fourth in the final round of the senior category of the competition.
digital_control	this study presents a k-band differential voltage-controlled oscillator (vco) with robust start-up. a hybrid technique that combines open-loop digitally controlled tail current with switchable auxiliary cross-coupled pairs (accps) is proposed to ensure robust start-up for wideband operation. compared with prior closed-loop current controlling method, the proposed technique does not suffer from phase-noise degradation. furthermore, by evenly distributing the accps, transistors with smaller size are allowed to achieve the same start-up condition, which leads to frequency boost and phase-noise improvement. implemented in 0.18 m complementary metal-oxide-semiconductor technology, the vco achieves a wide-frequency tuning range of 21.4-26.29 ghz (20.5%) and a low phase noise of -108.8 dbc/hz at 1 mhz offset from 25.8 ghz carrier frequency. at 1.1 v power supply, the power consumption of the core circuit is 7.9-11.4 mw across the entire output frequency range.
electric_motor	the risk of epidemics and emerging or re-emerging diseases such as avian flit, tuberculosis, malaria and other vector-borne diseases, is rising. these risks can be contained with prevention, early warning, and prompt management. despite progress in information technology, communication is still a bottleneck for health early warning and response systems in post-disaster situations. this paper presents satellites for epidemiology (safe), a component-based interoperable architecture for health early warning that employs satellite, radio, and wireless networks, geographic information systems, integration technology, and data mining to promptly identify, and respond to a disease outbreak. in a post-disaster situation, a mobile health emergency coordination center is established and integrated to public health services for health monitoring. the added-value of safe for post-disaster health management will he demonstrated as part of an earthquake readiness exercise regarding a typhoid fever epidemic, in the island of crete. advanced communication and data mining techniques in safe offer new tools to the ""epidemic intelligence"" and contribute to advanced preparedness and prompt response by lifting communication barriers, promoting collaboration, and reducing the isolation of affected areas.
symbolic_computation	we study the nonlinear dynamics of (2 + 1) dimensional ferromagnetic (fm) spin system with bilinear and biquadratic interactions in the semiclassical limit and the dynamics is found to be governed by a new integrable fourth order nonlinear schrodinger (nls) equation in (2 + 1) dimensions. the integrability is identified by using lax pair operators and soliton solutions are obtained using straightforward darboux transformation (dt) technique. the model hamiltonian representing (2 + 1) dimensional fm spin chain with varying bilinear and biquadratic interactions are also constructed and inhomogeneity effects are studied by performing a perturbation analysis. moreover, the modulational instability (mi) aspects are discussed through analytical solutions and graphical illustrations. (c) 2015 elsevier b.v. all rights reserved.
operational_amplifier	this paper presents a chopper instrumentation amplifier designed in 28nm cmos technology. the operational amplifier has a rail-to-rail folded cascode input stage, which ensures a constant gm over the available common-mode range. it is characterized by a nested miller compensation. all transistors operate in sub-threshold region; thus the opamp has been designed through a specific procedure for sub-threshold operation. the chopper technique is exploited to reduce the input referred offset and noise. the circuit operates with 0.9v supply voltage and exhibits a simulated 106db dc gain and 329khz gbw. montecarlo simulations demonstrate an offset distribution with 2.2 mu v standard deviation. the input noise spectral density is equal to 27nv/hz, giving a noise efficiency factor of 8.
parallel_computing	we have witnessed the tremendous momentum of the second spring of parallel computing in recent years. but, we should remember the low points of the field more than 20 years ago and review the lesson that has led to the question at that point whether ""parallel computing will soon be relegated to the trash heap reserved for promising technologies that never quite make it"" in an article entitled ""the death of parallel computing"" written by the late ken kennedy a prominent leader of parallel computing in the world. facing the new era of parallel computing, we should learn from the robust history of sequential computation in the past 60 years. we should study the foundation established by the model of turing machine (1936) and its profound impact in this history. to this end, this paper examines the disappointing state of the work in parallel turing machine models in the past 50 years of parallel computing research. lacking a solid yet intuitive parallel turing machine model will continue to be a serious challenge in the future parallel computing. our paper presents an attempt to address this challenge by presenting a proposal of a parallel turing machine model. we also discuss why we start our work in this paper from a parallel turing machine model instead of other choices.
algorithm_design	responding to the difficulties of implementing meta-heuristics hybridization, this paper introduces a set of scripting language constructs for the rapid algorithm design and development focusing on the two well-known meta-heuristics, namely particle swarm optimization (pso) and genetic algorithm (ga). additionally, the pso-ga hybrids have been embedded with dynamic parameterization. in this paper, the compiler specification and codes for developing the scripting language constructs are described. then, based on the several algorithms of pso-ga hybrids that have been developed with the scripting language constructs, the line of codes (loc) are measured in order to test the easiness of the programming language. the results show that across all algorithms, the scripting language is anticipated to enable easy programming, which has been presented by the very less of loc compared to the java programming language.
electricity	risk analysis is essential for attracting investment to solar projects. this paper measures risk as the variability in internal rate of return (irr) and estimates it from the uncertainty in (i) future systems prices, (ii) operations costs and (iii) revenues based on energy yield, irradiance and electricity prices. we quantify these risks for photovoltaic (pv) and concentrated photovoltaic (cpv) projects starting in 2016, 18 and 20 for customers selling solar-generated electricity under a fixed feed-in tariff (fit) and for large business customers displacing electricity loads that they would pay for according to variable market rates. an international comparison of results is provided. uncertainty in future systems prices causes on average 45% (pv) and 93% (cpv) variation in irr, which is important to a developer 's planning process but is resolvable with negotiated system prices from suppliers. uncertainty in future operations costs impacts the irr by on average 17% (pv) and 20% (cpv). uncertainty in revenues impacts the irr by at most 3.6%. furthermore, the analysis shows that overall percentage variability in a project 's irr is much less than the percentage variability in operations costs and revenues, which are the two factors at play once the system is operating. (c) 2017 elsevier ltd. all rights reserved.
computer_graphics	3d models of humans are commonly used within computer graphics and vision, and so the ability to distinguish between body shapes is an important shape retrieval problem. we extend our recent paper which provided a benchmark for testing non-rigid 3d shape retrieval algorithms on 3d human models. this benchmark provided a far stricter challenge than previous shape benchmarks. we have added 145 new models for use as a separate training set, in order to standardise the training data used and provide a fairer comparison. we have also included experiments with the faust dataset of human scans. all participants of the previous benchmark study have taken part in the new tests reported here, many providing updated results using the new data. in addition, further participants have also taken part, and we provide extra analysis of the retrieval results. a total of 25 different shape retrieval methods are compared.
electric_motor	internal combustion engines inherently demand startup assistance to perform its autonomous functioning. nevertheless, the common solution over more than one century has been the electric starter motor, for both otto and diesel cycles. the dynamic coupling system defined herein as the mechanical connection between the internal combustion engine and the starter motor has not evolved considerably since the intermittent pinion-ring gear interface has been adopted. this paper reviews the conceptual design behind the starting systems developed so far, focusing on their functional analysis, and proposes an innovative concept. preliminary study on dynamic simulation using lumped parameters model, implemented in amesim, is also discussed as potential aid for the proposed design. based on decision matrix method, it is possible to evaluate the proposed design against state-of-the-art and promising alternatives to find a real cost-effective alternative to the existing concepts to couple the electric motor and the internal combustion engine. the patented dynamic coupling system proposed herein demonstrates potential to evolve as a cost-effective solution to implement start-stop systems worldwide, contributing to reduction of pollution caused by automotive vehicle emissions.
signal-flow_graph	this paper proposes a new relaxation-based circuit simulation algorithm called backward-traversing waveform relaxation (btwr). btwr employs a brand new strategy to simulate: it simulates by performing depth-first search in the signal flow graph of simulated circuits. major advantage of btwr is the ability to flexibly schedule subcircuits for calculating according to subcircuits' converging situations, which enables btwr to act robustly as well as efficiently in dealing with various types of circuits. the simulation on demand (sod) function is also constructed in btwr. all proposed methods have been implemented and tested by simulating various circuits.
pid_controller	the relay autotuner provides a simple way of finding pid controller parameters. even though relay autotuning is much investigated in the literature, the practical aspects are not that well-documented. in this paper an asymmetric relay autotuner with features such as a startup procedure and adaptive relay amplitudes is proposed. parameter choices and handling of noise, disturbances, start in non-steady state and other possible error sources are discussed. the autotuner is implemented and tested on an industrial air handling unit to show its use in practice. the experiments show good results, and prove that the proposed simple autotuner is well-suited for industrial use. but the experiments also enlighten possible error sources and remaining problems. (c) 2016 elsevier ltd. all rights reserved.
data_structures	low-rank representation (lrr) is a useful tool for seeking the lowest rank representation among all the coefficient matrices that represent the images as linear combinations of the basis in the given dictionary. however, it is an unsupervised method and has poor applicability and performance in real scenarios because of the lack of image information. in this paper, based on lrr, we propose a novel semi-supervised approach, called label constrained sparse low-rank representation (lcslrr), which incorporates the label information as an additional hard constraint. specifically, this paper develops an optimization process in which the improvement of the discriminating power of the low-rank decomposition is presented explicitly by adding the label information constraint. we construct lcslrr-graph to represent data structures for semi-supervised learning and provide the weights of edges in the graph by seeking a low-rank and sparse matrix. we conduct extensive experiments on publicly available databases to verify the effectiveness of our novel algorithm in comparison to the state-of-the-art approaches through a set of evaluations.
operational_amplifier	based on the action principle of continuous wave doppler radio fuze, the hardware-in-the-loop simulation system is designed. will test the role of the fuze doppler signal which the fuze generated will be collected by using precision operational amplifier opa378, after its adjustment to the processor, the processor will collect the signal to ad conversion, and upload to the host computer, the received dopple signal waveform is displayed, to stop after the threshold accepted. finally, the experimental results show that the system can simulate the cw doppler airfuse fuze.
network_security	in the current era of computer and communication rapid development, network security has become one of the most important factors to consider. security considerations in wireless sensor networks (wsns) have been an interesting point in research especially with the fast spread of wsns. in this paper, an efficient two-layer and three-layer intrusion detection models are introduced. the two-layer model represents the levels of the sensor and sink nodes. the three-layer model represents the levels of the sensor, sink and base station. the models are elaborated and examined through a set of experiments. a supervised learning algorithm is introduced to be used in the sensor node layer and an unsupervised learning algorithm is introduced to be used in the other layers. the learning algorithms used only 10% of the data for training and gave a high detection accuracy on the used dataset, using lesser number of features compared to other approaches.
symbolic_computation	based on the invariant subspace method, a symbolic computation scheme and its corresponding maple package are developed to construct exact solutions for nonlinear evolution equations. in the symbolic computation scheme, a crucial step is constructing the linear differential equations as invariant subspaces that systems of evolution equations admin and taking their solutions as subspaces to construct exact solutions. the maple package is proved to provide an easy way for constructing exact solutions of evolution equations automatically by only inputting several necessary parameters. three different types of examples are given to illustrate the scope and demonstrate the validity of our package, especially for wave equation. the results of the examples reveal that there are polynomial subspaces, trigonometric subspaces, exponential subspaces and other complex subspaces as invariant subspaces that evolutions equations admit. in addition, our maple software package provides a helpful and easy-to-use tool in science and engineering to deal with a wide variety of (1+1) dimensional nonlinear evolution equations.
symbolic_computation	in this paper, a -dimensional generalized shallow water wave equation is investigated through bilinear hirota method. interestingly, the breather-type and lump-type soliton solutions are obtained. furthermore, dynamic properties of the soliton waves are revealed by means of the asymptotic analysis. based on hirota bilinear method and riemann theta function, we succeed in constructing quasi-periodic wave solutions with a generalized form. we also display the asymptotic properties of these quasi-periodic wave solutions and point out the relation between the quasi-periodic wave solutions and the soliton solutions.
parallel_computing	as a global optimization algorithm, genetic algorithm is an advantageous tool due to its global convergence, great robustness, suitable for parallel computing and so on. selection of optimal parameters, e.g., maximum generations, population size, and genetic operators (crossover fraction and mutation fraction), is extremely crucial for particle size characterization by ultrasound attenuation spectroscopy with genetic algorithm. a series of particle system with different distribution functions were numerically investigated in this work it revealed that the simulated results were consistent with the given particle size distribution when the maximum generations, population size crossover fraction and mutation fraction were appropriate chosen. furthermore, the anti-noise performance of genetic algorithm and its three improved forms applied in particle system with bimodal distribution were also studied. two groups of samples (micron-sized glass beads-glycerol suspension and aqueous polystyrene suspension) were investigated experimentally by ultrasound attenuation spectroscopy, and it showed a good agreement between improved genetic algorithm 3 (iga3) and microscope image analysis (mia). (c) 2016 elsevier b.v. all rights reserved.
parallel_computing	fpga-based accelerators have recently evolved as strong competitors to the traditional gpu-based accelerators in modern high-performance computing systems. they offer both high computational capabilities and considerably lower energy consumption. high-level synthesis (hls) can be used to overcome the main hurdle in the mainstream usage of the fpga-based accelerators, i.e., the complexity of their design flow. hls enables the designers to program an fpga directly by using high-level languages, e.g., c, c++, systemc, and opencl. this paper presents an hls-based fpga implementation of several algorithms from a variety of application domains. a performance comparison in terms of execution time, energy, and power consumption with some high-end gpus is performed as well. the algorithms have been modeled in opencl for both gpu and fpga implementation. we conclude that fpgas are much more energy-efficient than gpus in all the test cases that we considered. moreover, fpgas can sometimes be faster than gpus by using an fpga-specific opencl programming style and utilizing a variety of appropriate hls directives.
pid_controller	fiber laser can be used for fiber optic communications, laser cutting, industrial manufacture, defense security and many other fields because of its advantages of narrow output linewidth, good reproducibility, etc. however, due to nonlinear and thermal effects, only a limited output power of a single fiber can be obtained with a sharp attenuation of the output beam quality, which obstructs the applications of fiber lasers. therefore, the research of expanding the power of a fiber laser source while maintaining its beam quality by combining coherent beam has become a hot subject at present. in this field, the performance of phase control of coherent laser beams is a key factor to influence the efficiency of combination. the phase-controlling methods mainly include stochastic parallel gradient descent control algorithm, dithering, and heterodyne detection. in this paper, based on the active phase lock technology, the traditional heterodyne detection method is improved by the use of a fiber electro-optic phase modulator (eom) rather than an acousto-optic frequency shifter (aofs) to avoid the complex designs of the rf driver and circuit, which makes the overall experimental setup simple and stable. moreover, in order to achieve a stable and wide correction range of phase locking, two servo paths are designed by use of piezoelectric transducer (pzt) and eom1 to correct the optical phase differences. firstly, a single-frequency narrow-width fiber laser with its central wavelength of 1531 nm is split by a beam splitter to generate a signal and a reference beam, respectively. the reference beam is phase modulated by another eom2 with a 15 mhz signal. the phase error signal is obtained by demodulating the detected heterodyne signal at the modulation frequency. after that the error signal is divided into two parts, and sent to two pid servos to control pzt and eom1, respectively. the pzt, used in the slow feedback loop, eliminates the laser phase error induced by the ambient temperature drift, while the eom1, in the quick feedback loop, can eliminate the influence of high frequency noise. two pid servos are carefully designed according to the measurements of the dynamic response of the pzt and eom1. a stable feedback loop with a bandwidth of 220 khz (limited by the bandwidth of pid controller) is obtained according to the measurement of its phase error signal spectrum, thus a tight lock is expected. as a consequence, the error of phase locking is less than 0.88 degrees, which indicates that the phase control accuracy is lambda/400. the long-term stability of the system is assessed by a 2 hour monitoring of the lock error signal. according to the analysis of allan deviation, the best phase lock value of 0.006 degrees can be obtained for an integration time of 160 s. the overall phase lock experimental setup is simple and easy to operate; moreover the phase lock can be further improved by optimizing the parameters of the pid controller.
operating_systems	the pillars of computer science and engineering (cse) curriculum are data structures, database management systems, languages, operating systems and algorithms. this article explains the relationship and connectivity of these core courses. authors follow the pedagogy technique to teach the data structures (ds) by considering its evolution. the article focus on the method of providing connectivity between the building blocks of ds like data containers, container iterators, algorithms and functors. each data structure is explained by considering its property, iterations, problems and applications. the three fold method is followed to teach ds, which includes think, build and discuss phases. the pedagogy techniques practiced by authors are revealed many mysteries, which are not discussed in most of the ds text books.
analog_signal_processing	floating-gate mos transistor (fgmos) has proved to be suitable for low-voltage analog applications, owing to its threshold voltage programmability. this tutorial paper presents fgmos based circuit structures and their applications in analog signal processing. the fgmos based current mirror and its application as voltage controlled current source has been presented. the performance of these structures has been verified using pspice simulations for 0.5 m cmos technology at number0.75 v.
parallel_computing	modern semiconductor detectors allow for charged particle tracking with ever increasing position resolution. due to the reduction of the spatial hit uncertainties, multiple coulomb scattering in the detector layers becomes the dominant source for tracking uncertainties. in this case long distance effects can be ignored for the momentum measurement, and the track fit can consequently be formulated as a sum of independent fits to hit triplets. in this paper we present an analytical solution for a three-dimensional triplet(s) fit in a homogeneous magnetic field based on a multiple scattering model. track fitting of hit triplets is performed using a linearization ansatz. the momentum resolution is discussed for a typical spectrometer setup. furthermore the track fit is compared with other track fits for two different pixel detector geometries, namely the mu3e experiment at psi and a typical high-energy collider experiment. for a large momentum range the triplets fit provides a significantly better performance than a single helix fit. the triplets fit is fast and can easily be parallelized, which makes it ideal for the implementation on parallel computing architectures.
computer_programming	image definition will be influenced by alignment errors of mirrors in an optical system consisting of hyperbolic, parabolic or ellipse mirrors. the major factors of alignment errors are gravity, wind loads and heat exchange for some optical systems like ground-based telescopes, while vibration and temperature gradient for systems like space telescopes. larger telescopes are more sensitive to these error sources, which becomes the concerns of researchers. so the alignment errors of mirrors must be corrected in time to keep systems working in best condition. in order to solve the problem, many methods are proposed based on the detection of wave-front errors using wave-front sensors like hartmann-shack. however, wave-front sensors may not be used or cause optical systems to be more complicated. for example, multi-fields must be tested when telescope is working. on the one hand, if a wave-front sensor is used, it must be moved around imaging plane, on the other hand, if more wave-front sensors are used, system must be more complicated. so a new method is discussed for alignment error correction by evaluating the quality of spot diagrams based on the using of stochastic parallel gradient descent (spgd) algorithm. the method considers the performance metric like spot diagram radius as a function of control parameters and then uses the spgd optimization algorithm to improve the performance metric. the control parameters include positions of mirrors. the iteration process must be used in the right way to control position parameters. if it is not considered, a problem may come up that positions of spot diagrams may be influenced by the iteration. furthermore, spot diagrams will probably disappear from detectors. then the radii of spot diagrams are not correct. so a better way is put forward by the combination of de-center and tilt of mirrors. the way ensures that the position error produced by de-center and tilt are compensated for. a formula is provided in this paper to give the relationship between them. based on the analysis, an optical system is designed to verify the conclusion. the spgd algorithm is achieved by computer programming and the position of the mirror is controlled by a hexapod. firstly, the problem is verified that the spot diagram will disappear from the detector with a normal iteration process. then the new way is implemented. in the iteration process, the spot diagram is always in the center of the detectors. in order to prove the feasibility of the method, three different alignment errors are tested and all of them each give an airy disk finally. the experiment can provide reference for engineering practice.
cryptography	modern cryptography increasingly employs random numbers generated from physical sources in lieu of conventional software-based pseudorandom numbers, primarily owing to the great demand of unpredictable, indecipherable cryptographic keys from true random numbers for information security. thus, far, the sole demonstration of true random numbers has been generated through thermal noise and/or quantum effects, which suffers from expensive and complex equipment. in this paper, we demonstrate a method for self-powered creation of true random numbers by using triboelectric technology to collect random signals from nature. this random number generator based on coupled triboelectric and electrostatic induction effects at the liquid dielectric interface includes an elaborately designed triboelectric generator (teng) with an irregular grating structure, an electronic optical device, and an optical electronic device. the random characteristics of raindrops are harvested through teng and consequently transformed and converted by electronic optical device and an optical electronic device with a nonlinear characteristic. the cooperation of the mechanical, electrical, and optical signals ensures that the generator possesses complex nonlinear input output behavior and contributes to increased randomness. the random number sequences are deduced from final electrical signals received by an optical electronic device using a familiar algorithm. these obtained random number sequences exhibit good statistical characteristics, unpredictability, and unrepeatability. our study supplies a simple, practical, and effective method to generate true random numbers, which can be widely used in cryptographic protocols, digital signatures, authentication, identification, and other information security fields.
electrical_network	this work presents a three-phase harmonics measurement method based on the msdft (modulated sliding discrete fourier transform) and a variable sampling period technique. the proposal allows measuring the harmonic components of a three-phase signal and computes the corresponding imbalance by estimating its positive, negative and zero sequence. in addition, an adaptive variable sampling period is used in order to obtain a sampling frequency multiple of the main frequency. msdft high rejection to distortions in the electrical network and flexibility of proposed method makes it an interesting alternative for the design of grid power monitors.
image_processing	high spatial resolution images as well as image processing and object detection algorithms are recent technologies that aid the study of biodiversity and commercial plantations of forest species. this paper seeks to contribute knowledge regarding the use of these technologies by studying randomly dispersed native palm tree. here, we analyze the automatic detection of large circular crown (lcc) palm tree using a high spatial resolution panchromatic geoeye image (0.50 m) taken on the area of a community of small agricultural farms in the brazilian amazon. we also propose auxiliary methods to estimate the density of the lcc palm tree attalea speciosa (babassu) based on the detection results. we used the ""compt-palm"" algorithm based on the detection of palm tree shadows in open areas via mathematical morphology techniques and the spatial information was validated using field methods (i.e. structural census and georeferencing). the algorithm recognized individuals in life stages 5 and 6, and the extraction percentage, branching factor and quality percentage factors were used to evaluate its performance. a principal components analysis showed that the structure of the studied species differs from other species. approximately 96% of the babassu individuals in stage 6 were detected. these individuals had significantly smaller stipes than the undetected ones. in turn, 60% of the stage 5 babassu individuals were detected, showing significantly a different total height and a different number of leaves from the undetected ones. our calculations regarding resource availability indicate that 6870 ha contained 25,015 adult babassu palm tree, with an annual potential productivity of 27.4 t of almond oil. the detection of lcc palm tree and the implementation of auxiliary field methods to estimate babassu density is an important first step to monitor this industry resource that is extremely important to the brazilian economy and thousands of families over a large scale. (c) 2017 elsevier ltd. all rights reserved.
electrical_network	the primary purpose of this article is to study the impact of distributed generator (dg) integrated into the distribution system in terms of electrical line losses, reliability and interruption cost. the single- and multi-distributed generators (dg) under this study are connected to a 22 kv distribution system of the provincial electricity authority (pea) that is a part of thailand 's distribution system. geographic information systems data, including the lengths of the distribution line and the load locations that are key parameters of pea, are simulated using digital simulation and electrical network calculation program (digsilent). in addition, the capacity and location of dg installed into the distribution system are considered. the system average interruption frequency index (saifi), the system average interruption duration index (saidi) and the interruption cost are assessed as reliability indices by comparing the saifi, saidi, and interruption cost of the base case (without dg) and the cases of single- and multi-dgs connected to the distribution system. moreover, the electrical line loss is considered in terms of active power line loss, which is also compared with the base case. the results can be summarized by focusing on the location of dg, the capacity of dg, the number of dg, the size of the load, and the distance to the load, which are factors capable of impacting the electrical line loss, saifi, saidi, and interruption cost. (c) 2015 american institute of chemical engineers environ prog, 34: 1763-1773, 2015
operational_amplifier	in the present paper a novel automatic gain control pre-amplifier for hearing aid device is proposed and analyzed. the proposed design utilizes feedback and feed forward loop in order to control the gain of the device. input and output thresholds have been accommodated to provide dual control. the weak input signal is amplified in three modes. high gain for low input and low gain for high input forms the basis of amplification. the measured average power dissipation of the complete pre-amplifier is 410 mu w with a dual power supply of +/- 0.7 v in 180 nm technology node. frequency of operation is up to 20 khz.
electricity	here we present the technical and economical performances of a small scale trigeneration power plant based on solid oxide fuel cells and designed for a small residential cluster (i.e. 10 apartments). the energy system features a natural gas solid oxide fuel cell, a boiler, a refrigerator, and a thermal storage system. we compare different power plant configurations varying the size of the fuel cell and the refrigeration technology to satisfy the chilling demand (i.e. absorption or mechanical chiller). given that the ability to meet the power demand is crucial in this kind of applications, the plant performances are assessed following an optimal control strategy, as a function of different energy demand profiles and electricity prices, and of rated and part load efficiencies of each energy converter. the optimization of the energy system operating strategy is performed through a graph theory-based methodology. results are provided in terms of electrical and thermal efficiency, operating strategy, as well as economic saving, primary energy consumption reduction, and pay back period, considering different capital costs of the fuel cell. (c) 2016 elsevier ltd. all rights reserved.
symbolic_computation	this research deals with a novel approach to classification. new classifiers are synthesized as a complex structure via evolutionary symbolic computation techniques. compared to previous research, this paper synthesizes multi-input-multi-output (mimo) classifiers with different cost function based on distance measurements. an inspiration for this work came from the field of artificial neural networks (ann). the proposed technique creates a relation between inputs and outputs as a whole structure together with numerical values which could be observed as weights in ann. distances used in cost functions were: manhattan (absolute distances of output vectors), euclidean, chebyshev (maximum distance value), canberra distance, bray - curtis. the analytic programming (ap) was utilized as the tool of synthesis by means of the evolutionary symbolic regression. for experimentation, differential evolution for the main procedure and also for meta-evolution version of analytic programming was used iris data (a known benchmark for classifiers) was used for testing of the proposed method.
pid_controller	automatic voltage regulator (avr) is an equipment maintaining the terminal voltage of generators to a specific level all the time and under any load conditions. many controllers for avr system are designed based on a linearized normal model of avr system and they are not robust enough against uncertainties such as parameter variation and load change in the system. in this paper, a gray pid (gpid) controller is designed for avr system. the gpid controller consists of two parts, i.e. a conventional pid controller together with a gray compensation controller. in gpid controller, gray gm (0, n) model is used to estimate the uncertainties online, and a gray compensation controller is constructed according the estimation results to eliminate the effect of uncertainties. to further improve its performance, the gpid controller 's parameters are optimized through a new evolutionary algorithm, i.e., imperialist competitive algorithm (ica). the proposed gpid controller can effectively deal with the uncertainties in avr system. simulation results illustrate its effectiveness of the proposed control scheme.
image_processing	in the present research, we examined the effect of the starting and turning performances on the subsequent swimming parameters by (1) comparing the starting and turning velocities with the swimming parameters on the emersion and mid-pool segments and (2) by relating the individual behaviour of swimmers during the start and turns with subsequent behaviour on each swimming lap. one hundred and twelve 100m performances on the fina 2013 world swimming championships were analysed by an image-processing system (inthepool 2.0 (r)). at the point of the start emersion, the swimming parameters of the 100-m elite swimmers were substantially greater than the mid-pool parameters, except on the breaststroke races. on the other hand, no diminution in the swimming parameters was observed between the turn emersion and the mid-pool swimming, except on the butterfly and backstroke male races. changes on the surface swimming kinematics were not generally related to the starting or turning parameters, although male swimmers who develop faster starts seem to achieve faster velocities at emersion. race analysts should be aware of a transfer of momentum when swimmers emerge from underwater with implications on the subsequent swimming kinematics, especially for male swimmers who employ underwater undulatory techniques.
microcontroller	this paper further develops the concept of very large size flash-memory-based pulsewidth-modulated (pwm) algorithms for three-phase inverters. such algorithms differ from the conventional counter-based implementation, and they follow a preprogrammed optimal pwm pattern that is read from a very large size memory with magnitude and phase as coordinates. any sequence of states is thus possible within a pwm sampling interval. a novel digital structure has been built around the newly released flash memory integrated circuits. the paper demonstrates the feasibility of operation at any pwm sampling frequency up to 20 khz when using gigabit-size flash memory integrated circuits along any low-cost microcontroller with an spi peripheral. to empower the concept, a multioptimal pwm has been proposed and implemented on a 2-gbit memory table. the harmonics of the phase currents are reduced by more than 40% while a constant pwm sampling frequency is maintained in order to comply with the conventional vector control methods for grid or motor applications.
algorithm_design	it 's essential to establish a dynamic model of a wheeled tractor with suspended driver seat including air spring and magnetorheological (mr) damper to analyze its vibration characteristics and performance. the equivalent linearized model of the wheeled tractor always neglects the effect of nonlinear stiffness for scissors linkage driver seat and air spring with auxiliary chamber as well as dynamic characteristics of real tractor tyre and considers the driver seat as linear spring and damper elements, which causes the analysis to have a lower precision. we considered the effect of nonlinear stiffness for scissors linkage seat and air spring with auxiliary chamber as well as mr damper and dynamic characteristics of real tyre and developed a complete nonlinear dynamic model of wheeled tractor with suspended driver seat including air spring and mr damper. the experimental results demonstrate that the improved nonlinear dynamic model is more consistent with the actual state than the equivalent linearized model, and the validity of the proposed model is verified. furthermore, the effect of forward speed, ratio of volume for air spring with respect to volume of auxiliary chamber, and area of orifice on the acceleration of wheeled tractor was also investigated, which can provide a theoretical basis for control algorithm design of semiactive vibration isolation system.
analog_signal_processing	this paper presents a current-processing current-controlled universal biquad filter. the proposed filter employs only two current controlled current conveyor transconductance amplifiers (cccctas) and two grounded capacitors. the proposed configuration can be used either as a single input three outputs (sito) or as three inputs single output (tiso) filter. the circuit realizes all live different standard filter junctions i.e. low-pass (lp), band-pass (bp), high-pass (hp), band-reject (br) and all-pass (ap). the circuit enjoys electronic control of quality factor through the single bias current without disturbing pole frequency. effects of non-idealities are also discussed. the circuit exhibits low active and passive sensitivity figures. the validity of proposed filter is verified through computer simulations using pspice.
analog_signal_processing	we present a viewpoint showing that analog signal processing approaches are becoming configurable and programmable like their digital counterparts, while retaining a huge computational efficiency, for a given power budget, compared to their digital counterparts. we present recent results in programmable and configurable analog signal processing describing the widespread potential of these approaches. we discuss issues with configurable systems, including size, power, and computational tradeoffs, as well as address the computational efficiency of these approaches. analog circuits and systems research and education can significantly benefit from the computational flexibility provided by large-scale fpaas. the component density of these devices is sufficient to synthesize large systems in a short period of time. however, this level of reconfigurable and programmable complexity requires a development platform and cad tools to demonstrate the capabilities of large-scale fpaas before they will be widely accepted. to address this need, a self-contained fpaa setup has been developed along with an integrated software design flow. with only an ethernet connection and an ac power outlet, a researcher or student can explore the numerous analog circuit possibilities provided by large-scale fpaas. (c) 2007 elsevier inc. all rights reserved.
microcontroller	transcranial magnetic stimulation devices has been used mainly for diagnostic purposes by measuring the functions of the nervous system rather than for treatment purposes, and has a problem of considerable energy fluctuations per repeated pulse. the majority of strokes are caused by ischemia and result in brain tissue damage, leading to problems of the central nervous system including hemiparesis, dysfunction of language and consciousness, and dysfunction of perception. control is difficult and the size is large due to the difficulty of digitalizing the energy stored in a capacitor, and there are many heavy devices. in addition, there are many constraints when it is used for a range of purposes such as head and neck diagnosis, treatment and rehabilitation of nerve palsy, muscle strengthening, treatment of urinary incontinence etc. output stabilization and minimization of the energy variation rate are required as the level of the transcranial magnetic stimulation device is dramatically improved and the demand for therapeutic purposes increases. this study developed a compact, low cost transcranial magnetic stimulation device with minimal energy variation of a high repeated pulse and output stabilization using a real time capacitor charge discharge voltage. ischemia was induced in male sd rats by closing off the common carotid artery for 5 minutes, after which the blood was re-perfused. in the cerebrum, the number of parp reactive cells after 24 hours significantly decreased (p < 0.05) in the tms group compared to the gi group. as a result, tms showed the greatest effect on necrosis-related parp immuno-reactive cells 24 hours after ischemia, indicating necrosis inhibition, blocking of neural cell death, and protection of neural cells.
pid_controller	previous studies have shown that mimicking a human hand can be very challenging due to the fact that the structure of the human hand was delicate and complex. for a robotic hand, a simple task such as holding a pen requires a greater understanding of various topics such as hand mechanics and design, forward and inverse kinematics, tactile and force sensors, actuators and control. in this paper a new design of a multifingered robot hand known as a red hand is proposed. the model of the red is developed by using solidworks and simechanics. the red hand consists of 5 fingers, 16 degrees of freedom and actuated by the brushless dc motor. a pid controller is employed to show the effectiveness of the red hand grasping control. the simulation result showed that the pid controller was satisfactorily controlled each joint of the red hand. in addition, the red hand is able to grasp less than 2 seconds without overshoot and producing very small steady state error.
digital_control	preventing voltage waveform distortion in multifrequency current control during saturated operation is a difficult problem, which so far has been only partially solved. in this paper, a scheme based on the principle of realizable references is proposed. as the converter enters saturated operation, an algorithm recalculates the converter-current reference such that unsaturated operation returns, i.e., the converter-voltage reference does not exceed the space-vector-modulation hexagon. distortion is thereby avoided, as is integrator windup.
analog_signal_processing	in order to realize the non-connect measurement on the power and character of jamming bomb, we carried out the research on power measurement device of jamming bomb based on infrared radiation. first, the power and infrared radiant band of the jamming bomb was summarized and refined. then, ensuring the feature and power of jamming bomb was characterized by the magnitude of infrared radiation. afterwards, based on the theory of the above, a power measurement device of infrared radiation was simulated and developed. including the selection of detector and the detector application design, analog signal processing and digital signal processing, using correlation measurement method to detect and calculate the power of device. finally, the specific method and advantage of the device was introduced. the results of the experiment show that: the response time of the device is less than 3ms; the detection sensitivity is better than 3 x 10(8)cm root hz / w. the device successfully accomplished the accuracy measurement of infrared radiation between 1 to 20um wavelength with higher detection sensitivity and lower response time.
algorithm_design	this paper presents a robust, distributed algorithm to solve general linear programs. the algorithm design builds on the characterization of the solutions of the linear program as saddle points of a modified lagrangian function. we show that the resulting continuous-time saddle-point algorithm is provably correct but, in general, not distributed because of a global parameter associated with the nonsmooth exact penalty function employed to encode the inequality constraints of the linear program. this motivates the design of a discontinuous saddle-point dynamics that, while enjoying the same convergence guarantees, is fully distributed and scalable with the dimension of the solution vector. we also characterize the robustness against disturbances and link failures of the proposed dynamics. specifically, we show that it is integral-input-to-state stable but not input-to-state stable. the latter fact is a consequence of a more general result, that we also establish, which states that no algorithmic solution for linear programming is input-to-state stable when uncertainty in the problem data affects the dynamics as a disturbance. our results allow us to establish the resilience of the proposed distributed dynamics to disturbances of finite variation and recurrently disconnected communication among the agents. simulations in an optimal control application illustrate the results.
machine_learning	objective: the goal of this study was to develop a practical framework for recognizing and disambiguating clinical abbreviations, thereby improving current clinical natural language processing (nlp) systems' capability to handle abbreviations in clinical narratives. methods: we developed an open-source framework for clinical abbreviation recognition and disambiguation (card) that leverages our previously developed methods, including: (1) machine learning based approaches to recognize abbreviations from a clinical corpus, (2) clustering-based semiautomated methods to generate possible senses of abbreviations, and (3) profile-based word sense disambiguation methods for clinical abbreviations. we applied card to clinical corpora from vanderbilt university medical center (vumc) and generated 2 comprehensive sense inventories for abbreviations in discharge summaries and clinic visit notes. furthermore, we developed a wrapper that integrates card with metamap, a widely used general clinical nlp system. results and conclusion: card detected 27 317 and 107 303 distinct abbreviations from discharge summaries and clinic visit notes, respectively. two sense inventories were constructed for the 1000 most frequent abbreviations in these 2 corpora. using the sense inventories created from discharge summaries, card achieved an f1 score of 0.755 for identifying and disambiguating all abbreviations in a corpus from the vumc discharge summaries, which is superior to metamap and apache 's clinical text analysis knowledge extraction system (ctakes). using additional external corpora, we also demonstrated that the metamap-card wrapper improved metamap 's performance in recognizing disorder entities in clinical notes. the card framework, 2 sense inventories, and the wrapper for metamap are publicly available at https://sbmi.uth.edu/ccb/resources/abbreviation. htm. we believe the card framework can be a valuable resource for improving abbreviation identification in clinical nlp systems.
network_security	with the development of computer network technology, more closely the relationship between people and network. the current network security problem has also been gradually into the public 's field of vision, actively carried out on the network intrusion detection becomes an important direction of the development of the network security technology. on the basis of the original bp neural network, this paper puts forward an improved algorithm, and applied to network intrusion detection. after the test, the method is better than traditional convergence, better performance.
machine_learning	avian scavengers are declining throughout the world, and are affected by a large number of threats such as poisoning, electrocution, collision with man-made structures, direct persecution, changes in agricultural practices, landscape composition, and sanitary regulations that can reduce food availability. to formulate effective conservation strategies, it is important to quantify which of these factors has the greatest influence on demographic parameters such as territory occupancy and breeding success, and whether quantitative models can be transferred across geographic regions and political boundaries. we collated territory and nest monitoring data of the endangered egyptian vulture neophron percnopterus in the balkans to understand the relative influence of various factors on population declines. we monitored occupancy in 87 different territories and breeding performance of 405 territory-monitoring years between 2003 and 2015, with an overall territory occupancy rate of 69% and a mean productivity of 0.80 fledglings per occupied territory. we examined which of 48 different environmental variables were most influential in explaining variation in territory occupancy and breeding success in bulgaria and greece, and tested whether these models were transferrable to the former yugoslav republic of macedonia. territory occupancy and breeding success were affected by a wide range of environmental variables, each of which had a small effect that may not be the same across political boundaries. both models had reasonably good discriminative ability [area under the receiver-operated characteristic curve (auc) for territory occupancy = 0.871, auc for breeding success = 0.744], but were unsuccessful in predicting occupancy or breeding success in the external validation data set from a different country, possibly because the most influential factors vary geographically. management focussing on a small number of environmental variables is unlikely to be effective in slowing the decline of egyptian vultures on the balkan peninsula. we recommend that in the short term the reduction of adult mortality through the enforcement of anti-poison laws, and in the long term the adoption of large-scale landscape conservation programs that retain or restore historical small-scale farming practices may benefit vultures and other biodiversity.
pid_controller	medical robots are frequently used in minimally invasive surgery of the human body. a significant role to reach the position near the back wall of operating or artificial organs, play here the flexible or multibody effectors. this paper proposes a method of dynamics simulation of the effector serial chain with an electric drives in the form of dc motors and pid controllers in the simulink. the effector consists of four rigid bodies with six degrees of freedom in rrrs configuration. every joint of the effector is driven by the mathematical model of the dc motor. the pid controllers are applied to steer the movements of joints in velocity feedback loops and their parameters are identified by using the descent gradient optimization algorithm. a created model of dynamics will serve to instill algorithm running the effector on trajectory using the method of potential fields inside the tunnel, which will be obtained by using the medical imaging. the model in simulink allows to connect the model of dynamics, which was built by using the block diagram and simmechanics with code lines stored in the c language, where there is kept the created path planning algorithm.
signal-flow_graph	multi-loop feedback control has attracted considerable attention due to its simplicity and ease of implementation. 1 in order to simplify the cumbersome analysis of a multiloop circuit, the signal flow graph representation should be used rather than our familiar nodal analysis methods. this paper presents a criterion from the well-established mason 's formula for multi-loop oscillator in terms of signal flow graphs. the multi-loop oscillator circuit based on two operational transresistance amplifiers (otras) is used as an example.
digital_control	event-triggered control aims at reducing the resource utilization, especially the communication over the feedback link, while guaranteeing a certain control performance. although setpoint tracking problems are common in practice, the majority of the proposed approaches in literature focus on regulation problems. therefore, an event-triggered pi control design strategy with guaranteed performance is proposed in this paper, where both the event-triggering condition and the pi controller are implemented periodically. based on a quadratic cost function, the pi control design problem is introduced and formulated as an lmi optimization problem. comparisons with other approaches in the literature are made by simulation and by experimental studies to demonstrate the effectiveness of the proposed strategy.
electrical_network	the emergence of more electric aircraft needs to adapt their electrical architecture and their level of power generation and storage. this paper deals with the optimal sizing of battery and supercapacitor systems to match their energetic performances with the aircraft requirements. in this application, the global weight is minimized by acting on variables which are the cut-off frequency of the filter used for energy management, the discharge ratio for storage components and temperature. the optimization results, obtained with the simulated annealing method, are assessed on the whole temperature range. finally, a relation between the cut-off frequency and temperature is determined to adjust the on-board energy management.
bioinformatics	micrornas (mirna) have been implicated in a variety of pathological conditions including infectious diseases. knowledge of the mirnas affected by poly(i: c), a synthetic analog of viral double-stranded rna, in porcine airway epithelial cells (paecs) contributes to understanding the mechanisms of swine viral respiratory diseases, which bring enormous economic loss worldwide every year. in this study, we used high throughput sequencing to profile mirna expression in paecs treated with poly(i: c) as compared to the untreated control. this approach revealed 23 differentially expressed mirnas (dems),five of which have not been implicated in viral infection before. nineteen of the 23 mirnas were downregulated including members of the mir-17-92 cluster, a well-known polycistronic oncomir and extensively involved in viral infection in humans. target genes of dems, predicted using bioinformatic methods and validated by luciferase reporter analysis on two representative dems, were significantly enriched in several pathways including transforming growth factor-b signaling. a large quantity of sequence variations (isomirs) were found including a substitution at position 5, which was verified to redirect mirnas to a new spectrum of targets by luciferase reporter assay together with bioinformatics analysis. twelve novel porcine mirnas conserved in other species were identified by homology analysis together with cloning verification. furthermore, the expression analysis revealed the potential importance of three novel mirnas in porcine immune response to viruses. overall, our data contribute to clarifying the mechanisms underlying the host immune response against respiratory viruses in pigs, and enriches the repertoire of porcine mirnas.
electricity	a novel hybrid system composed of a photocatalytic fuel cell (pfc) and fenton reactor was developed with the aim to degrade the azo dye reactive black 5 (rb5) and generate electricity. compared to previously established system of bioelectro-fenton system, microbial fuel cell (mfc) system has significant challenge in the development and operation system. therefore, pfc is used instead of mfc to generate electrons for the fenton system. the effect of azo dye (rb5) on each pfc and fenton reactor was investigated. the experimental results showed that maximum power output was achieved in the absence of dye in the fenton reactor of this hybrid system. furthermore, higher degradation efficiency of rb5 could also be observed in the pfc reactor in this hybrid system. (c) 2016 elsevier b.v. all rights reserved.
pid_controller	in this paper, an adaptive fuzzy controller design methodology via multiobjective particle swarm optimization (mopso) based on robust stability criterion, is proposed. the plant to be controlled is modeled from its input-output experimental data considering a takagi-sugeno (ts) fuzzy narx model, by using the fuzzy c-means clustering algorithm (antecedent parameters estimation) and weighted recursive least squares (wrls) algorithm (consequent parameters estimation). an adaptation mechanism as mopso problem for online tuning of a fuzzy model based digital pid controller parameters, based on the gain and phase margins specifications, is formulated. experimental results for adaptive fuzzy digital pid control of a thermal plant with time varying delay is presented to illustrate the efficiency and applicability of the proposed methodology.
electric_motor	the air pollution have become a major social problem. the motor is applied to the traction system. the traction motor operates in wide operation range. in this paper, 120kw concentrated winding ipmsm is presented as existing model. in the high speed, harmonics of the motor becomes large, it becomes a problem in the control side. therefore, when designing a vehicle electric motor, it is necessary to design motor in order to reduce no-load back electromotive force in coasting and harmonics in high speed. through winding method and tendency of permanent magnet, we study improvement to satisfy constraints about the harmonics in the high speed and back electromotive force in coasting of existing model. we need to improve design to satisfy the output characteristic. we get the design parameters through tendency analysis. so we design the final model by using design parameters. finally we verify final model 's electromotive characteristics using fem.
cryptography	wireless body area network (wban) provide a mechanism of transmitting a persons physiological data to application providers e.g. hospital. given the limited range of connectivity associated with wban, an intermediate portable device e.g. smartphone, placed within wban 's connectivity, forwards the data to a remote server. this data, if not protected from an unauthorized access and modification may be lead to poor diagnosis. in order to ensure security and privacy between wban and a server at the application provider, several authentication schemes have been proposed. recently, wang and zhang proposed an authentication scheme for wban using bilinear pairing. however, in their scheme, an application provider could easily impersonate a client. in order to overcome this weakness, we propose an efficient remote authentication scheme for wban. in terms of performance, our scheme can not only provide a malicious insider security, but also reduce running time of wban (client) by 51 % as compared to wang and zhang scheme.
control_engineering	this paper starts by revisiting some founding, classical ideas for neural networks as artificial intelligence devices. the basic functionality of these devices is given by stability related properties such as the gradient-like and other collective qualitative behaviors. these properties can be linked to the structural - connectionist - approach. a version of this approach is offered by the hyperstability theory which is presented in brief (its essentials) in the paper. the hyperstability of an isolated hopfield neuron and the interconnection of these neurons in hyperstable structures are discussed. it is shown that the so-called ""triplet"" of neurons has good stability properties with a non-symmetric weight matrix. this suggests new approaches in developing of artificial intelligence devices based on the triplet interconnection of elementary systems (neurons) in order to obtain new useful emergent collective computational properties.
symbolic_computation	in this paper, the stability and local bifurcation for the rotating blade under high-temperature supersonic gas flow are investigated using analytical and numerical methods. based on obtained four-dimensional averaged equation for the case of 1:1 internal resonance and primary resonance, two types of critical points for the bifurcation response equations are considered. the points are characterized by a double zero and two negative eigenvalues and two pairs of purely imaginary eigenvalues, respectively. for each type,the steady state solutions and the stability region is obtained with the aid of center manifold theory and normal form theory. we find the hopf bifurcation solution which indicates the blade will flutter. in summary, the numerical solutions, whose initial conditions are chosen in the stability region, agree with the analytic results. (c) 2015 elsevier inc. all rights reserved.
microcontroller	surveillance plays a crucial role in day-to-day life. a typical surveillance system continuously monitors its vicinity and stores the surveillance data locally. this may end up in lots of memory and energy wastage. moreover, the surveillance records are under security threat, when the surveillance system is seized or damaged by the intruders. in this paper, a new design for surveillance using smartphone along with the passive infrared (pir) sensor and the microcontroller unit (mcu) is proposed. the pir sensor is attached to the smartphone through the mcu to detect motion. the video is captured only when the motion is detected and the short message services alert is sent to the user straight away. to overcome the memory restrictions of smartphone and to ensure the safe storage of surveillance records, it is uploaded in cloud, and the link is sent to the user through email. the proposed intelligent surveillance system offers cost effective, storage effective, energy efficient, and secured solution as it uses the computation and communication capabilities of the smartphone and the storage capabilities of cloud.
lorentz_force_law	in this paper, a novel lorentz-force-driven dc planar motor with low force ripple is proposed. the magnetic field distribution is calculated analytically by using magnetic surface charge model and image method. the expressions of force and torque are derived based on the lorentz force law. a method for electromagnetic design of the motor is also discussed. the static force characteristic is measured experimentally. the experiment results are in good agreement with the results of the analysis and simulation.
algorithm_design	digital tomosynthesis is a three-dimensional imaging technique with a lower radiation dose than computed tomography (ct). due to the missing data in tomosynthesis systems, out-ofplane structures in the depth direction cannot be completely removed by the reconstruction algorithms. in this work, we analyzed the impulse responses of common tomosynthesis systems on a plane-to-plane basis and proposed a fast and accurate convolution-based blur-and-add (baa) model to simulate the backprojected images. in addition, the analysis formalism describing the impulse response of out-of-plane structures can be generalized to both rotating and parallel gantries. we implemented a ray tracing forward projection and backprojection (ray-based model) algorithm and the convolution-based baa model to simulate the shift-and-add (backproject) tomosynthesis reconstructions. the convolution-based baa model with proper geometry distortion correction provides reasonably accurate estimates of the tomosynthesis reconstruction. a numerical comparison indicates that the simulated images using the two models differ by less than 6% in terms of the root-mean-squared error. this convolution-based baa model can be used in efficient system geometry analysis, reconstruction algorithm design, out-of-plane artifacts suppression, and ct-tomosynthesis registration.
analog_signal_processing	this paper presents the optimal design of an electromagnetic vibration-based generator using the simulated annealing method (sa). to optimally extract the vibrational energy of a system vibrating at a specific frequency, the selected mass and spring stiffness of a resonant vibration is required. the relationship between induced energy and the generator 's structure, its permanent magnet height and diameter, number of turns, and wire diameter in a single air coil are discussed. also, a prototype of the vibration-based electrical generator is built and tested via a shaker excited at resonance frequency and input amplitude of 0.06mm. consequently, results reveal that the design parameters (permanent magnet height and diameter, number of turns, and wire diameter) play essential roles in maximizing electrical power.
analog_signal_processing	wave energy is currently an untapped resource, but has the potential to make a significant contribution to the energy mix. in order to use conventional electrical generators mechanical interfaces are used, such as hydraulic systems and air-turbines. with the electrical generator these interfaces are known as the electrical power take-off and the type used depends upon the wave energy device. a brief description of the different power take offs is provided to show how conventional rotary generators are used in wave devices. both advantages and disadvantages are highlighted in the paper. direct drive systems can overcome some of the disadvantages, but there are additional engineering challenges to overcome, in particular physical size and mass. current and more novel direct machine topologies are discussed in the context of these challenges.
electrical_circuits	electrochemical impedance spectroscopy and cyclic voltammetry techniques were employed to study borohydride oxidation on a polycrystalline pt electrode in an aqueous alkaline media containing 0.05 m nabh4 and 1 m naoh. determined current density changes were interpreted in combination with eis measurements. the regions of decreasing anodic current leading to negative polarization resistance, r-p, were supposed to be appreciably related to increasing availability of oxygen-containing species (ohad and pt oxides) on the pt surface in the presence of the accumulated borohydride species. possible borohydride oxidation processes and electrical circuits were discussed regarding the potential applied.
relational_databases	in this digital world every one seeks for the information on the internet. as the time passed every one placed their digital content on the web. on the web the website developers support to place the data in the relational databases. the databases from different organizations and agencies are available online and are accessible through web query interfaces. the web query interfaces act as the front door to access the information from these relational databases. but these web forms or web query interfaces need human intervention to submit the form data. so in order to make search engines capable of accessing the relational databases i.e. data behind query interfaces, the query generation should be done automatically. so in this paper we discuss the different form submission techniques to fetch the data from the databases and propose a novel technique ""dynamic query processing for hidden web data extraction"".
microcontroller	this paper presents a handheld robust battery-operated contact-based ovality meter suitable for the measurement of ovality in pipeline in a plant site or in any industrial establishment. the ovality meter is mainly composed of a specially designed inductor with ferrite core. this inductor constitutes the part of an lc-type logic gate oscillator (lgo). a change in the sensor position during the measurement of pipe diameter causes a small change in inductance, which in turn changes the pulse frequency of the lgo when it is powered by 5 v dc. thus, frequency, the output of the instrument that is displayed on the liquid crystal display of the embedded processor, is a function of displacement. by measuring the diameter of pipe specimen at different locations, the ovality is computed. in the present design, the range of position measurement is about 25 mm. the sensitivity in position measurement up to 10 mm is similar to 850 hz/mm, which further reduces in higher range (>10 to 25 mm). such a sensitivity in the position measurement seems to be quite suitable for ovality measurement.
network_security	with the development of trusted network, the research of trusted evaluation mechanism of user behavior is a hotpot in the network security. in order to solve the problems of subjectivity, limitations and static in traditional trusted network user behavior evaluation models, we have to find a real-time and dynamic evaluation method for user behavior. in this paper, the authors construct a real-time evaluation mechanism based on double evidence classification of user behavior (dec-ub). the evaluation mechanism includes the process classification and characteristic classification of user behavior evidence, which makes the user behavior evidence of any time can be directly involved in the trust evaluation, and the evaluation result is more comprehensive and accurate. simulation experiments have evaluated the three kinds of user behaviors based on the dec-ub, and compared them with the other two kinds of trust evaluation methods of user behavior, the results show that the proposed methods can evaluate the user 's behavior comprehensively, accurately and dynamically in complex network environments, and the results are more realistic.
computer_vision	establishing correspondences is a fundamental task in many image processing and computer vision applications. in particular, finding the correspondences between a non-linearly deformed image pair induced by different modality conditions is a challenging problem. this paper describes a simple but powerful image transform called local area transform (lat) for modality-robust correspondence estimation. specifically, tat transforms an image from the intensity domain to the local area domain, which is invariant under nonlinear intensity deformations, especially radiometric, photometric, and spectral deformations. experimental results show that latransformed images provide a consistency for nonlinearly deformed images, even under random intensity deformations. lat reduces the mean absolute difference by approximately 0.20 and the different pixel ratio by approximately 58% on average, as compared to conventional methods. furthermore, the reformulation of descriptors with lat shows superiority to conventional methods, which is a promising result for the tasks of cross-spectral and modality correspondence matching. lat gains an approximately 23% improvement in the correct detection ratio and a 10% improvement in the recognition rate for the tasks of rgb-nir cross-spectral template matching and cross-spectral feature matching, respectively. lat reduces the bad pixel percentage by approximately 15% and the root mean squared errors by 13.5 in the task of cross-radiation stereo matching. lat also improves the cross-modal dense flow estimation task in terms of warping error, providing 50% error reduction.
computer_graphics	this paper presents two within-subjects studies (n=23) exploring how different combinations of visual and auditory feedback influence perceived realism, virtual self-perception and the experience of safety during walks on a virtual platform suspended over a canyon. in the first study, the frequency factor of the footstep sounds was altered and the visual appearance was changed between a newly built wooden bridge and an old bridge with a weaker structure and broken planks. in the second study, the sounds of creaking wood were added to the footstep sounds in half of the trails and compared against footsteps without creaking sounds. moreover, the frequency factor of the frequency controls for footsteps was also manipulated between trails, but the visual appearance of the bridge was limited to the model of the old broken bridge.
microcontroller	the design of a biomechanics prosthesis for right hand whose dimensions and weight allow its adaptation to children over 8 years and adolescents, is presented. each finger is disposed in two sections, a fusion of the middle and distal phalanx, and a proximal phalanx articulated to the hand palm. the angles of the movement for the extension and flexion of all fingers, except the thumb, are controlled by a link located sideways. the drive system, which generates three degrees of freedom, is based on three linear actuators located in the palm, led by an arduino microcontroller and activated by a voice recognition system to execute the cylindrical grasp 's functions, the precision grasp, hook prehension and the extended index finger, is based on three linear actuators located on the palm, which have a reference potentiometer that provides its position, such indication is used by the microcontroller via the analogic input signal. to validate the design, a stresses and displacements analysis, and the determination of the safety factor that offers the device for the selected materials is carried out, using a computer program based on the finite element method. the results obtained show a light prosthetic device that weights 200 grams, and can operate safely allowing four grip functions with the normal angles of the hand.
parallel_computing	mining with big data or big data mining has become an active research area. it is very difficult using current methodologies and data mining software tools for a single personal computer to efficiently deal with very large datasets. the parallel and cloud computing platforms are considered a better solution for big data mining. the concept of parallel computing is based on dividing a large problem into smaller ones and each of them is carried out by one single processor individually. in addition, these processes are performed concurrently in a distributed and parallel manner. there are two common methodologies used to tackle the big data problem. the first one is the distributed procedure based on the data parallelism paradigm, where a given big dataset can be manually divided into n subsets, and n algorithms are respectively executed for the corresponding n subsets. the final result can be obtained from a combination of the outputs produced by the n algorithms. the second one is the mapreduce based procedure under the cloud computing platform. this procedure is composed of the map and reduce processes, in which the former performs filtering and sorting and the later performs a summary operation in order to produce the final result. in this paper, we aim to compare the performance differences between the distributed and mapreduce methodologies over large scale datasets in terms of mining accuracy and efficiency. the experiments are based on four large scale datasets, which are used for the data classification problems. the results show that the classification performances of the mapreduce based procedure are very stable no matter how many computer nodes are used, better than the baseline single machine and distributed procedures except for the class imbalance dataset. in addition, the mapreduce procedure requires the least computational cost to process these big datasets. (c) 2016 elsevier inc. all rights reserved.
signal-flow_graph	the structure of dynamic neural networks and their on-line learning algorithm are two important factors for naicss (nonlinear adaptive inverse control system). recurrent neural networks are effective identifiers for nonlinear plant. however, they have complex architecture. in order to simplify the structure of dynamic neural networks, this paper proposed an improved dafnn (dynamic activation function neural network) by changing the neurons' structure. the modified dfann with the same simple feedforward architecture as the origin one had better dynamic ability. gradient. vectors calculation becomes the chief bottleneck for learning algorithms of dafnns due to its complex chain rule expansions. a new on-line learning algorithm was proposed to simplify the proceeding of gradient calculation for dafnns in this paper according to signal flow graph theory. the new algorithm had adaptive learning rates to guarantee its convergence. the algorithm was used as the learning algorithms of identifier and controller in naicss. simulation results show it is an efficient algorithm for naicss.
algorithm_design	in this paper, a new approach has been proposed to design any arbitrary e-plane filters, including band-pass, and band-stop filters, with a desired frequency response. the proposed method is based on replacing all conventional resonators with a new form of a resonator, which is made of a patterned plane. the patterned plane is a metal plane with infinitesimal thickness that some of its parts, are removed. the introduced patterned plane is supported by a thin and low permittivity dielectric slab, and is located longitudinally in the middle of a rectangular waveguide, parallel to the e-plane. to design the proposed filters, the scattering parameters of the structure should be calculated. for this purpose, a coupled set of electric field integral equations have been derived, and solved by method of moments. then, a suitable cost function was defined, and optimized using genetic algorithm. matlab ga tool has been used to optimize the cost function. the proposed method facilitates and accelerates the optimization process in comparison to full wave simulator software. as examples, both band-pass, and band-stop e-plane filters have been designed. the results show that the proposed filter, in comparison to the conventional filters, has some advantages, such as frequency band selectivity, compactness, and the ability of adjustment to any desired frequency response. the results of designed structures are validated by hfss simulator software.
bioinformatics	a previous bioinformatics analysis identified the mycobacterium tuberculosis proteins rv2125 and rv2714 as orthologs of the eukaryotic proteasome assembly chaperone 2 (pac2). we set out to investigate whether rv2125 or rv2714 can function in proteasome assembly. we solved the crystal structure of rv2125 at a resolution of 3.0 angstrom, which showed an overall fold similar to that of the pac2 family proteins that include the archaeal pbab and the yeast pba1. however, rv2125 and rv2714 formed trimers, whereas pbab forms tetramers and pba1 dimerizes with pba2. we also found that purified rv2125 and rv2714 could not bind to m. tuberculosis 20s core particles. finally, proteomic analysis showed that the levels of known proteasome components and substrate proteins were not affected by disruption of rv2125 in m. tuberculosis. our work suggests that rv2125 does not participate in bacterial proteasome assembly or function. importance although many bacteria do not encode proteasomes, m. tuberculosis not only uses proteasomes but also has evolved a posttranslational modification system called pupylation to deliver proteins to the proteasome. proteasomes are essential for m. tuberculosis to cause lethal infections in animals; thus, determining how proteasomes are assembled may help identify new ways to combat tuberculosis. we solved the structure of a predicted proteasome assembly factor, rv2125, and isolated a genetic rv2125 mutant of m. tuberculosis. our structural, biochemical, and genetic studies indicate that rv2125 and rv2714 do not function as proteasome assembly chaperones and are unlikely to have roles in proteasome biology in mycobacteria.
computer_vision	the core aspect of this work is a review for player detection and tracing. coaches and players prepare widely by studying the opponents attacking and self-protecting formations, plays and metrics before every game. moving object detection is one of the serious problems in the field of surveillance, traffic monitoring, computer vision, player tracking in sports video and so forth. detecting the objects in the video and tracking its movement to recognise its qualities have been a demanding examination zone in the area of computer image and image processing. the core aspect of this work is a review for player detection and tracking. as coaches and players prepare widely by studying the opponents offensive and defensive formations, plays and metrics before every game, tracking of player becomes a major problem because of different problems in appearance, occlusion and so on. this work offers an analysis on detection of objects, segmentation of objects and tracking of objects. it also provides the study of comparison of diverse methods used for player tracking.
electricity	smart meters play vital roles in the aspects of the management and operation of smart grids such as demand response, energy efficiency improvement, and electricity pricing. massive amounts of data are being collected owing to the popularity of smart meters. two main issues should be addressed in this context. one is the communication and storage of big data from smart meters at reduced cost. the other is the effective extraction of useful information from this massive dataset. in this paper, the k-svd sparse representation technique, which includes two phases (dictionary learning and sparse coding), is used to decompose load profiles into linear combinations of several partial usage patterns (pups), which allows the smart meter data to be compressed and hidden electricity consumption patterns to be extracted. then, a linear support vector machine (svm) based method is used to classify the load profiles into two groups, residential customers and small and medium-sized enterprises (smes), based on the extracted patterns. comprehensive comparisons with the results of k-means clustering, the discrete wavelet transform (dwt), principal component analysis (pca), and piecewise aggregate approximation (paa) are conducted on real datasets in ireland. the results show that our proposed technique outperforms these methods in both compression ratio and classification accuracy.
computer_vision	switched systems theory is used to analyze the stability of image-based observers for three-dimensional localization of objects in a scene in the presence of intermittent measurements due to occlusions, feature tracking losses, or a limited camera field of view, for example. generally, observers or filters that are exponentially stable under persistent measurement availability may have unbounded error growth under intermittent measurement loss, even while providing seemingly accurate state estimates. by constructing a framework that utilizes a state predictor during periods when measurements are not available, a class of image-based observers is shown to be exponentially convergent in the presence of intermittent measurements if an average dwell time, and a total unmeasurability time, condition is satisfied. the conditions are developed in a general form, applicable to any observer that is exponentially convergent assuming persistent visibility, and utilizes object motion knowledge to reduce the amount of time measurements must be available to maintain convergence guarantees. based on the stability results, simulations are provided to show improved performance compared to a zero-order hold approach, where state estimates are held constant when measurements are not available. experimental results are also included to verify the theoretical results, to demonstrate applicability of the developed observer and predictor design, and to compare against a typical approach using an extended kalman filter.
operating_systems	uncertainty quantification (uq) refers to quantitative characterization and reduction of uncertainties present in computer model simulations. it is widely used in engineering and geophysics fields to assess and predict the likelihood of various outcomes. this paper describes a uq platform called uq-pyl (uncertainty quantification python laboratory), a flexible software platform designed to quantify uncertainty of complex dynamical models. uq-pyl integrates different kinds of uq methods, including experimental design, statistical analysis, sensitivity analysis, surrogate modeling and parameter optimization. it is written in python language and runs on all common operating systems. uq-pyl has a graphical user interface that allows users to enter commands via pull-down menus. it is equipped with a model driver generator that allows any computer model to be linked with the software. we illustrate the different functions of uq-pyl by applying it to the uncertainty analysis of the sacramento soil moisture accounting model. we will also demonstrate that uq-pyl can be applied to a wide range of applications. (c) 2015 the authors. published by elsevier ltd.
machine_learning	the problem of stereoscopic image quality assessment, which finds applications in 3d visual content delivery such as 3dtv, is investigated in this work. specifically, we propose a new paraboost (parallel boosting) stereoscopic image quality assessment (pbsiqa) system. the system consists of two stages. in the first stage, various distortions are classified into a few types, and individual quality scorers targeting at a specific distortion type are developed. these scorers offer complementary performance in face of a database consisting of heterogeneous distortion types. in the second stage, scores from multiple quality scorers are fused to achieve the best overall performance, where the fuser is designed based on the parallel boosting idea borrowed from machine learning. extensive experimental results are conducted to compare the performance of the proposed pbsiqa system with those of existing stereo image quality assessment (siqa) metrics. the developed quality metric can serve as an objective function to optimize the performance of a 3d content delivery system. (c) 2017 elsevier inc. all rights reserved.
software_engineering	along with the progress in computer hardware architecture and computational power, in order to overcome technological bottlenecks, software applications that make use of expert and intelligent systems must race against time where nanoseconds matter in the long-awaited future. this is possible with the integration of excellent solvers to software engineering methodologies that provide optimization-based decision support for planning. since the logistics market is growing rapidly, the optimization of routing systems is of primary concern that motivates the use of vehicle routing problem (vrp) solvers as software components integrated as an optimization engine. a critical success factor of routing optimization is quality vs. response time performance. less time-consuming and more efficient automated processes can be achieved by employing stronger solution algorithms. this study aims to solve the vehicle routing problem with simultaneous pickup and delivery (vrpspd) which is a popular extension of the basic vehicle routing problem arising in real world applications where pickup and delivery operations are simultaneously taken into account to satisfy the vehicle capacity constraint with the objective of total travelled distance minimization. since the problem is known to be np-hard, a hybrid metaheuristic algorithm based on an ant colony system (acs) and a variable neighborhood search (vns) is developed for its solution. vns is a powerful optimization algorithm that provides intensive local search. however, it lacks a memory structure. this weakness can be minimized by utilizing long term memory structure of acs and hence the overall performance of the algorithm can be boosted. in the proposed algorithm, instead of ants, vns releases pheromones on the edges while ants provide a perturbation mechanism for the integrated algorithm using the pheromone information in order to explore search space further and jump from local optima. the performance of the proposed acs empowered vns algorithm is studied on well-known benchmarks test problems taken from the open literature of vrpspd for comparison purposes. numerical results confirm that the developed approach is robust and very efficient in terms of both solution quality and cpu time since better results provided in a shorter time on benchmark data sets is a good performance indicator. (c) 2016 elsevier ltd. all rights reserved.
electrical_network	this paper proposes to study the impacts of distributed generation on energy losses and voltage drop in 10 kv line in the gjilani distribution system. input data, including the lengths and impedance of 10 kv distribution lines and maximum load (p-max) is used to create network model using a digital simulation and electrical network calculation program digsilent/power factory. the model is used to analyze power and energy losses and voltage drop in 10 kv lines in the distribution system. in addition, the capacity and location of dg connected to the distribution system is considered. the results show that, with enough capacity of installed dg the power and energy losses and voltage drop in last point of 10 kv line are reduced.
pid_controller	the objective of the proposed work is to investigate the performance of hybrid self tuned fuzzy proportional integral derivative (stfpid) controller for brushless dc (bldc) motor drive. the proposed hybrid stfpid controller includes a proportional integral derivative (pid) controller at steady state, a pid type self tuned fuzzy logic (fl) controller (stflc) at transient state thereby combining the merits of both the controllers. the switching function incorporated in the controller ensures desired control response at various operating conditions by appropriately switching between pid and stfpid based on speed error. a detailed simulation study and performance comparison with other control approaches is performed to highlight the merits of the proposed work. the simulation results indicate that the proposed controller is robust with fast tracking capability and less steady state error. the experimental results are provided to validate the simulation study.
operating_systems	these days the number of processors in computer systems is increasing in a very fast speed, and different manufacturers are producing computers with manycore processors. in turn, these manycore computer systems require a new operating system that can solve the problems of commodity operating systems. commodity operating systems originally made for single, dual or multi-cores systems; they will have lower performance and scalability problem for higher number of cores that are hundreds or thousands in number. in this regard, scholars of different research institutions are trying to develop their own solutions for existing problems among commodity operating systems and the recently emerging the manycore processor. this paper intends to see what those manycore operating systems are. the main objective of this paper is to compare and contrast some of manycore operating systems, analyze their experimental results, and give some summarizing concepts. manycore operating systems are developing from either the scratch or the amendment on the existing commodity operating systems. operating systems projects that develop a manycore operating system from the scratch, need lots of effort, and generally new approaches are applied. they use completely new technical approaches for development of oses for increased number of cores. operating systems like fos and barrelfish are some examples of operating systems that developed from the scratch. on the other hand, some operating system projects focus on commodity oses problems for increased number of cores. these projects amend commodity operating systems and/or used them collectively. therefore, their main task is preparing systems that play an important role for this amendment. as compared with the above operating system development approach, these approaches are simple and more manycore oses used it. operating systems like fusedos, cerberus and others are such a type of operating systems. in this respect, this paper will see the reason behind the selection of either of the two approaches. also will provide highlights about the basic structural differences among the existing manycore operating systems, in order to catch the philosophy behind them.
operating_systems	this paper proposes a framework for the development of sensor node software for various operating systems in a sensor network environment. the proposed development framework consists of attributes, code templates and development support tool. sensor node software is developed, based on the framework through four steps - sensor network modeling, pim design, psm design and code generation. accordingly, this paper presents the methods for attributes design, code templates design, pim-to-psm mapping, and source code generation. through the proposed technique, reusability of sensor network software will be increased since models, attributes and code templates can be reused for various operating systems through the framework. productivity of software development will be increased, because software design is easily performed using attributes and software codes for all nodes in the sensor network can be generated at once from a model. also, expandability of sensor network software will be increased, since new functions of existing operating systems or new operating systems can be added through the framework and sensor network software can be rebuilt by applying the added functions or operating systems.
state_space_representation	a new system model based on state space representation of the received signal for narrow-band interference suppression in direct sequence-spread spectrum (ds-ss) system is given. this model recursively estimates the interfering signal in the presence of desired information and white gaussian noise. to further improve the performance, we employ mmse criteria to estimate the transmitted symbols. the mmse estimate requires low computational complexity than code-aided techniques. our simulation results demonstrate that this technique provides better sinr improvement over to nonlinear predictor, linear predictor, kalman-bucy predictor for -65 db to -5 db input sinr and up to 10 db awgn power. for high interfering signal and noise power, our results clearly show that our sinr improvement performance exceeds the sinr improvement upper-bound calculated for the prediction based techniques. besides reducing the effect of interfering signal, our technique also reduces awgn noise. our model also provides better ber performance than nonlinear predictor.
software_engineering	among many factors that influence the success of a software project, the software process model employed is an essential one. an improper process model will be time consuming, error-prone and cost expensive, and further lower the quality of software. therefore, how to choose an appropriate software process model is a very important problem for software development. current works focus on the selection criteria and often lead to subjective results. in this paper, we propose a software process model recommendation method, to help project managers choose the most appropriate software process model for a new project at an early stage of development process according to historical software engineering data. the proposed method casts the process model recommendation into a classification problem. it first evaluates the different combinations of the alternative classification and attribute selection algorithms, and the best one is used to build the recommendation model with historical software engineering data; then, the constructed recommendation model is used to predict process models for a new software project with only a few data. we also analyze the mutual impacts between process models and different types of project factors, to further help managers locate the most suitable process model. we found process models are also responsible for defect count, defect severity and software change. experiments on the data sets from 37 different development teams of different countries show that the average recommendation accuracy of our method reaches up to 82.5%, which makes it potentially useful in practice. (c) 2016 elsevier inc. all rights reserved.
image_processing	in this article, we present literature reviews on fire prevention methods, especially in mining industries, using thermal image processing techniques. fire protection systems are crucial because of the increased loss of human lives due to coal fires and fatal explosions in coal mines across the world in the past few decades. and with the growth in the demand for energy and the mining of coal expected up to the year 2050, determining conditions leading up to a breakout of fire is paramount. to detect uncertain fire breakout conditions, thermal imaging is considered the most significant among several early warning methods to recognize spontaneous combustion of coal piles (e.g., temperature recordings by sensors, compaction testing of ore seam, gas tests). the evolution of thermographic imaging applied in various industrial sectors (e.g., coal furnaces, oil tankers, building inspections, security) with numerous applications of mathematical models will be presented in the light of safety dimensions in the mining industry. the missing links or unattended areas of mathematics in the application of thermal image processing in mining, especially in the coal industry, will be evolved as the gap in knowledge suggested in our concluding statements.
relational_databases	the large-scale aggregation and analysis of user opinions is becoming increasingly relevant to a variety of applications, from detecting social mood on some political topics to tracking their sentiment changes related to events. the analysis of diverse sentiments is another important application, which becomes possible based on the ability of modern methods to capture sentiment polarity on various topics with high precision and on the ever-growing scale. therefore, there is a need for a scalable way of sentiment aggregation with respect to the time dimension, which stores enough information to preserve diversity, and which allows statistically accurate analysis of sentiment trends and opinion shifts. in this paper, we are focusing on the novel problem of aggregating diverse sentiments at a large scale, based on data sources that are continuously updated. first, we develop a theoretical framework that models sentiment diversity (contradiction) and defines two types of contradictions, depending on the distribution of sentiments over time. second, we introduce novel measures that capture sentiment diversity from aggregated sentiment statistics. third, we develop robust and scalable indexing and storage methods for diverse sentiments. finally, we propose an adaptive approach for identifying contradictions at different time scales. the experimental evaluation demonstrates the effectiveness of the proposed method of capturing contradictions and its superiority over relational databases in real-world scenarios.
analog_signal_processing	modern electronic systems claim for analog-to-digital (a/d) interfaces with strong requirements in terms of resolution and frequency. among several a/d architectures that intent to achieve these hard specifications, time-interleaved analog-to-digital converters (tiadc) arises as a competitive candidate. tiadc offer a higher sampling frequency with suitable moderate power consumption. however, their architecture introduces mismatch errors that affect the resolution of data conversion. calibration methods permit to reduce significantly the impact of these errors. a possible solution is the insertion of an additional circuitry in the a/d conversion system: a built-in self-calibration (bisc). a bisc system aims to compensate imperfections from the tiadc, such as offset, gain and timing errors. despite the benefits carried by the bisc, this system also introduces errors in the overall data conversion system. this paper proposes a case study of a mixed-signal bisc tiadc, highlighting the strengths and the weakness of using built-in calibration circuits. supplementary calibration methods will be explored to mitigate the impact of the bisc and to improve the a/d conversion performance. the debate is open: how calibration systems must be calibrated ?
software_engineering	software product line (spl) development is a new approach to software engineering which aims at the development of a whole range of products. however, as long as spl can be useful, there are many challenges regarding the use of that approach. one of the main problems which hinders the adoption of software product line (spl) is the complexity regarding product management. in that context, we can remark the scoping problem. one of the existent ways to deal with scoping is the product portfolio scoping (pps). pps aims to define the products that should be developed as well as their key features. in general, that approach is driven by marketing aspects, like cost of the product and customer satisfaction. defining a product portfolio by using the many different available aspects is a np-hard problem. this work presents an improved hybrid approach to solve the feature model selection problem, aiming at supporting product portfolio scoping. the proposal is based in a hybrid approach not dependent on any particular algorithm/technology. we have evaluated the usefulness and scalability of our approach using one real spl (argouml-spl) and synthetic spls. as per the evaluation results, our approach is both useful from a practitioner 's perspective and scalable. (c) 2016 elsevier b.v. all rights reserved.
electric_motor	electric propulsion has emerged as one of the most efficient propulsion arrangements for several vessel types over the last decades. even though examples can be found in the history at the end of 19th century, and further into the 20th century, the modern use of electric propulsion started in the 1980s along with the development of semiconductor switching devices to be used in high power drives (dc drives and later ac-to-ac drives). this development opened up for full rpm control of propellers and thrusters, and thereby enabling a simplification of the mechanical structure. however, the main reason for using electric propulsion in commercial ship applications is the potential for fuel savings compared to equivalent mechanical alternatives, except for icebreakers where the performance of an electric powered propeller is superior to a combustion engine powered propeller. the fuel saving potential lies within the fact that the applicable vessels have a highly varying operation profile and are seldom run at full power. this favors the power plant principle in which electric power can be produced at any time with optimum running of prime movers, e.g., diesel engines, by turning on and off units depending on the power demand for propulsion and other vessel loads. icebreakers were among the first vessels to take advantage of this technology later followed by cruise vessel, and the offshore drilling vessels operating with dynamic positioning (dp). the converter technology was rapidly developing and soon the dc drives were replaced with ac drives. in the same period electric propulsion emerged as basic standard for large cruise liners, and dp operated drilling vessels, but also found its way into other segments as shuttle tankers, ferries, and other special vessels. at the same time podded propulsion were introduced, where the electric motor was mounted directly on the propeller shaft in a submerged 360 degrees steerable pod, adding better efficiency, improved maneuvering, and reduced installation space/cost to the benefits of electric propulsion. the future trends are now focusing on further optimization of efficiency by allowing multiple energy sources, independent operation of individual power producers, and energy storage for various applications, such as power back up, peak shaving, or emission free operation (short voyages).
system_identification	we present an iterative algorithm, called the symmetric tensor eigen-rank-one iterative decomposition (steroid), for decomposing a symmetric tensor into a real linear combination of symmetric rank-1 unit-norm outer factors using only eigendecompositions and least-squares fitting. originally designed for a symmetric tensor with an order being a power of two, steroid is shown to be applicable to any order through an innovative tensor embedding technique. numerical examples demonstrate the high efficiency and accuracy of the proposed scheme even for large scale problems. furthermore, we show how steroid readily solves a problem in nonlinear block-structured system identification and nonlinear state-space identification. (c) 2016 elsevier b.v. all rights reserved.
computer_programming	sparse matrix-vector multiplication (spmvm) is the most time-consuming kernel in many numerical algorithms and has been studied extensively on all modern processor and accelerator architectures. however, the optimal sparse matrix data storage format is highly hardware-specific, which could become an obstacle when using heterogeneous systems. also, it is as yet unclear how the wide single instruction multiple data (simd) units in current multi-and many-core processors should be used most efficiently if there is no structure in the sparsity pattern of the matrix. we suggest sellc-sigma, a variant of sliced ellpack, as a simd-friendly data format which combines long-standing ideas from general-purpose graphics processing units and vector computer programming. we discuss the advantages of sell-c-sigma compared to established formats like compressed row storage and ellpack and show its suitability on a variety of hardware platforms (intel sandy bridge, intel xeon phi, and nvidia tesla k20) for a wide range of test matrices from different application areas. using appropriate performance models we develop deep insight into the data transfer properties of the sell-c-sigma spmvm kernel. sell-c-sigma comes with two tuning parameters whose performance impact across the range of test matrices is studied and for which reasonable choices are proposed. this leads to a hardware-independent (""catch-all"") sparse matrix format, which achieves very high efficiency for all test matrices across all hardware platforms.
symbolic_computation	we have investigated the femtosecond soliton propagation in inhomogeneous fiber, which is described by the modified inhomogeneous hirota equation with variable coefficient (mih-vc). with the aid of akns method, corresponding lax pair is constructed. by virtue of the darboux transformation method and symbolic computation, the analytic one- and two-soliton solutions are explicitly obtained. using obtained solutions, we graphically discuss the features of femtosecond solitons in modified inhomogeneous hirota system by changing the profile of variable coefficients. we analyze various form of group velocity dispersion, third order dispersion and nonlinearity parameter for periodic amplification system, exponentially distributed system, parabolic solitons, periodic exponentially modulated system, which will be observable in the future experiments. these results are potentially useful in future experiments and soliton control for long-distance optical communication. finally, the soliton solutions of the mih-vc equation in double wronskian form is constructed and further verified using the wronskian technique by substitute in bilinear equations.
electrical_circuits	there is a lack of system-level finite element (fe) model which can directly predict the performance of a piezoelectric energy harvester connected with interface circuits and electric load. this work developed a system-level model of piezoelectric strain energy harvesting system by directly coupling the finite element and electrical circuits. the strain energy harvester (seh) is a macro fibber composite adhesively bonded to a composite beam. simulations were performed with the seh connected with three circuits individually (i) a load resistor, (ii) a rectifier terminated with a load resistor and (iii) a rectifier terminated with a smoothing capacitor and a load resistor. experimental tests were carried out to validate the simulation results. good agreements were observed between the simulated and measured results. the developed model is able to predict the performance of the energy harvesting system when different circuit was connected. the validated system-level model can be used for the design and optimization of piezoelectric energy harvesting system by investigating the interactions between energy harvester and electrical circuits.
electrical_network	in this paper, a new solution is proposed for the remote monitoring and control of distributed generators (dgs) and energy storage systems (esss) connected to low-voltage distribution networks. the proposed system fulfills the in-force standard requirements for the connection of dgs to the utility grid. moreover, it allows implementing some enhanced functions for the remote control of inverters of dgs and esss, not only in terms of disconnection but also in terms of voltage regulation and power shuttering. the proposed solution is based on a new interface protection system and a dedicated secondary substation concentrator, which allows the communication between the distributed system operator and the inverters of dgs or esss. the proposed system was tested on field in the electrical network of the island of ustica. an experimental characterization was carried out to find the best communication conditions, i.e., the frequency band with the lowest noise and attenuation, considering the signal amplitude and signal-to-noise ratio constraints, as well as the desired transmission data rate and transfer time.
pid_controller	in this article, we study the effects of the temperature control on a dehydration tomato slices process when two control strategies are considered: pid controller and optimal linear control when inherent input time delay is considered. the first controller is tuned by d-partitions method and a numerical procedure in order to minimize a quadratic performance index, the second one considers a state predictor to compensate the effects of the input delayed. the energy savings and the intrinsic characteristics in the tomato slices (vitamin c, total phenols, and lycopene levels) are quantified in order to conclude advantages of the two controllers under study.
network_security	complex traffic networks include a number of controlled intersections, and, commonly, multiple districts or municipalities. the result is that the overall traffic control problem is extremely complex computationally. moreover, given that different municipalities may have distinct, non-aligned, interests, traffic light controller design is inherently decentralized, a consideration that is almost entirely absent from related literature. both complexity and decentralization have great bearing both on the quality of the traffic network overall, as well as on its security. we consider both of these issues in a dynamic traffic network. first, we propose an effective local search algorithm to efficiently design system-wide control logic for a collection of intersections. second, we propose a game theoretic (stackelberg game) model of traffic network security in which an attacker can deploy denial-of-service attacks on sensors, and develop a resilient control algorithm to mitigate such threats. finally, we propose a game theoretic model of decentralization, and investigate this model both in the context of baseline traffic network design, as well as resilient design accounting for attacks. our methods are implemented and evaluated using a simple traffic network scenario in sumo.
electric_motor	the design principles and technical characteristics are considered for a computerized suite providing metrological service to a wide range of radio and electrical measuring instruments with a high degree of independence.
state_space_representation	lap time simulation is one of the most powerful tools for evaluating design proposals in motorsport engineering. in particular, transient simulations play an important role as the ultimate and more accurate approach than other static or quasi-steady-state methodologies. in this paper, first, the method to transform the differential equations of a system into a formally linear continuous and then discrete state-space representation, particularised for a seven-degree-of-freedom suspension and a transient cornering model, is proposed. the use of time-variant coefficients in the matrices of the model will allow the non-linear and time-variant characteristics of these systems to be described. second, in the case of the transient cornering model, this representation is translated into a transfer function in order to apply a discrete control strategy such as a finite-time strategy or a predictive strategy for an adaptive ideal driver. it was found that the calculation methodology described above can be successfully applied with a more than acceptable degree of accuracy according to comparison with the results using other mechanical or numerical software (adams or simulink). it was also observed that the use of the curvature of the track as a reference in the control closed loop is sufficiently accurate to force the car to follow the target path closely. furthermore, both predictive control and finite-time control (including integration) provide excellent results with a smooth response of the steering input. many lap time simulators are language specific; however, the methodology proposed in this paper will run in most programming languages.
pid_controller	this paper proposes an approach of forming the average performance by grey modeling, and use an average performance as reference model for performing evolutionary computation with error type control performance index. the idea of the approach is to construct the reference model based on the performance of unknown systems when users apply evolutionary computation to fine-tune the control systems with error type performance index. we apply this approach to particle swarm optimization for searching the optimal gains of baseline pi controller of wind turbines operating at the certain set point in region 3. in the numerical simulation part, the corresponding results demonstrate the effectiveness of grey modeling. (c) 2015 elsevier ltd. all rights reserved.
cryptography	field inversion in dominates the cost of modern software implementations of certain elliptic curve cryptographic operations, such as point encoding/hashing into elliptic curves (brown et al. in: submission to nist, 2008; brown in: iacr cryptology eprint archive 2008:12, 2008; aranha et al. in: cryptology eprint archive, report 2014/486, 2014) itoh-tsujii inversion using a polynomial basis and precomputed table-based multi-squaring has been demonstrated to be highly effective for software implementations (taverne et al. in: ches 2011, 2011; oliveira et al. in: j cryptogr eng 4(1):3-17, 2014; aranha et al. in: cryptology eprint archive, report 2014/486, 2014), but the performance and memory use depend critically on the choice of addition chain and multi-squaring tables, which in prior work have been determined only by suboptimal ad-hoc methods and manual selection. we thoroughly investigated the performance/memory tradeoff for table-based linear transforms used for efficient multi-squaring. based upon the results of that investigation, we devised a comprehensive cost model for itoh-tsujii inversion and a corresponding optimization procedure that is empirically fast and provably finds globally-optimal solutions. we tested this method on eight binary fields commonly used for elliptic curve cryptography; our method found lower-cost solutions than the ad-hoc methods used previously, and for the first time enables a principled exploration of the time/memory tradeoff of inversion implementations.
data_structures	full-spectrum dependent types promise to enable the development of correct-by-construction software. however, even certified software needs to interact with simply-typed or untyped programs, be it to perform system calls, or to use legacy libraries. trading static guarantees for runtime checks, the dependent interoperability framework provides a mechanism by which simplytyped values can safely be coerced to dependent types and, conversely, dependently-typed programs can defensively be exported to a simply-typed application. in this paper, we give a semantic account of dependent interoperability. our presentation relies on and is guided by a pervading notion of type equivalence, whose importance has been emphasized in recent work on homotopy type theory. specifically, we develop the notion of partial type equivalences as a key foundation for dependent interoperability. our framework is developed in coq; it is thus constructive and verified in the strictest sense of the terms. using our library, users can specify domain-specific partial equivalences between data structures. our library then takes care of the (sometimes, heavy) lifting that leads to interoperable programs. it thus becomes possible, as we shall illustrate, to internalize and hand-tune the extraction of dependently-typed programs to interoperable ocaml programs within coq itself.
bioinformatics	strawberry is one of the most economically important fruit crops in the world. cytokinins (cks) play a critical role in plant growth and development, as well as the stress response, and the level of cks in plants is regulated by synthesis and degradation pathways. the key synthetic enzymes of cks are isopentenyl transferases (ipts) and lonely guys (logs). we surveyed the strawberry genome and identified seven fvipt genes and nine fvlog genes. we analyzed gene structures, conserved domains, and their phylogenetic relationships with rice and arabidopsis. the isoelectric points and glycosylation sites of the proteins were predicted. we also analyzed tissue- or organ-specific expression patterns of the fvipt and fvlog genes. the fvipt and fvlog genes showed different expression profiles in different organs. most fvipt and fvlog genes were down-regulated in response to osmotic stress, high-temperature treatment, and exogenous abscisic acid (aba) application, suggesting possible roles of these genes in the plants' resistance to abiotic stresses. in addition, we found that the results of bioinformatics analyses to identify cis-regulatory elements may not be consistent with experimental expression data; thus, computer-predicted putative cis-elements need to be confirmed by experiments. our systematic analyses of the fvipt and fvlog families provide a foundation for characterizing the function of these genes in the regulation of growth, development, and stress tolerance in fragaria vesca, as well as a reference for improving stress tolerance by manipulating ck content.
pid_controller	today, the buildings' energy consumption is considerable amount of whole. therefore, optimizing energy in buildings leads to a noticeable decrease in total energy consumption of the world. energy-efficient buildings have developed by carrying out great research effort. the control procedures serve as a privileged method to help new buildings to comply with the most optimal system as an energy consumer and thus meet 'nearly zero-energy'. the purpose of this paper is to present a method of controlling the building temperature and simultaneously reducing the cost of providing the hybrid heating systems with sufficient energy. investigating a room in tehran city on a day as an example, methods of (a) model predictive control (mpc) with economic optimization (mpc consecutively with on-off), (b) mpc without economic optimization, (c) proportional-integral-derivative (pid) controller optimized by genetic algorithm (ga) in presence of gas thermal source, (d) pid controller optimized with ga in presence of electric thermal source and (e) pid controller optimized with multi-objective ga in the presence of two gas and electric thermal sources have been designed and implemented in this research. furthermore, the effect of each of these methods on cost reduction and temperature regulation of inside of the room has been studied. eventually it has been specified that using mpc method with economical optimization has the highest influence on cost reduction and keeps the temperature of inside of the room in the predefined range. this method achieved cost saving of 50% compared to the mpc and ga. but the main targets of this study are both of regulating inside temperature and cost optimization. according to the main targets of this study, using mpc methods without economical optimization and multi-objective genetic algorithm would be more effective. (c) 2016 elsevier b.v. all rights reserved.
relational_databases	the eminent web-applications of today are data-intensive. the data generated is of the order of petabytes and zetabytes. using relational databases for storing them only complicates the storage and retrieval in the db and degradation of its performance. the big data explosion demanded the need for a more flexible, high-performance storage concept the nosql movement. the nosql databases were designed to overcome the flaws of the relational databases including the security aspects. the effective performance and efficient storage criteria were satisfied by the non-relational databases. the attackers, as usual found their way into the nosql databases that were considered to be secure. the injection attacks, one of the top-listed attack type of the relational databases poses threat to the non-relational databases as well. mongodb is one of the prominent nosql databases to which the application development trends are shifting. in this paper, we present the different injection attacks on the leading nosql database and an automata based detection and prevention technique for this attack. we also evaluate the effectiveness on different subjects with a number of legitimate as well as illegitimate inputs. our results show that our approach was able to detect all the attacks.
bioinformatics	the multidrug and toxin extrusion (mate) transporter family comprises 70 members in the medicago truncatula genome, and they play seemingly important, yet mostly uncharacterized, physiological functions. here, we employed bioinformatics and molecular genetics to identify and characterize mate transporters involved in citric acid export, al3+ tolerance and fe translocation. mtmate69 is a citric acid transporter induced by fe-deficiency. overexpression of mtmate69 in hairy roots altered fe homeostasis and hormone levels under fe-deficient or fe-oversupplied conditions. mtmate66 is a plasma membrane citric acid transporter primarily expressed in root epidermal cells. the mtmate66 mutant had less root growth than the wild type under al3+ stress, and seedlings were chlorotic under fe-deficient conditions. overexpression of mtmate66 rendered hairy roots more tolerant to al3+ toxicity. mtmate55 is involved in seedling development and iron homeostasis, as well as hormone signaling. the mtmate55 mutant had delayed development and chlorotic leaves in mature plants. both knock-out and overexpression mutants of mtmate55 showed altered fe accumulation and abnormal hormone levels compared with the wild type. we demonstrate that the zinc-finger transcription factor mtstop is essentially required for mtmate66 expression and plant resistance to h+ and al3+ toxicity. the proper expression of two previously characterized mate flavonoid transporters mtmate1 and mtmate2 also depends on several transcription factors. this study reveals not only functional diversity of mate transporters and regulatory mechanisms in legumes against h+ and al3+ stresses, but also casts light on their role in metal nutrition and hormone signaling under various stresses. significance statement as there are many mate transporters in legumes, they potentially have diversified functions. here we analyzed mutants and overexpression lines for two mate transporters involved in citric acid export and aluminum tolerance and iron translocation, and one mate transporter affecting growth and development and iron homeostasis. manipulating the expression of these mate transporters might prove useful in improving tolerance to acidic soils and aluminum stress.
distributed_computing	by the reason of the variability of light and pedestrians' appearance, it is hard for a camera to obtain a clear human figure. person re-identification with different cameras is a difficult visual recognition task. in this paper, a novel approach called attribute learning based on distributed deep convolutional neural network model is proposed to address person re-identification task. it shows how attributes, namely the mid-level medium between classes and features, are obtained automatically and how they are employed to re-identify person with semantics when an author-topic model is used to mapping category. besides, considering the ability to operate on raw pixel input without the need to design special features, deep convolutional neural network is employed to generate features without supervision for attributes learning model. to overcome the model 's weakness in computing speed, parallelized implementations such as distributed parameter manipulation and attributes learning are employed in attribute learning based on distributed deep convolutional neural network model. experiments show that the proposed approach achieves state-of-the-art recognition performance in the viper data set and is with a good semantic explanation. copyright (c) 2016 john wiley & sons, ltd.
cryptography	first-order and high-order correlation-power-analysis attacks have been shown to be a severe threat to cryptographic devices. as such, they serve as a security measure for evaluation and comparison of security-oriented implementations. when properly designed, data-dependent delays can be used as a barrier to these attacks. this paper introduces a security-oriented delay assignment algorithm for mitigating single and multibit attacks. the algorithm enables a reduction of the correlation between the processed data and the consumed current by utilizing the data-dependent delays as a source of correlated noise. this is done while minimizing the area overhead, propagation time, and power. we show that for the same security level this new algorithm provides x2 and x6 more area efficiency, and x1.5 and x2.25 higher frequencies than a permuted path delay assignment and random embedding of delay elements.
pid_controller	features like high power to weight ratio, self lubrication, heat dissipation and fast control make hydraulic systems superior to mechanical and electric systems. such systems are used in aircraft, motion simulators, metal-cutting, universal-testing machines and material handling for heavy industries. for a precision operation, it is usual to employ electrohydraulic servo systems that are more sophisticated than systems with proportional valve. due to larger deadband and higher flow nonlinearities, the low-cost rugged proportional valves together with standard pid controllers result in poor response for tracking demand. a controller has been designed through a novel state estimation algorithm and the usual pole placement (pp) technique by carefully choosing the operating points. one high friction cylinder and another industrial grade cylinder have been driven separately by using the same proportional control valve. the designed controller has yielded better performance compare to the pid controller.
analog_signal_processing	in this paper, a new cmos minus-type current-controlled third-generation voltage conveyor (cc-vciii-) is presented. as application example using the presented new active building block a novel voltage-mode first-order all-pass filter is proposed, where instead of floating resistor the electronically controllable intrinsic resistance of the y terminal is used. hence, the circuit is resistorless and it shows low sensitivity performance. the behavior of the all-pass filter is verified by spice simulations and the tsmc 0.35 mu m level 3 cmos process parameters are used to confirm the theoretical analysis.
cryptography	revocation and key evolving paradigms are central issues in cryptography, and in pki in particular. a novel concern related to these areas was raised in the recent work of sahai, seyalioglu, and waters (crypto 2012) who noticed that revoking past keys should at times (e.g., the scenario of cloud storage) be accompanied by revocation of past ciphertexts (to prevent unread ciphertexts from being read by revoked users). they introduced revocable-storage attribute-based encryption (rs-abe) as a good access control mechanism for cloud storage. rs-abe protects against the revoked users not only the future data by supporting key-revocation but also the past data by supporting ciphertext-update, through which a ciphertext at time t can be updated to a new ciphertext at time t 1 using only the public key. motivated by this pioneering work, we ask whether it is possible to have a modular approach, which includes a primitive for time managed ciphertext update as a primitive. we call encryption which supports this primitive a ""self-updatable encryption"" (sue). we then suggest a modular cryptosystems design methodology based on three sub-components: a primary encryption scheme, a key-revocation mechanism, and a time-evolution mechanism which controls the ciphertext self-updating via an sue method, coordinated with the revocation (when needed). our goal in this is to allow the self-updating ciphertext component to take part in the design of new and improved cryptosystems and protocols in a flexible fashion. specifically, we achieve the following results: we first introduce a new cryptographic primitive called self-updatable encryption (sue), realizing a time-evolution mechanism. in sue, a ciphertext and a private key are associated with time. a user can decrypt a ciphertext if its time is earlier than that of his private key. additionally, anyone (e.g., a cloud server) can update the ciphertext to a ciphertext with a newer time. we also construct an sue scheme and prove its full security under static assumptions. following our modular approach, we present a new rs-abe scheme with shorter ciphertexts than that of sahai et al. and prove its security. the length efficiency is mainly due to our sue scheme and the underlying modularity. we apply our approach to predicate encryption (pe) supporting attribute-hiding property, and obtain a revocable storage pe (rs-pe) scheme that is selectively-secure. we further demonstrate that sue is of independent interest, by showing it can be used for timed-release encryption (and its applications), and for augmenting key-insulated encryption with forward-secure storage. (c) 2017 elsevier b.v. all rights reserved.
operating_systems	geoweb 2.0, laying the foundations of volunteered geographic information (vgi) systems, has led to platforms where users can contribute to the geographic knowledge that is open to access. moreover, as a result of the advancements in 3d visualization, virtual globes able to visualize geographic data even on browsers emerged. however the integration of vgi systems and virtual globes has not been fully realized. the study presented aims to visualize volunteered data in 3d, considering also the ease of use aspects for general public, using free and open source software (foss). the new application programming interface (api) of nasa, web world wind, written in javascript and based on web graphics library (webgl) is cross-platform and cross-browser, so that the virtual globe created using this api can be accessible through any webgl supported browser on different operating systems and devices, as a result not requiring any installation or configuration on the client-side, making the collected data more usable to users, which is not the case with the world wind for java as installation and configuration of the java virtual machine (jvm) is required. furthermore, the data collected through various vgi platforms might be in different formats, stored in a traditional relational database or in a nosql database. the project developed aims to visualize and query data collected through open data kit (odk) platform and a cross-platform application, where data is stored in a relational postgresql and nosql couchdb databases respectively.
electric_motor	design and performance of mechatronic systems depends on many factors and subsystems like gears, hydraulic components and electric motors. these latter are considered as a principle device in electromechanical power conversion, thus their design becomes of a prime importance. this paper aims to build electric motor models along with its control strategy and power electronics component in order to study the impact of the temperature rise in critical areas of this motor on mechatronic systems. this paper focuses on constructing a detailed thermal network of a permanent magnet synchronous machine and comparing it to experimental results in order to evaluate its accuracy. this model, along with the electromechanical model of the machine, the power converter and the control strategy are integrated and simulated in amesim - an advanced software environment for simulating mechatronic systems.
computer_programming	this work presents a new method of examining the structure of public-transport networks (ptns) and analyzes their topological properties through a combination of computer programming, statistical data and large-network analyses. in order to automate the extraction, processing and exporting of data, a software program was developed allowing to extract the needed data from general transit feed specification, thus overcoming difficulties occurring in accessing and collecting data. the proposed method was applied to a real-life ptnin auckland, new zealand, with the purpose of examining whether it showed characteristics of scale-free networks and exhibited features of ""small-world"" networks. as a result, new regression equations were derived analytically describing observed, strong, non-linear relationships among the probabilities of randomly chosen stops in the ptn to be serviced by a given number of routes. the established dependence is best fitted by an exponential rather than a power-law function, showing that the ptn examined is neither random nor scale-free, but a mixture of the two. this finding explains the presence of hubs that are not typical of exponential networks and simultaneously not highly connected to the other nodes as is the case with scale-free networks. on the other hand, the observed values of the topological properties of the network show that although it is highly clustered, owing to its representation as a directed graph, it differs slightly from ""small-world"" networks, which are characterized by strong clustering and a short average path length. (c) 2016 elsevier b.v. all rights reserved.
pid_controller	this paper proposes the application of fractional order pid controller (fopid) for reactive power compensation and stability analysis in a stand-alone micro grid. for enhancement of voltage stability and reactive compensation of the isolated system, a svc based controller has been incorporated. this paper emphasizes the role of fractional pid based svc controller for reactive power management and improved stability in the stand alone micro grid, as it provides a special advantage of having two more degree of freedom for accurate tuning in comparison with the conventional controller the system performance, particularly the variations in different parameters values are studied properly with different input parameters and loading conditions. further improvement of stability margin and optimisation of the system parameters have been achieved by the controller, based on imperialist competitive algorithm. (c) 2015 elsevier ltd. all rights reserved.
operational_amplifier	this paper presents an accurate design approach for two-stage cmos operational amplifiers developed based on the usual design procedure. it eliminates the errors existed in design results by employing the accurate mos model and carrying out the design procedure iteratively. the specifications of the amplifier designed by this approach match exactly with the user specified values. a design example in 0.18 mu m cmos technology is given to illustrate the effectiveness of the proposed design approach.
image_processing	the montage image mosaic engine was designed as a scalable toolkit, written in c for performance and portability across *nix platforms, that assembles fits images into mosaics. this code is freely available and has been widely used in the astronomy and it communities for research, product generation, and for developing next-generation cyber-infrastructure. recently, it has begun finding applicability in the field of visualization. this development has come about because the toolkit design allows easy integration into scalable systems that process data for subsequent visualization in a browser or client. the toolkit it includes a visualization tool suitable for automation and for integration into python: mviewer creates, with a single command, complex multi-color images overlaid with coordinate displays, labels, and observation footprints, and includes an adaptive image histogram equalization method that preserves the structure of a stretched image over its dynamic range. the montage toolkit contains functionality originally developed to support the creation and management of mosaics, but which also offers value to visualization: a background rectification algorithm that reveals the faint structure in an image; and tools for creating cutout and downsampled versions of large images. version 5 of montage offers support for visualizing data written in healpix sky-tessellation scheme, and functionality for processing and organizing images to comply with the toast sky-tessellation scheme required for consumption by the world wide telescope (wwt). four online tutorials allow readers to reproduce and extend all the visualizations presented in this paper.
pid_controller	this paper presents a novel control scheme based on auto-tuning pid controller to suppress wing rock phenomena. due to having a complex dynamic, wing rock motion identification is not a simple task, and this complexity can adversely affect the performance of pid controller. employing a wavelet neural network based identifier, this paper develops an auto tuning adaptive pid controller to tackle the problem. since having an acceptable control performance inevitably involves having a meticulously trained identifier, the training performance is of utmost importance. aiming at boosting the training efficacy, a two-phase algorithm encompassing bees algorithm and back-propagation (bp) is proposed by this paper to train the proposed identifier respectively in off-line and on-line modes. due to its inherent capability in sifting the global minima, bees algorithm is employed to find initial values of weights around which it is then possible to conduct a local search by means of bp based online training. therefore, the identifier can precisely furnish the proposed pid controller with the system sensitivity in on-line mode. the adaption of pid controller can thus be performed in each time step. the performance of this method has been presented in simulation results and the comparison section confirms the effectiveness of proposed scheme.
computer_graphics	in this paper we survey all known (including own recent results) properties of the longest-edge n-section algorithms. these algorithms (in classical and recently designed conforming form) are nowadays used in many applications, including finite element simulations, computer graphics, etc. as a reliable tool for controllable mesh generation. in addition, we present a list of open problems arising in and around this topic. (c) 2015 elsevier b.v. all rights reserved.
electrical_network	this paper proposes a mathematical formulation for energy management in a connected microgrid. the aim is determining the optimal operating strategy for energy storage, to fulfil a time-varying energy demand and operational constraints while achieving a tradeoff between microgrid running costs and energy storage system life. the microgrid is composed by various renewable power production plants, storage devices and controllable loads, and has the ability to increase energy efficiency and reduce costs for energy purchasing from the main grid. the problem is formulated as a mixed-integer linear optimization problem. the optimization is aimed at minimizing the overall cost function of the system while satisfying the customer demand and safety of the electrical network. a case study of an existing microgrid is investigated: the microgrid consists of a photovoltaic and a hydroelectric power plant, a battery storage, an office building and an industrial facility. the optimization problem is solved in an efficient way by using commercial software. simulation results show the feasibility and the effectiveness of the proposed approach to satisfy the load and reduce total costs.
bioinformatics	background: female moths synthesize species-specific sex pheromone components and release them to attract male moths, which depend on precise sex pheromone chemosensory system to locate females. two types of genes involved in the sex pheromone biosynthesis and degradation pathways play essential roles in this important moth behavior. to understand the function of genes in the sex pheromone pathway, this study investigated the genome-wide and digital gene expression of sex pheromone biosynthesis and degradation genes in various adult tissues in the diamondback moth (dbm), plutella xylostella, which is a notorious vegetable pest worldwide. results: a massive transcriptome data (at least 39.04 gb) was generated by sequencing 6 adult tissues including male antennae, female antennae, heads, legs, abdomen and female pheromone glands from dbm by using illumina 4000 next-generation sequencing and mapping to a published dbm genome. bioinformatics analysis yielded a total of 89,332 unigenes among which 87 transcripts were putatively related to seven gene families in the sex pheromone biosynthesis pathway. among these, seven [ two desaturases (des), three fatty acyl-coa reductases (far) one acetyltransferase (act) and one alcohol dehydrogenase (ad)] were mainly expressed in the pheromone glands with likely function in the three essential sex pheromone biosynthesis steps: desaturation, reduction, and esterification. we also identified 210 odorantdegradation related genes (including sex pheromone-degradation related genes) from seven major enzyme groups. among these genes, 100 genes are new identified and two aldehyde oxidases (aoxs), one aldehyde dehydrogenase (aldh), five carboxyl/cholinesterases (cces), five udp-glycosyltransferases (ugts), eight cytochrome p450 (cyp) and three glutathione s-transferases (gsts) displayed more robust expression in the antennae, and thus are proposed to participate in the degradation of sex pheromone components and plant volatiles. conclusions: to date, this is the most comprehensive gene data set of sex pheromone biosynthesis and degradation enzyme related genes in dbm created by genome-and transcriptome-wide identification, characterization and expression profiling. our findings provide a basis to better understand the function of genes with tissue enriched expression. the results also provide information on the genes involved in sex pheromone biosynthesis and degradation, and may be useful to identify potential gene targets for pest control strategies by disrupting the insect-insect communication using pheromone-based behavioral antagonists.
machine_learning	we present a set of matlab/octave functions to compute measures of emergence, self-organization, and complexity applied to discrete and continuous data. these measures are based on shannon 's information and differential entropy. examples from different datasets and probability distributions are provided to show how to use our proposed code.
operating_systems	as recent heterogeneous system designs integrate general purpose processors, gpus, and other specialized accelerator devices into a single platform to provide both power and performance benefits, it is important to support efficient dispatching mechanisms in terms of performance and programmability. this work proposes models for integrating hardware accelerators with applications executing under standard operating systems on an embedded processor. instead of using direct mapping of accelerator units to user applications, or using legacy drivers that incur communication overheads and large programming effort, we develop an abstraction layer in kernel driver which driver communicates with a custom dispatcher to interface a number of hardware accelerators. at the same time we remove the need to include iommus for virtual-to-physical translation from the device side, and the need to perform copies from user to kernel space when offtoading computational instensive tasks to the accelerators. we demonstrate the effectiveness of our solutions running real applications on a prototype hybrid heterogeneous system-on-chip platform.
parallel_computing	using gpus as general-purpose processors has revolutionized parallel computing by providing, for a large and growing set of algorithms, massive data-parallelization on desktop machines. an obstacle to their widespread adoption, however, is the difficulty of programming them and the low-level control of the hardware required to achieve good performance. this paper proposes a programming approach, safegpu, that aims to make gpu data-parallel operations accessible through high-level libraries for object-oriented languages, while maintaining the performance benefits of lower-level code. the approach provides data-parallel operations for collections that can be chained and combined to express compound computations, with data synchronization and device management all handled automatically. it also integrates the design-by-contract methodology, which increases confidence in functional program correctness by embedding executable specifications into the program text. we present a prototype of safegpu for eiffel, and show that it leads to modular and concise code that is accessible for gpgpu non-experts, while still providing performance comparable with that of hand-written cuda code. we also describe our first steps towards porting it to c#, highlighting some challenges, solutions, and insights for implementing the approach in different managed languages. finally, we show that runtime contract-checking becomes feasible in safegpu, as the contracts can be executed on the gpu. (c) 2016 elsevier ltd. all rights reserved.
data_structures	this paper surveys value systems for developmental cognitive robotics. a value system permits a biological brain to increase the likelihood of neural responses to selected external phenomena. many machine learning algorithms capture the essence of this learning process. however, computational value systems aim not only to support learning, but also autonomous attention focus to direct learning. this combination of unsupervised attention focus and learning aims to address the grand challenge of autonomous mental development for machines. this survey examines existing value systems for developmental cognitive robotics in this context. we examine the definitions of value used-including recent pioneering work in intrinsic motivation as value-as well as initialisation strategies for innate values, update strategies for acquired value and the data structures used for storing value. we examine the extent to which existing value systems support attention focus, learning and prediction in an unsupervised setting. the types of robots and applications in which these value systems are used are also examined, as well as the ways that these applications are evaluated. finally, we study the strengths and limitations of current value systems for developmental cognitive robots and conclude with a set of research challenges for this field. (c) 2016 elsevier b.v. all rights reserved.
data_structures	v-order is a global order on strings related to unique maximal factorization families (umffs), themselves generalizations of lyndon words. v-order has recently been proposed as an alternative to lexicographic order in the computation of suffix arrays and in the suffix-sorting induced by the burrows-wheeler transform. efficient v-ordering of strings thus becomes a matter of considerable interest. in this paper we discover several new combinatorial properties of v-order, then explore the computational consequences; in particular, a fast, simple on-line v-order comparison algorithm that requires no auxiliary data structures. (c) 2016 elsevier b.v. all rights reserved.
state_space_representation	the paper summarises the properties of linear systems that are described by differential-algebraic equations (dae systems). it derives the conditions under which dae systems can be equivalently represented by a state-space model (ode systems). the index nu is introduced as an important parameter and its role is explained by examples.
image_processing	when an image is given with only some measurable data, e.g., projections, the most important task is to reconstruct it, i.e., to find an image that provides the measured data. these tomographic problems are frequently used in the theory and applications of image processing. in this paper, memetic algorithms are investigated on triangular grids for the reconstruction of binary images using their three and six direction projections. the algorithm generates an initial population using the network flow algorithm for two of the input projections. the reconstructed images evolve towards an optimal solution or close to the optimal solution, by using crossover operators and guided mutation operators. the quality of the images is improved by using switching components and compactness operator. (c) 2016 elsevier b.v. all rights reserved.
parallel_computing	this paper proposes a parallelized online optimization of low voltage distribution network (lvdn) operation. it is performed on a graphics processing unit (gpu) by combining the optimization procedure with the load flow method. in the case study, performed for the test lvdn with distributed generators (dgs) and controllable loads, differential evolution optimization based on a backward-forward sweep load flow method was parallelized on gpu. the goal of online optimization is to keep the lvdn voltage profile within the prescribed limits, to minimize lvdn losses, and to enable demand response functionality. this is achieved by the optimization determined reference values for the controllable load 's operation, and the reactive power generation, and active power curtailment of dgs. the results show that the parallelized gpu implemented optimization can be significantly faster than similar implementation on a central processing unit, and is, therefore, suitable for the online optimization of the presented lvdn.
data_structures	we consider the problems of computing the maximal and the minimal non-empty suffixes of substrings of a longer text of length n. for the minimal suffix problem we show that for every tau, 1 <= tau <= logn, there exists a linear-space data structure with o(tau) query time and o(n logn/tau) preprocessing time. as a sample application, we show that this data structure can be used to compute the lyndon decomposition of any substring of the text in o(k tau) time, where k is the number of distinct factors in the decomposition. for the maximal suffix problem, we give a linear-space structure with o(1) query time and o(n) preprocessing time. in other words, we simultaneously achieve both the optimal query time and the optimal construction time. (c) 2015 elsevier b.v. all rights reserved.
operational_amplifier	output voltage and an inverting input voltage of inverting amplifier circuit are measured when conducted disturbance is injected to power supply pin by dpi measurement. correlation between output voltage and inverting input voltage is shown.
machine_learning	this paper addresses the problem of finding credible sources among twitter social network users to detect and prevent various malicious activities, such as spreading false information on a potentially inflammatory topic, forging accounts for false identities, etc. existing research works related to source credibility are graph-based, considering the relationships among users to predict the spread information; human-based, using human perspectives to determine reliable sources; or machine learning-based, relying on training classifiers to predict users' credibility. very few of these approaches consider a user 's sentimentality when analyzing his/her credibility as a source. in this paper, we propose a novel approach that combines analysis of the user 's reputation on a given topic within the social network, as well as a measure of the user 's sentiment to identify topically relevant and credible sources of information. in particular, we propose a new reputation metric that introduces several new features into the existing models. we evaluated the performance of the proposed metric in comparison with two machine learning techniques, determining that the accuracy of the proposed approach satisfies the stated purpose of identifying credible twitter users. copyright (c) 2016 john wiley & sons, ltd.
digital_control	this paper presents the design and implementation of a digital control system for modular multilevel converters, based on digital signal processors. to achieve higher system control reliability and multi-functionality, the proposed architecture has been built with an effective split of the control tasks involved between a master controller and six slave controllers, one for each of the six arms of the converter. the master controller handles energy flow within the converter and user communication using ethernet and universal serial bus. each slave controller handles capacitors voltages balancing within the arm. intercommunication between the different boards is achieved mainly through optical fiber and inter integrated circuit bus. experiments have been carried out to verify the effectiveness of this architecture.
operational_amplifier	an accurate design of low power voltage controlled oscillator (vco) enabled quantizer in continuous time sigma delta adc in 180nm cmos technology using tanner eda tools is done. the proposed architecture consists of the loop filter, vco quantizer and the dac in the feedback side of model. the operational amplifier (opamp) used in designed of loop filters offers 40db gain, 70 degree phase margin and unity gain bandwidth of 79.06mhz that consuming power of 3 mw. even order harmonics of vco are reduced by vco quantizer loop structures. the higher order loop filter is designed using an active resistance and capacitive based integrators and vco quantizer is implemented using 15 multiple stage ring oscillator and register of dff which provides an added advantage of low phase noise with frequency of 100 khz rang. remarkable power dissipation of overall circuit is 3mw.
operating_systems	as the deceleration of processor scaling due to moore 's law accelerates research in new types of computing structures, the need arises for rethinking operating systems paradigms. traditionally, an operating system is a layer between hardware and applications and its primary function is in managing hardware resources and providing a common abstraction to applications. how does this function apply, however, to new types of computing paradigms? are operating systems even needed for these new structures? this paper revisits operating system functionality for new computing paradigms. the structure of these new computers is uncertain as there are many possibilities such as neuromorphic, bio-inspired, adiabatic, reversible, approximate, quantum, combinations of these and others unforeseen [1]. we do know, however, that whatever these new computers will be, there will be some need to manage their resources, to provide programming support, to partition, scale, and connect them and to deal with (partial) failure, along with other traditional operating system 's functionality. there might also be some new functionality, such as creating abstract control loops, reasoning about precision, new ways of reconfiguring, and more. we strongly believe that even if traditional operating systems functionality evolves, that the need for operating systems will remain in the new era of computing.
computer_vision	the computer graphics and computer vision communities have been working closely together in recent years, and a variety of algorithms and applications have been developed to analyze and manipulate the visual media around us. there are three major driving forces behind this phenomenon: 1) the availability of big data from the internet has created a demand for dealing with the ever-increasing, vast amount of resources; 2) powerful processing tools, such as deep neural networks, provide effective ways for learning how to deal with heterogeneous visual data; 3) new data capture devices, such as the kinect, the bridge between algorithms for 2d image understanding and 3d model analysis. these driving forces have emerged only recently, and we believe that the computer graphics and computer vision communities are still in the beginning of their honeymoon phase. in this work we survey recent research on how computer vision techniques benefit computer graphics techniques and vice versa, and cover research on analysis, manipulation, synthesis, and interaction. we also discuss existing problems and suggest possible further research directions.
software_engineering	software developers use many different communication tools and channels in their work. the diversity of these tools has dramatically increased over the past decade and developers now have access to a wide range of socially enabled communication channels and social media to support their activities. the availability of such social tools is leading to a participatory culture of software development, where developers want to engage with, learn from, and co-create software with other developers. however, the interplay of these social channels, as well as the opportunities and challenges they may create when used together within this participatory development culture are not yet well understood. in this paper, we report on a large-scale survey conducted with 1,449 github users. we discuss the channels these developers find essential to their work and gain an understanding of the challenges they face using them. our findings lay the empirical foundation for providing recommendations to developers and tool designers on how to use and improve tools for software developers.
electric_motor	induction motors fail due to many reasons, and many are rewound two or more times during their lifetimes. it is generally assumed that a rewound motor is not as efficient as the original motor. precise estimation of efficiency of a refurbished motor or any existing motor is crucial in industries for energy savings, auditing, and management. full-load and partial-load efficiency can be measured by using the dynamometer. this paper presents a novel technique for estimating refurbished induction motors' full-load and partial-load efficiencies from only no-load tests. the technique can be applied in any electric motor workshop and eliminates the need for the dynamometer procedure. it also eliminates the need for the locked-rotor test. experimental and field results of testing eight induction motors are presented, and the degree of accuracy is shown by comparing the estimated efficiencies against the measured values. to provide the necessary credits to the proposed technique, an error analysis is conducted to investigate the level of uncertainty through testing three induction motors, and the results of uncertainty of the direct measurements and no-load measurements using the proposed technique are presented.
software_engineering	context: reuse can improve productivity and maintainability in software development. research has proposed a wide range of methods and techniques. are these successfully adopted in practice? objective: we propose a preliminary answer by integrating two in-depth empirical studies on software reuse at two large software-producing companies. method: we compare and interpret the study results with a focus on reuse practices, effects, and context. results: both companies perform pragmatic reuse of code produced within the company, not leveraging other available artefacts. reusable entities are retrieved from a central repository, if present. otherwise, direct communication with trusted colleagues is crucial for access. reuse processes remain implicit and reflect the development style. in a homogeneous infrastructure supported context, participants strongly agreed on higher development pace and less maintenance effort as reuse benefits. in a heterogeneous context with fragmented infrastructure, these benefits did not materialize. neither case reports statistically significant evidence of negative side effects of reuse nor inhibitors. in both cases, a lack of reuse led to duplicate implementations. conclusion: technological advances have improved the way reuse concepts can be applied in practice. homogeneity in development process and tool support seem necessary preconditions. developing and adopting adequate reuse strategies in heterogeneous contexts remains challenging. (c) 2016 elsevier inc. all rights reserved.
bioinformatics	various model selection methods can be applied to seek sparse subsets of the covariates to explain the response of interest in bioinformatics. while such methods often offer very helpful predictive performances, their selections of the covariates may be much less trustworthy. indeed, when the number of covariates is large, the selections can be highly unstable, even under a slight change of the data. this casts a serious doubt on reproducibility of the identified variables. for a sound scientific understanding of the regression relationship, methods need to be developed to find the most important covariates that have higher chance to be confirmed in future studies. such a method based on variable selection deviation is proposed and evaluated in this work.
relational_databases	this article argues that the study of literary representations of landscapes can be aided and enriched by the application of digital geographic technologies. as an example, the article focuses on the methods and preliminary findings of litescape. pt-atlas of literary landscapes of mainland portugal, an on-going project that aims to study literary representations of mainland portugal and to explore their connections with social and environmental realities both in the past and in the present. litescape. pt integrates traditional reading practices and 'distant reading' approaches, along with collaborative work, relational databases, and geographic information systems (gis) in order to classify and analyse excerpts from 350 works of portuguese literature according to a set of ecological, socioeconomic, temporal and cultural themes. as we argue herein this combination of qualitative and quantitative methods-itself a response to the difficulty of obtaining external funding-can lead to (a) increased productivity, (b) the pursuit of new research goals, and (c) the creation of new knowledge about natural and cultural history. as proof of concept, the article presents two initial outcomes of the litescape. pt project: a case study documenting the evolving literary geography of lisbon and a case study exploring the representation of wolves in portuguese literature.
network_security	in this paper, we propose a secured openflowbased switch architecture. the architecture is a combination of openflow processing that routes packets according to the openflow protocol and security processing that defends against network attacks. therefore, the proposed switch can work not only as a openflow-based forwarding device but also as a network protection system. we implement our prototype switch on a xilinx virtex 5 xc5vtx240t fpga device. in this prototype version, we integrate two different ddos countermeasure techniques, the hop-count filtering and port ingress/egress filtering. the experimental results show that the switch achieves packet processing throughput by up to 19.7 gbps while a 100% ddos detection rate with up to a 2.9% false positive rate and a 0% false negative rate is obtained. our prototype system uses up to 36% look-up tables, 38% registers, and 62% block ram of the fpga device.
parallel_computing	a significant challenge in fitting metamodels of large-scale simulations with sufficient accuracy is in the computational time required for rigorous statistical validation. this paper addresses the statistical computation issues associated with the bootstrap and modified press statistic, which yield key metrics for error measurements in metamodelling validation. experimentation is performed on different programming languages, namely, matlab, r, and python, and implemented on different computing architectures including traditional multicore personal computers and high-power clusters with parallel computing capabilities. this study yields insight into the effect that programming languages and computing architecture have on the computational time for simulation metamodel validation. the experimentation is performed across two scenarios with varying complexity.
microcontroller	plant irradiation during the germination period, by using environmental low level microwave radiation (known as electrosmog) alters the plant germination and the growing process. in order to analyze if such a subtle effect is generated only by the microwave irradiation, the environmental parameters (light, temperature, and humidity) must be kept identical for the reference and the irradiated lot. this is a difficult task because the humidity and temperature are interrelated. in order to study the plant behavior under microwaves low power irradiation, the paper describes the design, manufacturing and operating process and device performances on plant growth. to this end, a low power microwave field (average microwaves power density of 3.8 mw/m(2)) under controlled environmental parameters is used. the device consists of a reference chamber (r) and a microwave irradiation chamber (i), of 0.5 m(3) volume each one, equipped with access doors. the irradiation chamber ensures microwave field distribution with programmable power, frequency and bandwidth in the most commonly used standards for network communication such as: global system for mobile communications (gsm900/1800), code division multiple access (cdma), the third generation of mobile telecommunications technology (3g) or 2.4/5 ghz wireless local area network (wlan). both chambers provide a radiofrequency (rf) shielding (at least -60 db) against and toward outside, so the electrosmog is shielded and does not interfere with the inner environment. both chambers are equipped with performing temperature/humidity sensors and controlled led lighting system (maximum 400 mu mol cm(-2) s(-1)) with a uniformity of +/- 5 mu mol cm(-2) s(-1) measured at the bottom level of the chamber. an embedded system (microcontroller) measures the temperature and humidity and proceeds continuously to match the humidity into the chambers pair with less than +/- 1.5% relative humidity (rh) difference, by using a low flux exhaust ventilation process through a simple innovative method. the accuracy of the temperature measurement is better than +/- 0.2 degrees c. humidity and temperature data set are logged (with programmable acquisition rate) during the whole experiment and can be read later by a personal computer. to identify the influence of microwave treatment on bean seeds and plants development, three growing experiments were settled, based on 122 bean seeds each. the number of germinated seeds (determined each day during 8 days of experiment), the germination energy (ge [%]) of the seeds, the length of stems (sl) and roots (rl), the germination (g) [%], the seedling vigor index (svi) and dry matter content (dm%) have been measured and computed. the obtained data showed significant increase for all parameters on microwave irradiation condition. (c) 2015 elsevier b.v. all rights reserved.
cryptography	in wireless communication systems, the conventional secret key exchange is based on the public key cryptography, which requires complex computations to retain the secrecy level of these key bits. the proposed physical layer-based algorithms have shown promising performance to extract secret keys from the privately shared randomness relying on the reciprocal channel state between both communicated nodes. in this study, the authors propose a physical layer key exchange method which transmits the key bits by encoding them within some phase randomisation (pr) sequences that are privately indexed to a specific channel criterion. the pr sequences only randomise the data phases and thus no efficiency reduction will be incurred. in fact, by choosing a pool of randomisation sequences with certain statistical properties, they could also be used to condition the signal to meet physical layer transmission requirements such as bandwidth, envelope and so on. they quantify the potential of the proposed method by demonstrating it within the context of a multiple-input multiple-output orthogonal frequency division multiplexing system. the results reveal that, relative to existing techniques, the proposed method offers superior key error rate performance at lower computational complexity with better secrecy level.
data_structures	many applications require specialized data structures not found in the standard libraries, but implementing new data structures by hand is tedious and error-prone. this paper presents a novel approach for synthesizing efficient implementations of complex collection data structures from high-level specifications that describe the desired retrieval operations. our approach handles a wider range of data structures than previous work, including structures that maintain an order among their elements or have complex retrieval methods. we have prototyped our approach in a data structure synthesizer called cozy. four large, real-world case studies compare structures generated by cozy against handwritten implementations in terms of correctness and performance. structures synthesized by cozy match the performance of handwritten data structures while avoiding human error.
image_processing	in recent decades, compressive sensing (cs) is a popular theory for studying the inverse problem, and has been widely used in synthetic aperture radar (sar) image processing. however, the computation complexity of cs-based methods limits its wide applications in sar imaging. in this paper, we propose a novel sparse sar imaging method using the multiple measurement vectors model to reduce the computation cost and enhance the imaging result. based on using the structure information and the matched filter processing, the new cs-sar imaging method can be applied to high-quality and high-resolution imaging under sub-nyquist rate sampling with the advantages of saving the computational cost substantially both in time and memory. the results of simulations and real sar data experiments suggest that the proposed method can realize sar imaging effectively and efficiently.
pid_controller	proportional-integral-derivative (pid) controllers are the most popular control systems equipped in industries due to their simplicity, effectiveness, and functionality. in this article, an adaptive differential evolution (de) algorithm is presented to tune controller parameters of pid systems. the proposed algorithm uses shift based parameter control and pseudo population reduction procedures. all algorithmic parameters of de are adapted and no additional parameter is introduced. a set of three typical control instances is taken to study the performance of the proposed algorithm. four recently reported de algorithms are chosen as baselines. through numerical experiment, it turns out that the proposed algorithm yields better performance than the four baseline de algorithms. moreover, the proposed algorithm has a better scalability and reliability than other test algorithms.
control_engineering	the transition time between states plays an important role in designing quantum devices as they are very sensitive to environmental influences. decoherence phenomenon is responsible for possible destructions of the entanglement that is a fundamental requirement to implement quantum information processing systems. if the time between states is minimized, the decoherence effects can be reduced, thus, it is advantageous to the designer to develop expressions for time performance measures. quantum speed limit (qsl) problem has been studied from the theoretical point of view, providing general results. considering the implementation of quantum control systems, as the decoherence phenomenon is unavoidable, it is important to apply these general results to particular cases, developing expressions and performance measures, to assist control engineering designers. here, a minimum time performance measure is defined for quantum control problems, for time-independent or time-dependent hamiltonians, and applied to some practical examples, providing hints that may be useful for researchers pursuing optimization strategies for quantum control systems.
data_structures	the growth in large-scale data management capabilities and the successful care of patients with congenital heart defects have coincidentally paralleled each other for the last three decades, and participation in multicenter congenital heart disease databases and registries is now a fundamental component of cardiac care. this manuscript attempts for the first time to consolidate in one location all of the relevant databases worldwide, including target populations, specialties, web sites, and participation information. since at least 1,992 cardiac surgeons and cardiologists began leveraging this burgeoning technology to create multi-institutional data collections addressing a variety of specialties within this field. pediatric heart diseases are particularly well suited to this methodology because each individual care location has access to only a relatively limited number of diagnoses and procedures in any given calendar year. combining multiple institutions data therefore allows for a far more accurate contemporaneous assessment of treatment modalities and adverse outcomes. additionally, the data can be used to develop outcome benchmarks by which individual institutions can measure their progress against the field as a whole and focus quality improvement efforts in a more directed fashion, and there is increasing utilization combining clinical research efforts within existing data structures. efforts are ongoing to support better collaboration and integration across data sets, to improve efficiency, further the utility of the data collection infrastructure and information collected, and to enhance return on investment for participating institutions.
algorithm_design	intentional or unintentional leakage of confidential data is undoubtedly one of the most severe security threats that organizations face in the digital era. the threat now extends to our personal lives: a plethora of personal information is available to social networks and smartphone providers and is indirectly transferred to untrustworthy third party and fourth party applications. in this work, we present a generic data lineage framework lime for data flow across multiple entities that take two characteristic, principal roles (i. e., owner and consumer). we define the exact security guarantees required by such a data lineage mechanism toward identification of a guilty entity, and identify the simplifying non-repudiation and honesty assumptions. we then develop and analyze a novel accountable data transfer protocol between two entities within a malicious environment by building upon oblivious transfer, robust watermarking, and signature primitives. finally, we perform an experimental evaluation to demonstrate the practicality of our protocol and apply our framework to the important data leakage scenarios of data outsourcing and social networks. in general, we consider lime, our lineage framework for data transfer, to be an key step towards achieving accountability by design.
machine_learning	parentage data from beef calves has shown that in multiple-sire pastures a disproportionate number of calves are born from a single bull. investigating and accurately quantifying bull behavior within multiple sire pastures will begin to determine reason(s) for the variability in the number of calves sired. the study objective was to assess accelerometer data and various classification algorithms to accurately predict bull behavior events in a multiple-sire pasture. behavior events of interest in this study included lying, standing, walking, and mounting. two bulls and ten estrous synchronized cows were used. true behavior events were determined during daylight hours with video analysis, and matched with accelerometer data. accelerometers were attached to both ears, withers, and neck of both bulls. accelerometer data were recorded for every second over 3 days. accelerometer data were used to generate algorithms and accuracy was evaluated compared to known video behavioral data. the prevalence based on the raw video data for lying was 32.6%, standing was 59.4%, walking was 7.4%, and mounting was 0.6%. the random forest classifier had the highest accuracy compared to other classifiers (random tree and decision tree) for each tag location and behavior of interest. the accuracies from the random forest algorithms ranged from 92 to 99% for lying, 85 to 90% for standing, 73 to 77% for walking, and 74% to 80% for mounting. the classification algorithm was able to accurately predict a lying and standing event, and predict a walking and mounting event with a lower accuracy. further research is needed to determine how behaviors between bulls affects overall parentage data. (c) 2017 elsevier b.v. all rights reserved.
bioinformatics	background: a basic task in bioinformatics is the counting of k-mers in genome sequences. existing k-mer counting tools are most often optimized for small k= 32. our software is the result of an intensive process of algorithm engineering. it implements a two-step approach. in the first step, genome reads are loaded from disk and redistributed to temporary files. in a second step, the k-mers of each temporary file are counted via a hash table approach. in addition to its basic functionality, gerbil can optionally use gpus to accelerate the counting step. in a set of experiments with real-world genome data sets, we show that gerbil is able to efficiently support both small and large k. conclusions: while gerbil 's performance is comparable to existing state-of-the-art open source k-mer counting tools for small k < 32, it vastly outperforms its competitors for large k, thereby enabling new applications which require large values of k.
parallel_computing	the computational demand of exact-search procedures has pressed the exploitation of parallel processing accelerators to reduce the execution time of many applications. however, this often imposes strict restrictions in terms of the problem size and implementation efforts, mainly due to their possibly distinct architectures. to circumvent this limitation, a new exact-search alignment tool (bowmapcl) based on the burrows-wheeler transform and fm-index is presented. contrasting to other alternatives, bowmapcl is based on a unified implementation using opencl, allowing the exploitation of multiple and possibly different devices (e.g., nvidia, amd/ati, and intel gpus/apus). furthermore, to efficiently exploit such heterogeneous architectures, bowmapcl incorporates several techniques to promote its performance and scalability, including multiple buffering, work-queue task-distribution, and dynamic load-balancing, together with index partitioning, bit-encoding, and sampling. when compared with state-of-the-art tools, the attained results showed that bowmapcl (using a single gpu) is 2 x to 7.5x faster than mainstream multi-threaded cpu bwt-based aligners, like bowtie, bwa, and soap2; and up to 4 x faster than the best performing state-of-the-art gpu implementations (namely, soap3 and hpg-bwt). when multiple and completely distinct devices are considered, bowmapcl efficiently scales the offered throughput, ensuring a convenient load-balance of the involved processing in the several distinct devices.
cryptography	key encapsulation mechanism (kem) is an important key distribution mechanism that not only allows both sender and receiver to safely share a random session key, but also can be mainly applied to construct a hybrid public key encryption scheme. in this paper, we give an positive answer to the question of if it is possible to build an efficient kem over lattices. more precisely, wedesign an efficientkemscheme in standard model based on ideal lattices. we prove that the proposed scheme captures indistinguishability against active chosen ciphertext attacks (ind-cca) under the ring learning with errors problem, or more formally, ind-cca security. compared with the current cca secure kem schemes based on lattices in the standard model, our scheme has shorter public key, secret key and encapsulation ciphertext. in addition, our kem scheme realizes ind-cca security in the standard model.
computer_vision	recent studies experienced the use of advanced tools for smart aircraft maintenance and inspection. these tools often require the use of computer-vision based technologies to recognize and track a given aircraft mechanical part in order to make it possible to show additional information to a technician on a suitable display. in this paper we propose a visual recognition module of aircraft mechanical parts that has been included in a prototype system designed for the smart maintenance of the alenia-aermacchi m346. the evaluation, carried out on real aircrafts, considers different kind of maintenance operations that require the recognition of 20 different mechanical parts. the visual recognition module has been tested under different imaging conditions and varying the scale and the orientation of the parts of interest. the results confirm the feasibility of our proposal also in such a very challenging and realistic condition. (c) 2017 elsevier b.v. all rights reserved.
voltage_law	today 's power systems become more prone to cyber-attacks due to the high integration of information technologies. in this paper, we demonstrate that the outages of some lines can be masked by injecting false data into a set of measurements. the success of the topology attack can be guaranteed by making that: 1) the injected false data obeys kirchhoff current law and kirchhoff voltage law to avoid being detected by the bad data detection program in the state estimation and 2) the residual in the line outage detection is increased such that the line outage cannot be detected by phasor measurement unit data. a bilevel optimization problem is set up to determine the optimal attack vector that can maximize the residual of the outaged line. the ieee 39-bus and 118-bus systems are used to demonstrate the masking scheme.
electric_motor	to reduce fuel consumption and exhaust emissions in hybrid electric vehicles (hevs), it is important to develop a well-organized energy management system (ems). this paper proposes a torque control strategy coupled with optimization for a parallel hev. a torque control strategy is developed first. in particular, a function to control the driving condition, called the internal combustion engine (ice) torque control function, is introduced. this function controls the driving conditions (electric motor (em) driving, ice driving, and ice driving assisted by em) for reducing fuel consumption and exhaust emissions. this function depends on several design variables that should be optimized. numerical simulation of hev using matlab/simulink is so computationally intensive that a sequential approximate optimization (sao) using a radial basis function network (rbf) is adopted to determine the optimal values of these design variables. as the result, the optimal ice torque control function is determined with a small number of simulation runs. in this paper, co2 and nox emissions are minimized simultaneously for reducing the fuel consumption and exhaust emission. through numerical simulations using typical driving cycles, the trade-off between co2 and nox emissions is clarified and the validity of the proposed torque control strategy coupled with the proposed optimization is examined.
computer_programming	online question and answer (q&a) forums are emerging as excellent learning platforms for learners with varied interests. in this paper, we present our results on the clustering of stack overflow users into four clusters, namely naive users, surpassing users, experts, and outshiners. this clustering is based on various metrics available on the forum. we use the x-means and expectation maximization clustering algorithms and compare the results. the results have been validated using internal, external, and relative validation techniques. the objective of this clustering is to be able to trace and predict the activity of a user on this forum. according to our results, majority of users (71 % of 40,000 users under consideration) fall in the 'experts' category. this indicates that the users in stack overflow are of high quality thereby making the forum an excellent platform for users to learn about computer programming.
operating_systems	future low-end embedded systems will make an increased use of heterogeneous mpsocs. to utilize these systems efficiently, methods and tools are required that support the extraction and implementation of parallelism typically found in embedded applications. ideally, large amounts of existing legacy code should be reused and ported to these new systems. existing parallelization infrastructures, however, mostly support parallelization according to the requirements of hpec systems. for resource-restricted embedded systems, different parallelization strategies are necessary to achieve additional non-functional objectives such as the reduction of energy consumption. hpc-focused parallelization also assumes processor, memory and communication structures different from low-end embedded systems and therefore wastes optimization opportunities essential for improving the performance of resource-constrained embedded systems. this paper describes a new approach and infrastructure inspired by the openmp api to support the extraction and implementation of pipeline parallelism, which is commonly found in complex embedded applications. in addition, advanced techniques to extract parallelism from legacy applications requiring only minimal code modifications are presented. further, the resulting toolflow combines advanced parallelization, mapping and communication optimization tools leading to a more efficient approach to exploit parallelism for typical embedded applications on heterogeneous mpsocs running distributed real-time operating systems. (c) 2016 elsevier inc. all rights reserved.
software_engineering	software cybernetics research is to apply a variety of techniques from cybernetics research to software engineering research. for more than fifteen years since 2001, there has been a dramatic increase in work relating to software cybernetics. from cybernetics viewpoint, the work is mainly on the first-order level, namely, the software under observation and control. beyond the first-order cybernetics, the software, developers/users, and running environments influence each other and thus create feedback to form more complicated systems. we classify software cybernetics as software cybernetics i based on the first-order cybernetics, and as software cybernetics ii based on the higher order cybernetics. this paper provides a review of the literature on software cybernetics, particularly focusing on the transition from software cybernetics i to software cybernetics ii. the results of the survey indicate that some new research areas such as internet of things, big data, cloud computing, cyber-physical systems, and even creative computing are related to software cybernetics ii. the paper identifies the relationships between the techniques of software cybernetics ii applied and the new research areas to which they have been applied, formulates research problems and challenges of software cybernetics with the application of principles of phase ii of software cybernetics; identifies and highlights new research trends of software cybernetic for further research. (c) 2016 elsevier inc. all rights reserved.
electrical_network	power quality (pq) disturbances are becoming increasingly important concerns of the network operators and customers during the delivery of power. voltage dip is one of the pq disturbances which is caused by different factors but mainly by the unpredictable faults occurring at different parts of the electrical network. dips originating at some parts of the network may propagate to other parts of the network causing huge financial losses to industrial and commercial customers. knowing the maximal fault impedance beyond which dips are not detected by the monitoring equipment is very helpful for the grid operator. this paper mainly focuses on the influence of critical impedance or distance, which is measured from a point of common coupling (pcc) at the main busbar next to the ilv/mv transformer to the fault point, to the monitoring of dips. a typical dutch mv network is analyzed and mathematical models are developed with different fault types. taking the different grounding techniques into account, simulations are performed using matlab. for industrial customers connected to the same pcc, the critical distances corresponding to each fault types are evaluated and compared. based on computer simulations, the dips missed by the monitoring device placed at the most appropriate location are thoroughly discussed. the influence of different system groundings on the phase and line voltage dips are also explained in this paper. moreover, the transfer of dips from mv to lv network and the impact of the critical distance with each fault to the transfer of dips are briefly explained.
machine_learning	commercial anti-virus software traditionally memorizes specific byte sequences (known as ""signatures"") in the file contents of previously encountered malware. however, malware authors can evade signature based detection in many ways; for instance, by using obfuscation techniques such as ""packing"" (encryption or compression) to hide snippets of malicious code; by writing metamorphic malware; or by tampering with existing malware. we hypothesize that certain evasion techniques can leave traces in the file 's entropy signal, revealing either similarities to known malware or the presence of tampering per se. to this end, we present suspend (suspicious entropy signal detector), an expert system which evaluates the suspiciousness of an executable file 's entropy signal in order to subserve malware classification. whereas traditionally, entropy analysis has been used for the goal of packer detection (and therefore entropy-based features often merely comprise mean entropy or the entropy of a few file subcomponents), suspend applies non-stationary time series modeling to aid in malware detection. in particular, suspend (a) quantifies the ""amount of structure"" in the entropy signal (through detrended fluctuation analysis), (b) finds the location and size of sudden jumps in entropy (through mean change point modeling), and (c) computes the distribution of entropic variation across multiple spatial scales (through wavelet decomposition). in addition, suspend (d) summarizes the entropy signal 's empirical probability distribution. because suspend 's run time can be made to scale linearly in file size, it is well-suited for large-scale malware analysis. we apply suspend to a large-scale malware detection task with 500,000 heterogeneous real-world samples and over 1 million features. we find that suspend boosts the predictive performance of traditional entropy analysis (as found in packer detectors) from 77.02% to 96.62%. moreover, suspend 's focus on entropy signals makes it a natural candidate for combining with other types of features; for instance, combining suspend with a strings-based feature set boosts predictive accuracy from 97.18% to 98.62%. thus, whereas traditionally, entropy analysis has focused on detecting that a file is packed, suspend 's more comprehensive representation of the entropy signal helps to determine that a file is malicious. we illustrate the application of suspend by studying 18 pieces of virransom, a family of viral ransomware which could cost millions to large organizations. suspend is able to detect 100% of the studied files with over 99% confidence, whereas a more traditional strings-based model was very close to undecided and represents the entire family with a single string. (c) 2016 elsevier ltd. all rights reserved.
symbolic_computation	in this paper, the hopf bifurcation in a new hyperchaotic system is studied. based on the first lyapunov coefficient theory and symbolic computation, the conditions of supercritical and subcritical bifurcation in the new hyperchaotic system are obtained. numerical simulations are used to illustrate some main results.
electrical_circuits	electrode performances of iro2-ta2o5/ti and pbo2/ti anodes were investigated by electrochemical measurements and phenol oxidation. the cyclic voltammetry (cv), polarization and electrochemical impedance spectroscopy (eis) conducted in phenol solution indicate the oxidation ability of pbo2/ti anode is higher than that of iro2-ta2o5/ti electrode because it can reduce oxygen evolution and thus increase effective current. a novel parameter, gamma, associated with anode materials was proposed to quantitatively describe the effective current applied to main reactions and its value could be achieved through eis fitted data of the components in equivalent electrical circuits (eec). the suitability of the used eec was checked by consistency of the exchange current density between tafel plots and eis data. with involvement of the novel parameter (gamma) into organics oxidation, a universal kinetics was thereafter presented to predict variations of chemical oxygen demand, average current efficiency and power consumption. the results of regression analysis and f-test show higher agreement between the experimental and model estimation during phenol oxidation, verifying necessity of the parameter gamma in characterizing effective current for anodic reactions and rationality of the kinetics in describing organics oxidation by different electrodes. (c) 2016 elsevier ltd. all rights reserved.
parallel_computing	the ex-core detector response calculation is an important part in reactor design. however, the response function cannot be measured by experiments quantitatively. ex-core detector response simulation is therefore required. for decades, the s-n code has been used as the dedicated tool. nowadays, more and more engineers are expressing an interest in using the monte-carlo method instead of the s-n method in simulations, as it is expected that the monte-carlo method will give higher accuracy. in this paper, the modeling and simulation of ex-core detector responses is briefly reviewed based on the korean kori unit 1 reactor. then, the differences between the s-n simulation and monte-carlo simulation are compared. the sensitivity of computational conditions is also discussed. it is shown that the problem dependence of cross sections and meshing dependence of spatial discretization in the ex-core detector response calculations are not as strong as expected. however, the ray effect is the main shortcoming for the s-n calculation. based on the analysis, two benefits are shown by using mcnp for the direct 3d calculation. firstly, the impact of ray effect is eliminated without using the s-n angular discretization. secondly, the direct 3d calculation is easier to perform based on the powerful ability of 3d modeling and parallel computing of the monte-carlo code. the new drf values are adopted in the dynamic control rod reactivity measurement of kori unit 1 reactor. the results show that the new drf values improve the error of measured control rod worth by a percentage of 3. (c) 2016 elsevier ltd. all rights reserved.
system_identification	the acquisition of information from parallel sensory pathways is a hallmark of coordinated movement in animals. insect flight, for example, relies on both mechanosensory and visual pathways. our challenge is to disentangle the relative contribution of each modality to the control of behavior. toward this end, we show an experimental and analytical framework leveraging sensory conflict, a means for independently exciting and modeling separate sensory pathways within a multisensory behavior. as a model, we examine the hovering flower-feeding behavior in the hawkmoth manduca sexta. in the laboratory, moths feed from a robotically actuated two-part artificial flower that allows independent presentation of visual and mechanosensory cues. freely flying moths track lateral flower motion stimuli in an assay spanning both coupled motion, in which visual and mechanosensory cues follow the same motion trajectory, and sensory conflict, in which the two sensory modalities encode different motion stimuli. applying a frequency-domain system identification analysis, we find that the tracking behavior is, in fact, multisensory and arises from a linear summation of visual and mechanosensory pathways. the response dynamics are highly preserved across individuals, providing a model for predicting the response to novel multimodal stimuli. surprisingly, we find that each pathway in and of itself is sufficient for driving tracking behavior. when multiple sensory pathways elicit strong behavioral responses, this parallel architecture furnishes robustness via redundancy.
electric_motor	multi-rotors vehicles have become a consolidated reality in modern aeronautical field. these small helicopters consist in a fuselage ""hanged"" under a set of fixed pitch propellers each powered by an electric motor. these vehicles have great potentials and research in this topic is increasing aimed to reduce the structure weight to maximize flight time, range and payload. multi rotor components represent a key challenge for 3d modeling, optimization and additive manufacturing: they mainly consist in complex shapes where the most important feature are robustness and lightweight. usually produced in small series, for example, eight parts for a single prototype, they almost need to be able to interface different materials. the work here presented shows the advanced research conducted in cooperation between altair engineering and politecnico di torino to develop vital components for the structure of a multi-rotor: they represent a challenge because the main need is to interface arms, consisting in carbon fiber tubes, with motor or frame, both made in 7075 alloy. the use of topology optimization techniques plays a key role to minimize the weight of the components and to improve the productivity of the machines. moreover, additive manufacturing (fdm with sharebot ng) allows producing more parts in less time improving the cost effectiveness of the project. the process will be described from a simple characterization of the anisotropic properties of 3-d printed specimens to fem analysis of the preliminary design of the component and to the optimization phase performed with altair optistruct code. an important role is played from the altair tool used for the preliminary design: inspire. this tool is conceived to generate structural efficient concepts quickly and easily to obtain lighter designs and eliminate structural design problems and finally provide input files for 3-d printers. (c) 2015 the authors. published by elsevier b.v.
software_engineering	teams working on the development of software systems use certain tools and workflows of product and knowledge management. these tools and workflows help them plan, monitor and control the product at all stages of the product lifecycle as well as capture, develop and share project-related knowledge. this paper discusses the tools and workflows development teams of the german national library of science and technology (tib) use when developing the web portals. the use case illustrated here is a project, in which the interaction concept and screen design of the video portal of tib (tib vertical bar av-portal) had to be adapted to the new look and feel of the main portal (tib-portal). in the course of the project, the team gathered and structured preliminary requirements in the enterprise wiki, created an axure user interface prototype, evaluated the prototype and specified the requirements using sprints from the scrum framework, commissioned external screen designers and software developers to create a new screen design based on the prototype and implement the requirements, tested the implementations in a collaborative workflow and approved their deployment after debugging.
electric_motor	crocodilians are by their very nature difficult animals to study. however, research on wild animals is essential for the development of reliable long-term management. here, we describe methods for the acquisition and monitoring of behavioural and physiological variables from free-ranging crocodilians through the use of archival tags (data-loggers) and via satellite, radio and acoustic telemetry. specifically, the attachment or implantation of electronic tags is described and examples provided of the type of data that can be collected. our research group has used a combination of approaches to monitor the movements, diving activity, body temperatures and heart rates of crocodilians, including studies on the australian freshwater crocodile (crocodylus johnstoni), the estuarine crocodile (crocodylus porosus) and the caiman (caiman latirostris). each approach or method presents unique challenges and problems, chiefly as a consequence of differences in body morphology and size of the crocodilian species, their behaviours and the habitats they occupy.
distributed_computing	the paper presents design and implementation of the cellular automata (ca) model, which predicts damage of forging tools due to fatigue. the transition rules for the model were developed on the basis of known information regarding crack initiation and propagation. the coefficients in the model were determined by the inverse analysis of the thermal fatigue tests performed on the gleeble 3800 simulator and in the special device with a rotating disc. the ca model was coupled with the conventional abrasive wear model. the layers of cell in the ca space, which are in contact with the workpiece, were removed successively following the abrasive wear of the tool. the ca model was connected with the finite element (fe) programme, which simulates stresses in tools during forging. since this multiscale approach appeared to be extremely demanding as far as computing times are considered, an efficient implementation of the model on heterogeneous hardware architectures was prepared. results of simulations were compared with the industrial data and good predictive capabilities of the model were confirmed. published by elsevier sp. z o.o. on behalf of politechnika wroclawska.
analog_signal_processing	the well known built-in voltage potential for some select semiconductor p-n junctions and various rectifying devices is proposed to be favorable for generating dc electricity at ""zero bias"" (with no dc bias voltage applied) in the presence of johnson noise or 1/f noise which originates from the quantum vacuum (koch et at., 1982). the 1982 koch discovery that certain solid state devices exhibit measurable quantum noise has also recently been labeled a finding of dark energy in the lab (beck and mackey, 2004). tunnel diodes are a class of rectifiers that are qualified and some have been credited with conducting only because of quantum fluctuations. microwave diodes are also good choices since many are designed for zero bias operation. a completely passive, unamplified zero bias diode converter/detector for millimeter (ghz) waves was developed by hrl labs in 2006 under a darpa contract, utilizing a sb-based ""backward tunnel diode"" (btd). it is reported to be a ""true zero-bias diode"". it was developed for a ""field radiometer"" to ""collect thermally radiated power"" (in other words, 'night vision'). the diode array mounting allows a feed from horn antenna, which functions as a passive concentrating amplifier. an important clue is the ""noise equivalent power"" of 1.1 pw per root hertz and the ""noise equivalent temperature difference"" of 10 degrees k, which indicate sensitivity to johnson noise (lynch, et al., 2006). there also have been other inventions such as ""single electron transistors"" that also have ""the highest signal to noise ratio"" near zero bias. furthermore, ""ultrasensitive"" devices that convert radio frequencies have been invented that operate at outer space temperatures (3 degrees above zero point: 3 degrees k). these devices are tiny nanotech devices which are suitable for assembly in parallel circuits (such as a 2-d array) to possibly produce zero point energy direct current electricity with significant power density (brenning el al., 2006). photovoltaic p-n junction cells are also considered for possible higher frequency zpe transduction. diode arrays of self-assembled molecular rectifiers or preferably, nano-sized cylindrical diodes are shown to reasonably provide for rectification of electron fluctuations from thermal and non-thermal zpe sources to create an alternative energy dc electrical generator in the picowatt per diode range.
microcontroller	in this paper the implementation of training modules are presented as teaching support in the area of power semiconductor devices, for practical learning of this discipline. the system is composed by five modules that allow the development of different applications in power electronics including de ac and dc power electric control. each of prototypes was developed with the aim that the student can validate and test the typical circuits employed in this topic easy and intuitive form.
computer_vision	the flickr30k dataset has become a standard benchmark for sentence-based image description. this paper presents flickr30k entities, which augments the 158k captions from flickr30k with 244k coreference chains, linking mentions of the same entities across different captions for the same image, and associating them with 276k manually annotated bounding boxes. such annotations are essential for continued progress in automatic image description and grounded language understanding. they enable us to define a new benchmark for localization of textual entity mentions in an image. we present a strong baseline for this task that combines an image-text embedding, detectors for common objects, a color classifier, and a bias towards selecting larger objects. while our baseline rivals in accuracy more complex state-of-the-art models, we show that its gains cannot be easily parlayed into improvements on such tasks as image-sentence retrieval, thus underlining the limitations of current methods and the need for further research.
analog_signal_processing	in hybrid electric vehicle (hev) drive-trains an electrical generator is coupled onto the shaft of an internal-combustion engine (ice) in order to process either the entire or a given fraction of the traction power required by the vehicle wheels. as such an ice-driven generator is being confined within the vehicle hood and is exposed to heating resulting from ice operation, high compactness, totally-enclosed construction and suitable machine cooling arrangement become challenging targets the generator design must deal with. due to unique characteristics such as higher torque per volume and higher efficiency compared to other machine topologies, the axial-field permanent magnet machine (afpm) topology was selected for the development of a 15 kw @ 4500 rev/min rated generator prototype that would be utilized in a demonstrator of hev drive train. this paper describes the original solutions adopted for the design of such a hev generator and reports experimental results taken from the prototype machine.
cryptography	for multi-output boolean functions (also called s-boxes), various measures of nonlinearity have been widely discussed in the literature but many problems are left open in this topic. the purpose of this paper is to present a new approach to estimating the nonlinearity of s-boxes. a more fine-grained view on the notion of nonlinearity of s-boxes is presented and new connections to some linear codes are established. more precisely, we mainly study the nonlinearity indicator (denoted by n-v) for s-boxes from a coding theory point of view. such a cryptographic parameter n-v is more related to best affine approximation attacks on stream ciphers. we establish a direct link between nv and the minimum distance of the corresponding linear code. we exploit that connection to derive the first general lower bounds on n-v of non-affine functions from f(2)n to f(2)m for m dividing n. furthermore, we show that n-v can be determined directly by the weight distribution of the corresponding linear code.
operating_systems	a design of an advanced-reliability piezoelectric transducer of acoustic emission (ae) is suggested. the advanced reliability is achieved by eliminating the main reasons that lead to failures; duplicating/backing the main operating systems; and imparting redundant or extended technical capabilities to the transducer design that make it possible to compensate for partial or complete performance loss of the antenna group. it is shown that given such a design approach, it is feasible to achieve technical characteristics that are stipulated for industrial acoustic-emission transducers. theoretical estimates of transducer reliability are presented that show that a combination of backing of ae registration channels with different versions of their connection gives ample opportunities for governing the reliability of sensors during their usage/service life.
pid_controller	sharma et al. have investigated the performance of two-layered fractional order fuzzy logic controller (tl-foflc) for a 2-link rigid planer robotic manipulator with payload. in this work, the performance of tl-foflc has been compared with two-layered flc (tl-flc), single-layered flc (sl-flc) and the conventional proportional-integral-derivative (pid) controllers, for trajectory tracking, model uncertainties and disturbance rejection. in this comment, it is pointed out that this work has several missing essential parameters, and therefore, it is not possible for the reader to validate all the claimed results of sharma et al. (2016). six numerical values, three gains for each of the used two pid controllers are found to be unreported in addition to the six gains for each of the used two sl-flcs. since the performances of the pids and the sl-flcs are highly dependent on their tuned gains it is concluded that the reported performances of these controllers cannot be validated. (c) 2016 elsevier b. v. all rights reserved.
control_engineering	the reuse of some industrial by-products in the construction industry saves natural resources and energy, while at the same time reduces environmental problems related to their surface disposal. mine tailings are currently among the largest industrial by-products in the world, and yet, only limited studies have been conducted to evaluate their reuse potential. moreover, abandoned base-metal tailings are increasingly used in some developing countries for the manufacture of mortars without any control, engineering basis or environmental concern. in this study, an experimental program using mechanical tests, mineralogical investigations and leaching tests is presented to assess the use of low sulfide base-metal tailings, with varying properties, as fine aggregates for rendering and masonry mortars. an authentic case study illustrating their use in moroccan construction is additionally presented. overall, it was observed that the main properties affecting the performances of these tailings-based mortars are the residual pb-zn concentrations and the fine content of each tailing. the pb-zn fraction, when using the appropriate substitution level, may serve as an active set retardant improving mortars setting time. the leaching of metals was also successfully stabilized in mortars. (c) 2015 elsevier ltd. all rights reserved.
computer_programming	in this paper, we describe the design, development, deployment and evaluation of nooblab, our novel on-line environment for the teaching and learning of computer programming. although originally devised for the teaching of elementary javascript, the system now also supports java, php and a prescriptive form of pseudocode designed to assist in the teaching of elementary programming concepts. the system incorporates a number of innovative features, such as automated checking of program code, detection of plagiarism, ""gamification"", and automatically logs all of each user 's interactions with it, facilitating performing learning analytics relating to student engagement and performance. the system has already proved to be of value in teaching programming, and helping people to learn to program, not just to specialist computer science students, but also people studying engineering or mathematics as their main subject discipline.
algorithm_design	batch processes are of great importance in process industry. however, the control algorithm design is difficult for those with constraints. this is because stability and recursive feasibility along directions of time and batch should be guaranteed simultaneously. in this paper, a stable model predictive control strategy with zero terminal state constraints is proposed. stability and recursive feasibility along two directions are guaranteed and proved. simulation results are given to show the effectiveness of the algorithm. (c) 2015, ifac (international federation of automatic control) hosting by elsevier ltd. all rights reserved.
parallel_computing	the fast sweeping method is a popular algorithm for solving a variety of static hamilton-jacobi equations. fast sweeping algorithms for parallel computing have been developed, but are severely limited. in this work, we present a multilevel, hybrid parallel algorithm that combines the desirable traits of two distinct parallel methods. the fine and coarse grained components of the algorithm take advantage of heterogeneous computer architecture common in high performance computing facilities. we present the algorithm and demonstrate its effectiveness on a set of example problems including optimal control, dynamic games, and seismic wave propagation. we give results for convergence, parallel scaling, and show state-of-the-art speedup values for the fast sweeping method. (c) 2016 elsevier inc. all rights reserved.
electric_motor	appropriate structure is the first key issue that a designer of an efficient hybrid vehicle should pay attention to. this paper presents three different structures for the concept of series-parallel structure in hybrid electric vehicles (hevs) and compares them with each other for the application of toyota prius 2004 as a well-known case study. the first structure consisting of one electric motor, one electric generator, and one power split device is the conventional structure as one existing in toyota prius 2004 and called ths-ii in the literature. the second and third structures are based on two special electric machines named transmotor-based structure (tbs) and dual-mechanical-port (dmp) machine-based structure (dmpbs), respectively. the three structures are compared by considering different aspects such as weight, occupied volume, and overall efficiency. a surface-mounted fractional-slot concentrated winding dmp machine is designed, and the design is verified by applying the finite-element analysis. simulation results have been presented to support the accomplished comparison of the structures under study. simulation results show that all structures have approximately equal weight, volume, and efficiency, but dmpbs is a compact, efficient, and simple way to convert the existing fossil-fuel cars into an hev. one dmp machine prototype has been implemented, and experimental results have been included.
operational_amplifier	flexible hybrid electronics combine the best characteristics of printed electronics and silicon ics to create high performance, ultra-thin, physically flexible systems. new static and dynamic tests are being developed to evaluate the performance of these systems. dynamic radius of curvature and torsional test results are presented for a flexible hybrid electronics system with a flex silicon-on-polymer operational amplifier manufactured in an 180nm cmos process with 4-levels of metal interconnect mounted on a pet substrate.
microcontroller	moisture measurement in ppm level is always challenging and costly. among different technologies available for moisture measurement, the thin film capacitive sensor-based dew point meter offers a low-cost solution. still, the cost of the dew point meter is high and it suffers from high response time. there is a need of wireless moisture measurement in ppm level that is not available with the commercial meter according to our knowledge. this paper deals with development of a low-cost passive wireless tag for capacitive type sensors. the tag can be energized by any 13.56-mhz commercial tag reader from a distance of 1 cm (approx). the tag is capable of transmitting sensor data at 2.4-ghz ism band up to a distance of 12 m. an efficient algorithm has been developed to reduce the power consumption. the prototype system has been tested with two custom designed capacitive sensors to measure humidity over a wide range. both sensors, having a highly stable hygroscopic film of al2o3, are fabricated in the lab. finally, a low-cost (approximately u.s. $250) digital hygrometer to measure trace moisture has been developed. the performances of the digital hygrometer have been compared with the commercial dew point meter, and accuracy is found to be nearly 1% in the range of 6.5-127-ppm moisture. the system can be employed for contactless measurement with any capacitive sensor in the range of 50-3200 pf.
electrical_circuits	the advanced space-borne thermal emission and reflection radiometer (aster) is one of the five sensors on the nasa 's terra satellite on orbit since december 1999. aster consists of three radiometers, the visible and near infrared (vnir), the short-wave infrared (swir) and thermal infrared (tir) whose spatial resolutions are 15 m, 30 m and 90 m, respectively. unfortunately the swir image data are saturated since april 2008 due to the offset rise caused by the cooler temperature rise, but the vnir and the tir are taking earth images of good quality. the vnir and the tir experienced responsivity degradation while the swir showed little change. from the lamp calibration, band 1 decreased the most among three vnir bands and 31 % in thirteen years. the vnir has the electrical calibration mode to check the healthiness of the electrical circuits through the charge coupled device (ccd). four voltage levels from line 1 to line 4, which are from 2.78 v to 3.10 v, are input to the ccd in the onboard calibration sequence and the output digital numbers (dns) are detected in the images. these input voltages are monitored as telemetry data and have been stable up to now. from the electrical calibration we can check stabilities of the offset, gain ratio and gain stability of the electric circuit. the output level of the line1 input is close to the offset level which is measured while observing the earth at night. the trend of the line 1 output is compared to the offset level. they are similar but are not exactly the same. the trend of the even pixel and odd pixel is the same so the saturated offset levels of the odd pixel is corrected by using the even pixel trend. the gain ratio trend shows that the ratio is stable. but the ratio values are different from those measured before launch. the difference comes up to 10 % for the band 2. the correct gain ratio should be applied to the vicarious calibration result because the onboard calibration is measured with the normal gain whereas the vicarious calibration often measures with the high gain. the cause of the vnir responsivity degradation is not known but one of the causes might be the change of the electric circuit. the band 3 gain shows 16 % decrease whereas the gain changes of the band 1 and band 2 are 5 % to 8 %. the responsivity decrease after 1000 days since launch might be controlled by the electric circuit change.
operational_amplifier	the control systems course is taught in educational electric engineering programs all over the world. the method used for teaching this course is mainly by mathematical representation and software simulation of systems' behavior. in this work the author presents a different approach, which is based on making hands-on experimental applications. the solution presented in this article is based on decomposing and re-arranging the transfer function representation of a dynamic system in order to implement it using electronic circuits. combining the presented method with a popular simulation software leads to the implementation of practical and effective laboratory classes for this course.
computer_programming	this section based on the gis technology, spatial database technology, computer programming technology, based on the transformation of villages in the city management system of gis, developed a set of data management, query (query attribute query, spatial query, condition), thematic map making, drawing generation and other functions in one of the gis system, provide data support and technical services for the reconstruction planning of city villages.
parallel_computing	this paper presents a new parallel domain decomposition algorithm based on integer linear programming (ilp), a mathematical optimization method. to minimize the computation time of coastal ocean circulation models, the ilp decomposition algorithm divides the global domain in local domains with balanced work load according to the number of processors and avoids computations over as many as land grid cells as possible. in addition, it maintains the use of logically rectangular local domains and achieves the exact same results as traditional domain decomposition algorithms (such as cartesian decomposition). however, the ilp decomposition algorithm may not converge to an exact solution for relatively large domains. to overcome this problem, we developed two ilp decomposition formulations. the first one (complete formulation) has no additional restriction, although it is impractical for large global domains. the second one (feasible) imposes local domains with the same dimensions and looks for the feasibility of such decomposition, which allows much larger global domains. parallel performance of both ilp formulations is compared to a base cartesian decomposition by simulating two cases with the newly created parallel version of the stevens institute of technology 's estuarine and coastal ocean model (secom). simulations with the ilp formulations run always faster than the ones with the base decomposition, and the complete formulation is better than the feasible one when it is applicable. in addition, parallel efficiency with the ilp decomposition may be greater than one.
computer_vision	zebrafish (danio rerio) is an important vertebrate model organism in biomedical research, especially suitable for morphological screening due to its transparent body during early development. deep learning has emerged as a dominant paradigm for data analysis and found a number of applications in computer vision and image analysis. here we demonstrate the potential of a deep learning approach for accurate high-throughput classification of whole-body zebrafish deformations in multifish microwell plates. deep learning uses the raw image data as an input, without the need of expert knowledge for feature design or optimization of the segmentation parameters. we trained the deep learning classifier on as few as 84 images (before data augmentation) and achieved a classification accuracy of 92.8% on an unseen test data set that is comparable to the previous state of the art (95%) based on user-specified segmentation and deformation metrics. ablation studies by digitally removing whole fish or parts of the fish from the images revealed that the classifier learned discriminative features from the image foreground, and we observed that the deformations of the head region, rather than the visually apparent bent tail, were more important for good classification performance.
data_structures	os-level virtualization is often used for server consolidation in data centers because of its high efficiency. however, the sharing of storage stack services among the colocated containers incurs contention on shared kernel data structures and locks within i/o stack, leading to severe performance degradation on manycore platforms incorporating fast storage technologies (e.g., ssds based on nonvolatile memories). this article presents multilanes, a virtualized storage system for os-level virtualization on manycores. multilanes builds an isolated i/o stack on top of a virtualized storage device for each container to eliminate contention on kernel data structures and locks between them, thus scaling them to manycores. meanwhile, we propose a set of techniques to tune the overhead induced by storage-device virtualization to be negligible, and to scale the virtualized devices to manycores on the host, which itself scales poorly. to reduce the contention within each single container, we further propose sfs, which runs multiple file-system instances through the proposed virtualized storage devices, distributes all files under each directory among the underlying file-system instances, then stacks a unified namespace on top of them. the evaluation of our prototype system built for linux container (lxc) on a 32-core machine with both a ram disk and a modern flash-based ssd demonstrates that multilanes scales much better than linux in micro-and macro-benchmarks, bringing significant performance improvements, and that multilanes with sfs can further reduce the contention within each single container.
relational_databases	data integration (di) is the problem of combining a set of heterogeneous, autonomous data sources and providing the user with a unified view of these data. integrating data raises several challenges, since the designer usually encounters incompatible data models characterized by differences in structure and semantics. one of the hardest challenges is to define correspondences between schema elements (e.g., attributes) to determine how they relate to each other. since most business data is currently stored in relational databases, here present a declarative and formal approach to specify 1-to-1, 1-m, and m-to-n correspondences between relational schema components. differently from usual approaches, our (cas) have semantics and can deal with outer-joins and data-metadata relationships. finally, we demonstrate how to use the cas to generate mapping expressions in the form of sql queries, and we present some preliminary tests to verify the performance of the generated queries.
electricity	as one of the most successfully commercialized distributed energy resources, the long-term effects of microturbines (mts) on the distribution network has not been fully investigated due to the complex thermo-fluid-mechanical energy conversion processes. this is further complicated by the fact that the parameter and internal data of mts are not always available to the electric utility, due to different ownerships and confidentiality concerns. to address this issue, a general modeling approach for mts is proposed in this paper, which allows for the long-term simulation of the distribution network with multiple mts. first, the feasibility of deriving a simplified mt model for long-term dynamic analysis of the distribution network is discussed, based on the physical understanding of dynamic processes that occurred within mts. then a three-stage identification method is developed in order to obtain a piecewise mt model and predict electro-mechanical system behaviors with saturation. next, assisted with the electric power flow calculation tool, a fast simulation methodology is proposed to evaluate the long-term impact of multiple mts on the distribution network. finally, the model is verified by using capstone 00 micro turbine experiments, and further applied to the dynamic simulation of a modified ieee 37-node test feeder with promising results. (c) 2016 elsevier ltd. all rights reserved.
machine_learning	we study geometric and topological properties of the image of a smooth submanifold of under a bi-lipschitz map to . in particular, we characterize how the dimension, diameter, volume, and reach of the embedded manifold relate to the original. our main result establishes a lower bound on the reach of the embedded manifold in the case where and the bi-lipschitz map is linear. we discuss implications of this work in signal processing and machine learning, where bi-lipschitz maps on low-dimensional manifolds have been constructed using randomized linear operators.
system_identification	the paper develops a methodology that uses the thermoeconomic functional diagram applied for allocating cost of products obtained by the plant and afterwards demonstrates how it is possible to calculate the marginal cost in us$/kw h of the production. the methodology which was adopted includes the plant exergetic analysis development, the function system identification through physical diagram of the plant, construction of the thermoeconomic functional diagram and the determination of the expressions for the plant 's exergetic functions. the methodology also includes the determination of some parameters such as, investments, maintenance, operation, raw materials (canola oil, catalysts, methanol, glycerine and natural gas) and utility costs (electricity and steam water). as a result, it can be said that the simultaneously production of biodiesel and hydrogen is a suitable technology to minimize biodiesel production cost. about 6% of the thermoeconomic cost of biodiesel production was diminished when compared to the values previolisly published in the present literature. in relation to the hydrogen production thermoeconomic costs, the values are closer when they are compared to the ones which were identified in the literature. as a contribution to the scientific knowledge, it can be said that the obtained results shows the high performance of simultaneous biodiesel and hydrogen production, especially when glycerine is further processed into valuable energetic matter, in other words, considering economic aspects associated with the exergy conception, in order to develop a tool to assist the equipment operation, as well as to optimize the biodiesel plant design. also shows that in a biodiesel production plant the hydrogen technology is more sustainable than the traditional one. the paper aims to innovate the production process of biodiesel by incorporating the hydrogen production process through glycerine steam reforming. (c) 2016 elsevier ltd. all rights reserved.
analog_signal_processing	this paper presents a new electronically tunable voltage-mode universal biquadratic filter with one input and five outputs employing five operational transconductance amplifiers, two grounded capacitors and one resistor. the filter can offer voltage-mode low-pass, band-pass, high-pass, band-stop and all-pass filter responses from the same circuit. the properties of the circuit such as no inverting-type input signal requirements, high-input impedance, orthogonal- and electronic-control of the natural frequency and the quality factor, are also possessed. moreover, the active and passive sensitivities of the filter are low. pspice simulation results are provided to demonstrate the theoretical analysis.
electrical_circuits	at a singular point of a dae, the ivp fails to have a unique solution. hence, numerical integration methods cannot provide reasonable results. unfortunately, common error control strategies do not always detect these circumstances and arbitrary solutions may be given to the user without warnings of any kind. automatic (or algorithmic) differentiation (ad) opens new possibilities to realize an analysis of daes and to monitor assumptions required for the existence and uniqueness of ivps. we show how the diagnosis of singular points can be performed for structured quasi-linear daes up to index 2. our approach uses the projector based analysis for daes employing ad. the resulting method is illustrated by several examples, with particular emphasis on simple electrical circuits containing controlled sources.
operating_systems	between 2008 and 2015, bus rapid transit system (brts) in india increased its implementation from two cities to eight cities with a significant increase in total ridership. this paper attempts to give a detailed review of brts implementation in cities of india. this is a systematic effort that could inform readers about the current system and network characteristics of indian brts. different system and corridor characteristics including off board and on board ticketing systems are adopted in india. gross cost revenue collection model is adopted by almost all special purpose vehicle (spv) companies developed to manage brt systems. a variety of carriageway concept designs for brts are implemented in these cities considering a right of way of 22, 24, 30, 32, 40, 45, 60 meters respectively. out of the eight cities, ahmedabad has almost 30% of the total fleet size. in terms of regulatory context, spv companies are formed in almost all eight cities after observing ahmedabad brt success. documentation of these operating systems shall provide a sound database to planners and decision makers actively involved with brt system implementation in developing countries.
distributed_computing	cloud computing is a new distributed computing paradigm that consists in provisioning of infrastructure, software and platform resources as services. this paradigm is being increasingly used for the deployment and execution of service-based applications. to efficiently manage them according the autonomic computing approach, service-based applications can be associated with autonomic managers that monitor them, analyze monitoring data, plan and execute configuration action on them. although, in these last years, autonomic management of cloud services has received an increasing attention, optimization of autonomic managers (ams) assigned to cloud services and their placement in the cloud remain not well explored. in fact, almost all the existing solutions on autonomic computing have been interested in modeling and implementing of autonomic environments without paying attention on optimization. to address this issue, we present in this paper a novel approach to optimize autonomic management of service-based applications that consists in minimizing both the cost of allocated ams while avoiding bottlenecks in management and the cost of their placement in the cloud (the inter-virtual machine communication cost). we propose two algorithms: (i) an algorithm that determines the optimal number of ams to be assigned to services of a managed service-based application, and (ii) an algorithm that approximates the optimal placement of ams in the cloud. experiments conducted show the efficiency of our finding.
parallel_computing	improper functioning of traffic signals at the intersections result in extreme congestion leading to increase in overall journey time and wastage of precious fuel. various algorithms have been proposed in literature for alleviating the problem of congestion. fixed-time, non-preemptive and preemptive approaches work towards reduction of queue length at the intersections to decrease the overall waiting time on roads. high traffic volume on the road results in large queue length which takes huge amount of time to process using a single processor. hence, there is a need for fast processing which can be obtained by parallelizing the algorithm. this paper proposes a parallel preemptive algorithm to reduce the average queue length resulting in decrease of overall waiting time. the implementation of parallel algorithm is done using compute unified device architecture (cuda) by harnessing the power of graphical processing units (gpus). the performance of the proposed parallel preemptive algorithm is compared with fixed-time, non-preemptive and preemptive approaches. obtained results show the reduction in queue length in case of the proposed algorithm which is also confirmed using t-test with 99% confidence. (c) 2016 elsevier inc. all rights reserved.
data_structures	while criteria for schenkerian analysis have been much discussed, such discussions have generally not been informed by data. kirlin [kirlin, phillipb., 2014 a probabilistic model of hierarchical music analysis. ph.d. thesis, university of massachusetts amherst] has begun to fill this vacuum with a corpus of textbook schenkerian analyses encoded using data structures suggested byyust [yust, jason, 2006 formal models of prolongation. ph.d. thesis, university of washington] and a machine learning algorithm based on this dataset that can produce analyses with a reasonable degree of accuracy. in this work, we examine what musical features (scale degree, harmony, metrical weight) are most significant in the performance of kirlin 's algorithm.
digital_control	our aim of the project is to demonstrate all the protections and interlocks available in the critical equipments of power station such as boiler, turbine, the alternator, and how these critical equipments are protected from abnormal conditions and parameters. the failure of any one of these equipments will lead to loss of power generation. the cost of these equipments is huge. boiler has got protection against abnormal drum level, abnormal live steam pressure, abnormal live steam temperature, abnormal furnace pressure. turbine has got protection against abnormal condenser vacuum, abnormal lubricating oil pressure, abnormal axial shiftand abnormal turbine speed. similarly the generator has also got the following protections 1.10.5kv earth fault, 220kv earth fault, differential protection, incomplete phase condition, rotor earth fault, stator inter turn fault, over current protection, stator overvoltage, rotor overvoltage. these protections are classified as class a, class b and class c protections. distributed digital controls and numerical protections relays play vital role in providing protections to critical equipments to demonstrate these protections in real sense in our project kit. however an effort has been made to demonstrate the functioning of these protections with the aid of a programmable logic controller. also a few suggestions to improve the existing system are also discussed.
pid_controller	a novel closed-loop process is demonstrated to control deposition microstructure during laser additive manufacturing (lam) in real-time. an infrared imaging system is developed to monitor surface temperatures during the process as feedback signals. cooling rates and melt pool temperatures are recorded in real-time to provide adequate information regarding thermal gradients, and thus control the deposition microstructure affected by cooling rates during lam. using correlations between the cooling rate, traveling speed, and the clad microstructure, a novel feedback pid controller is established to control the cooling rate. the controller is designed to maintain the cooling rate around a desired point by tuning the traveling speed. the performance of the controller is examined on several single-track and multi-track closed-loop claddings in order to achieve desired microstructures with specific properties. results indicate that the closed-loop controller is capable of generating a consistent controlled microstructure during the lam process in real-time.
digital_control	direct model predictive power control (dmppc) has emerged as a viable alternative for grid-tied active front end (afe) power converters. however, its one-switching-vectorper-sampling-interval character leads to big ripples in its control variables. this work proposes a performance-enhanced direct multiple-vector model predictive power control (dmv-mppc) solution for grid-tied afes directly implementable on an fpga. the proposed control scheme is compared with the classical dmppc. the presented experimental results illustrate that the control performance can be significantly improved by the proposed dmv-mppc scheme.
algorithm_design	raw signal simulation is a useful tool for synthetic aperture radar (sar) system design, mission planning, processing algorithm testing, and inversion algorithm design. time and frequency synchronization is the key technique of bistatic sar (bisar) system, and raw data simulation is an effective tool for verifying the time and frequency synchronization techniques. according to the two-dimensional (2-d) frequency spectrum of fixed-receiver bisar, a rapid raw data simulation approach with time and frequency synchronization errors is proposed in this paper. through 2-d inverse stolt transform in 2-d frequency domain and phase compensation in range-doppler frequency domain, this method can significantly improve the efficiency of scene raw data simulation. simulation results of point targets and extended scene are presented to validate the feasibility and efficiency of the proposed simulation approach.
computer_vision	accurate scale estimation and occlusion handling is a challenging problem in visual tracking. recently, correlation filter-based trackers have shown impressive results in terms of accuracy, robustness, and speed. however, the model is not robust to scale variation and occlusion. in this paper, we address the problems associated with scale variation and occlusion by employing a scale space filter and multi-block scheme based on a kernelized correlation filter (kcf) tracker. furthermore, we develop a more robust algorithm using an appearance update model that approximates the change of state of occlusion and deformation. in particular, an adaptive update scheme is presented to make each process robust. the experimental results demonstrate that the proposed method outperformed 29 state-of-the-art trackers on 100 challenging sequences. specifically, the results obtained with the proposed scheme were improved by 8% and 18% compared to those of the kcf tracker for 49 occlusion and 64 scale variation sequences, respectively. therefore, the proposed tracker can be a robust and useful tool for object tracking when occlusion and scale variation are involved.
state_space_representation	in this study, the stabilization problem for nonlinear multiple time-delay large-scale systems is considered. first, a neural-network (nn) model is employed to approximate each interconnected subsystem. then, a linear differential inclusion (ldi) state-space representation is established for the dynamics of the nn model. based on this ldi state-space representation, a robust fuzzy control design is proposed to overcome the effect of modeling errors between the nonlinear multiple time-delay large-scale systems and the nn models. next, in terms of lyapunov 's direct method, a delay-dependent criterion is derived in order to guarantee the stability ([tub) of nonlinear multiple time-delay large-scale systems. subsequently, the stability conditions of this criterion are reformulated into linear matrix inequalities (lmis). based on the lmis and the decentralized control scheme, a set of fuzzy controllers is then synthesized to stabilize the nonlinear large-scale system and the h-infinity control performance is achieved at the same time. if the designed fuzzy controllers cannot stabilize the nonlinear large-scale system, a batch of dithers (as the auxiliaries of fuzzy controllers) is simultaneously introduced to stabilize the nonlinear large-scale system. the injection of high-frequency signals, commonly called dithers, into nonlinear systems may improve their performance. if the frequencies of the dithers are high enough, the outputs of the dithered large-scale system and those of its corresponding mathematical model-the relaxed large-scale system can be made as close as desired. this makes it possible to obtain a rigorous prediction of the stability of the dithered large-scale system by establishing that of the relaxed large-scale system. finally, a numerical example with simulations is provided to illustrate the feasibility of our approach.
machine_learning	while quantitative structure activity relationship (qsar) models have been employed successfully for the prediction of small model protein chromatographic behavior, there have been few reports to date on the use of this methodology for larger, more complex proteins. recently our group generated focused libraries of antibody fab fragment variants with different combinations of surface hydrophobicities and electrostatic potentials, and demonstrated that the unique selectivities of multimodal resins can be exploited to separate these fab variants. in this work, results from linear salt gradient experiments with these fabs were employed to develop qsar models for six chromatographic systems, including multimodal (capto mmc, nuvia cprime, and two novel ligand prototypes), hydrophobic interaction chromatography (hic; capto phenyl), and cation exchange (cex; cm sepharose ff) resins. the models utilized newly developed local descriptors to quantify changes around point mutations in the fab libraries as well as novel cluster descriptors recently introduced by our group. subsequent rounds of feature selection and linearized machine learning algorithms were used to generate robust, well-validated models with high training set correlations (r-2>0.70) that were well suited for predicting elution salt concentrations in the various systems. the developed models then were used to predict the retention of a deamidated fab and isotype variants, with varying success. the results represent the first successful utilization of qsar for the prediction of chromatographic behavior of complex proteins such as fab fragments in multimodal chromatographic systems. the framework presented here can be employed to facilitate process development for the purification of biological products from product-related impurities by in silico screening of resin alternatives. biotechnol. bioeng. 2017;114: 1231-1240. (c) 2016 wiley periodicals, inc.
parallel_computing	with the development of the design complexity in embedded systems, hardware/software (hw/sw) partitioning becomes a challenging optimization problem in hw/sw co-design. a novel hw/sw partitioning method based on position disturbed particle swarm optimization with invasive weed optimization (pdpso-iwo) is presented in this paper. it is found by biologists that the ground squirrels produce alarm calls which warn their peers to move away when there is potential predatory threat. here, we present pdpso algorithm, in each iteration of which the squirrel behavior of escaping from the global worst particle can be simulated to increase population diversity and avoid local optimum. we also present new initialization and reproduction strategies to improve iwo algorithm for searching a better position, with which the global best position can be updated. then the search accuracy and the solution quality can be enhanced. pdpso and improved iwo are synthesized into one single pdpso-iwo algorithm, which can keep both searching diversification and searching intensification. furthermore, a hybrid noderank (hnoderank) algorithm is proposed to initialize the population of pdpso-iwo, and the solution quality can be enhanced further. since the hw/sw communication cost computing is the most time-consuming process for hw/sw partitioning algorithm, we adopt the gpu parallel technique to accelerate the computing. in this way, the runtime of pdpso-iwo for large-scale hw/sw partitioning problem can be reduced efficiently. finally, multiple experiments on benchmarks from state-of-the-art publications and large-scale hw/sw partitioning demonstrate that the proposed algorithm can achieve higher performance than other algorithms.
electric_motor	the paper presents a measurement campaign (electrical, thermal and user comfort) for the performance characterization of energy storage systems in real-world electric bicycles. specific sensors were added to characterize three vehicles which differ for electric motor, energy storage system size and control strategies. the controller can implement energy recovery strategies when braking and change the level of electric assistance depending on the desired trade-off between the comfort of the driver and the battery duration. experimental results show that a control strategy aiming at preserving the soc (state-of-charge), together with regenerative braking, can ensure very long battery duration with no need of recharge. the soc is kept at about 50% for a long period. instead, control strategies optimizing the full comfort of the driver by maximizing the level of assistance can ensure real-world e-bicycle missions of about 2 h and 40 km, when the soc of the battery drops down from 95% to 5%.
microcontroller	localization and tracking of resources on construction jobsites are an emerging area where the location of materials, labor, and equipment is used to estimate productivity, measure project 's progress and/or enhance jobsite safety. gps has been widely used for outdoor tracking of construction operations. however, gps is not suitable for indoor applications due to the lack of signal coverage; particularly inside tunnels or buildings. several indoor localization research studies had been attempted, however such developments rely heavily on extensive external communication network infrastructures. these developments also are susceptible to electromagnetic interference in noisy construction jobsites. this paper presents indoor localization system using a microcontroller equipped with an inertial measurement unit (imu). the imu contains a cluster of sensors: accelerometer, gyroscope and magnetometer. the microcontroller uses a direct cosine matrix algorithm to fuse sensors data and calculate non-gravitational acceleration using nine-degrees-of-freedom motion equations. current position is calculated based on measured acceleration and heading, while accounting for growing error in speed estimation utilizing jerk integration algorithm. experimental results are presented to illustrate the relative effectiveness of the developed system, which is able to operate independently of any external aids and visibility conditions. (c) 2016 elsevier b.v. all rights reserved.
microcontroller	in this paper, we present a hardware/software coattack to hijack a program flow on microcontrollers. the basic idea is to skip a few instructions using multiple fault injection in microcontrollers in cooperation with a software attack. we focus on buffer overflow (bof) attacks together with such multiple fault injection. the proposed attack can be applied to a program code with a typical software countermeasure against bof attacks. the attack manipulates the program control flowby skipping specific instructions related to the countermeasure, and thus, the subsequent bof attack code is successfully executed on the microcontroller. we show the effectiveness of our proposed attack through experiments using an 8-bit avr atmega163 microcontroller and a 32-bit arm cortex-m0+ microcontroller, where the target software was equipped with a countermeasure limiting the size of user input against bof attacks. the result showed that our attack can overwrite a return address stored in a stack and call an arbitrary malicious function. we also propose a software countermeasure against our attack and prove its validity by examining all the possible instruction skips.
digital_control	a monolithic integrated low-voltage deep brain stimulator with wireless power and data transmission is presented. data and power are transmitted to the stimulator by mutual inductance coupling, while the in-vitro controller encodes the stimulation parameters. the stimulator integrates the digital control module and can generate the bipolar current with equal amplitude in four channels. in order to reduce power consumption, a novel controlled threshold voltage cancellation rectifier is proposed in this paper to provide the supply voltage of the stimulator. the monolithic stimulator was fabricated in a smic 0.18 mu m 1-poly 6-metal mixed-signal cmos process, occupying 0.23 mm(2), and consumes 180 mu w on average. compared with previously published stimulators, this design has advantages of large stimulated current (0-0.8 ma) with the double low-voltage supply (1.8 and 3.3 v), and high-level integration.
distributed_computing	this paper presents the results obtained from the implementation of an infrastructure to improve technological services of email, virtual learning environment, digital repository and virtual library at the polytechnic agricultural higher school of manabi (polytechnic school of agriculture of manabi), espam, through the use of high availability and virtualization mechanisms to provide more reliable resources. virtualization is an empowering and cutting-edge technology that is transforming the operation of technological services, but it involves a paradigm shift in service-oriented information technologies and cloud computing. to execute each of the processes the v-cycle methodology was used as a strategy. virtualization services empowers companies and institutions by transforming how they operate to be at the forefront of innovation in their services as a technological solution. so the implementation of redundant technology in the espam, has allowed its technological services are always operative, for the benefit of the university community, because if there were failures in the main system or services, the backups will be enabled quickly allowing the systems come into operation immediately.
electric_motor	a complete numerical dynamic analysis of reciprocating compressor mechanism is presented, coupling the instantaneous pressure in the compression chamber, the electric motor torque and the hydrodynamic reactions, which arise from the piston and crankshaft secondary movements. additionally, non-constant crankshaft angular velocity and the piston and crankshaft misalignment torques have also been considered. two sensitivity analyses have been carried out to prove that neither the inertial forces in the directions of the secondary movements, nor the oscillations of the angular velocity produce significant differences in the compressor behaviour. finally, a set of parametric studies has been developed to evaluate the influence of geometrical parameters in the stability of the secondary movements, the friction power losses and the compressor consumption.
electrical_network	in this paper, the effects of shunt capacitor on electrical network integrated with renewable energy resources are investigated. for this proposes, we conduct 24-hours load flow analyses for ieee 39 buses power system containing intermittent renewable sources modeled by hourly generation profiles during a day using matlab program, and then shunt capacitor connected to the selected load buses on systems and power factor changes in buses are evaluated during a day.
computer_vision	this paper aims to provide a road map for future works related to reverse engineering field of expertise. reverse engineering, in a mechanical context, relates to any process working in a bottom-up fashion, namely that it goes from a lower level concept or product (closer to the final product) to a higher level one (closer to the ideation step). nowadays, the manufacturing industry is facing unprecedented increase in data exchange and data warehousing. this comes with new issues that our work will not explore, such as ""how to store these data in an efficient manner?"", ""what should be stored?"" and so on. nonetheless, this trend also creates new opportunities if we manage to integrate these data into the expertise workflows. in this paper we will cover the possibilities offered by machine learning to succeed in this challenge. we will also present a first and major step in our road map in order to achieve our research goals. we plan to design a metric to quantify how well and how precise can we perform some specific reverse engineering tasks such as detection, segmentation and classification of mechanical parts in imagery data. we aspire to open this metric; and make it freely and widely available to researchers and industry in order to compare the effectiveness, robustness and preciseness of the existing and future approaches.
software_engineering	in our studies of global software engineering (gse) teams, we found that informal, non-work-related conversations are positively associated with trust. seeking to use novel analytical techniques to more carefully investigate this phenomenon, we described these non-work-related conversations by adapting the economics literature concept of ""cheap talk,"" and studied it using evolutionary game theory (egt). more specifically, we modified the classic stag-hunt game and analyzed the dynamics in a fixed population setting (an abstraction of a gse team). doing so, we were able to demonstrate how cheap talk over the internet (e-cheap talk) was powerful enough to facilitate the emergence of trust and improve the probability of cooperation where the punishment for uncooperative behavior is comparable to the cost of the cheap talk. to validate the results of our theoretical approach, we conducted two empirical case studies that analyzed the logged irc development discussions of apache lucene and chromium os using both quantitative and qualitative methods. the results provide general support to the theoretical propositions. we discuss our findings and the theoretical and practical implications to gse collaborations and research.
distributed_computing	this paper presents a distributed prony analysis algorithm using data fusion approach. this classic approach can be found in kalman filter 's measurement update. distributed optimization algorithms, e.g., alternating direction method of multipliers (admm), suitable for constrained optimization problems, have been proposed in the previous literature to develop distributed architecture. in this article, we show that prony analysis, a non-constrained least square estimation (lse) problem, can be solved using the classic data fusion approach. compared to the iterative distributed optimization algorithms (e.g., admm and subgradient methods), data fusion takes only one step. there is no need for iteration and there is no issue related to convergence. this approach leads to a distributed prony analysis architecture which requires a much less demanding communication system (the bandwidth can be less than 0.1 hz) compared to the conventional centralized prony analysis for multiple channels which requires a bandwidth of 30 hz. the application discussed in this paper is to identify oscillation modes from real world phasor measurement unit (pmu) data and further reconstruct signals. a key technical challenge to implement prony analysis for signals from multiple channels is the difficulty to identify the noise characteristics of each channel. in this paper, a method is proposed to identify the noise covariances, which leads to the construction of a weighted least square estimation (wise) problem. this problem is solved through a distributed architecture. the effectiveness of the proposed distributed prony analysis is demonstrated through case study results. the accuracy of the estimation is improved in one order compared with the centralized prony analysis. (c) 2016 elsevier b.v. all rights reserved.
microcontroller	a simplified, highly reliable, cost effective high temperature (rt-1373 k) vertical dilatometer system, based on linear variable differential transformer (lvdt) has been designed, fabricated and tested for measurement of linear thermal dilation of solid samples. unique features of this fully automated pc-controlled system are: simple design, fabrication from locally available components, ease of operation and maintenance, good temperature resolution (1 k), wide measurement range (+/- 1 mm, with 100 nm resolution), microcontroller-based data acquisition hardware and a simple windows-based software. the system has been tested for its performance using nist sapphire reference and high purity metals including aluminum and nickel. overall accuracy of the system for measurement of linear thermal dilation is within 3% of the reported values for nist sapphire. the system is a good example of a simple experimental facility for routine thermal expansion characterization of solids. combination of simplified design, automation and reliable performance without using sophisticated instrumentation/control systems makes it a novel cost effective thermo-analytical equipment, which can be put to widespread routine usage for researchers, academy and small/medium-scale industries. (c) 2016 elsevier ltd. all rights reserved.
machine_learning	online photo sharing is an increasingly popular activity for internet users. more and more users are now constantly sharing their images in various social media, from social networking sites to online communities, blogs, and content sharing sites. in this article, we present an extensive study exploring privacy and sharing needs of users' uploaded images. we develop learning models to estimate adequate privacy settings for newly uploaded images, based on carefully selected image-specific features. our study investigates both visual and textual features of images for privacy classification. we consider both basic image-specific features, commonly used for image processing, as well as more sophisticated and abstract visual features. additionally, we include a visual representation of the sentiment evoked by images. to our knowledge, sentiment has never been used in the context of image classification for privacy purposes. we identify the smallest set of features, that by themselves or combined together with others, can perform well in properly predicting the degree of sensitivity of users' images. we consider both the case of binary privacy settings (i.e., public, private), as well as the case of more complex privacy options, characterized by multiple sharing options. our results show that with few carefully selected features, one may achieve high accuracy, especially when high-quality tags are available.
computer_programming	provide opportunities for educational and scientific development, but also poses a challenge. era of traditional teaching methods cannot meet the manpower needs of new curriculum reform requires renewing teaching ideas, changing teaching methods, reflect students 'subjectivity in the study and cultivation of students' innovative spirit, formed the awareness and capability for lifelong learning. inquiry teaching to cultivate students' innovative spirit and practical ability for objective, reflect and respond to the demand for education in the era, are effective means of implementation of the new curriculum.
state_space_representation	a method of chemistry tabulation combined with presumed probability density function (pdf) is applied to simulate piloted premixed jet burner flames with high karlovitz number using large eddy simulation. thermo-chemistry states are tabulated by the combination of auto-ignition and extended auto-ignition model. to evaluate the predictive capability of the proposed tabulation method to represent the thermo-chemistry states under the condition of different fresh gases temperature, a-priori study is conducted by performing idealised transient one-dimensional premixed flame simulations. presumed pdf is used to involve the interaction of turbulence and flame with beta pdf to model the reaction progress variable distribution. two presumed pdf models, dirichlet distribution and independent beta distribution, respectively, are applied for representing the interaction between two mixture fractions that are associated with three inlet streams. comparisons of statistical results show that two presumed pdf models for the two mixture fractions are both capable of predicting temperature and major species profiles, however, they are shown to have a significant effect on the predictions for intermediate species. an analysis of the thermo-chemical state-space representation of the sub-grid scale (sgs) combustion model is performed by comparing correlations between the carbon monoxide mass fraction and temperature. the sgs combustion model based on the proposed chemistry tabulation can reasonably capture the peak value and change trend of intermediate species. aspects regarding model extensions to adequately predict the peak location of intermediate species are discussed.
electrical_network	microgrid protection schemes are different from those used in conventional distribution networks. with the incorporation of distributed generation (dg), and the ability for bi-directional power flow and island operation; the fault current and delay parameters of protective relays need to be recalculated and updated in response to the dynamic operation of microgrid. performance evaluation (e.g. fault clearance time and recovery time) and parameter estimation (fault current and trip delay) for such a protection scheme have been difficult because they require comprehensive modeling of electrical network, ied behaviors, and iec61850-based communication. in this paper, we present a centralized scheme with detailed modeling and co-simulation of all these aspects. we also demonstrate how the analysis of the simulation results helps overcoming the forth-mentioned difficulties.
algorithm_design	differential evolution (de) research for multi-objective optimization can be divided into proposals that either consider de as a stand-alone algorithm, or see de as an algorithmic component that can be coupled with other algorithm components from the general evolutionary multiobjective optimization (emo) literature. contributions of the latter type have shown that de components can greatly improve the performance of existing algorithms such as nsga-ii, spea2, and ibea. however, several experimental factors have been left aside from that type of algorithm design, compromising its generality. in this work, we revisit the research on the effectiveness of de for multi-objective optimization, improving it in several ways. in particular, we conduct an iterative analysis on the algorithmic design space, considering de and environmental selection components as factors. results show a great level of interaction between algorithm components, indicating that their effectiveness depends on how they are combined. some designs present state-of-the-art performance, confirming the effectiveness of de for multi-objective optimization.
symbolic_computation	the method of multiple scales is a global perturbation technique that has resulted to be very useful in perturbed ordinary differential equations characterized by disparate time scales. the general principle behind the method is that the solution to the differential equation is uniformly expanded in terms of two or more independent variables, referred to as time scales. in this article, we present a mathematical object based on a poisson series to apply the method of multiple scales via specific symbolic computation. copyright (c) 2016 john wiley & sons, ltd.
electrical_network	carriers of the fragile x premutation (fpm) have cgg trinucleotide repeat expansions of between 55 and 200 in the 5'-utr of fmr1, compared to a cgg repeat length of between 5 and 54 for the general population. carriers were once thought to be without symptoms, but it is now recognized that they can develop a variety of early neurological symptoms as well as being at risk for developing the late onset neurodegenerative disorder fragile x-associated tremor/ataxia syndrome (fxtas). several mouse models have contributed to our understanding of fpm and fxtas, and findings from studies using these models are summarized here. this review also discusses how this information is improving our understanding of the molecular and cellular abnormalities that contribute to neurobehavioral features seen in some fpm carriers and in patients with fxtas. mouse models show much of the pathology seen in fpm carriers and in individuals with fxtas, including the presence of elevated levels of fmr1 mrna, decreased levels of fragile x mental retardation protein, and ubiquitin-positive intranuclear inclusions. abnormalities in dendritic spine morphology in several brain regions are associated with neurocognitive deficits in spatial and temporal memory processes, impaired motor performance, and altered anxiety. in vitro studies have identified altered dendritic and synaptic architecture associated with abnormal ca2+ dynamics and electrical network activity. fpm mice have been particularly useful in understanding the roles of fmr1 mrna, fragile x mental retardation protein, and translation of a potentially toxic polyglycine peptide in pathology. finally, the potential for using these and emerging mouse models for preclinical development of therapies to improve neurological function in fxtas is considered.
bioinformatics	introduction the alternative lengthening of telomeres (alt) mechanism was first observed in the model organism s. cerevisiae. interestingly, this mechanism is necessary for the viability of some tumor cells. unfortunately, its molecular underpinnings are not yet completely understood. objective here, we combine carefully designed non-targeted mass spectrometry-based metabolomics experiments with a bioinformatics approach to characterize the alt positive phenotype observed in yeast at the metabolomics level. methods we profiled the metabolome using mass spectrometry in yeast strains that have lost telomerase expression, as well as that in pre-senescence and the rescued states. to dissect unwanted technical variation from biologically relevant variation between these states, we used a two-step normalization strategy, i. e., first, an empirical bayesian framework; and next, we corrected for secondorder technical effects. results our results show that alt-positive yeast strains present two different types of metabolic responses to the genetically-induced telomerase dysfunction: (i) systemic and (ii) specific. the key-difference between these responses is that the systemic response lasts even after the yeast strains have been genetically rescued, while the specific response does not. interestingly, these metabolic changes can be associated with generic stress responses (e. g., dna damage) as well as specific responses like accelerated aging of early telomerase-inactivation. conclusions a mass spectrometry-based metabolomics approach reveals two distinct types of metabolomics response to telomerase dysfunction in yeast. by identifying these changes in protein (e. g., arg7, and arg1), and metabolite (e. g., datp, and ddtp) amounts, we complement the available information on alt at the genome-wide level.
analog_signal_processing	miniaturization of the electronic devices has steadily reduced both the size and the cost. but a power density of battery has not increased a lot. batteries are a prime agent to penetrate and expand of ubiquitous life. but their intrinsically low energy densities and short lifetimes impose a fundamental limitation. due to this reasons, a small linear reciprocating engine and electric generator are designed for a portable power pack in this paper. if an engine is used solely to produce electrical power in a portable power pack, it is not necessary to convert the reciprocating linear motion of the piston to rotary motion. instead, a linear electrical generator may be coupled directly to the piston for a conversion of mechanical energy into electrical energy. such a design has many advantages such as mechanical simplicity and low friction and it can make possible a small engine having high efficiency.
electrical_circuits	energy harvesting is now an established field, and the linear equivalent circuit models for single-and multiple-degree-of-freedom systems are being routinely used to assess the energy harvesting efficiency of various interface and electronic circuits. however, as the field of energy harvesting moves toward more complex systems such as nonlinear energy harvesting and fluidic energy harvesting, modified equivalent circuits are required to effectively capture the behavior of these devices. this article presents two general methods (a system-level approach and a dependent source equivalent approach) that can adequately model the behavior of more advanced harvesters. these approaches can also be easily used to model single-and multiple-degree-of-freedom linear harvesters. equivalent circuits for both piezoelectric and electromagnetic harvesters are discussed. four case studies are presented to illustrate the application of these equivalent circuit approaches including the following: (1) a piezoelectric duffing harvester, (2) an electromagnetic duffing harvester, (3) a simplified aeroelastic harvester, and (4) a piezoelectric duffing harvester with a rectifier circuit.
image_processing	in this paper, 3d experiments are conducted aiming at the combined investigation of the hydroelastic and the structural (connectors' internal forces) response of a pontoon-type modular floating breakwater (fb), consisting of flexibly connected, moored with chains modules, under the action of perpendicular and oblique regular waves. regarding the fb 's hydroelastic response (i.e. 3d displacements of the modules under the wave action), video recording of the horizontal and the vertical displacements of specific points on the fb relatively to some fixed points is implemented, and this response is determined through an appropriate image processing procedure. for asseasing the fb 's structural response, strain rosettes are utilized, enabling the evaluation of the connectors' forces through the corresponding strains' measurements. the effect of the incident wave characteristics (period, height, obliquity) on the fb 's hydroelastic and structural response is analyzed. the correlation between the connectors' forces and the fb 's hydroelastic response is extensively discussed. the fb 's hydroelastic and structural response depends strongly upon the wave period, while the wave height and obliquity affect this response in the low frequency range. strong dependency of the connectors' forces upon the existence or not of a fb 's intense deformed shape is demonstrated.
electric_motor	grid-enabled vehicles (gevs) such as plug-in electric vehicles present environmental and energy sustainability advantages compared to conventional vehicles. gev runs solely on power generated by its own battery group, which supplies power to its electric motor. this battery group can be charged from external electric sources. nowadays, the interaction of gev with the power grid is unidirectional by the charging process. however, gev can be operated bi-directionally by modifying its power unit. in such operating conditions, gev can operate as an uninterruptible power supply (ups) and satisfy a portion or the total energy demand of the consumption center independent from utility grid, which is known as vehicle-to-home (v2h). in this paper, a power unit is developed for gevs in the laboratory to conduct simulation and experimental studies to test the performance of gevs as a ups unit in v2h mode at the time of need. the activation and deactivation of the power unit and islanding protection unit are examined when energy is interrupted.
electrical_network	this paper presents a fast and accurate approach for the dynamic electrothermal analysis of photovoltaic (pv) plants with a cell-level discretization. a circuit model is developed for the elementary cell, and an equivalent electrical network is automatically built in a preprocessing stage to account for the power-temperature feedback. the pv plant under analysis is represented as an electrical macrocircuit that can be solved with low cpu/memory requirements and without convergence issues by using any spice-like simulator. the proposed strategy can be successfully exploited for diagnostic purposes.
electrical_circuits	in the paper, mathematical models of the supercapacitors are investigated. the models are based on electrical circuits in the form of rc ladder networks. the elementary cell of the network may consist of resistances and capacitances that are connected in series or parallel. the dynamic behavior of the circuit is described using fractional-order differential equations and its properties are analyzed. the identification procedure with quadratic performance index is performed in time domain to identify the parameters of the supercapacitor models. the results of numerical simulations are compared with the results measured experimentally in the physical system. in addition, an example from the automotive industry is used for an experimental evaluation of the theoretical analysis and to present a perspective on the applicability of the approach for other industrial projects.
signal-flow_graph	a systematic design approach using signal flow graph (sfg) is presented in this paper, tailored for integrated reconfigurable switched-capacitor (sc) power converters. to achieve an optimal power stage, an unified signal flow graph (usfg) model is developed. system transfer function and i/o impedance can be evaluated based on it. to verify the design approach, the paper demonstrates a step-up/down reconfigurable sc power converter with five optional gain ratios. a dual-loop control scheme is employed to reconfigure the converter according to the instantaneous line/load conditions. a low-power, digital controller is designed in the subthreshold region for the feedback control loop. the converter was fabricated with a 130-nm cmos process. experimental results show that its output can be continuously regulated from 0.4 to 2.2 v, while allowing the input voltage to randomly vary between 0.9 and 1.5 v. the line regulation is maintained below 1.4%, with a lowest value of 0.07%. the maximum efficiency of 90.22% is measured at 0.55-v output voltage and 20-mw load.
distributed_computing	simple object access protocol (soap) among other techniques implements web services (ws). soap offers a lightweight and simple mechanism for exchange of structured and typed information among computing devices in a decentralized, distributed computing environment. however, soap transmits data in extensible markup language (xml) format. xml documents are huge in size and verbose thus becoming a major hindrance in performance for high-performance applications that process lots of data. in this paper, we develop, implement and evaluate soap performance optimization aggregated architecture in a disadvantaged network, i.e., 10mbps bandwidth. the aggregated architecture entailed: client side caching, document-literal web services description language (wsdl) description, simple database queries on the server side and gzip compression technique. the experimental results showed a relatively high turnaround time and low network throughput. nevertheless, improved performance of soap is evident in terms of bandwidth utilization and transfer time. this can be useful in disadvantaged networks.
bioinformatics	lysine crotonylation on histones is a recently identified post-translational modification that has been demonstrated to associate with active promoters and to directly stimulate transcription. given that crotonyl-coa is essential for the acyl transfer reaction and it is a metabolic intermediate widely localized within the cell, we postulate that lysine crotonylation on nonhistone proteins could also widely exist. using specific antibody enrichment followed by high resolution mass spectrometry analysis, we identified hundreds of crotonylated proteins and lysine residues. bioinformatics analysis reveals that crotonylated proteins are particularly enriched for nuclear proteins involved in rna processing, nucleic acid metabolism, chromosome organization, and gene expression. furthermore, we demonstrate that crotonylation regulates hdac1 activity, expels hp1 alpha from heterochromatin, and inhibits cell cycle progression through s-phase. our data thus indicate that lysine crotonylation could occur in a large number of proteins and could have important regulatory roles in multiple nuclei-related cellular processes.
pid_controller	hydraulic turbine governing system (htgs) is a complicated nonlinear system, which regulates frequency and power of hydropower generating unit. in previous study, control model of htgs is always overly simplified and the elastic water hammer model is seldom considered. in this paper, a nonlinear htgs model with elastic water hammer effect has been studied and a fuzzy-pid controller is designed to improve control quality of this system. in order to optimize the fuzzy-pid controller, a novel gravitational search algorithm based on cauchy mutation and mass weighing (gsa-cw) has been proposed with two improvements: a weighting strategy is designed to accelerate the convergence by assigning weights to agents in mass calculation; a combined mutation strategy based on cauchy and gaussian distribution is proposed to balance the exploration and exploitation ability of the proposed algorithm. at first, the searching ability of the gsa-cw has been verified on a set of 13 complex benchmark functions by statistical analysis. and then, the gsa-cw is applied to optimize the fuzzy-pid controller, while different meta-heuristics and different pid controllers are employed for comparison. experimental results indicate that the fuzzy-pid controller optimized by the gsa-cw is more effective to improve the control quality of the nonlinear htgs. (c) 2016 elsevier b.v. all rights reserved.
cryptography	the security of traditional identity-based signature (ibs) is totally built upon the assumption that the private key is absolutely secure. however, with the increasing use of mobile and unprotected devices in today 's cryptosystems, the threat of key exposure represents a more serious and realistic concern. to mitigate the damage of key exposure in the setting of ibs, we propose to integrate key evolution and user revocation into ibs, and present forward-secure identity-based signature with user revocation (fs-ribs). specifically, we formalize the syntax and security definition of fs-ribs, and give a concrete construction. the proposed scheme is proven secure in the standard model under a q-type complexity assumption. to demonstrate the merits of our scheme, we theoretically analyse its performance by comparing it with other related works. moreover, we provide an implementation and the corresponding timing results of our scheme to show its practicability.
electricity	the objectives of the nuclear fusion power plant demo, to be built after the iter experimental reactor, are usually understood to lie somewhere between those of iter and a 'first of a kind' commercial plant. hence, in demo the issues related to efficiency and rami (reliability, availability, maintainability and inspectability) are among the most important drivers for the design, as the cost of the electricity produced by this power plant will strongly depend on these aspects. in the framework of the eurofusion work package heating and current drive within the power plant physics and development activities, a conceptual design of the neutral beam injector (nbi) for the demo fusion reactor has been developed by consorzio rfx in collaboration with other european research institutes. in order to improve efficiency and rami aspects, several innovative solutions have been introduced in comparison to the iter nbi, mainly regarding the beam source, neutralizer and vacuum pumping systems.
signal-flow_graph	wavelet transform algorithm has emphasized the research attention for its ability to study transient signal analysis. this has incredible applications in pattern recognition and image processing. rn this paper, mathematical formulations of wavelet transform have been developed for multiprocessor applications, the signal flow graph of the algorithm has been designed for the multiresolution level wavelet transform. the pow graph has been modeled for implementation on multiprocessors connected through de bruijn graph. the modeling results are derived in terms of computation time, speedup and efficiency.
control_engineering	in order to get the unbiased parameter estimation of transfer function from noisy input and output data, this paper presents an auxiliary model based method. the basic idea is to replace the unmeasurable outputs in the information vector of the system by auxiliary model outputs, and to modify the recursive least squares parameter estimation by the errors between the system output and auxiliary model output. the proposed method improves the precision of parameter estimates, and has wide application in modelling and control engineering without strict mathematical assumption. finally, the advantages of the proposed approach are shown by simulation tests. (c) 2014 elsevier inc. all rights reserved.
electricity	the trend toward a more fiercely competitive and strictly environmentally regulated electricity market in several countries, including china has led to efforts by both industry and government to develop advanced performance evaluation models that adapt to new evaluation requirements. traditional operational and environmental efficiency measures do not fully consider the influence of market competition and environmental regulations and, thus, are not sufficient for the thermal power industry to evaluate its operational performance with respect to specific marketing goals (operational effectiveness) and its environmental performance with respect to specific emissions reduction targets (environmental effectiveness). as a complement to an operational efficiency measure, an operational effectiveness measure not only reflects the capacity of an electricity production system to increase its electricity generation through the improvement of operational efficiency, but it also reflects the system 's capability to adjust its electricity generation activities to match electricity demand. in addition, as a complement to an environmental efficiency measure, an environmental effectiveness measure not only reflects the capacity of an electricity production system to decrease its pollutant emissions through the improvement of environmental efficiency, but it also reflects the system 's capability to adjust its emissions abatement activities to fulfill environmental regulations. furthermore, an environmental effectiveness measure helps the government regulator to verify the rationality of its emissions reduction targets assigned to the thermal power industry. several newly developed effectiveness measurements based on data envelopment analysis (dea) were utilized in this study to evaluate the operational and environmental performance of the thermal power industry in china during 2006-2013. both efficiency and effectiveness were evaluated from the three perspectives of operational, environmental, and joint adjustments to each electricity production system. the operational and environmental performance changes over time were also captured through an effectiveness measure based on the global malmquist productivity index. our empirical results indicated that the performance of china 's thermal power industry experienced significant progress during the study period and that policies regarding the development and regulation of the thermal power industry yielded the expected effects. however, the emissions reduction targets assigned to china 's thermal power industry are loose and conservative. (c) 2017 elsevier ltd. all rights reserved.
system_identification	a comparative study of different models and identification techniques applied to the quantification of valve stiction in industrial control loops is presented in this paper, with the objective of taking into account for the presence of external disturbances. a hammerstein system is used to model the controlled process (linear block) and the sticky valve (nonlinear block): five different candidates for the linear block and two different candidates for the nonlinear block are evaluated and compared. two of the five linear models include a nonstationary disturbance term that is estimated along with the input-to-output model, and these extended models are meant to cope with situations in which significant nonzero mean disturbances affect the collected data. the comparison of the different models and identification methods is carried out thoroughly in three steps: simulation, application to pilot plant data and application to industrial loops. in the first two cases (simulation and pilot plant) the specific source of fault (stiction with/without external disturbances) is known and hence a validation of each candidate can be carried out more easily. nonetheless, each fault case considered in the previous two steps has been found in the application to a large number of datasets collected from industrial loops, and hence the merits and limitations of each candidate have been confirmed. as a result of this study, extended models are proved to be effective when large, time varying disturbances affect the system, whereas conventional (stationary) noise models are more effective elsewhere. (c) 2016 elsevier ltd. all rights reserved.
electricity	the economics of establishing perennial species as renewable energy feedstocks has been widely investigated as a climate change adapted diversification option for landholders, primarily using net present value (npv) analysis. npv does not account for key uncertainties likely to influence relevant landholder decision making. while real options analysis (roa) is an alternative method that accounts for the uncertainty over future conditions and the large upfront irreversible investment involved in establishing perennials, there have been limited applications of roa to evaluating land use change decision economics and even fewer applications considering climate change risks. further, while the influence of spatially varying climate risk on biomass conversion economic has been widely evaluated using npv methods, effects of spatial variability and climate on land use change have been scarcely assessed with roa. in this study we applied a simulation-based roa model to evaluate a landholder 's decision to convert land from agriculture to biomass. this spatially explicit model considers price and yield risks under baseline climate and two climate change scenarios over a geographically diverse farming region. we found that underlying variability in primary productivity across the study area had a substantial effect on conversion thresholds required to trigger land use change when compared to results from npv analysis. areas traditionally thought of as being quite similar in average productive capacity can display large differences in response to the inclusion of production and price risks. the effects of climate change, broadly reduced returns required for land use change to biomass in low and medium rainfall zones and increased them in higher rainfall areas. additionally, the risks posed by climate change can further exacerbate the tendency for npv methods to underestimate true conversion thresholds. our results show that even under severe drying and warming where crop yield variability is more affected than perennial biomass plantings, comparatively little of the study area is economically viable for conversion to biomass under $200/dm t, and it is not until prices exceed $200/dm t that significant areas become profitable for biomass plantings. we conclude that for biomass to become a valuable diversification option the synchronisation of products and services derived from biomass and the development of markets is vital. (c) 2017 elsevier ltd. all rights reserved.
bioinformatics	pectin degrading enzymes are essential for quality of product from cocoa fermentation. previously, we studied purified pectate lyases (pel) produced by bacillus strains from fermenting cocoa and characterized the cloned pel genes. this study aims to search for biological signals that modulates pel production and regulators that influence pel gene expression. strains were grown to the end of exponential phase in media containing various carbon sources. pel enzymes production in bacillus was unaffected by simple sugar content variation up to 2%. additionally, it appeared that pel gene is not under the control of the most common carbon and pectin catabolism regulators ccpa and kdgr, which could explain the insensitivity of pel production to carbon source variation. however, a 6-fold decrease in pel production was observed when bacteria were grown in lb rich medium as opposed to basal mineral medium. subsequently, bioinformatics analysis of cloned pel gene promoter region revealed the presence of degu binding site. furthermore, the deletion of degu gene dramatically reduces the pel gene expression, as revealed by real time quantitative pcr, showing an activation effect of degu on pel synthesis in bacillus strains studied. we assumed that, during the latter stage of cocoa fermentation when simple sugars are depleted, production of pel in bacillus is stimulated by degu to supply microbial cells with carbon source from polymeric pectic compounds. (c) 2016 elsevier ltd. all rights reserved.
system_identification	this paper addresses the identification of switched linear mimo state-space systems. the proposed methodology explores the use of subspace identification techniques, clustering, and data classification to obtain an estimate of the submodels. the main contribution of this work lies in the inclusion of an identification step of points generated by the same mode. for this points classification it is proposed to use a hybrid filtering technique known as interacting multiple model (imm) algorithm. an important feature of the overall identification algorithm is that the matrices of different submodels can be directly combined because, they are obtained for the same state-space basis. the efficiency of the developed method is demonstrated via numerical examples.
data_structures	with existing programming tools, writing high-performance simulation code is labor intensive and requires sacrificing readability and portability. the alternative is to prototype simulations in a high-level language like matlab, thereby sacrificing performance. the matlab programming model naturally describes the behavior of an entire physical system using the language of linear algebra. however, simulations also manipulate individual geometric elements, which are best represented using linked data structures like meshes. translating between the linked data structures and linear algebra comes at significant cost, both to the programmer and to the machine. high-performance implementations avoid the cost by rephrasing the computation in terms of linked or index data structures, leaving the code complicated and monolithic, often increasing its size by an order of magnitude. in this article, we present simit, a new language for physical simulations that lets the programmer view the system both as a linked data structure in the form of a hypergraph and as a set of global vectors, matrices, and tensors depending on what is convenient at any given time. simit provides a novel assembly construct that makes it conceptually easy and computationally efficient to move between the two abstractions. using the information provided by the assembly construct, the compiler generates efficient in-place computation on the graph. we demonstrate that simit is easy to use: a simit program is typically shorter than a matlab program; that it is high performance: a simit program running sequentially on a cpu performs comparably to hand-optimized simulations; and that it is portable: simit programs can be compiled for gpus with no change to the program, delivering 4 to 20x speedups over our optimized cpu code.
distributed_computing	with advances in technology, frequent pattern mining has been used widely in our daily lives. by using this technology, one can obtain interesting or useful information that would help one make decisions and apply judgment. for example, marketplace managers mine transaction data to obtain information that can help improve services, understand customer buying habits, determine a suitable scheme for placement of goods to increase profits, or for medical and biotechnology applications. however, the rate at which data is generated is very rapid, leading to problems caused by big data. therefore, many researchers have studied distributed, parallel and cloud computing technology to select the best among them. however, data mining uses multiple computing nodes, which requires the transmission of a considerable amount of data in a network environment. the available network bandwidth is limited when many different tasks are being transmitted at the same time and many servers are working in the same network segment. this results in poor transmission, causing severe transfer delay, either internal or external to the network. thus, we propose the fast and distributed mining algorithm for discovering frequent patterns in congested networks (fdmcn) algorithm, which is based on carm. the main purpose is to reduce fp-tree transmission such that only a portion of the information is required for mining using computing nodes. the results of empirical evaluation under various simulation conditions show that the proposed method fdmcn delivers excellent performance in terms of execution efficiency and scalability when compared with the psws algorithm.
electrical_network	distributed generation (dg) brought new challenges for protection engineers since standard relay settings of traditional system may no longer function correctly under the new conditions of dg. the extreme case is coordination loss between primary and backup relays. the directional overcurrent relay (docr) which is the most implemented protection device in the electrical network also suffers performance degradation in presence of dg. therefore, the paper proposes the mitigation of dg impact on docr coordination employing adaptive protection scheme (aps) using differential evolution algorithm (de). the impacts of dg prior and after the application of aps are presented and a new mitigation scheme is proposed.
bioinformatics	introduction: casein201 is one of the human milk sourced peptides that differed significantly in preterm and full-term mothers. this study is designed to demonstrate the biological characteristics, antibacterial activity and mechanisms of casein201 against common pathogens in neonatal infection. methodology: the analysis of biological characteristics was done by bioinformatics. disk diffusion method and flow cytometry were used to detect the antimicrobial activity of casein201. killing kinetics of casein201 was measured using microplate reader. the antimicrobial mechanism of casein201 was studied by electron microscopy and electrophoresis. results: bioinformatics analysis indicates that casein201 derived from 0-casein and showed significant sequence overlap. antibacterial assays showed casein201 inhibited the growth of s taphylococcus aureus and y ersinia enterocolitica. ultrastructural analyses revealed that the antibacterial activity of casein201 is through cytoplasmic structures disintegration and bacterial cell envelope alterations but not combination with dna. conclusion: we conclude the antimicrobial activity and mechanism of casein201. our data demonstrate that casein201 has potential therapeutic value for the prevention and treatment of pathogens in neonatal infection. (c) 2017 elsevier inc. all rights reserved.
symbolic_computation	this paper investigates the integrability of a generalized seventh-order korteweg-de vries equation arising in fluids and plasmas. by means of singularity structure analysis, it is proven that this equation passes the painleve test for integrability in only three distinct cases. under three sets of painleve integrable conditions, the soliton solutions are obtained by using hirota 's bilinear method; the pseudopotentials and lax pairs are derived by virtue of the method developed by nucci. finally, the infinite conservation laws are found by using its lax pair, and all conserved densities and fluxes are presented with explicit recursion formulas.
digital_control	the efforts for more reliable power conversion systems have been gaining momentum in recent years. the majority of the studies concerning reliability of power switches focus on the package-related failures, mainly caused by the cyclic thermal stress. the basic failure precursor for this type of stress has been identified as increased on-state resistance for power mosfets in the recent literature. on-state resistance monitoring during converter operation is a challenging and costly task as it requires current and voltage sensing circuits, which can block the high voltage across the switch during off-state to protect the measurement or control unit. this paper proposes a software frequency response analysis method to determine the health status of high-voltage power mosfets with high on-state resistance. this is achieved by analyzing and evaluating the variation in the plant model at double pole frequency using the same dsp that is used for control purposes. the proposed concept is analyzed for boost converter; however, it can be used to detect the on-state resistance variation in other types of converters operating in continuous condition mode (ccm). the proposed algorithm is embedded in a low cost dsp and experimentally verified on a dc/dc boost converter.
electric_motor	ionospheric scintillation is a significant component of space-weather studies and serves as an estimate for the level of perturbation in the satellite radio wave signal caused due to small-scale ionospheric irregularities. b-spline functions are used on the gps ground based data collected during the year 2007-2012 for modeling high- and mid-latitude ionospheric scintillation. proposed model is for hornsund, svalbard and warsaw, poland. the input data used in this model were recorded by gsv 4004b receivers. for validation, results of this model are compared with the observation and other existing models. physical behavior of the ionospheric scintillation during different seasons and geomagnetic conditions are discussed well. model is found in good coherence with the ionospheric scintillation theory as well as to the accepted scintillation mechanism for high-and mid-latitude.
cryptography	in this paper, a dynamical and adaptive ldpc coding scheme is proposed in order to improve the performance of the cryptographic key distillation protocol of an fso/cv-qkd system considering the atmospheric turbulence levels that may be present in the classic channel. in this scheme, the generator and parity-check matrices of the encoder are modified according to the rytov variance values estimated in the classical channel in order to improve the final secret key rate of the qkd system. the simulation results show that the final secret key was incremented 87.5 kbps (from 52.5 kbps to 140 kbps) using the adaptive code rate; meaning that the information encrypted and transmitted is increased. in addition, the use of the dynamical encoder avoids the drastically reduction of the final secret key rate when the conditions of the classical channel are considered. our proposal might be implemented based on the use of high-speed fpga 's and dsp 's commercially available.
parallel_computing	image denoising is one of the fundamental and essential tasks within image processing. in medical imaging, finding an effective algorithm that can remove random noise in mr images is important. this paper proposes an effective noise reduction method for brain magnetic resonance (mr) images. our approach is based on the collateral filter which is a more powerful method than the bilateral filter in many cases. however, the computation of the collateral filter algorithm is quite time-consuming. to solve this problem, we improved the collateral filter algorithm with parallel computing using gpu. we adopted cuda, an application programming interface for gpu by nvidia, to accelerate the computation. our experimental evaluation on an intel r xeon r cpu e5-2620 v3 2.40ghz with a nvidia tesla k40c gpu indicated that the proposed implementation runs dramatically faster than the traditional collateral filter. we believe that the proposed framework has established a general blueprint for achieving fast and robust filtering in a wide variety of medical image denoising applications.
microcontroller	a new technique to measure a capacitor or a capacitive sensor by means of a direct sensor-to-microcontroller interface circuit that does not need a calibration capacitor is proposed. basically, the measurement process consists of three consecutive steps of charge, discharge and charge of the capacitor under test. a non-linear equation is obtained and solved that is dependent only on known circuit parameters. experimental results show that it is possible to measure a wide range of capacitor values with a maximum deviation of 2% from the reference value, and that temperature changes from 18 to 70 degrees c yield relative errors below 0.1%. for the lowest measured capacitor range (33 pf-4.7 nf) the uncertainty holds below 1 pf which enables measurement of commercially available capacitive sensors. the main advantage of the proposed technique is cost and space reduction of the final design.
distributed_computing	the equality problem is usually one 's first encounter with communication complexity and is one of the most fundamental problems in the field. although its deterministic and randomized communication complexity were settled decades ago, we find several new things to say about the problem by focusing on three subtle aspects. the first is to consider the expected communication cost (at a worst-case input) for a protocol that uses limited interaction-i.e., a bounded number of rounds of communication-and whose error probability is zero or close to it. the second is to treat the false negative error rate separately from the false positive error rate. the third is to consider the information cost of such protocols. we obtain asymptotically optimal rounds-versus-cost tradeoffs for equality: both expected communication complexity and information complexity scale as , where r is the number of rounds and , with k logs. these bounds hold even when the false negative rate approaches 1. for the case of zero-error communication cost, we obtain essentially matching bounds, up to a tiny additive constant. we also provide some applications. as an application of our information cost bounds, we obtain new bounded-round randomized lower bounds for the intersection problem, in which there are two players who hold subsets . in many realistic scenarios, the sizes of s and t are significantly smaller than n, so we impose the constraint that . we study the minimum number of bits the parties need to communicate in order to compute the entire intersection set , using r rounds. we show that any r-round protocol has information cost (and thus communication cost) bits. we also give an o(r)-round protocol achieving bits, which for gives a protocol with o(k) bits of communication. this is in contrast to other basic problems such as computing the union or symmetric difference, for which bits of communication is required for any number of rounds.
analog_signal_processing	with higher rate of depletion of the non-renewable fuels, the quest for an appropriate alternative fuel has gathered great momentum. though diesel engines are the most trusted power sources in the transportation industry, due to stringent emission norms and rapid depletion of petroleum resources there has been a continuous effort to use alternative fuels. hydrogen is one of the best alternatives for conventional fuels. hydrogen has its own benefits and limitations in its use as a conventional fuel in automotive engine system. in the present investigation, hydrogen-enriched air is used as intake charge in a diesel engine adopting exhaust gas recirculation (egr) technique with hydrogen flow rate at 201/min. experiments are conducted in a single-cylinder, four-stroke, water-cooled, direct-injection diesel engine coupled to an electrical generator. performance parameters such as specific energy consumption, brake thermal efficiency are determined and emissions such as oxides of nitrogen, hydrocarbon, carbon monoxide, particulate matter, smoke and exhaust gas temperature are measured. usage of hydrogen in dual fuel mode with egr technique results in lowered smoke level, particulate and no, emissions. (c) 2007 elsevier ltd. all rights reserved.
digital_control	in this paper an adaptive rotor flux observer is developed. this observer performs a real-time correction of the mutual inductance and rotor resistance of the motor using data from the dc-link voltage sensor, the inverter state and the phase current and position sensors. the observer compares the behavior of two independent observers (sensorless and sensored observers) in order to correct the parameters of the sensored observer. the adaptation algorithm corrects the mutual inductance, which can vary due to change of the magnetization current, and the rotor resistance, which can change due to variation of the rotor temperature. computer simulation results are presented to validate the proposed method.
computer_graphics	prior to having available the high dynamic range (hdr) techniques, certain levels of luminance could only by captured by the human eye. currently, hdr technology overcomes the limitations of conventional imaging technology (also referred as low dynamic range or ldr) and allows the capture and delivery of contents that can match the dynamic range of the real world. however, the state of the art of hdr video focus mainly on conventional sized displays typical of tvs or pcs. as the usage of mobile devices for multimedia consumption is increasing considerably, there is a need for studying the impact of the viewing of hdr video on such devices. this will allow to take full advantage of hdr technology, creating a set of opportunities for the digital business as it allows, among others, the presentation of products in a much more efficient and captivating way. on this paper it is presented a study that evaluates the impact of the hdr video delivery on mobile devices and compares it with the impact of low dynamic range (ldr) content. results show that the delivery of hdr video on mobiles is possible without requiring much more resources when comparing the delivery of ldr video.
control_engineering	environmental noise control is offered to undergraduate students whose major is environmental engineering, to let students know the basic knowledge and control technologies of noise pollution, so that they can solve related problems. as one of the main special courses, it requires to be constructed to keep it up-to-date with currents noise control technologies. this paper analyzed the current conditions of this course. in addition, it described the construction process and effects, including adjustment of the content, improvement of methods, revision of mode, compiling of databases and performance of experiments in noise control.
relational_databases	large, multi-institutional groups or collaborations of scientists are engaged in nuclear physics research projects, and the number of research facilities is dwindling. these collaborations have their own authorship rules, and they produce a large number of highly-cited papers. multiple authorship of nuclear physics publications creates a problem with the assessment of an individual author 's productivity relative to his/her colleagues and renders ineffective a performance metrics solely based on annual publication and citation counts. many institutions are increasingly relying on the total number of first-author papers; however, this approach becomes counterproductive for large research collaborations with an alphabetical order of authors. a concept of fractional authorship (the claiming of credit for authorship by more than one individual) helps to clarify this issue by providing a more complete picture of research activities. in the present work, nuclear physics fractional and total authorships have been investigated using nuclear data mining techniques. historic total and fractional authorship averages have been extracted from the nuclear science references database, and the current range of fractional contributions has been deduced. the results of this study and their implications are discussed and conclusions presented.
data_structures	a correspondence is a set of mappings that establishes a relation between the elements of two data structures (i.e. sets of points, strings, trees or graphs). if we consider several correspondences between the same two structures, one option to define a representative of them is through the generalised median correspondence. in general, the computation of the generalised median is an np-complete task. in this paper, we present two methods to calculate the generalised median correspondence of multiple correspondences. the first one obtains the optimal solution in cubic time, but it is restricted to the hamming distance. the second one obtains a sub-optimal solution through an iterative approach, but does not have any restrictions with respect to the used distance. we compare both proposals in terms of the distance to the true generalised median and runtime.
analog_signal_processing	induced polarization method is one of common methods for electrical prospecting of geophysical. the paper is to analyses and research application of embedded technology for induced polarization instrument and design multifunctional transceiver instrument. the paper is to realize hardware part of induced polarization instrument by regarding arm processor as hardware core by combination of current intelligent power module (ipm), induced polarization analog signal processing and 24-digit delta-sigma high-precision aid conversion chip (cs5532), etc. it can transplant embedded operation system (uclinux) on embedded arm processor and formulate drive program which matches hardware circuit and application program to fulfils various functions including data acquisition, data processing & display, data storage & transmission required by induced polarization instrument under uclinux system management.
operating_systems	optimal supply of trace elements (te) is a prerequisite for microbial growth and activity in anaerobic digestion (ad) bioprocesses. however, the required concentrations and ratios of essential te for ad biotechnologies strongly depend on prevailing operating conditions as well as feedstock composition. furthermore, te in ad bioreactors undergo complex physicochemical reactions and may be present as free ions, complex bound or as precipitates depending on ph, or on the presence of sulfur compounds or organic macromolecules. to overcome te deficiency, various commercial mineral products are typically applied to ad processes. the addition of heavy metals poses the risk of overdosing operating systems, which may be toxic to microbial consortia and ultimately the environment. adequate supplementation, therefore, requires appropriate knowledge not only about the composition, but also on the speciation and bioavailability of te. however, very little is yet fully understood on this specific issue. evaluations of te typically only include the measurement of total te concentrations but do not consider the chemical forms in which te exist. thus detailed information on bioavailability and potential toxicity cannot be provided. this review provides an overview of the state of the art in approaches to determine bioavailable te in anaerobic bioprocesses, including sequential fractionation and speciation techniques. critical aspects and considerations, including with respect to sampling and analytical procedures, as well as mathematical modeling, are examined. the approaches discussed in this review are based on our experiences and on previously published studies in the context of the cost action 1302: european network on ecological roles of trace metals in anaerobic biotechnologies.
analog_signal_processing	microelectromechanical systems are utilized alongside with transistor amplifiers and resistive connections for implementing of oscillatory associative memories. phase locking is studied in such a network and all requirements of the circuit level implementation are satisfied. a very high gain trans-impedance amplifier operating in 1 ghz in addition to a novel automatic amplitude control circuit is employed to remove amplitude dynamics of the system. requiring resonator characteristics are extracted and calculated as well. a new method for initialization of the network is proposed. each neuron consumes 1.08 mw from a 1.8 v power supply. the convergence time of a typical network trained by hebbian rule is less than 1.5 ns which results in an ultra high speed analog signal processing system.
electrical_circuits	capacitance limits the bandwidth of engineered and biological electrical circuits because it determines the gain-bandwidth product (gbwp). with a fixed gbwp, bandwidth can only be improved by decreasing gain. in engineered circuits, an inductance reduces this limitation through shunt peaking but no equivalent mechanism has been reported for biological circuits. we show that in blowfly photoreceptors a voltage-dependent k+ conductance, the fast delayed rectifier (fdr), produces shunt peaking thereby increasing bandwidth without reducing gain. furthermore, the fdr 's time constant is close to the value that maximizes the photoreceptor gbwp while reducing distortion associated with the creation of a wide-band filter. using a model of the honeybee drone photoreceptor, we also show that a voltage-dependent na+ conductance can produce shunt peaking. we argue that shunt peaking may be widespread in graded neurons and dendrites.
computer_graphics	since conventional evacuation drills do not adequately simulate disaster situations, participants do not feel a sense of tension during evacuation. we developed a game based evacuation drill (gbed) system that focuses on situational and audio-visual realities and scenario-based interactivity. to improve the visual reality in a gbed, we adopt simple augmented reality (ar) and a binocular opaque head-mounted display (hmd). the simple ar represents vague extensive disaster situations (i.e., rain, fog, smoke and fire) by superimposing the overall disaster situations (dynamic three-dimensional computer graphics) onto the real-time vision captured by a stereo camera (attached to the hmd).
computer_vision	many computer vision applications require finding corresponding points between images and using the corresponding points to estimate disparity. today 's correspondence finding algorithms primarily use image features or pixel intensities common between image pairs. some 3-d computer vision applications, however, do not produce the desired results using correspondences derived from image features or pixel intensities. two examples are the multimodal camera rig and the center region of a coaxial camera rig. we present an image correspondence finding technique that aligns pairs of image sequences using optical flow fields. the optical flow fields provide information about the structure and motion of the scene, which are not available in still images but can be used in image alignment. we apply the technique to a dual focal length stereo camera rig consisting of a visible light-infrared camera pair and to a coaxial camera rig. we test our method on real image sequences and compare our results with the state-of-the-art multimodal and structure from motion (sfm) algorithms. our method produces more accurate depth and scene velocity reconstruction estimates than the state-of-the-art multimodal and sfm algorithms. (c) 2017 spie and is&t
analog_signal_processing	the doubly salient electrical generator (dseg) has characteristics of easy control and high reliability, so it has been used in the high speed field. to satisfy the low speed and high power characteristics of direct driven wind power (ddwp), this paper first analyzes the control strategy of dseg used in ddwp, and then studies the novel direct driven doubly salient electrical wind generator (dddsewg) with exterior rotor by the finite element analysis in ansoft. the dddsewg is fitted for the area of wide speed and load range. simulation results by matlab demonstrate the positive electrical characteristics of dddsewg.
distributed_computing	distributed computing is a good alternative to expensive supercomputers. there are plenty of frameworks that enable programmers to harvest remote computing power. however, until today, much computation power in the edges of the internet remains unused. while idle devices could contribute to a distributed environment as generic computation resources, computation-intense applications could use this pool of resources to enhance their execution quality. in this paper, we identify heterogeneity as a major burden for distributed and edge computing. heterogeneity is present in multiple forms. we draw our vision of a comprehensive distributed computing system and show where existing frameworks fall short in dealing with the heterogeneity of distributed computing. afterwards, we present the tasklet system, our approach for a distributed computing framework. tasklets are fine-grained computation units that can be issued for remote and local execution. we tackle the different dimensions of heterogeneity and show how to make use of available computation power in edge resources. in our prototype, we use middleware and virtualization technologies as well as a host language concept.
parallel_computing	the rapid development of the latest distributed computing paradigm, i. e., cloud computing, generates a highly fragmented cloud market composed of numerous cloud providers and offers tremendous parallel computing ability to handle big data problems. one of the biggest challenges in multiclouds is efficient workflow scheduling. although the workflow scheduling problem has been studied extensively, there are still very few primal works tailored for multicloud environments. moreover, the existing research works either fail to satisfy the quality of service (qos) requirements, or do not consider some fundamental features of cloud computing such as heterogeneity and elasticity of computing resources. in this paper, a scheduling algorithm, which is called multiclouds partial critical paths with pretreatment (mcpcpp), for big data workflows in multiclouds is presented. this algorithm incorporates the concept of partial critical paths, and aims to minimize the execution cost of workflow while satisfying the defined deadline constraint. our approach takes into consideration the essential characteristics of multiclouds such as the charge per time interval, various instance types from different cloud providers, as well as homogeneous intrabandwidth vs. heterogeneous interbandwidth. various types of workflows are used for evaluation purpose and our experimental results show that the mcpcpp is promising.
machine_learning	explicit prediction of the suspended sediment loads in rivers or streams is very crucial for sustainable water resources and environmental systems. suspended sediments are a governing factor for the design and operation of hydraulic structures, like canals, diversions and dams. in recent decades, to model hydrological phenomena which are complex in nature the machine learning models are used commonly. in the present study, support vector machine (svm) with wavelet transform (wasvm) has been employed for prediction of daily suspended sediment load (sl) for two south indian watersheds (marol and muneru) using hydrometeorological data. a 40-year daily observed data (1972-2011) have been used for the analysis, where past sl, streamflow (q), and rainfall (r) data were used as the model inputs, and sl was the model output. using conventional correlation coefficient analysis between input and output variables, the best input of wasvm model was identified. the reliability of svm and wasvm models were evaluated on the basis of different performance criteria, i.e.,coefficient of determination (r2), root mean square error (rmse), normalized mean square error (nmse), and nash-sutcliffe coefficient (ns). initially, 1-day ahead sl prediction was performed using the best wasvm model. the results showed that, 1-day predictions were very precise, showing a close agreement with the observed sl data (r2=0.94, ns=0.94 for the marol watershed, and r2=0.77, ns=0.77 for the muneru watershed) in the testing period. the same wasvm model was then used for the prediction of sl for the higher lead periods. the nmse value for the marol watershed was found as low as 0.06 for 1-day ahead prediction, and increases subsequently as 0.29, 0.46, and 0.70 for 3-, 6-, and 9-day higher leads, respectively. likewise, for the muneru watershed, the nmse value was found as low as 0.21 for 1-day ahead prediction, and increases subsequently as 0.42, 0.53, and 0.68 for 3-, 6-, and 9-day higher leads, respectively. further, the model was evaluated on the basis of its capability of predicting peak sl and cumulative sl for 1- to 6-day leads. the statistical analysis shows that the developed wasvm model can predict the target value successfully up to a 6-day lead and is not suitable for higher lead specifically in the selected watersheds having similar hydroclimatic conditions like the ones selected in this study. predictions by the wasvm model were found significantly superior to the ones obtained by the conventional svm model. the results revealed that the wasvm model provides a very good accuracy in predicting sl and can be used as an effective forecasting tool for hydrological applications.
symbolic_computation	the purpose of this paper is to develop constructive versions of stafford 's theorems on the module structure of weyl algebras a (n) (k) (i.e., the rings of partial differential operators with polynomial coefficients) over a base field k of characteristic zero. more generally, based on results of stafford and coutinho-holland, we develop constructive versions of stafford 's theorems for very simple domains d. the algorithmization is based on the fact that certain inhomogeneous quadratic equations admit solutions in a very simple domain. we show how to explicitly compute a unimodular element of a finitely generated left d-module of rank at least two. this result is used to constructively decompose any finitely generated left d-module into a direct sum of a free left d-module and a left d-module of rank at most one. if the latter is torsion-free, then we explicitly show that it is isomorphic to a left ideal of d which can be generated by two elements. then, we give an algorithm which reduces the number of generators of a finitely presented left d-module with module of relations of rank at least two. in particular, any finitely generated torsion left d-module can be generated by two elements and is the homomorphic image of a projective ideal whose construction is explicitly given. moreover, a non-torsion but non-free left d-module of rank r can be generated by r+1 elements but no fewer. these results are implemented in the stafford package for d=a (n) (k) and their system-theoretical interpretations are given within a d-module approach. finally, we prove that the above results also hold for the ring of ordinary differential operators with either formal power series or locally convergent power series coefficients and, using a result of caro-levcovitz, also for the ring of partial differential operators with coefficients in the field of fractions of the ring of formal power series or of the ring of locally convergent power series.
parallel_computing	visual feature learning, which aims to construct an effective feature representation for visual data, has a wide range of applications in computer vision. it is often posed as a problem of nonnegative matrix factorization (nmf), which constructs a linear representation for the data. although nmf is typically parallelized for efficiency, traditional parallelization methods suffer from either an expensive computation or a high runtime memory usage. to alleviate this problem, we propose a parallel nmf method called alternating least square block decomposition (alsd), which efficiently solves a set of conditionally independent optimization subproblems based on a highly parallelized fine-grained grid-based blockwise matrix decomposition. by assigning each block optimization subproblem to an individual computing node, alsd can be effectively implemented in a mapreduce-based hadoop framework. in order to cope with dynamically varying visual data, we further present an incremental version of alsd, which is able to incrementally update the nmf solution with a low computational cost. experimental results demonstrate the efficiency and scalability of the proposed methods as well as their applications to image clustering and image retrieval.
computer_graphics	we present preliminary results of work on a low-cost multi-user immersive virtual reality system that enables collaborative experiences in large virtual environments. in the proposed setup at least three users can walk and interact freely and untethered in a 200 m(2) area. the required equipment is worn on the body and rendering is performed locally on each user to minimize latency. inside-out optical head tracking is coupled with a low-cost motion capture suit to track the full body and the head. movements of users, 3d interactions and the positions of selected real world objects are distributed over a wireless network in a server-client architecture. as a result, users see the effect of their interactions with objects and other users in real time. we describe the architecture of our implemented proof-of-concept system.
signal-flow_graph	the radix-2(k) fast fourier transform (fft) algorithm is used to achieve at the same time both a radix-2 butterfly and a reduced number of twiddle factor multiplication. in this paper we present a new identical radix-2(k) fft algorithms, which has same number of butterfly and twiddle factor multiplication. the difference is only in twiddle factor stage location in signal flow graph (sfg). further, analyze these algorithms and is shown that the round-off noise of identical radix-2(2), radix-2(3), and radix-2(4) fft algorithms at output is reduced 27%, 8%, 3% respectively.
operational_amplifier	this paper presents a low-power, low-noise and high precision operational amplifier for a tracking system containing the intelligent medical device, and is an extended version of paper previously published by nenadovic et al. in proc. of icecs 2014. the accuracy of the tracking system strongly depends on the accurate amplitude acquisition of the received signal. therefore, an operational amplifier with precise gain control and effective temperature compensation has been designed and fabricated. the operational amplifier provides linear and temperature independent signal amplification at frequencies between 0.2 and 20 khz at a body temperature. the amplifier shows measured gain over temperature sensitivity as low as 32 ppm/a degrees c in temperature range from 20 to 40 a degrees c and consumes 300 mu a from a supply voltage of 2.5 v. furthermore, the measured gain over temperature sensitivity in the range from -40 to 130 a degrees c is only 60 ppm/a degrees c. simulated linearity for signal amplitudes up to 10 mv is 0.4 % and the input-referred noise at 1 khz is 32 nv/aehz. an open-loop gain of 46 db at 1 khz and bandwidth-gain product of 4.8 mhz is measured. the operational amplifier was designed in ihps 250 nm sige bicmos technology and occupies an area of 0.2 mm(2).
machine_learning	the quest to observe gravitational waves challenges our ability to discriminate signals from detector noise. this issue is especially relevant for transient gravitational waves searches with a robust eyes wide open approach, the so called all-sky burst searches. here we show how signal classification methods inspired by broad astrophysical characteristics can be implemented in all-sky burst searches preserving their generality. in our case study, we apply a multivariate analyses based on artificial neural networks to classify waves emitted in compact binary coalescences. we enhance by orders of magnitude the significance of signals belonging to this broad astrophysical class against the noise background. alternatively, at a given level of mis-classification of noise events, we can detect about 1/4 more of the total signal population. we also show that a more general strategy of signal classification can actually be performed, by testing the ability of artificial neural networks in discriminating different signal classes. the possible impact on future observations by the ligo-virgo network of detectors is discussed by analysing recoloured noise from previous ligo-virgo data with coherent waveburst, one of the flagship pipelines dedicated to all-sky searches for transient gravitational waves.
algorithm_design	in their celebrated paper (furst et al., math. syst. theory 17(1), 13-27 (12)), furst, saxe, and sipser used random restrictions to reveal the weakness of boolean circuits of bounded depth, establishing that constant-depth and polynomial-size circuits cannot compute the parity function. such local restrictions have played important roles and have found many applications in complexity analysis and algorithm design over the past three decades. in this article, we give a brief overview of two intriguing applications of local restrictions: the first one is for the isomorphism conjecture and the second one is for moderately exponential time algorithms for the boolean formula satisfiability problem.
computer_graphics	many real world information can be represented by a graph with a set of nodes interconnected with each other by multiple type of relations called edge layers (e.g., social network, biological data). edge bundling techniques have been proposed to solve cluttering issue for standard graphs while few efforts were done to deal with the similar issue for multilayer graphs. in multilayer graphs scenario, not only the clutter induced by large amount of edges is a problem but also the fact that different type of edges can overlap each other making useless the final visualization. in this paper we introduce a new multilayer graph edge bundling technique that firstly produces a preliminary edge bundling independently of the different edge layers and then deals with the specificity of multilayer graphs where more than one type of edges can be routed on the same bundle. the proposed visualization is tested on a real world case study and the outcomes point out the ability of our proposal to discover patterns present in the data.
software_engineering	three key drivers of change in the world of software are identified, and their impact on a range of software engineering research is assessed. the rise of agile approaches to software development adds further pressure for software process research to develop and evolve processes that are supportive of change while meeting the most stringent needs of society. two examples of successful process evolution, aimed at highly regulated industries, are outlined as pointers to the future direction of software process research. copyright (c) 2015 john wiley & sons, ltd.
lorentz_force_law	this paper presents the controller design and implementation of a high-precision 6-degree-of-freedom (6-dof) magnetically levitated (maglev) positioner. this high-precision positioning system consists of a novel concentrated-field magnet matrix and a triangular single-moving part that carries three 3-phase permanent-magnet linear-levitation-motor armatures. since only a single levitated moving part, namely the platen, generates all required fine and coarse motions, this positioning system is reliable and low-cost. three planar levitation motors based on the lorentz-force law not only generate the vertical force to levitate the triangular platen but control the platen 's position and orientation in the horizontal plane. all 6-dof motions are controlled by magnetic forces only. the platen is regarded a pure mass system, and the spring and damping coefficients are neglected except for the vertical directions. single-input single-output (siso) digital lead-lag controllers are designed and implemented on a digital signal processor (dsp). this 6-dof fully magnetically levitated positioner has a total mass of 5.91 kg and currently exhibits a 120 mm x 120 mm travel range. this positioner is highly suitable for semiconductor-manufacturing applications such as wafer steppers, several experimental motion profiles are presented to demonstrate the maglev stage 's capability of accurately tracking any planar and 3-d paths.
electrical_network	this paper presents the convergence analysis of seidel method for solving power systems automatic tasks. in a condition of use of programmable logical controllers with low capacity as a hardware, algorithm solution based on seidel method have some advantages, such as memory saving. however, there are some limits for seidel method convergence. if the electrical network condition is close to resonance there will be no assurance that seidel method will converge. as a result of made experiments we can conclude that usage of relaxation method in conjunction with convergence control on the phase plane allows to solve network analysis problem with nonexpansible hardware.
parallel_computing	the deployment of smart grids and renewable energy dispatch centers motivates the development of forecasting techniques that take advantage of near real-time measurements collected from geographically distributed sensors. this paper describes a forecasting methodology that explores a set of different sparse structures for the vector autoregression (var) model using the least absolute shrinkage and selection operator (lasso) framework. the alternating direction method of multipliers is applied to fit the different lasso-var variants and create a scalable forecasting method supported by parallel computing and fast convergence, which can be used by system operators and renewable power plant operators. a test case with 66 wind power plants is used to show the improvement in forecasting skill from exploring distributed sparse structures. the proposed solution outperformed the conventional autoregressive and vector autoregressive models, as well as a sparse var model from the state of the art. copyright (c) 2016 john wiley & sons, ltd.
electric_motor	fully electric vehicles with multiple drivetrains allow a significant variation of the steady-state and transient cornering responses through the individual control of the electric motor drives. as a consequence, alternative driving modes can be created that provide the driver the option to select the preferred dynamic vehicle behavior. this article presents a torque-vectoring control structure based on the combination of feedforward and feedback contributions for the continuous control of vehicle yaw rate. the controller is specifically developed to be easily implementable on real-world vehicles. a novel model-based procedure for the definition of the control objectives is described in detail, together with the automated tuning process of the algorithm. the implemented control functions are demonstrated with experimental vehicle tests. the results show the possibilities of torque-vectoring control in designing the vehicle understeer characteristic. (c) 2015 the authors. published by elsevier ltd.
state_space_representation	the pull-in range of phase locked loop (pll) is a key parameter for evaluating the performance of the pll circuit. it is defined as the maximum detuning frequency range where the loop locks. different methods have been proposed for computing the pull-in range of phase locked loops in the absence of time delay. in this paper, the effect of time delay on the pull-in range of second-order phase locked loop as well as its dynamical behavior will be discussed. the time delay is modeled using first order pade approximation. using pade approximation, the nonlinear second order delay differential equation which describes the phase error dynamic of the pll is transformed into fourth order system in the state space representation. the new time-delay pll model is simulated and different behavior is observed which is different than a typical pll system without delay. as the gain of the loop increases, new behavior such as change of circuit stability and chaos are recognized which suggests that the gain of the loop cannot be arbitrary large. we compare the pull-in range of a time delay pll with those without time delay. results demonstrate the degradation in the pull-in range for the time delay pll. moreover, result shows that the pull in range gets narrower as time delay increases.
signal-flow_graph	a technique for designing square-root domain elliptic filters that simulate the operation of the corresponding lc ladder prototypes is introduced in this paper. this is achieved by manipulating the equations that describe the operation of differentiation in such a way that only lossless integrator and weighted summation blocks are needed. the derived signal flow graph (sfg) is transposed to the corresponding one in the square-root domain using an appropriate set of operators in order to preserve the linear operation of the whole filter. in order to demonstrate the validity of the proposed technique, a third-order elliptic lowpass filter was simulated and its behavior was evaluated using an hspice simulator.
pid_controller	this paper presents the effects on output voltage and current total harmonic distortion (thd) response with increasing the arm inductance (smooth reactor for hvdc) for the modular multilevel converter (mmc) behavior based on a closed loop-needless pid controller control. also, it presents the effects on mmc quantities, such as a circulating current ripple, maximum output voltage, and submodule capacitor ripple responses with increasing the value of arm inductance. because increasing arm inductor size could reduce the thd and circulating current ripple waveforms of the mmc, this effect will be investigated in this paper. the closed loop-needless pid controller control is presented first. second, an examination of the effect of changing the arm inductor for mmc behavior is carried out based on many simulation results in this paper in order to analyze the change in thd for all mmc quantities, including circulating current, upper arm current and voltage, lower arm current and voltage, and ac output voltage and current. third, arm inductance relationships with output voltage and current thd are shown. also, arm inductance relationships with a circulating current ripple and submodule capacitor ripple are presented. as a part of this study, the relationship between arm inductance and maximum output voltage is explained. finally, the hardware design and software design of the prototype are presented to verify the arm inductor value effect on mmc experimentally. the experimental results are also documented in this paper. (c) 2015 elsevier b.v. all rights reserved.
software_engineering	software defect prediction predicts fault-prone modules which will be tested thoroughly. thereby, limited quality control resources can be allocated effectively on them. without sufficient local data, defects can be predicted via cross-project defect prediction (cpdp) utilizing data from other projects to build a classifier. software defect datasets have the class imbalance problem, indicating the defect class has much fewer instances than the non-defect class does. unless defect instances are predicted correctly, software quality could be degraded. in this context, a classifier requires to provide high accuracy of the defect class without severely worsening the accuracy of the non-defect class. this class imbalance principle seamlessly connects to the purpose of the multi-objective (mo) optimization in that mo predictive models aim at balancing many of the competing objectives. in this paper, we target to identify effective multi-objective learning techniques under cross-project (cp) environments. three objectives are devised considering the class imbalance context. the first objective is to maximize the probability of detection (pd). the second objective is to minimize the probability of false alarm (pf). the third objective is to maximize the overall performance (e.g., balance). we propose novel mo naive bayes learning techniques modeled by a harmony search meta-heuristic algorithm. our approaches are compared with single-objective models, other existing mo models and within-project defect prediction models. the experimental results show that the proposed approaches are promising. as a result, they can be effectively applied to satisfy various prediction needs under cp settings. (c) 2016 elsevier b.v. all rights reserved.
network_security	with the rapid development of mobile internet, people pay increasing attention to the wireless network security problem. but due to the specificity of the wireless network, at present it is rare to see the research of wireless intrusion alerts clustering method for mobile internet. this paper proposes a wireless intrusion alert clustering method (wiacm) based on the information of the mobile terminal. the method includes alert formatting, alert reduction and alert classification. by introducing key information of the mobile terminal device, this method aggregates the original alerts into hyper alerts. the experimental results show that wiacm would be appropriate for real attack scenarios of mobile internet, and reduce the amount of alerts with more accuracy of alert analysis.
microcontroller	a hardware accelerator is presented to compute the probabilistic inference for a bayesian network (bn) in distributed sensing applications. for energy efficiency, the accelerator is operated at a near-threshold voltage of 0.5 v, while achieving a maximum clock frequency of 33 mhz. clique-tree message passing algorithm is leveraged to compute the probabilistic inference. the theoretical maximum size of a factor that the proposed hardware accelerator can handle is 2((8x20)=160) entries, which is sufficient for handling massive bns, such as pathfinder, munin, and so on (>1000 nodes). a logical alarm reduction mechanism (alarm) bn is used to benchmark the performance of the accelerator. the accelerator consumes 76 nj to execute the alarm network using a clique-tree message-passing algorithm, while the same algorithm executed on an ultralow-power microcontroller consumes 20 mj.
symbolic_computation	in this paper a generalized fractional modified korteweg-de vries (fmkdv) equation with time-dependent variable coefficients, which is a generalized model in nonlinear lattice, plasma physics and ocean dynamics, is investigated. with the aid of a simplified bilinear method, fractional transforms and symbolic computation, the corresponding n-soliton solutions are given and illustrated. the characteristic line method and graphical analysis are applied to discuss the solitonic propagation and collision, including the bidirectional solitons and elastic interactions. finally, the resonance phenomenon for the equation is examined.
analog_signal_processing	silicon photonics offers the possibility of a reduction in size weight and power for many optical systems, and could open up the ability to build optical systems with complexities that would otherwise be impossible to achieve. silicon photonics is an emerging technology that has already been inserted into commercial communication products. this technology has also been applied to analog signal processing applications. mit lincoln laboratory in collaboration with groups at mit has developed a toolkit of silicon photonic devices with a focus on the needs of analog systems. this toolkit includes low-loss waveguides, a high-speed modulator, ring resonator based filter bank, and all-silicon photodiodes. the components are integrated together for a hybrid photonic and electronic analog-to-digital converter. the development and performance of these devices will be discussed. additionally, the linear performance of these devices, which is important for analog systems, is also investigated.
distributed_computing	joint service involving several clouds is an emerging form of cloud computing. in hybrid clouds, the schedulers within 1 cloud must not only self-adapt to the job arrival processes and the workload but also mutually adapt to the scheduling polices of other schedulers. however, as a combinatorial optimization problem, scheduling is challenged by the adaptation to those dynamics and uncertain behaviors of the peers. this article studies the collaboration among benevolent clouds that are cooperative in nature and willing to accept jobs from other clouds. we take advantage of machine learning and propose a distributed scheduling mechanism to learn the knowledge of job model, resource performance, and others' policies. without explicit modeling and prediction, machine learning guides scheduling decisions based on experiences. to examine the performance of our approach, we conducted simulation using the sp2 job workload log of the san diego supercomputer center under a test bed based on agent-based systems-swarm. the results validate that our approach has much shorter mean response time than 5 typical dynamic scheduling algorithms-opportunistic load balancing, minimum execution time, minimum completion time, switching algorithm, and k-percent best. a better collaboration in hybrid cloud is achieved by full adaptation.
bioinformatics	satsuma myomphala is critically endangered through loss of natural habitats, predation by natural enemies, and indiscriminate collection. it is a protected species in korea but lacks genomic resources for an understanding of varied functional processes attributable to evolutionary success under natural habitats. for assessing the genetic information of s. myomphala, we performed for the first time, de novo transcriptome sequencing and functional annotation of expressed sequences using illumina next-generation sequencing (ngs) platform and bioinformatics analysis. we identified 103,774 unigenes of which 37,959, 12,890, and 17,699 were annotated in the panm (protostome db), unigene, and cog (clusters of orthologous groups) databases, respectively. in addition, 14,451 unigenes were predicted under gene ontology functional categories, with 4581 assigned to a single category. furthermore, 3369 sequences with 646 having enzyme commission (ec) numbers were mapped to 122 pathways in the kyoto encyclopedia of genes and genomes pathway database. the prominent protein domains included the zinc finger (c2h2-like), reverse transcriptase, thioredoxin-like fold, and rna recognition motif domain. many unigenes with homology to immunity, defense, and reproduction-related genes were screened in the transcriptome. we also detected 3120 putative simple sequence repeats (ssrs) encompassing dinucleotide to hexanucleotide repeat motifs from >1 kb unigene sequences. a list of pcr primers of ssr loci have been identified to study the genetic polymorphisms. the transcriptome data represents a valuable resource for further investigations on the species genome structure and biology. the unigenes information and microsatellites would provide an indispensable tool for conservation of the species in natural and adaptive environments. (c) 2016 the authors. published by elsevier inc.
state_space_representation	nonlinear adaptive filtering techniques for system identification (based on the volterra model) are widely used for the identification of nonlinearities in many applications. in this correspondence, the improved tracking capability of a numeric variable forgetting factor recursive least squares (nvff-rls) algorithm is presented for first-order and second-order time-varying volterra systems under a nonstationary environment. the nonlinear system tracking problem is converted into a state estimation problem of the time-variant system. the time-varying volterra kernels are governed by the first-order gauss-markov stochastic difference equation, upon which the state-space representation of this system is built. in comparison to the conventional fixed forgetting factor recursive least squares algorithm, the nvff-rls algorithm provides better channel estimation as well as channel tracking performance in terms of the minimum mean square error (mmse) for first-order and second-order volterra systems. the nvff-rls algorithm is adapted to the time-varying signals by using the updating prediction error criterion, which accounts for the nonstationarity of the signal. the demonstrated simulation results manifest that the proposed method has good adaptability in the time-varying environment, and it also reduces the computational complexity.
parallel_computing	the investigation of solar-like oscillations for probing star interiors has enjoyed a tremendous growth in the last decade. once observations are over, the most notable difficulties in properly identifying the true oscillation frequencies of stars are due to the gaps in the observation time-series and the intrinsic stellar granulation noise. this paper presents an innovative neuro-wavelet reconstructor for the missing data of photometric signals. firstly, gathered data are transformed using wavelet operators and filters, and this operation removes granulation noise, then we predict missing data by a composite of two neural networks, which together allow a ""forward and backward"" reconstruction. this resulting error is greatly lower than the absolute a priori measurement error. the devised reconstruction approach gives a signal that is better suited to be fourier transformed when compared with other existing methods. (c) 2016 elsevier ltd. all rights reserved.
computer_vision	malaria in human is a serious and fatal tropical disease. this disease results from anopheles mosquitoes that are infected by plasmodium species. the clinical diagnosis of malaria based on the history, symptoms and clinical findings must always be confirmed by laboratory diagnosis. laboratory diagnosis of malaria involves identification of malaria parasite or its antigen / products in the blood of the patient. manual diagnosis of malaria parasite by the pathologists has proven to become cumbersome. therefore, there is a need of automatic, efficient and accurate identification of malaria parasite. in this paper, we proposed a computer vision based approach to identify the malaria parasite from light microscopy images. this research deals with the challenges involved in the automatic detection of malaria parasite tissues. our proposed method is based on the pixel-based approach. we used k-means clustering (unsupervised approach) for the segmentation to identify malaria parasite tissues.
control_engineering	high-performance control of quantum dynamics is key to the development of quantum technologies. from quantum-state engineering to quantum metrology, theory and practice of quantum control enable robust and cheaper technologies for future industrial applications. starting from fundamental matter-field interactions, we overview various approaches to modelling quantum control systems, in which control can be implemented by either changing field or material properties. these models are built in time or frequency domain and can be interconnected to form quantum feedback networks. this review can be taken as a useful reference for engineers to understand the quantum physics behind, or for physicists to resolve control problems from a control engineering point of view.
analog_signal_processing	an universal multi input single output type multifunction biquad is proposed. the proposed configuration employs only one current differencing transconductance amplifier as the active element, two capacitors and three resistors. the circuit realizes all five filter functions (i.e. low pass, high pass, band pass, notch and all pass) without changing the circuit topology. the natural frequency omega(0) is independently and electronically tunable. the workability of the proposed multifunction biquad has been verified using spice simulation.
software_engineering	context: software library reuse has significantly increased the productivity of software developers, reduced time-to-market and improved software quality and reusability. however, with the growing number of reusable software libraries in code repositories, finding and adopting a relevant software library becomes a fastidious and complex task for developers. objective: in this paper, we propose a novel approach called libfinder to prevent missed reuse opportunities during software maintenance and evolution. the goal is to provide a decision support for developers to easily find ""useful"" third-party libraries to the implementation of their software systems. method: to this end, we used the non-dominated sorting genetic algorithm (nsga-ii), a multi-objective search-based algorithm, to find a trade-off between three objectives : 1) maximizing co-usage between a candidate library and the actual libraries used by a given system, 2) maximizing the semantic similarity between a candidate library and the source code of the system, and 3) minimizing the number of recommended libraries. results: we evaluated our approach on 6083 different libraries from maven central super repository that were used by 32,760 client systems obtained from github super repository. our results show that our approach outperforms three other existing search techniques and a state-of-the art approach, not based on heuristic search, and succeeds in recommending useful libraries at an accuracy score of 92%, precision of 51% and recall of 68%, while finding the best trade-off between the three considered objectives. furthermore, we evaluate the usefulness of our approach in practice through an empirical study on two industrial java systems with developers. results show that the top 10 recommended libraries was rated by the original developers with an average of 3.25 out of 5. conclusion: this study suggests that (1) library usage history collected from different client systems and (2) library semantics/content embodied in library identifiers should be balanced together for an efficient library recommendation technique. (c) 2016 elsevier by. all rights reserved.
operational_amplifier	in comparison with conventional operational amplifier, ring amplifier can achieve better power efficiency for switched capacitor circuits. however, the cascade-inverter architecture of ring amplifier may suffer from undesirable oscillation which has a great impact on transient stability. this paper presents a latched-based ring amplifier which is capable of decreasing the probability of oscillation. besides, two auto-zero schemes are employed in different pipelined stages to reduce the common-mode voltage offset and to increase the stability. the prototype adc was fabricated in a 90-nm cmos technology. the measured sndr and sfdr are 52.06 db and 63.15 db, respectively, for a nyquist frequency input sampled at 35 ms/s, and the adc consumes 3.65 mw.
operating_systems	heap-based priority queues are very common dynamical data structures used in several fields, ranging from operating systems to scientific applications. however, the rise of new multicore cpus introduced new challenges in the process of design of these data structures: in addition to traditional requirements like correctness and progress, the scalability is of paramount importance. it is a common opinion that these two demands are partially in conflict each other, so that in these computational environments it is necessary to relax the requirements of correctness and linearizability to achieve high performances. in this paper we introduce a loosely coordinated approach for the management of heap based priority queues on multicore cpus, with the aim to realize a tradeoff between efficiency and sequential correctness. the approach is based on a sharing of information among only a small number of cores, so that to improve performance without completely losing the features of the data structure. the results obtained on a scientific problem show significant benefits both in terms of parallel efficiency, as well as in term of numerical accuracy.
computer_vision	integrating computer vision and natural language processing is a novel interdisciplinary field that has received a lot of attention recently. in this survey, we provide a comprehensive introduction of the integration of computer vision and natural language processing in multimedia and robotics applications with more than 200 key references. the tasks that we survey include visual attributes, image captioning, video captioning, visual question answering, visual retrieval, human-robot interaction, robotic actions, and robot navigation. we also emphasize strategies to integrate computer vision and natural language processing models as a unified theme of distributional semantics. we make an analog of distributional semantics in computer vision and natural language processing as image embedding and word embedding, respectively. we also present a unified view for the field and propose possible future directions.
parallel_computing	background: population structure inference using the software structure has become an integral part of population genetic studies covering a broad spectrum of taxa including humans. the ever- expanding size of genetic data sets poses computational challenges for this analysis. although at least one tool currently implements parallel computing to reduce computational overload of this analysis, it does not fully automate the use of replicate structure analysis runs required for downstream inference of optimal k. there is pressing need for a tool that can deploy population structure analysis on high performance computing clusters. results: we present an updated version of the popular python program strauto, to streamline population structure analysis using parallel computing. strauto implements a pipeline that combines structure analysis with the evanno delta k analysis and visualization of results using structure harvester. using benchmarking tests, we demonstrate that strauto significantly reduces the computational time needed to perform iterative structure analysis by distributing runs over two or more processors. conclusion: strauto is the first tool to integrate structure analysis with post- processing using a pipeline approach in addition to implementing parallel computation - a set up ideal for deployment on computing clusters. strauto is distributed under the gnu gpl (general public license) and available to download from http://strauto.popgen.org.
operational_amplifier	this paper proposes a macromodel to emulate the nonlinear behavior of current-feedback operational amplifiers (cfoas) at low-frequency. the main difference between this macromodel and those reported previously in the literature is that herein, real physical active device performance parameters along with parasitic elements associated to the input-output terminals of the amplifier are considered. to validate the deduced behavioral model, a saturated nonlinear function series (snfs) based on cfoas is built and numerical simulations are generated. in this point, the modeling problem is cast in terms of an augmented set of equations but that, unlike a piece-wise linear (pwl) approach, the dynamic behavior of each cfoa is considered. afterwards, the snfs is experimentally tested by using commercially available active devices, confirming good agreement among theoretical simulations and experimental tests at two operating frequencies and showing a better accuracy compared with a pwl approach and a linear model for cfoas. because the derived nonlinear macromodel for cfoas is used for generating the behavioral model of the snfs, one concludes that the latter is also both accurate and efficient with respect to traditional techniques, such as pwl approaches. (c) 2015 elsevier ltd. all rights reserved.
electric_motor	designing efficient transmission mechanisms for advanced satellite networks is a demanding task, requiring the definition and the implementation of protocols and architectures well suited to this challenging environment. in particular, transport protocols performance over satellite networks is impaired by the characteristics of the satellite radio link, specifically by the long propagation delay and the possible presence of segment losses due to physical channel errors. the level of impact on performance depends upon the link design (type of constellation, link margin, coding and modulation) and operational conditions (link obstructions, terminal mobility, weather conditions, etc.). to address these critical aspects a number of possible solutions have been presented in the literature, ranging from limited modifications of standard protocols (e.g. tcp, transmission control protocol) to completely alternative protocol and network architectures. however, despite the great number of different proposals (or perhaps also because of it), the general framework appears quite fragmented and there is a compelling need of an integration of the research competences and efforts. this is actually the intent of the transport protocols research line within the european satnex (satellite network of excellence) project. stemming from the authors' work on this project, this paper aims to provide the reader with an updated overview of all the possible approaches that can be pursued to overcome the limitations of current transport protocols and architectures, when applied to satellite communications. in the paper the possible solutions are classified in the following categories: optimization of tcp interactions with lower layers, tcp enhancements, performance enhancement proxies (pep) and delay tolerant networks (dtn). advantages and disadvantages of the different approaches, as well as their interactions, are investigated and discussed, taking into account performance improvement, complexity, and compliance to the standard semantics. from this analysis, it emerges that dtn architectures could integrate some of the most efficient solutions from the other categories, by inserting them in a new rigorous framework. these innovative architectures therefore may represent a promising solution for solving some of the important problems posed at the transport layer by satellite networks, at least in a medium-to-long-term perspective. copyright (c) 2006 john wiley & sons, ltd.
state_space_representation	this paper describes an algorithm for computing the distribution of conditional forecasts, i.e., projections of a set of variables of interest on future paths of some other variables, in dynamic systems. the algorithm is based on kalman filtering methods and is computationally viable for large models that can be cast in a linear state space representation. we build large vector autoregressions (vars) and a large dynamic factor model (dfm) for a quarterly data set of 26 euro area macroeconomic and financial indicators. the two approaches deliver similar forecasts and scenario assessments. in addition, conditional forecasts shed light on the stability of the dynamic relationships in the euro area during the recent episodes of financial turmoil, and indicate that only a small number of sources drive the bulk of the fluctuations in the euro area economy. (c) 2014 international institute of forecasters. published by elsevier b.v. all rights reserved.
parallel_computing	given a graph g and a non-negative integer h, the h-restricted connectivity of g, denoted by kappa(h)(g), is defined as the minimum size of a set x of nodes in g (x subset of v (g)) such that g - x is disconnected, and the degree of each component in g - x is at least h. the h-restricted connectivity measure is a generalization of the traditional connectivity measure, and it improves the connectivity measurement accuracy. moreover, studies have revealed that if a network possesses a restricted connectivity property, it is more reliable and demonstrates a lower node failure rate compared with other networks. the n-dimensional locally twisted cube ltq(n), which is a well-known interconnection network for parallel computing, is a variant of the hypercube q(n). most studies have examined the h-restricted connectivity of networks under the conditions of h = 1 or h = 2. this paper examines a generalized h-restricted connectivity measure for n-dimensional locally twisted cube and reveals that kappa(h)(ltq(n)) = 2(h)(n - h) for 0 <= h <= n - 2. (c) 2016 elsevier b.v. all rights reserved.
microcontroller	the aim of this paper is to present the design and implementation of an electric foot rehabilitation machine that uses an advanced risc (reduced instruction set computer) machine (arm) microcontroller based brushless dc (bldc) motor drive. the function of the electric foot rehabilitation machine is to help patients who need physical therapy for a foot. the goal is for patients to have increased muscle strength after rehabilitation. the system hardware and software are designed and programmed. the proportion, integration and derivation (pid) control algorithm is employed to the motor drive for the speed and torque control. a user interface is also developed and implemented to provide a user-friendly experience. finally, a prototype of the foot rehabilitation machine is built and tested. the experimental results demonstrate the feasibility and integrity of the complete system. (c) 2016 elsevier ltd. all rights reserved.
distributed_computing	voltage scaling is a fundamental technique in the energy efficient computing field. recent studies tackling this topic show degraded system reliability as frequency scales. to address this conflict, the subject of reliability aware power management (rapm) has been extensively explored and is still under investigation. heterogeneous computing systems (hcs) provide high performance potential which attracts researchers to consider these systems. unfortunately, the existing scheduling algorithms for precedence constrained tasks with shared deadline in hcs do not adequately consider reliability conservation. in this study, we design joint optimization schemes of energy efficiency and system reliability for directed acyclic graph (dag) by adopting the shared recovery technique, which can achieve high system reliability and noticeable energy preservation. to the best of our knowledge, this is the first time to address the problem in hcs. the extensive comparative evaluation studies for both randomly generated and some real-world applications graphs show that our scheduling algorithms are compelling in terms of enhancement of both system reliability and energy saving. (c) 2015 elsevier ltd. all rights reserved.
cryptography	recently, wei et al. propose a 2-out-of-2 sharing digital image scheme (sdis) that shares a color secret image into two shadow images based on boolean exclusive-or operation. there are three types of shadow images for wei et al. 's sdis: noise-like, black-and-white meaningful, and color meaningful shadow images. however, there exist some wealmesses in wei et al. 's sdis: the incorrect assignment of color palette data for the color index 255, the erroneous recovery in secret image, and the partial region in shadow image revealing the cover image. in this paper, we solve the weaknesses and propose a new sdis. experimental results demonstrate that our scheme effectively avoids these weaknesses.
network_security	computer network vulnerability analysis is a method of analysis and evaluation of network security beforehand. the attacks method has occurred in the network, the previous network status change as input information, calculated by the model analysis. forecasting network node may be network attacks given the current security level value network, network security reinforcement measures taken before the danger. administrators can proactively identify network security issues, to take measures in advance to avoid information leakage, financial losses, ensure the safety of individuals and countries. therefore, vulnerability analysis computer network is very important. based on the properties of attack graph shows the method of attack graphs to bayesian network transformation, using the new algorithm to eliminate loops attribute attack graph optimization, building the bayesian attribute attack graph model used to evaluate the network itself security situation. in this model, based on bayes formula for calculating the probability of a new node probability calculation formula and attack paths occur for calculating network vulnerability assessment of the quantitative indicators. the model not only can visually process description of cyber attacks, but also into the bayesian network probabilistic thinking of possible network attack path prediction and assessment.
symbolic_computation	building fractional mathematical models for specific phenomena and developing numerical or analytical solutions for these fractional mathematical models are crucial issues in mathematics, physics, and engineering. in this work, a new analytical technique for constructing and predicting solitary pattern solutions of time-fractional dispersive partial differential equations is proposed based on the generalized taylor series formula and residual error function. the new approach provides solutions in the form of a rapidly convergent series with easily computable components using symbolic computation software. for method evaluation and validation, the proposed technique was applied to three different models and compared with some of the well-known methods. the resultant simulations clearly demonstrate the superiority and potentiality of the proposed technique in terms of the quality performance and accuracy of substructure preservation in the construct, as well as the prediction of solitary pattern solutions for time-fractional dispersive partial differential equations. (c) 2014 elsevier inc. all rights reserved.
symbolic_computation	in euclidean plane geometry, the evolute of both b-spline and nurbs curves are nurbs curves. moreover, this evolute can be computed symbolically. this article extends those results to the equiaffine plane geometry. analogously to euclidean geometry, the equi-affine evolute of both b-spline and nurbs curves are nurbs curves and an algorithm for the symbolic computation is given for b-spline curves. this results in a new method to analyze the global affine differential properties of b-spline curves and assess b-spline curve quality in an affine invariant context.
operational_amplifier	this paper presents an extension of the ballistic carbon nanotube field-effect transistor (cntfet) raychowdhury [1] compact model with adding acoustic phonon (ap) and optical phonon scattering (op) mechanisms. these mechanisms cause noise in the device. to obtain an accurate compact model, the flicker and thermal noise-models should be included. this model can be easily implemented with a hardware description language (hdl)-like verilog-a in the agilent advanced design system simulation tool ads. the impact of the ap scattering mechanism on operational amplifier (op amp) circuit performances is investigated and the simulation results are compared with respect to op amp including both ap and op scattering and to amp op using ballistic model. hence, degradation in the op amp performances with ap and op scattering models is observed especially in gain and bandwidth figure of merits in addition to the increase of the flicker noise in the device.
image_processing	in remote sensing image processing, the traditional fusion algorithm is based on the intensity-hue-saturation (ihs) transformation. this method does not take into account the texture or spectrum information, spatial resolution and statistical information of the photos adequately, which leads to spectrum distortion of the image. although traditional solutions in such application combine manifold methods, the fusion procedure is rather complicated and not suitable for practical operation. in this paper, an improved ihs transformation fusion algorithm based on the local variance weighting scheme is proposed for remote sensing images. in our proposal, firstly, the local variance of the spot (which comes from french ""systeme probatoire d'observation dela tarre"" and means ""earth observing system"") image is calculated by using different sliding windows. the optimal window size is then selected with the images being normalized with the optimal window local variance. secondly, the power exponent is chosen as the mapping function, and the local variance is used to obtain the weight of the i component and match spot images. then we obtain the i'component with the weight, the i component and the matched spot images. finally, the final fusion image is obtained by the inverse intensity-hue-saturation transformation of the i', h and s components. the proposed algorithm has been tested and compared with some other image fusion methods well known in the literature. simulation result indicates that the proposed algorithm could obtain a superior fused image based on quantitative fusion evaluation indices.
computer_programming	many of the students in our classrooms belong to the gamer generation. because of the success of digital games as entertainment products as well as formidable motivators, the possibility of using them in educational settings is being contemplated from a while. in this research we try to identify a set of digital games with the potential to be used to design learning activities, specifically to learn computer programming concepts like: algorithms, variables, and control structures. based on the contents and sequencing of learning, two games were chosen and incorporated into the activities of a workshop on introduction to programming in order to analyze their usefulness. the workshop was designed on the moodle platform using a gamification approach. here, we present a selection of serious games focused on computer language programming, the selection criteria of two of them and their use in a workshop for incoming students, as well as some of the results obtained from this experience.
symbolic_computation	a improvement of the expansion methods namely the improved tan(phi(xi)/2)-expansion method for solving the tzitzeica type nonlinear evolution equations is proposed. in this work, the dispersive optical solitons that are governed by the tzitzeica type nonlinear evolution equations. as a result, many new and more general exact travelling wave solutions are obtained including periodic function solutions, soliton-like solutions and trigonometric function solutions. the exact particular solutions containing four types hyperbolic function solution, trigonometric function solution, exponential solution and rational solution. we obtained the further solutions comparing with other methods. recently this method is developed for searching exact travelling wave solutions of nonlinear partial differential equations. abundant exact travelling wave solutions including solitons, kink, periodic and rational solutions have been found. these solutions might play important role in engineering fields. it is shown that this method, with the help of symbolic computation, provides a straightforward and powerful mathematical tool for solving the nonlinear problems.
operational_amplifier	this paper presents a low voltage continuous-time delta-sigma modulator (dsm) intended for the receiver of an ultra-low-power radio. the dsm features a 2nd-order loop filter implemented with a single operational amplifier to reduce the power consumption. furthermore, a 4-bit quantizer is used to achieve high resolution while keeping the sampling frequency low. the quantizer is realized using the successive approximation register architecture with asynchronous control which is more power efficient than the commonly used flash architecture. the dsm has been implemented in a 65 nm cmos process. simulation results show a peak sndr of 65 db over a 500 khz signal bandwidth. the dsm consumes 69 w from a 800 mv power supply.
algorithm_design	we are on the cusp of the emergence of a new wave of nonvolatile memory technologies that are projected to become the dominant type of main memory in the near future. a key property of these new memory technologies is their asymmetric read-write costs: writes can be an order of magnitude or more higher energy, higher latency, and lower (per module) bandwidth than reads. this high cost for writes motivates a rethinking of algorithm design towards ""write efficient"" algorithms and data structures that reduce their number of writes [1, 2, 3, 4, 5, 6]. many popular techniques for sequential, distributed, and parallel algorithms are tuned to the setting where reads and writes cost the same, and hence need to be revisited. prior work on reducing writes to contended cache lines in shared memory algorithms can be useful here, but with the new technologies, even writes to uncontended memory is costly. moreover, the new technologies are unlikely to replace the fastest cache memory, motivating the study of a multi-level memory hierarchy comprised of smaller symmetric level(s) and a larger asymmetric level. lower bounds, too, need to be revisited in light of asymmetric costs. this talk provides background on these emerging memory technologies, highlights the progress to date on these exciting research questions, and touches on a few of the many open problems.
image_processing	this work presents the application of terahertz imaging to three-dimensional formalin-fixed, paraffin-embedded human breast cancer tumors. the results demonstrate the capability of terahertz for in-depth scanning to produce cross section images without the need to slice the tumor. samples of tumors excised from women diagnosed with infiltrating ductal carcinoma and lobular carcinoma are investigated using a pulsed terahertz time domain imaging system. a time of flight estimation is used to obtain vertical and horizontal cross section images of tumor tissues embedded in paraffin block. strong agreement is shown comparing the terahertz images obtained by electronically scanning the tumor in-depth in comparison with histopathology images. the detection of cancer tissue inside the block is found to be accurate to depths over 1 mm. image processing techniques are applied to provide improved contrast and automation of the obtained terahertz images. in particular, unsharp masking and edge detection methods are found to be most effective for three-dimensional block imaging.
pid_controller	the constrained control of unmanned aerial vehicles (uavs) is a challenging task due to their nonlinear and underactuacted dynamics. this brief focuses on the position control of a quadrotor uav with state and input constraints using an inner-outer loop control structure. the outer loop generates a saturated thrust, and the reference roll and pitch angles, while the inner loop is designed to follow these reference angles using a traditional pid controller. assuming perfect inner loop tracking, the outer loop nested saturation controller guarantees global asymptotic stability for output regulation and tracking. the effect of nonideal inner loop tracking on closed-loop stability is analyzed. the proposed method is experimentally validated on an indoor quadrotor platform.
machine_learning	in this paper a novel tensor-based image segmentation algorithm (tbisa) is presented, which is dedicated for segmentation of colour images. a purpose of tbisa is to distinguish specific objects based on their characteristics, i.e. shape, colour, texture, or a mixture of these features. all of those information are available in colour channel data. nonetheless, performing image analysis on the pixel level using rgb values, does not allow to access information on texture which is hidden in relation between neighbouring pixels. therefore, to take full advantage of all available information, we propose to incorporate the structural tensors as a feature extraction method. it forms enriched feature set which, apart from colour and intensity, conveys also information of texture. this set is next processed by different classification algorithms for image segmentation. quality of tbisa is evaluated in a series of experiments carried on benchmark images. obtained results prove that the proposed method allows accurate and fast image segmentation.
analog_signal_processing	we describe architectures for audio classification front ends on a reconfigurable analog platform. real-time implementation of audio processing algorithms involving discrete-time signals tend to be power-intensive. we present an alternate continuous-time system implementation of a noise-suppression algorithm on our reconfigurable chip, while detailing the design considerations. we also describe a framework that enables future implementations of other speech processing algorithms, classifier front ends, and hearing aids.
electric_motor	mathematical model of the linear induction motor and energy flow relationship of dual linear induction motor system were analyzed in this paper, on the basis of above analysis, a energy cross feed dual linear induction motor testing system was designed. cross feed dual energy linear induction motor testing system consists of two linear induction motors. in accordance with certain control strategies, one electric motor is in the state, and the other one is in the power generation state. testing systems could be used to simulate the characteristics of motor loading status and the motor can traverse mechanical energy produced by mechanical motion into electrical energy, which backs to the grid. the testing system possesses excellent properties such as good reliability, energy efficiency and flexible control ability.
signal-flow_graph	sigma-delta modulator structure is presented in the form of matrix equations. the equations allow to easily obtain analytical expressions for the noise and signal transfer functions for arbitrary modulator structures. as a result the modulator structures analysis and comparison become straightforward.
voltage_law	in 2020 electricity production from wind power should constitute nearly 50% of electricity demand in denmark. in this paper we look at optimal expansion of the transmission network in order to integrate 50% wind power in the system, while minimizing total fixed investment cost and expected cost of power generation. we allow for active switching of transmission elements to reduce congestion effects caused by kirchhoff 's voltage law. results show that actively switching transmission lines may yield a better utilization of transmission networks with large-scale wind power and increase wind power penetration. furthermore, it is shown that transmission switching is likely to affect the optimal line capacity expansion plan.
lorentz_force_law	this paper presents the controller design and implementation of a high-precision six-degree-of-freedom (6-dof) magnetically levitated (maglev) positioner. this high-precision positioning system consists of a novel concentrated-field magnet matrix and a triangular single moving part that carries three three-phase permanent-magnet planar-levitation-motor armatures. since only a single levitated moving part, namely the platen, generates all required fine and coarse motions, this positioning system is reliable and potentially low-cost. the three planar levitation motors based on the lorentz force law not only produce the vertical force to levitate the triangular platen but also control the platen 's position and orientation in the horizontal plane. the main contribution of this paper is that all 6-dof motions are solely controlled by magnetic forces without any other means to support the platen 's weight against gravity, and the most suitable controller of the magnetic levitation system was designed and implemented. the platen can be regarded as a pure mass, and the spring and damping effects are neglected except for the vertical directions. single-input single-output digital lead-lag controllers were designed and implemented on a digital signal processor. this 6-dof fully magnetically levitated positioner has a total mass of 5.91 kg and exhibits a 120 x 120 mm maximum travel range. the position resolution of 20 nm and position noise of 10-nm root mean square are demonstrated. the positioner has sub-microradian angular resolution in about the x, y, and z-axes. a maximum velocity of 24.8 mm/s in y is achieved. this single-moving-part maglev positioner structure is highly suitable for semiconductor manufacturing applications such as wafer steppers. several experimental motion profiles are presented to demonstrate the maglev stage 's capability of accurately tracking any planar and three-dimensional paths.
electric_motor	as electric vehicles (evs) become more popular, an abundance of valuable engineering resources are dedicated to creating full-scale test beds to validate and modify vehicle hardware and software. this paper presents a systematic approach to down-scaling full-size electric vehicles' parameters and environmental conditions to a level that can be handled by a small-scale hardware-in-the-loop (hil) simulation test bed. the paper also presents the method for scaling the simulation results back up to the full-size vehicle level. the ev test bed is realized using a two-electric machine system, where one machine represents the vehicle 's traction motor and the other emulates the vehicle parameters and operating environment.
control_engineering	the concept of web laboratories with remotely controlled laboratory set ups or virtual laboratories with different simulations have an important role in engineering education and training. this paper presents an evaluation of the fundamental objectives of laboratories for distance education, comparing the effectiveness of a remotely controlled approach versus simulations. the results and analysis show that students prefer remotely controlled laboratories compared to simulation labs. the results show that remotely controlled laboratories better fulfill objectives important for laboratory exercises. (c) 2013 wiley periodicals, inc. comput appl eng educ 23:191-202, 2015; view this article online at ; doi
cryptography	visual cryptography (vc) is a variant form of secret sharing. in general threshold setting, the k-out-of-n vc allows that, in a set of n participants, any k can recover and reconstruct the secret by stacking their shares. recently, the notion of multiple-secret vc has been introduced to embed multiple secrets. region incrementing visual cryptography (rivc) is referred to as a new type of multi-secret vc. rivc defines s layers and takes s secrets, and then embeds each secret into each layer. the layers are defined by the number of participants; for example, let two secrets and two layers be s-2, s-3 and l-2, l-3 in two-out-of-three rivc, where any two participants in l-2 can recover s-2 and three in l-3 can recover s-2, s-3. however, there is another multi-secret vc, called fully incrementing visual cryptography (fivc), which also has the layers, but only one secret s-i will reveal in one layer l-i. in this paper, our stating point is to propose a new notion of non-monotonic visual cryptography (nvc) for human vision system as a primitive to construct fivc. we first present an ideal construction of simple nvc, which relies on a slightly unreasonable assumption. based on the simple nvc, we show a few methods to extend the functionality for complicated cases of nvc. then, the generic construction is presented as a systematic manner to eliminate the above-mentioned assumption. finally, we formally introduce a transformation nvc-to-fivc algorithm, which takes nvc as input and then produce a construction of fivc. also, show a demonstration the nvc-to-rivc algorithm, and analyze some properties regarding nvc. we believe that the notion of nvc can potentially find other applications and is of independent interest.
electrical_circuits	a series of zinc-phosphate glass containing different concentrations of v2o5 ((80 - x) napo3 + 20 zno + x v2o5 (x = 0-25 mol%)) was prepared by melt quenching method and analyzed by differential scanning caloremetry (dsc) and impredance spectroscopy. the electrical properties of these samples were measured using ac impedance spectroscopy technique over a frequency range of 10 hz to 13 mhz at several temperatures in the range of 323-673 k. the ac conductivity, dc conductivity, dielectric constant and loss factors were obtained from these measurements. constant-phase elements (cpe) are used in equivalent electrical circuits for the fitting of experimental impedance data. the impedance spectra have also indicated that the conduction is predominantly polaronic in nature. the frequency and temperature dependence of the electrical modulis as well as dielectric loss parameters have exhibited a relaxation character attributed to the vanadyl complexes. the relaxation effects have been analyzed by the graphical method. from this analysis, it has been established that there is a spread of relaxation times. the results have been further discussed quantitatively in the light of different valance states of vanadium ions with the aid of the data on spectroscopic properties. the frequency dependence of the electric conductivity was found to follow a simple power law behavior, in accordance with the relation sigma(ac)(omega) = sigma(0) + lambda(1).omega(s)(2), where s(1) and s(2) are smaller than 1. the thermal activation energies for the electronic conduction were estimated on the basis of the arrhenius plots. (c) 2014 published by elsevier b.v.
pid_controller	in this paper a method for an automatic tuning of a fractional pid-controller is proposed. a fractional pid-controller contains non-integer integrations and derivatives.
symbolic_computation	recursive branch and bound algorithms are often used, either rigorously or non-rigorously, to refine and isolate solutions to global optimization problems or systems of equations and inequalities involving nonlinear functions. the presented software library, kodiak, integrates numeric and symbolic computation into a generic framework for the solution of such problems over hyper-rectangular variable and parameter domains. the correctness of both the generic branch and bound algorithm and the self-validating enclosure methods used, namely interval arithmetic and, for polynomials and rational functions, bernstein expansion, has been formally verified. the algorithm has three main instantiations, for systems of equations and inequalities, for constrained global optimization, and for the computation of equilibria and bifurcation sets for systems of ordinary differential equations. for the latter category, and to enable the computation of bisection heuristics to reduce the branching factor, advantage is taken of the partial derivatives of the constraint functions, which are symbolically manipulated. pavings (unions of box subsets) for a continuum of solutions to underdetermined systems may also be produced. the capabilities of the software tool are outlined, and computational examples are presented.
cryptography	in the russian cards problem, alice, bob and cath draw a, b and c cards, respectively, from a publicly known deck. alice and bob must then communicate their cards to each other without cath learning who holds a single card. solutions in the literature provide weak security, where alice and bob 's exchanges do not allow cath to know with certainty who holds each card that is not hers, or perfect security, where cath learns no probabilistic information about who holds any given card. we propose an intermediate notion, which we call -strong security, where the probabilities perceived by cath may only change by a factor of . we then show that strategies based on affine or projective geometries yield -strong safety for arbitrarily small and appropriately chosen values of a, b, c.
data_structures	medium and large construction projects typically involve multiple structural consultants who use a wide range of structural analysis applications. these applications and technologies have inadequate interoperability and there is still a dearth of investigations addressing interoperability issues in the structural engineering domain. this paper proposes a novel approach which combines an industry foundation classes (ifc)-based unified information model with a number of algorithms to enhance the interoperability: (a) between architectural and structural models, and (b) among multiple structural analysis models (bidirectional conversion or round tripping). the proposed approach aims to achieve the conversion by overcoming the inconsistencies in data structures, representation logics and syntax used in different software applications. the approach was implemented in both client server (c/s) and browser server (b/s) environments to enable central and remote collaboration among geographically dispersed users. the platforms were tested in four large real-life projects. the testing involved four key scenarios: (a) the bidirectional conversion among four structural analysis tools; (b) the comparison of the conversion via the proposed approach with the conversion via direct links among the involved tools; (c) the direct export from an ifc-based architectural tool through the application program interface (api), and (d) the conversion and visualization of structural analysis results. all these scenarios were successfully performed and tested in four significant case studies. in particular, the conversion among the four structural analysis applications (etabs, sap2000, ansys and midas) was successfully tested for all possible conversion routes among the four applications in two of the case studies (i.e., project a and project b). the first four steps of natural mode shapes and their natural vibration periods were calculated and compared with the converted models. they were all achieved within a standard deviation of 0.1 s and 0.2 sin project a and project b, respectively, indicating an accurate conversion. (c) 2016 elsevier b.v. all rights reserved.
image_processing	the use of white light based three fringe photoelasticity (tfp)/rgb photoelasticity has gained importance in the recent years. with recent advances in tfp, it is possible to resolve fringe orders upto twelve. the main advantage of this technique is that it requires only a single image for isochromatic demodulation, which makes it suitable especially for problems where recording multiple images is difficult. the accuracy of isochromatic data obtained using tfp/rgb photoelasticity is dependent on the scanning scheme used to refine the data, which is necessary to incorporate fringe order continuity. in this paper, the existing scanning schemes are critically evaluated for their ability to scan the entire model domain, influence of seed point selection and noise propagation. the scanning schemes are assessed using four problems of increasing level of geometric complexity - circular disc under compression (simply connected), bi-axially loaded cruciform specimen with an inclined crack, a thick ring subjected to internal pressure and a finite plate with a hole (multiply connected). (c) 2016 elsevier ltd. all rights reserved.
electrical_network	with the increasing penetration of renewable energy sources and inclusion of additional features, the electrical networks have become more active. every passing decade has seen newer features of the electrical network and with the emerging smart grid, distribution systems becomes active. grid tied inverters are vital component of active distribution systems, acting as interfaces for the distributed generators. this paper presents model predictive control (mpc) of a multifunctional inverter used for power quality compensation of non-linear local loads and grid integration of solar photovoltaic generators. by including the discrete nature of the switches in the power converter, the optimisation problem of mpc the reference current for the converter control is generated using instantaneous power theory. the control is simulated in matlab/simulink.
computer_graphics	this paper presents a method to solve - in real time the three dimensional workspace generation problem for arbitrary serial manipulators. our approach is based on monte carlo simulation, to process a high number of forward kinematics with randomly chosen joint values. this results in an asymptotic coverage of the reachable workspace. additionally, collision detection is integrated to consider obstacles within the manipulator 's environment. the method is implemented on the graphics processing unit (gpu), such that an extremely high number of workspace points can be processed in parallel. tests have shown that this approach is capable to generate acceptable workspace coverage within milliseconds. furthermore, the workspace is held as a three dimensional texture volume on the graphics memory, allowing for instant visualisation of the workspace during the generation process without the need for further time-intensive data exchange.
system_identification	this paper proposes and studies the nonparametric system identification of a foil-air bearing (fab). this research is motivated by two advantages: (a) it removes computational limitations by replacing the air film and foil structure equations by a displacement/force relationship and (b) it can capture complications that cannot be easily modeled, if the identification is based on empirical data. a recurrent neural network (rnn) is trained to identify the full numerical model of a fab over a wide range of speeds. the variable-speed rnn-fab model is then successfully validated against benchmark results in two ways: (i) by subjecting it to different input data sets and (ii) by using it in the harmonic balance (hb) solution process for the unbalance response of a rotor-bearing system. in either case, the results from the identified variable-speed rnn maintain very good correlation with the benchmark over a wide range of speeds, in contrast to an earlier identified constant-speed rnn, demonstrating the great potential of this method in the absence of self-excitation effects.
operating_systems	performance and determinism are two critical metrics in most embedded systems with real-time requirements. owing to the complexity of current embedded systems, along with increased application demands, real-time operating systems (rtoss) have become a de facto solution providing specific services to the system tasks. however, this extra layer, which abstracts the hardware from the software, makes it harder for a system to achieve good performance and determinism. to ease the impact of a rtos in the system, rtos run-time services are offloaded to the hardware layer. this paper presents a hybrid rtos implementation, where several critical rtos services were migrated from software to hardware, improving system latency and predictability. special focus was given to the rtos scheduler and to the mutexes handling subsystem. the developed hardware accelerators were synthesised on a field-programmable gate array (fpga), exploiting the point-to-point fast simplex link (fsl) bus to interconnect to the xilinx microbaze soft-core processor. our approach shows that hybrid rtos has a better performance and predictability when compared to its software-only version.
cryptography	proteins are one of the most versatile modular assembling systems in nature. experimentally, more than 110 000 protein structures have been identified and more are deposited every day in the protein data bank. such an enormous structural variety is to a first approximation controlled by the sequence of amino acids along the peptide chain of each protein. understanding how the structural and functional properties of the target can be encoded in this sequence is the main objective of protein design. unfortunately, rational protein design remains one of the major challenges across the disciplines of biology, physics and chemistry. the implications of solving this problem are enormous and branch into materials science, drug design, evolution and even cryptography. for instance, in the field of drug design an effective computational method to design protein-based ligands for biological targets such as viruses, bacteria or tumour cells, could give a significant boost to the development of new therapies with reduced side effects. in materials science, self-assembly is a highly desired property and soon artificial proteins could represent a new class of designable self-assembling materials. the scope of this review is to describe the state of the art in computational protein design methods and give the reader an outline of what developments could be expected in the near future.
digital_control	based on time-domain quality factor ( q-factor) measurement principle, we have proposed an architecture which has the potential to be integrated on-chip. thanks to the proposed original reconfigurable structure, the main measurement error from the offset of the operational trans conductance amplifier (ota) used can be cancelled automatically during the measurement operation, leading to a high accuracy q-factor measurement. the digital control circuit plays an important role in the automatic passage between the two configurations designed, i.e., peak detector and comparator. the main advantages of the proposed time-domain q-factor measurement lay on the possibility of being integrated next to the micro electro mechanical system (mems) resonator to be measured, the miniaturization of the whole measuring system as well as the enhancement of the measurement performance, and to guide the design of such architecture, a theoretical analysis linking the required accuracy and the given q-factor to the circuit parameters have been given in this paper. the proposed circuit is designed and simulated in a 0.35 pm complementary metal oxide semiconductors (cmos) technology. the post-layout simulation results show that the operating frequency can reach up to 200 khz with an accuracy of 0.4%.
computer_vision	both subspace learning methods and feature selection methods are often used for removing irrelative features from high-dimensional data. studies have shown that feature selection methods have interpretation ability and subspace learning methods output stable performance. this paper proposes a new unsupervised feature selection by integrating a subspace learning method (i.e., locality preserving projection (lpp)) into a new feature selection method (i.e., a sparse feature-level self-representation method), aim at simultaneously receiving stable performance and interpretation ability. different from traditional sample-level self-representation where each sample is represented by all samples and has been popularly used in machine learning and computer vision. in this paper, we propose to represent each feature by its relevant features to conduct feature selection via devising a feature-level self-representation loss function plus an l(2,1)-norm regularization term. then we add a graph regularization term (i.e., lpp) into the resulting feature selection model to simultaneously conduct feature selection and subspace learning. the rationale of the lpp regularization term is that lpp preserves the original distribution of data after removing irrelative features. finally, we conducted experiments on uci data sets and other real data sets and the experimental results showed that the proposed approach outperformed all comparison algorithms. (c) 2016 elsevier b.v. all rights reserved.
software_engineering	simulation-based studies (sbs) have become an interesting investigation approach for software engineering (se). however, the reports on experiments with dynamic simulation models found in the technical literature lack relevant information, hampering the full understanding of the procedures and results reported, as well as their replicability. apart from the limitations on the length in conferences and journal papers, some of the relevant information seems to be missing due to methodological issues not considered when conducting such studies. this is the case of missing research questions and goals, lack of evidence regarding the dynamic simulation model validity, poorly designed simulation experiments, amongst others. based on findings from a previous quasi-systematic literature review, we propose a set of reporting guidelines for sbs with dynamic models in the context of se aiming at providing guidance on which information the report should contain. furthermore, these guidelines were evolved to support sbs planning by identifying potential threats to simulation study validity and in making recommendations to avoid them, through qualitative analysis and external evaluation. finally, we conducted different evaluations regarding both the reporting and planning guidelines, apart from using them to support the planning of a sbs as regards software evolution. a set of 33 reporting and planning guidelines for different stages of the simulation lifecycle and focused on the experimentation with dynamic simulation models have been put together. the first assessments point to a comprehensive set of guidelines, supporting a comprehensive preparation and review of the plans and reports from the studies, apart from the planning of a sbs focused on software evolution, potentially reducing the threats to the experimentation with the validity of dynamic simulation models. the 33 guidelines cannot be understood as separate groups for reporting and planning as they overlap in many aspects. the main goal is to use the guidelines to support the planning of a simulation-based study with dynamic models so that experimenters may identify potential threats to validity and produce relevant information for a complete simulation experiment report in advance. despite their initial contribution to increase the validity of sbs, the reporting and planning of simulation-based experiments with dynamic models still has to be discussed and improved in se. therefore, additional assessments of this set of guidelines are needed to strengthen the confidence in their completeness and usefulness.
computer_programming	an important number of academic tasks should be solved collaboratively by groups of learners. the computer-supported collaborative learning (cscl) systems support this collaboration by means of shared workspaces and tools that enable communication and coordination between learners. successful collaboration and interaction can depend on the criteria followed when forming the groups of learners. this paper proposes a method that analyses the collaboration and interaction between learners using a set of indicators or variables about how they solve academic tasks. then, the concept of data depth is used as a measurement of the closeness of the analysis indicators' values for a learner with respect to the values that the same indicators take for the other learners. finally, the data depth is used to form new groups of learners whose analysis indicators take similar or different values. thus, the method enables teachers to form homogeneous and heterogeneous groups according to their preferences. this group formation process is carried out automatically by a software tool. this paper presents two case studies in which the method is applied to form groups of learners who solve academic tasks in different domains (computer programming and data mining). (c) 2014 elsevier ltd. all rights reserved.
electricity	herein a techno-economic assessment was performed on an energy-crop-based biogas plant coupled with a greenhouse for utilizing thermal energy produced by cogeneration. seven energy crops were evaluated: triticale, maize, alfalfa, sunflower, clover, barley and wheat. according to the evaluation, triticale was the most competitive energy crop under selected climate conditions for northern greece. although maize displays higher biomass yield and biogas potential than the drought-resistant crop triticale, it has high irrigation demand that contributes significantly to total production costs. for a triticale-based biogas production to become economically feasible, agricultural arable area larger than 500 ha, or biogas plant size larger than 1000 kw(el), is required. however, with public funding, biogas production becomes feasible at smaller area (>250 ha) or biogas plant size (>500 kw(el)). the inclusion of a greenhouse into the design of the biogas plant contributes positively to the economic viability of the entire system. under this scenario, greenhouse financial income accounts for about 17-18% of total income. results of a sensitivity analysis suggest that the selection of an appropriate energy crop for biogas production should be based principally on both digestibility (specific methane yield) and biomass yield per hectare, these factors being more critical than biomass production costs.
network_security	due to the appearance of some new characteristics of the electric power industry such as widely interconnection, high intelligent, the open and interactive, energy internet architecture put forward more new requirements of the electric information network security prevention and the information security faced a severe challenge. at present, the method of information security is extensive, management model and prevention system exist some weak links. this paper put forward a new model to guide the overall development of information security work through the quantization of risk indicator and fuzzy intelligent analysis.
operating_systems	recent approaches to network functions virtualization (nfv) have shown that commodity network stacks and drivers struggle to keep up with increasing hardware speed. despite this, popular cloud networking services still rely on commodity operating systems (oss) and device drivers. taking into account the hardware underlying of commodity servers, we built an nfv profiler that tracks the movement of packets across the system 's memory hierarchy by collecting key hardware and os-level performance counters. leveraging the profiler 's data, our service chain coordinator 's (scc) run-time accelerates user-space nfv service chains, based on commodity drivers. to do so, scc combines multiplexing of system calls with scheduling strategies, taking time, priority, and processing load into account. by granting longer time quanta to chained network functions (nfs), combined with i/o multiplexing, scc reduces unnecessary scheduling and i/o overheads, resulting in three-fold latency reduction due to cache and main memory utilization improvements. more importantly, scc reduces the latency variance of nfv service chains by up to 40x compared to standard fastclick chains by making the average case for an nfv chain to perform as well as the best case. these improvements are possible because of our profiler 's accuracy. (c) 2017 the author(s). published by elsevier inc. this is an open access article under the cc by-nc-nd license. (http://creativecommons.org/licenses/by-nc-nd/4.0/)
electrical_circuits	feedback indicating how well students are performing during a learning task can be very stimulating. in this study with a pre- and post-test design, the effects of two types of performance feedback on learning results were compared: feedback during a learning task was either stated in terms of how well the students were performing relative to other students (social comparison feedback) or relative to an absolute criterion (criterion-based feedback). thirty-four students in secondary vocational engineering education were randomly assigned to one of two conditions. in both conditions, students worked together in small groups. all groups completed a math learning task, during which they received either social comparison feedback or criterion-based performance feedback. the findings showed that the type of feedback had a strong effect on learning outcomes: the post-test scores and gains of students in the social comparison condition were significantly higher than those of students in the criterion-based feedback condition.
electricity	this paper discusses the concepts and current trends in the structure of wholesale electricity markets and additionally reviews the structure of some electricity markets in the world. it also reviews the experience around the system operation and market operation, as well as how the main processes are handled in european and american markets. this review shows that there are various designs to which these markets are converging depending on your needs and structures. some trends turn around the presence of tso, iso and market operator (om); as well as the operation of derivatives markets.
computer_vision	this paper presents an innovative solution based on time-of-flight (tof) video technology to motion patterns detection for real-time dynamic hand gesture recognition. the resulting system is able to detect motion-based hand gestures getting as input depth images. the recognizable motion patterns are modeled on the basis of the human arm anatomy and its degrees of freedom, generating a collection of synthetic motion patterns that is compared with the captured input patterns in order to finally classify the input gesture. for the evaluation of our system a significant collection of gestures has been compiled, getting results for 3d pattern classification as well as a comparison with the results using only 2d information.
control_engineering	this paper describes the development of a motivating and innovative multi-robot formation control platform for laboratory experiments with mobile robots. the platform is composed of two components: a simulator and an environment to experiment with low cost wheeled mobile robots. the environment constitutes a ready to use test tool that provides to engineering students the opportunity to simulate and test many different formation and cooperation control strategies with a real system. currently the platform is used in the systems and control engineering master program offered by the national university of distance education (uned) and the complutense university of madrid (ucm) in spain. the use of the platform exposes students to hands-on laboratory sessions, contributing to their development as engineers.
system_identification	the authors propose a diagnostic technique for the state-space model fitting of time series by deleting some observations and measuring the change in the parameter estimates. they consider this approach in order to distinguish an observational outlier from an innovational one. thus, they present a robust subspace identification algorithm that is less sensitive to outliers. a monte carlo simulation for a vibrating structure model demonstrates the effectiveness of the proposed algorithm and its ability to detect outliers in the measurements as well as the dynamical state.
network_security	a distributed denial of service (ddos) attack is an austere menace to extensively used internet-based services. the in-time detection of ddos attacks poses a tough challenge to network security. revealing a low-rate ddos (lr-ddos) attack is comparatively more difficult in modern high speed networks, since it can easily conceal itself due to its similarity with legitimate traffic, and so eluding current anomaly based detection methods. this paper investigates the aptness and impetus of the information theory-based generalized entropy (ge) and generalized information distance (gid) metrics in detecting different types of ddos attacks. the results of ge and gid metrics are compared with shannon entropy and other popular information divergence measures. in addition, the feasibility of using these metrics in discriminating a high-rate ddos (hr-ddos) attack from a similar looking legitimate flash event (fe) is also verified. we used real and synthetically generated datasets to elucidate the efficiency and effectiveness of the proposed detection scheme in detecting different types of ddos attacks and fes. the results clearly show that the ge and gid metrics perform well in comparison with other metrics and have reduced false positive rate (fpr). (c) 2017 elsevier b.v. all rights reserved.
machine_learning	most of the well-known supervised dimensionality reduction methods assume unimodal or gaussian like-lihoods, which may not be appropriate in the real life applications. in this manuscript, we introduce a novel supervised dimensionality reduction approach, moments discriminant analysis, which models linear relationships between the high-dimensional input space and a low-dimensional space by maximizing the discrimination between second order raw moments of different classes to improve the generalization capability of a classifier. unlike the state-of-the-art methods, moments discriminant analysis is intended to accommodate data distributions that may be multimodal and non-gaussian. initially, experiments using synthetic random data (generated from different probability distributions) are performed to prove the efficiency of the proposed method for multimodal and non-gaussian data with the help of five separability measures. also, extensive experimental results on uci machine learning repository and image retrieval on wang and mit (oliva and torralba) databases are carried out in order to exhibit the effectiveness of moments discriminant analysis over the state-of-the-art methods.
operating_systems	cloud-based mobile networks are foreseen to be a technological enabler for the next generation of mobile networks. their design requires substantial research as they pose unique challenges, especially from the point of view of additional delays in the fronthaul network. commonly used network protocols should therefore be adjusted to cope with the peculiarities of these networks. in this paper, we investigate an optimized design of the transmission control protocol (tcp), as it plays a central role in all-ip mobile networks to ensure optimal performances for application-layer services. tcp implementations of 3 popular operating systems are investigated in our network model. the results on the most influential parameters are used to design an optimized tcp for cloud-based mobile networks.
software_engineering	regarding the issue of role-playing games (rpg) and the experiential learning cycle (elc), the integration of rpg use as a pedagogical and simulation tool for practice and elc as a learning theoretical foundation is essential for promoting students' effective learning. however, few studies have applied rpg to simulate the practice with the elc stages, namely, concrete experience (ce), reflective observation (ro), abstract conceptualization, (ac) and active experimentation (ae), to examine the learning process and further enhance the effective learning outcomes for learners. this study integrates the rpg development and use for practice derived from the elc 's four stages based on practising the project assessment of software development in a software engineering course. the results show a significant improvement in students' learning outcomes after rpg use. more importantly, this study provides the major activities and findings of each elc stage via rpg use and the mapping of rpg activities with elc stages. the insightful implications and suggestions of this study are discussed. (c) 2014 elsevier ltd. all rights reserved.
microcontroller	pilot balloon observatories of india meteorological department (avid) are using hand held data logger (hhdl), manufactured by sameer, to compute upper air data since 2007. the hhdl, which is a sleek and microcontroller based battery operated unit, accepts all information through the numeric keypad pertaining to the pb ascent for raw file generation and pilot balloon data processing. the raw file can be transferred to computer system as an input file to pc based pibal computation software. this software generates pibal messages similar to hhdl in addition to national data centre (ndc) data format and monthly climate. in case of any failure of hardware, both hhdl & pc based pibal computation software cannot be used. therefore to overcome this problem, a pc based pibal data keying software has been developed using visual c sharp. the new software, what is developed, creates an input file similar to hhdl; it was tested with pc based pibal computation software which works successfully as an alternate in case of failure of hhdl & it 's hardware accessories
bioinformatics	asian soybean rust (asr), caused by the obligate biotrophic fungus phakopsora pachyrhizi, can cause losses greater than 80%. despite its economic importance, there is no soybean cultivar with durable asr resistance. in addition, the p. pachyrhizi genome is not yet available. however, the availability of other rust genomes, as well as the development of sample enrichment strategies and bioinformatics tools, has improved our knowledge of the asr secretome and its potential effectors. in this context, we used a combination of laser capture microdissection (lcm), rnaseq and a bioinformatics pipeline to identify a total of 36 350 p. pachyrhizi contigs expressed in planta and a predicted secretome of 851 proteins. some of the predicted secreted proteins had characteristics of candidate effectors: small size, cysteine rich, do not contain pfam domains (except those associated with pathogenicity) and strongly expressed in planta. a comparative analysis of the predicted secreted proteins present in pucciniales species identified new members of soybean rust and new pucciniales- or p. pachyrhizi-specific families (tribes). members of some families were strongly up-regulated during early infection, starting with initial infection through haustorium formation. effector candidates selected from two of these families were able to suppress immunity in transient assays, and were localized in the plant cytoplasm and nuclei. these experiments support our bioinformatics predictions and show that these families contain members that have functions consistent with p. pachyrhizi effectors.
analog_signal_processing	a new universal current-mode biquad filter using current differencing transconductance amplifier (cdta) is proposed. the proposed configuration can realize the second-order low pass, high pass, band pass, and band reject responses simultaneously. the circuit employs both grounded capacitors (ideal for integrated circuit implementation), and offers low active and passive sensitivities. the workability of the proposed configuration has been verified using spice simulation. (c) 2008 elsevier gmbh. all rights reserved.
electric_motor	the application of an auto-guided tractor to rice cultivation in korean paddy fields may be limited by tire slippage and headland turning due to wet soil conditions and the use of small-sized fields30%, thereby requiring more accurate estimation of sliding parameters. (c) 2015 elsevier b.v. all rights reserved.
digital_control	in this technical note, we first present an adaptive distributed observer for a discrete-time leader system. this adaptive distributed observer will provide, to each follower, not only the estimation of the leader 's signal, but also the estimation of the leader 's system matrix. then, based on the estimation of the matrix s, we devise a discrete adaptive algorithm to calculate the solution to the regulator equations associated with each follower, and obtain an estimated feedforward control gain. finally, we solve the cooperative output regulation problem for discrete-time linear multi-agent systems by both state feedback and output feedback adaptive distributed control laws utilizing the adaptive distributed observer.
signal-flow_graph	a new approach is proposed to improve a graphical approach with considering intensity coupling loss coefficients in the analytical derivation of the optical transfer functions for a symmetric double stage vertically coupled microring resonator. an optimum transmission coupling condition is determined with considering terms of couplers intensity loss which leads to low insertion loss of 1.2 db, finesse of 1525, the out of band rejection ratio of 61.8 db. the resonating system is used as an optical force sensing system to make the benefit of the accuracy of measurements in micro and nano scales. the sensitivity of proposed force sensor in terms of wavelength-shift is 33 nm/nn and the limit of detection is 1.6 x 10 (2) nn. the proposed sensing system has the advantages of self-calibration and the low power consumption due to the low intensity. (c) 2014 elsevier ltd. all rights reserved.
computer_graphics	e-learning is a new learning model based on computer, multimedia and network, and it is based on ""constructivism education theory"" and ""humanistic education theory"". after study the limits of classical methods of computer graphic experiment learning, this paper implemented an e-learning platform. this platform includes 4 parts: the basic knowledge module, the tools and material module, the learning and communication module, and the learning evaluation module. this platform can improve the interest and enthusiasm of student. it can achieve better learning effect.
state_space_representation	in this paper, we present a tuning methodology for a simple offset-free siso model predictive controller (mpc) based on autoregressive models with exogenous inputs (arx models). arx models simplify system identification as they can be identified from data using convex optimization. furthermore, the proposed controller is simple to tune as it has only one free tuning parameter. these two features are advantageous in predictive process control as they simplify industrial commissioning of mpc. disturbance rejection and offset-free control is important in industrial process control. to achieve offset-free control in face of unknown disturbances or model-plant mismatch, integrators must be introduced in either the estimator or the regulator. traditionally, offset-free control is achieved using brownian disturbance models in the estimator. in this paper we achieve offset-free control by extending the noise model with a filter containing an integrator. this filter is a first order arma model. by simulation and analysis, we argue that it is independent of the parameterization of the underlying linear plant: while the tuning of traditional disturbance models is system dependent. using this insight, we present mpc for siso systems based on arx models combined with the first order filter. we derive expressions for the closed-loop variance of the unconstrained mpc based on a state space representation in innovation form and use these expressions to develop a tuning procedure for the regulator. we establish formal equivalence between gpc and state space based off-set free mpc. by simulation we demonstrate this procedure for a third order system. the offset-free arx mpc demonstrates satisfactory set point tracking and rejection of an unmeasured step disturbance for a simulated furnace with a long time delay. (c) 2012 elsevier ltd. all rights reserved.
electrical_circuits	learning the analysis of electrical circuits represented by circuit diagrams is often challenging for novice students. an open research question in electrical circuit analysis instruction is whether color coding of the mathematical symbols (variables) that denote electrical quantities can improve circuit analysis learning. the present study compared two groups of high school students undergoing their first introductory learning of electrical circuit analysis. one group learned with circuit variables in black font. the other group learned with colored circuit variables, with blue font indicating variables related to voltage, red font indicating those related to current, and black font indicating those related to resistance. the color group achieved significantly higher post-test scores, gave higher ratings for liking the instruction and finding it helpful, and had lower ratings of cognitive load than the black-font group. these results indicate that color coding of the notations for quantities in electrical circuit diagrams aids the circuit analysis learning of novice students.
digital_control	envelope tracking (et) and envelope elimination and restoration (eer) are techniques that have gained in importance in the last decade in order to obtain highly efficient radio frequency power amplifier that transmits signals with high peak-to-average power ratio. in this study, a multilevel multiphase buck converter is presented as a solution for the envelope amplifier used in et and eer. the presented multiphase buck converter generates multilevel voltage using ""node"" duty cycles and nonlinear control. in this way, the multilevel is implemented using only one simple power stage. however, the complexity of the multilevel converter implementation has been shifted from complicated power topologies to complicated digital control. detailed discussion regarding the influence of the design parameters (switching frequency, output filter, and time resolution of the digital control) on the performance of the proposed envelope amplifier is presented. the design of the output filter is conducted fulfilling the constraints of the envelope slew rate and minimum driver pulse that can be reproduced. in the cases when these two constraints cannot be fulfilled, they may be relieved by the modified control that is presented and experimentally validated. finally, in order to validate the concept, a prototype has been designed and integrated with a nonlinear class f amplifier. efficiency measurements showed that by employing eer, it is possible to save up to 15% of power losses, comparing to the case when it is supplied by a constant voltage. additionally, adjacent channel power ratio has been measured. the obtained results showed the value higher than 30 db for signals up to 5 mhz of bandwidth, without using a predistortion technique.
computer_vision	estimating transformations from degraded point sets is necessary for many computer vision and pattern recognition applications. in this paper, we propose a robust non-rigid point set registration method based on spatially constrained context-aware gaussian fields. we first construct a context-aware representation (e.g., shape context) for assignment initialization. then, we use a graph laplacian regularized gaussian fields to estimate the underlying transformation from the likely correspondences. on the one hand, the intrinsic manifold is considered and used to preserve the geometrical structure, and a priori knowledge of the point set is extracted. on the other hand, by using the deterministic annealing, the presented method is extended to a projected high-dimensional feature space, i.e., reproducing kernel hilbert space through a kernel trick to solve the transformation, in which the local structure is propagated by the coarse-to-fine scaling strategy. in this way, the proposed method gradually recovers much more correct correspondences, and then estimates the transformation parameters accurately and robustly when facing degradations. experimental results on 2d and 3d synthetic and real data (point sets) demonstrate that the proposed method reaches better performance than the state-of-the-art algorithms.
image_processing	this study investigates the ignition characteristics of pulverised coal, biomass and co-firing by use of a visual drop tube furnace (vdtf) and a high speed imaging technique. three coals (anthracite, a bituminous coal and a lignite), four biomasses (pine, eucalyptus, olive residue and miscanthus) and various biomass-coal mixtures were tested. with each coal, biomass or their mixture, a distinct flame was established within the vdtf through the continuous feeding of the fuel under the environment of air and at a furnace teniperature of 800 degrees c. to observe the ignition point, a phantom v12.1 high-speed camera was used to capture the videos of fuel combustion at 500 frames per second (fps). a technique was developed using matiab 's image analysis tool to automate the ignition point detection. the results of the image processing were used to statistically analyse and determine the changes to the ignition behaviour with different fuels and co-firing ratios. the results obtained with the tested coals have shown that the distance to ignition increases as the coal volatile matter content decreases, whereas the opposite trend was found for the biomass fuels. further, the addition of biomass to the anthracite significantly reduces the distance to ignition but a much less pronounced effect on the ignition was found when biomass was co-fired with the bituminous coal or lignite. the synergistic effect on the ignition of biomass-anthracite mixture is mainly attributed to the high volatile content and the potential effects of catalysis from the alkali metals present in the biomass. the results of this study have shown that the vdtf testing coupled with the image analysis technique allows for an effective and simple method of characterising ignition behaviours of pulverised coal, biomass and their mixtures. (c) 2016 the authors. published by elsevier b.v.
computer_programming	machine learning is continuing to gain popularity due to its ability to solve problems that are difficult to model using conventional computer programming logic. much of the current and past work has focused on algorithm development, data processing, and optimization. lately, a subset of research has emerged which explores issues related to security. this research is gaining traction as systems employing these methods are being applied to both secure and adversarial environments. one of machine learning 's biggest benefits, its data-driven versus logic-driven approach, is also a weakness if the data on which the models rely are corrupted. adversaries could maliciously influence systems which address drift and data distribution changes using re-training and online learning. our work is focused on exploring the resilience of various machine learning algorithms to these data-driven attacks. in this paper, we present our initial findings using monte carlo simulations, and statistical analysis, to explore the maximal achievable shift to a classification model, as well as the required amount of control over the data.
distributed_computing	frequent items in high-speed streaming data are important to many applications like network monitoring and anomaly detecting. to deal with high arrival rate of streaming data, it is desirable that such systems be capable of supporting high processing throughput with tight guarantees on errors. in this paper, we address the problem of finding frequent and top-k items, and present a parallel version of the space saving algorithm in the context of the open source distributed computing system. based on the theoretical analysis, the errors are restrictively bounded in our algorithm, and our parallel design could achieve high throughput. taking advantage of the distributed computing resources, our evaluation reveals that such design delivers linear speedup with remarkable scalability.
computer_vision	the heart rate (hr) measurements based on the camera (visible light) can be used to detect hr in non-contact mode, which has great application prospects both in the clinical application and home health care. however, cmos sensors equipped with ""rolling shutters"", which distinguishes different lines per frame to become light sensitive at different moments in time, and stylized dithering of image acquisition (imaq) time caused by different computer programs running in the background will greatly influence the accuracy of the measured hr. in this paper, we analyze the phase error caused by cmos sensor and the system error introduced by system sampling clock jitters. according to derivation, we propose two methods, amplitude-frequency superposition and a cubic spline interpolation reconstruction method based on actual schedules, that can be widely utilized in computer vision to overcome the camera phase error and sampling time fluctuation error. amplitude of signal is analyzed and processed in amplitude-frequency domain in the method of amplitude-frequency superposition, which ignores the signal phase. thus it can eliminate the phase error effectively. the cubic spline interpolation reconstruction method based on actual schedules can reconstructed the non-uniform sampling of images as uniform ones, so it can eliminate the system error involved by the system clock jitters. what 's more, the properties of the methods are tested by applying them to both simulation experiments and real hr measurements. in the simulation, amplitude of measured signal is improved 4. 58% relative to the amplitude measured without the method of amplitude-frequency superposition; root mean square error of signal 's frequency, detected by the cubic spline interpolation reconstruction method based on actual schedules, is reduced more than 30%. in the real hr measurements, the amplitude of hr is raised to 33. 5% relatively based on amplitude-frequency superposition. and the accuracy of hr is raised to approximately 40% by the method of cubic spline interpolation reconstruction method based on actual schedules. therefore, the simulation experiments and real hr measurement proof that we can effectively eliminate the camera phase error based on the amplitude-frequency superposition extraction method, and the cubic spline interpolation based on the timetable method can effectively reduce the random error in imaq due to system clock jitters. these methods can both be widely used in dynamic signal detection based on machine vision.
computer_vision	cell tracking plays crucial role in biomedical and computer vision areas. as cells generally have frequent deformation activities and small sizes in microscope image, tracking the non-rigid and non-significant cells is quite difficult in practice. traditional visual tracking methods have good performances on tracking rigid and significant visual objects, however, they are not suitable for cell tracking problem. in this paper, a novel cell tracking method is proposed by using convolutional neural networks (cnns) as well as multi-task learning (mtl) techniques. the cnns learn robust cell features and mtl improves the generalization performance of the tracking. the proposed cell tracking method consists of a particle filter motion model, a multi-task learning observation model, and an optimized model update strategy. in the training procedure, the cell tracking is divided into an online tracking task and an accompanying classification task using the mtl technique. the observation model is trained by building a cnn to learn robust cell features. the tracking procedure is started by assigning the cell position in the first frame of a microscope image sequence. then, the particle filter model is applied to produce a set of candidate bounding boxes in the subsequent frames. the trained observation model provides the confidence probabilities corresponding to all of the candidates and selects the candidate with the highest probability as the final prediction. finally, an optimized model update strategy is proposed to enable the multi-task observation model for the variation of the tracked cell over the entire tracking procedure. the performance and robustness of the proposed method are analyzed by comparing with other commonly-used methods. experimental results demonstrate that the proposed method has good performance to the cell tracking problem. (c) 2016 elsevier b.v. all rights reserved.
signal-flow_graph	two types of numerical errors occur in the implementation of the fast fourier transform (fft): coefficient errors and arithmetic errors. this paper deals with the second type, due to the finite word-length used in all operations. the signal-flow graph of the sub-band dft (sb-dft, or sb-fft as realized in the same efficient structure) consists of two parts: the hadamard part (which contains only additions and subtractions) and the recombination part (which contains also multiplications). the outputs of all these mathematical operations must be scaled. results for the two 's complement fixed-point arithmetic errors of the classical radix-2, ""cooley-tukey type"" (ct-) fft are known from various publications. especially, three radix-2 dit butterflies were defined and studied, which are normally used in most integrated dsp realizations and which differ in the quantizer locations. three corresponding butterfly structures are now defined for the recombination network of the sb-fft; they are analysed theoretically, and error equations are derived from a suitable error model. real input data are assumed in the analysis of arithmetic errors in sb-fft with both rounding and truncation scaling in the hadamard and the recombination parts. monte-carlo simulations are included in the analysis of the arithmetic errors in sb-fft. the results of a thorough evaluation are to be presented, yielding insights into the mechanisms of scaling and multiplier-output quantizations and allowing for a comparison between the sb-fft and ct-fft. for the partial-band versions of the sb-fft, the arithmetic errors are compared with the aliasing components inherent in those approximated versions. both half-band and quarter-band sb-fft are considered in this study. conclusions are drawn for the necessary internal wordlengths of fixed-point realizations. (c) 2002 elsevier science b.v. all rights reserved.
analog_signal_processing	this letter presents a single-step tunable group delay phaser for spectrum sniffing. this device may be seen as a ""time filter"", where frequencies are suppressed by time separation rather than by spectral attenuation. compared to its multiple-step counterpart, this phaser features higher processing resolution, greater simplicity, lower loss and better channel equalization, due to the smaller and channel-independent group delay swing. a two-channel example is provided for illustration.
network_security	acting as a focus of network security field, intrusion detection technology (idt) plays a very important role in different conditions. feature selection methods for intrusion detection directly affect the efficiency of intrusion detect system. in this paper, feature selection algorithm based on relief and relief sequential backward search (relief-sbs) is proposed under considering statistical correlation of relief and relief-sbs. the improved algorithm eliminates a feature after each round of iteration, and adopts the result of relief algorithm as the assessment criteria for feature. simulation results show that the proposed feature selection algorithm improves the efficiency of intrusion detection; moreover, it provides correlation technique support for idt.
computer_graphics	we present a general method for transferring skeletons and skinning weights between characters with distinct mesh topologies. our pipeline takes as inputs a source character rig (consisting of a mesh, a transformation hierarchy of joints, and skinning weights) and a target character mesh. from these inputs, we compute joint locations and orientations that embed the source skeleton in the target mesh, as well as skinning weights to bind the target geometry to the new skeleton. our method consists of two key steps. we first compute the geometric correspondence between source and target meshes using a semi-automatic method relying on a set of markers. the resulting geometric correspondence is then used to formulate attribute transfer as an energy minimization and filtering problem. we demonstrate our approach on a variety of source and target bipedal characters, varying in mesh topology and morphology. several examples demonstrate that the target characters behave well when animated with either forward or inverse kinematics. via these examples, we show that our method preserves subtle artistic variations; spatial relationships between geometry and joints, as well as skinning weight details, are accurately maintained. our proposed pipeline opens up many exciting possibilities to quickly animate novel characters by reusing existing production assets.
operating_systems	portable devices are today used in all areas of life thanks to their ease of use as well as their applications with unique features. the increase in the number of users, however, also leads to an increase in security threats. this study examines the threats to mobile operating systems. addressing the four mobile operating systems (android, apple os (ios), symbian and java me) with the highest number of users, the study provides statistical information about the features of the corresponding operating systems and their areas of use. in the study, the most important threats faced by the mobile operating systems (malware, vulnerabilities, attacks) and the risks posed by these threats were analyzed in chronological order and the future-oriented security perspective was suggested..
operating_systems	binary tree traversal algorithm can be applied in many aspects, such as information encryption, network, operating systems, cluster computing and so on. we have already proposed a useful method to verify the correctness of algorithmic programs based on isabelle proof assistant and dijkstra 's weakness precondition theory, and have manually derived and verified binary tree traversal non-recursive algorithms in our previous work. in order to ensure the security of the non-recursive algorithms, the focus of this paper is to construct a unified recurrence-relations expression about preorder, in-order, and post-order binary tree traversal non-recursive algorithms. the recurrence-relations expression make it easier to derive the loop invariants of three algorithms. meanwhile, we automatically verify the correctness of three kinds of non-recursive algorithms by using a generic proof assistant isabelle. this work realizes mechanically automatic-verification and overcomes the intricacies and weakness of manual verification, improves the verification efficiency, and ensures the trustworthiness and reliability of the algorithm program.
pid_controller	the paper focuses on the design of a new automatic landing system (als) in longitudinal plane; the new als controls the aircraft trajectory and longitudinal velocity. aircraft control is achieved by means of a proportional-integral (pi) controller and the instrumental landing system-the first phase of landing (the glide slope) and a proportional-integral-derivative (pid) controller together with a radio-altimeter-the second phase of landing (the flare); both controllers modify the reference model associated with aircraft pitch angle. the control of the pitch angle and longitudinal velocity is performed by a neural network adaptive control system, based on the dynamic inversion concept, having the following as components: a linear dynamic compensator, a linear observer, reference models, and a pseudo control hedging (pch) block. the theoretical results are software implemented and validated by complex numerical simulations; compared with other alss having the same radio-technical subsystems but with conventional or fuzzy controllers for the control of aircraft pitch angle and longitudinal velocity, the architecture designed in this paper is characterized by much smaller overshoots and stationary errors. (c) 2017 chinese society of aeronautics and astronautics. production and hosting by elsevier ltd. this is an open access article under theccby-nc-nd license.
algorithm_design	increasing interest in simultaneously optimizing many objectives (typically more than three objectives) of problems leads to the emergence of various many-objective algorithms in the evolutionary multi-objective optimization field. however, in contrast to the development of algorithm design, how to assess many-objective algorithms has received scant concern. many performance indicators are designed in principle for any number of objectives, but in practice are invalid or infeasible to be used in many-objective optimization. in this paper, we explain the difficulties that popular performance indicators face and propose a performance comparison indicator (pci) to assess pareto front approximations obtained by many-objective algorithms. pci evaluates the quality of approximation sets with the aid of a reference set constructed by themselves. the points in the reference set are divided into many clusters, and the proposed indicator estimates the minimum moves of solutions in the approximation sets to weakly dominate these clusters. pci has been verified both by an analytic comparison with several wellknown indicators and by an empirical test on four groups of pareto front approximations with different numbers of objectives and problem characteristics.
analog_signal_processing	a methodology for optimum sizing of different components (i.e., rotor diameter, electrical generator rating, and battery capacity) of a standalone wind-battery system is proposed in this paper. on the basis of time series simulation of the system performance along with different design constraints, the entire set of feasible design options, also known as the design space, has been identified on a rotor diameter vs. rated power diagram. the design space of a standalone wind-battery system identifies the entire envelope within which a feasible system may be designed. the optimum configuration of the standalone system is identified on the basis of minimum cost of energy (us$/kwh). it is observed that the cost of energy is sensitive to the magnitude of average demand and the wind regime. sensitivity of the capital cost on the minimum cost of energy is also studied. (c) 2009 elsevier ltd. all rights reserved.
parallel_computing	in this paper, we analyze the preconditioned gmres algorithm in detail and decompose it into components to implement on multiple-gpu architecture. the operations of vector updates, dot products and sparse matrix vector multiplication (spmv) are implemented in parallel. in addition, a specific communication mechanism for spmv is designed. the preconditioner is established on the host (cpu) and solved on the devices (gpus). validated by a series of numerical experiments, the gpu-based gmres solver is effective and favorable parallel performance is achieved. (c) 2016 elsevier ltd. all rights reserved.
state_space_representation	in this paper, we focus on the heavy-tailed stochastic signals generated through continuous-time autoregressive (car) models excited by infinite-variance alpha-stable processes. our goal is to estimate the parameters of the continuous-time model, such as the autoregressive coefficients and the distribution parameters related to the excitation process for the alpha-stable car process with 0 < alpha < 2 based on the state-space representation. likewise, we investigate the closed form expressions for the parameters of equivalent model in the discrete-time setting via regular samples of the process. we analyze the estimator based on the monte carlo simulations and illustrate the estimator consistency to the desired values when sampling frequency and sample size tend to infinity. we also apply the proposed method to the two types of real-world data, financial and ground magnetometer data, to evaluate its performance in real environments. (c) 2016 elsevier inc. all rights reserved.
computer_vision	a ground surface roughness measurement method is proposed to address current problems in the use of machine vision technology to measure roughness: the calculations are complex, and the measurement process is largely affected by the light source. based on the area of diffusion regions between the virtual images formed by a light source on ground surfaces with different roughness levels are different, a reference light source containing two base color is designed. red and green color space-based color distribution statistical matrices, as well as corresponding overlap indices, are proposed. a relationship model between overlap index and roughness is constructed. the effect of light source brightness and texture direction on the relationship model is discussed based on the experimental data. the results demonstrate that the surface roughness measurement method, which is based on the overlap degree of the color image, has relatively high accuracy and a relatively wide measurement range and is, to a certain degree, robust to the brightness of the light source and the texture direction. the surface roughness measurement method has huge potential for engineering applications. (c) 2017 elsevier ltd. all rights reserved.
computer_programming	failure to understand evolutionary dynamics has been hypothesized as limiting our ability to control biological systems. an increasing awareness of similarities between macroscopic ecosystems and cellular tissues has inspired optimism that game theory will provide insights into the progression and control of cancer. to realize this potential, the ability to compare game theoretic models and experimental measurements of population dynamics should be broadly disseminated. in this tutorial, we present an analysis method that can be used to train parameters in game theoretic dynamics equations, used to validate the resulting equations, and used to make predictions to challenge these equations and to design treatment strategies. the data analysis techniques in this tutorial are adapted from the analysis of reaction kinetics using the method of initial rates taught in undergraduate general chemistry courses. reliance on computer programming is avoided to encourage the adoption of these methods as routine bench activities.
parallel_computing	a robust multi-objective optimization method for truss optimum design is presented. in the robust design, materials and loads are assumed to be affected by epistemic uncertainties (imprecise or lack of knowledge). uncertainty quantification using evidence theory in optimum design subject to epistemic uncertainty is undertaken. in addition to a functional objective, an evidence-based plausibility measure of failure of constraint satisfaction is minimized to formulate the robust design into a multi-objective optimization problem. in order to alleviate the computational difficulties in the evidence theory-based uncertainty quantification analysis, a combined strategy of differential evolution-based interval optimization method and parallel computing technique is proposed. a population-based multi-objective differential evolution optimization algorithm is designed for searching robust pareto front. two truss structures with shape and sizing optimum design problems are presented to demonstrate the effectiveness and applicability of the proposed method.
system_identification	a novel estimator for the identification of continuous-time linear time-varying systems is presented in this paper. the estimator uses kernel-based regression to identify the time-varying coefficients of a linear ordinary differential equation, based on noisy samples of the input and output signals. the estimator adopts a mixed time- and frequency-domain formulation, which allows it to be formulated as the solution of a set of algebraic equations, without relying on finite differences to approximate the time derivatives. since a kernel-based approach is used, the model complexity selection of the time-varying parameters is formulated as an optimisation problem with continuous variables. variance and bias expressions of the estimate are derived and validated on a simulation example. also, it is shown that, in highly noisy environments, the proposed kernel-based estimator provides more reliable results than an oracle'-based estimator which is deprived of regularisation.
microcontroller	precision ultrasonic measurements in binary gas systems provide continuous real-time monitoring of mixture composition and flow. using custom microcontroller-based electronics, we have developed sonar instruments, with numerous potential applications, capable of making continuous high-precision sound velocity measurements. the instrument measures sound transit times along two opposite directions aligned parallel to - or obliquely crossing - the gas flow. the difference between the two measured times yields the gas flow rate while their average gives the sound velocity, which can be compared with sound velocity vs. molar composition look-up curves to obtain the binary mixture at a given temperature and pressure. the look-up curves may be generated from prior measurements in known mixtures of the two components, from theoretical calculations, or from a combination of the two. we describe the instruments and their performance within numerous applications in the atlas experiment at the cern large hadron collider (lhc). the instruments can be of interest in other areas where continuous in-situ binary gas analysis and flowmetry are required.
operational_amplifier	we describe a dc superconducting quantum interference device (squid) readout electronics in flux locked loop (fll) mode without integrator and with only one operational amplifier, which is called single chip readout electronics (scre). a weakly damped niobium-squid magnetometer with a large flux-to-voltage transfer coefficient of about. partial derivative v/partial derivative phi approximate to 380 mu v/phi(0) and scre results in a very simple squid system. we characterize the system and demonstrate its applicability to magnetocardiography (mcg) and measurements using the transient electromagnetic (tem) method. scre not only simplifies the readout scheme, but also improves the system stability, the bandwidth and the slew rate. the difference between scre and a conventional readout scheme (preamplifier + amplifier + integrator) is also discussed.
symbolic_computation	bound-state vector soliton solutions for the coupled variable-coefficient higher-order nonlinear schrodinger equations, which describe the simultaneous propagation of nonlinear waves in the inhomogeneous optical fiber, are investigated. introducing auxiliary functions, we derive the bilinear forms and corresponding constraints on the variable coefficients. through symbolic computation, we construct the one- and two-soliton solutions. we see that the variable coefficients in the equations affect the soliton structures. with different choices of the variable coefficients, we obtain the cubic, periodic, and parabolic solitons. bound-state solitons and interactions are analyzed graphically.
lorentz_force_law	since the eddy-current problem usually depends on the geometry of the moving conductive sheet and the pole shape, there is no general method for solving it analytically. this paper presents a method for analysis of the eddy current in the special case of a rotating disk in a time-invariant field. the analysis uses coulomb 's law and the method of images to consider the boundary conditions. first, the surface charge generated in the rotating disk is obtained and coulomb 's law is applied to calculate the electric field intensity, assuming an infinite disk radius. second, the finite disk radius is taken into account by introducing an imaginary electric field intensity to satisfy the boundary condition that the radial component of the eddy current is zero at the edge of the rotating disk. third, the braking torque is calculated by applying the lorentz force law. the paper compares the computed braking torque with the experimental results to establish the validity of the model.
network_security	embedded systems are routinely deployed in critical infrastructures nowadays, therefore their security is increasingly important. this, combined with the pressing requirement of deploying massive numbers of low-cost and low-energy embedded devices, stimulates the evolution of lightweight cryptography and other green-computing security mechanisms. new crypto-primitives are being proposed that offer moderate security and produce compact implementations. in this article, we present a lightweight authenticated encryption scheme based on the integrated hardware implementation of the lightweight block cipher present and the lightweight hash function spongent. the presented combination of a cipher and a hash function is appropriate for implementing authenticated encryption schemes that are commonly utilized in one-way and mutual authentication protocols. we exploit their inner structure to discover hardware elements usable by both primitives, thus reducing the circuit 's size. the integrated versions demonstrate a 27% reduction in hardware area compared to the simple combination of the two primitives. the resulting solution is ported on a field-programmable gate array (fpga) and a complete security application with input/output from a universal asynchronous receiver/transmitter (uart) gate is created. in comparison with similar implementations in hardware and software, the proposed scheme represents a better overall status.
system_identification	in many case-control designs of genome-wide association (gwas) or next generation sequencing (ngs) studies, extensive data on secondary traits that may correlate and share the common genetic variants with the primary disease are available. investigating these secondary traits can provide critical insights into the disease etiology or pathology, and enhance the gwas or ngs results. methods based on logistic regression (lg) were developed for this purpose. however, for the identification of rare variants (rvs), certain inadequacies in the lg models and algorithmic instability can cause severely inflated type i error, and significant loss of power, when the two traits are correlated and the rv is associated with the disease, especially at stringent significance levels. to address this issue, we propose a novel set-valued (sv) method that models a binary trait by dichotomization of an underlying continuous variable, and incorporate this into the genetic association model as a critical component. extensive simulations and an analysis of seven secondary traits in a gwas of benign ethnic neutropenia show that the sv method consistently controls type i error well at stringent significance levels, has larger power than the lg-based methods, and is robust in performance to effect pattern of the genetic variant (risk or protective), rare or common variants, rare or common diseases, and trait distributions. because of the sv method 's striking and profound advantage, we strongly recommend the sv method be employed instead of the lg-based methods for secondary traits analyses in case-control sequencing studies.
cryptography	in a strong designated verifier signature with message recovery (sdvswmr) scheme, only the designated receiver has the capability to recover and validate the message-signature pair. in 2015, using the bilinear pairing, islam and biswas presented an sdvswmr scheme (we call it: isbi-sdvswmr) with non-delegatability, which has better performance than other schemes in terms of communication and computation cost. however, in this study, we address that isbi-sdvswm scheme does not satisfy the security property of non-delegatability as they claimed and we present two types of delegatability attack to their scheme. we also propose a new and pairing-free sdvswmr scheme that possesses the following security requirements: non-delegatability, unforgeability, non-transferability and privacy of signer 's identity (prsi). compared our scheme with other existing related schemes, our scheme obtains better performance; that is, the computational cost is only 58%(lower) of isbi-sdvswm scheme (other schemes), and the communication cost is 800bits that is only 68%(lower) of isbi-sdvswm scheme (other schemes). copyright (c) 2017 john wiley & sons, ltd.
relational_databases	the aim of this work was to check the possibilities of usage the beacons to find out the relations between the members of cattle herd. relations between animals are important because of animals welfare and can influence on animal health and productivity. in the early stage of the research, relations between animals were determined on the base of the distance between animals and described as like/not like"" (they like each other or not). it 's difficult to precisely determine when animals like each other. not only distance is the criterium but also time and direct behavior. the experiment was carried out in the cowshed with 70 dairy cows. ble beacons (bluetooth low energy beacons) were attached to the cows and they regularly transmitted data about the cows' localisation in the cowshed to the smartphones which were distributed in the cowshed. from smartphones with android system data were sent to the relational database. because of the large amount of data, in the database data were processed, i.e. aggregated. some of the data were transformed to the geometric form and then, thanks to the specially developed application, these geometric data were mapped to relations and written in the graph database. graph databases are very useful tool to analyse and show relations between animals. the neo4j technology was used to prepare the graph database. other ict technologies used in this work were: sql server 2014, visual studio 2015 and entity framework 6. relational databases are still very usefull to analyse data and the graph databases are especially useful to visualize the spatial relations between objects. new technologies allows to widen our perceptions and create new possibilities of getting knowledge. there are a lot of tools to connect these technoogies, but it requires multidisciplinary approach.
operational_amplifier	in this paper, a single-stage multi-path operational transconductance amplifier (ota) with fast-settling response for high performance applications is designed. the produced amplifier uses current-shunt technique, double recycling structure, cross-coupled positive feedback configuration and all idle devices in the signal path to enhance transconductance of the conventional folded cascode (fc) amplifier. these transconductance boosting techniques lead to higher dc gain, gain bandwidth (gbw), slew rate and lower settling time compared to the previous fc structures while phase margin is degraded. simulation results are presented using 90nm cmos technology which show 1,800% increment in gbw and a 33.2 db dc gain improvement in the approximately same power consumption compared to the conventional fc amplifier.
network_security	an increasing number of wireless internet users and deployed wireless access points over the past several years and have raised the importance of wireless security issues. the absolute majority of wireless users are not it professionals, but a population unaware of wireless security types, settings and importance. wireless security assessment and analytics can help in raising the security awareness of users and in increasing their skills, leading to improvement of the entire security situation. in this paper a short overview of wireless security assessment and history is presented. the methodology and tools for a more accurate wireless security assessment, including data acquisition, processing and analysis, are offered. the proposed methodology and tools are used for processing wireless scan results for the two capital cities, hungary (budapest) and serbia (belgrade). the possibility of access point configuration changes and security improvement has also been investigated. the research results and potential improvements of wireless security situation are discussed.
electric_motor	the identification of different loss mechanisms and the prediction of exact power dissipations play a significant role in the development of new electric motor designs and the achievement of highest power densities and, therefore, high continuous drive powers. as many approaches exist to estimate the ohmic losses in the windings of a motor and additional mechanical losses, such as bearing losses, the most significant calculation error is usually made in the iron loss estimation of the stator core. in this paper, an analytic calculation method of the iron losses is presented, which gives the opportunity to predict the stator 's losses without time-consuming 3d fem calculations. the basis of the calculation model are commonly known material parameters of the lamination sheet and the insulation varnish, as well as geometric parameters of the target geometry. the result of the loss model is compared and validated with measurement values, delivered by a novel test device for stator segments.
system_identification	the true dynamic characteristics of dams, namely, natural frequencies, damping ratios, and mode shapes, are important to earthquake-resistant design. thus, system identification based on in-site measurements is useful for numerical analysis and health monitoring. the well-instrumented strong motion array on an arch dam in southwestern china recorded some seismic response data. the dynamic properties of the dam are identified from records of the top five strongest earthquake motions using power spectral density functions, transfer functions, and the arx model. the identified modal parameters of the different seismic events are compared, and the stability of the stiffness of the dam system from 2002 to 2008 and the nonuniformity in the input ground motion are indicated. a linear finite element model of the dam and a nonlinear model that considers contraction joints are constructed and calibrated to reproduce the frequencies determined from the system identification. the modal analysis highlights potential information about the dynamic characteristics of the dam. the comparison of the results of the system identification and calibration shows that the use of the nonlinear model may be reasonable in simulating the dynamic response of the ertan dam.
state_space_representation	in this paper, we study the deterministic blind identification of multiple channel state-space models having a common unknown input using measured output signals that are perturbed by additive white noise sequences. different from traditional blind identification problems, the considered system is an autoregressive system rather than an fir system; hence, the concerned identification problem is more challenging but possibly having a wider scope of application. two blind identification methods are presented for multi-channel autoregressive systems. a cross-relation identification method is developed by exploiting the mutual references among different channels. it requires at least three channel systems with square and stably invertible transfer matrices. moreover, a general subspace identification method is developed for which two channel systems are sufficient for the blind identification; however, it requires the additive noises to have identical variances and the transfer matrices having no transmission zeros. finally, numerical simulations are carried out to demonstrate the performance of the proposed identification algorithms. (c) 2015 elsevier ltd. all rights reserved.
electrical_circuits	this paper deals with a dynamical modelling in view of behavior analysis of double stars induction machine (dsim) supplied by voltage source pwm inverter. two modelling approaches are elaborated. in the first one the stator armatures of the dsim are described by two coupled circuits in concordia 's frame. in the second approach the stator armatures of the dsim are described by two decoupled circuits. one is equivalent to the model of three phase machine in concordia 's frame. and the other is equivalent to a passive circuit and does not produce torque. based on the established electrical circuits, the effect of supply mode and the increasing of the inverter level on the current quality and the torque ripples are analyzed.
electrical_circuits	there is an increasing diversity of educational background of students entering ordinary degree (level 7) and honours degree (level 8) programmes in engineering at dublin institute of technology (dit). partly as a result, student reasoning about basic electricity concepts often differs from accepted explanations. the paper reports, analyses and reflects on the results of a multiple-choice diagnostic test to assess student understanding of such concepts (developed for u.s. high school and college students [1]) taken, as a pre-test, by four cohorts of first year students, on the same dit level 7 engineering programme, from 2008-12 (n=106) and two cohorts of first year students, on the same dit level 8 engineering programme, from 2010-12 (n=64). the performance of the student cohorts is similar, and is little influenced by previous exposure to relevant subjects in second level (high school) education. in the 2012-13 academic year, an updated version of the diagnostic test was taken, in a pilot study, by one cohort of first year students on the dit level 8 engineering programme; this test was administered as a pre-test before instruction, as a post-test immediately after instruction and as a delayed post-test approximately fifteen weeks after instruction. results show that there is little improvement in conceptual understanding of d.c. resistive electric circuits, as measured by the test, when pre-test, post-test and delayed post-test scores are compared.
algorithm_design	as an overlay cognitive radio, transform domain communication system (tdcs) has been proposed to support reliable communications with low probability of interception. however, most of research on tdcs assume perfect synchronization to simplify algorithm design. in this paper, we present a low complexity symbol timing offset (sto) and carrier frequency offset (cfo) estimation method for practical tdcs applications. by utilizing preamble consisted of multiple identical training sequences, sto can be estimated by the demodulation procedure of cyclic code shift keying (ccsk), in which the circular correlation is performed by utilizing fast fourier transform (fft). thus the estimation procedure is significantly simplified with considerable complexity reduction, which is analyzed and compared to other two conventional methods. the simulation results demonstrates that the proposed sto and cfo estimation scheme is a low complexity solution for tdcs in multipath rayleigh fading channels with comparable estimation performance in terms of probability of incorrect timing offset and mean-square-error of cfo.
symbolic_computation	the transition phenomenon of few-cycle-pulse optical solitons from a pure modified korteweg-de vries (mkdv) to a pure sine-gordon regime can be described by the non-autonomous mkdv-sinh-gordon equation with time-dependent coefficients. based on the bell polynomials, hirota method and symbolic computation, bilinear forms and soliton solutions for this equation are obtained. backlund transformations (bts) in both the binary bell polynomial and bilinear forms are obtained. by virtue of the bts and ablowitz-kaup-newell-segur system, lax pair and infinitely many conservation laws for this equation are derived as well.
computer_programming	augmented reality allows to add virtual object in real scene. it has an increasing interest last years since mobile device becomes performant and cheap. the augmented reality is used in different domains, like maintenance, training, education, entertainment or medicine. the demonstrator we show is focused on maintenance operations. a step by step process is presented to the operator in order to maintain an element of a system. based on this demonstration, we will explain the modelling we propose allowing describing an entire maintenance process with augmented reality. indeed it is still difficult creating augmented reality application without computer programming skills. the proposed model will allow to create an authoring tool - or to plug to an existing one - in order to create augmented reality process without deep computer programming skills.
bioinformatics	background the electrocardiographically measured qt interval (qt) is heritable and its prolongation is an established risk factor for several cardiovascular diseases. yet, most qt genetic studies have been performed in european ancestral populations, possibly reducing their global relevance. objective to leverage diversity and improve biological insight, we fine mapped 16 of the 35 previously identified qt loci(46%) in populations of african american(n = 12,410) and hispanic/latino (n = 14,837) ancestry. methods racial/ethnic-specific multiple linear regression analyses adjusted for heart rate and clinical covariates were examined separately and in combination after inverse-variance weighted trans-ethnic meta-analysis. results the 16 fine-mapped qtlociincludedontheillumina metabochip represented 21 independent signals, of which 16(76%) were significantly (p-value100 kb). finally, bioinformatics-based functional characterization suggested a regulatory function in cardiac tissues for the majority of independent signals that generalized and the novel snps. conclusion our findings suggest that a majority of identified snps implicate gene regulatory dysfunction in qt prolongation, that the same loci influence variation in qt across global populations, and that additional, novel, population-specific qt signals exist.
network_security	today, the development of information and communications technologies have changed the utility landscape dramatically. in particular, electricity distribution networks rely heavily on a multitude of intelligent systems and devices that communicate among each other in much more advanced ways than in the past. as the smart grid is becoming nowadays a critical component in the electricity delivery system, it is important to make sure the grid is equipped with adequate security mechanisms that are able to guarantee its reliable operation and real-time information exchange within the power infrastructure. therefore, in this paper we analyze critical cybersecurity aspects associated with smart grid services, including previous cyber-attack cases on smart grids, potential vulnerabilities/threats, and advanced cybersecurity strategies for smart grids with technical and management measures. ultimately, while the service providers should continuously enhance the traditional security measures such as authentication, access control, authorization, data encryption, public key infrastructure (pki), firewalls, log analysis, intrusion detection systems, and network security protocols, we propose that the advanced technical measures should 1) make smart grids survivable even under cyber attacks and internal failures; 2) employ a defense-in-depth approach; 3) employ a defense-in-depth approach; and 4) provide more scalable security measures. furthermore, we also propose that the advanced management measures should 1) establish a cybersecurity governance strategy; 2) develop a strong incident response plan; 3) cultivate a culture of security; 4) employ a public-private partnership approach; and 5) comply with widely recognized security standards.
electrical_circuits	orthogonal connectors are used in drawings of many types of network diagrams, especially those representing electrical circuits. one approach for routing such connectors has been to compute an orthogonal visibility graph formed by intersecting vertical and horizontal lines projected from the corners of all obstacles and then use an a* search over this graph. however the search can be slow since many routes are in some sense topologically equivalent. we introduce obstacle-hugging routes which we conjecture provide a canonical representative for a set of topologically equivalent routes. we also introduce a new 1-bend visibility graph that supports computation of these canonical routes. essentially this contains a node for each obstacle corner and connector endpoint in the diagram and an edge between two nodes iff they can be connected using an orthogonal connector with one bend. we show that the use of a 1-bend visibility graph significantly improves the speed of orthogonal connector routing.
network_security	internet protocol (ip) spoofing is a serious problem on the internet. it is an attractive technique for adversaries who wish to amplify their network attacks and retain anonymity. many approaches have been proposed to prevent ip spoofing attacks; however, they do not address a significant deployment issue, i.e., filtering inefficiency caused by a lack of deployment incentives for adopters. to defeat attacks effectively, one mechanism must be widely deployed on the network; however, the majority of the antispoofing mechanisms are unsuitable to solve the deployment issue by themselves. each mechanism can work separately; however, their defensive power is considerably weak when insufficiently deployed. if we coordinate partially deployed mechanisms such that they work together, they demonstrate considerably superior performance by creating a synergy effect that overcomes their limited deployment. therefore, we propose a universal antispoofing (uas) mechanism that incorporates existing mechanisms to thwart ip spoofing attacks. in the proposed mechanism, intermediate routers utilize any existing anti-spoofing mechanism that can ascertain if a packet is spoofed and records this decision in the packet header. the edge routers of a victim network can estimate the forgery of a packet based on this information sent by the upstream routers. the results of experiments conducted with real internet topologies indicate that uas reduces false alarms up to 84.5% compared to the case where each mechanism operates individually.
machine_learning	forecasting stock returns and their risk represents one of the most important concerns of market decision makers. although many studies have examined single classifiers of stock returns and risk methods, fusion methods, which have only recently emerged, require further study in this area. the main aim of this paper is to propose a fusion model based on the use of multiple diverse base classifiers that operate on a common input and a meta classifier that learns from base classifiers' outputs to obtain more precise stock return and risk predictions. a set of diversity methods, including bagging, boosting and ada-boost, is applied to create diversity in classifier combinations. moreover, the number and procedure for selecting base classifiers for fusion schemes is determined using a methodology based on dataset clustering and candidate classifiers' accuracy. the results demonstrate that bagging exhibited superior performance within the fusion scheme and could achieve a maximum of 83.6% accuracy with decision tree, lad tree and rep tree for return prediction and 88.2% accuracy with bf tree, dtnb and lad tree in risk prediction. for feature selection part, a wrapper-ga algorithm is developed and compared with the fusion model. this paper seeks to help researcher select the best individual classifiers and fuse the proper scheme in stock market prediction. to illustrate the approach, we apply it to tehran stock exchange (tse) data for the period from 2002 to 2012. (c) 2016 elsevier b.v. all rights reserved.
electrical_network	one of the most effective means of minimizing mortalities of large raptors from collisions with hazards is to locate hazards away from major activity centers. a reliable means of delineating bird activity centers on the landscape has been a significant impediment to progress in proactive infrastructure planning. we used brownian bridge movement modeling to develop a population-wide, utilization probability surface for bald eagles (haliaeetus leucocephalus) within the upper chesapeake bay. we used locations (n=320,304) for individuals (n=63) tracked with global positioning system (gps) satellite transmitters between 2007 and 2011 in the analysis. we intersected the electrical network on the probability surface within aberdeen proving ground, a 350-km(2) military installation to identify overlap between power lines and eagle activity centers. we also overlaid locations of eagle mortalities attributed to the lines (n=67) on the installation to assess the relationship between mortality rates and utilization probabilities. areas of high bald eagle use were relatively rare on the landscape with only 0.1% and 5% of the area accounting for 10% and 30% of estimated utilization. most electric lines were along roads and distributed away from eagle activity centers, with only 0.3% of lines located within areas with the highest estimated eagle use. eagle mortalities were highly skewed to lines that overlapped with eagle activity centers. eagle mortality rates (birds/100km/yr) were 42 times higher along lines associated with the highest 10% of eagle use compared to lines associated with the lowest 10% use, suggesting that estimated utilization may be an effective proxy for mortality risk associated with electric line hazards. the majority (71.9%) of high-use bald eagle areas delineated within the study area have no existing electric lines. utilization probabilities may be a potential tool for site-specific infrastructure planning. (c) 2015 the wildlife society.
algorithm_design	this paper studies robust resource-allocation algorithm design for a multiuser multiple-input-single-output (miso) cognitive radio (cr) downlink communication network. we focus on a secondary system that provides wireless unicast secure layered video information to multiple single-antenna secondary receivers. the resource-allocation algorithm design is formulated as a nonconvex optimization problem for the minimization of the total transmit power at the secondary transmitter. the proposed framework takes into account a quality-of-service (qos) requirement regarding video communication secrecy in the secondary system, the imperfection of the channel state information (csi) of potential eavesdroppers (primary receivers) at the secondary transmitter, and a limit for the maximum tolerable received interference power at the primary receivers. thereby, the proposed problem formulation exploits the self-protecting architecture of layered transmission and artificial noise generation to ensure communication secrecy. the considered nonconvex optimization problem is recast as a convex optimization problem via semidefinite programming (sdp) relaxation. it is shown that the global optimal solution of the original problem can be constructed by exploiting both the primal and the dual optimal solutions of the sdp-relaxed problem. in addition, two suboptimal resource-allocation schemes are proposed for the case when the solution of the dual problem is unavailable for constructing the optimal solution. simulation results demonstrate significant transmit power savings and robustness against csi imperfection for the proposed optimal and suboptimal resource-allocation algorithms employing layered transmission compared to baseline schemes employing traditional single-layer transmission.
electric_motor	this article describes the design of a global monitoring system for remotely piloted aircrafts using a satellite, radio, and gsm datalink. the final solution aims for small, general-purpose drones weighing less than 20 kg, which could be engaged into an internet-of-things concept. in this work we propose a solution for drone operation and crash monitoring, protection of flight-restricted areas, protection of urgent low-altitude flights (emergency), and a flight hours logging system for general purpose drones or remotely piloted airplanes. the article describes the certification process of current aerospace products to attempt to apply this certification process for rpas. we define the categories of vehicles and specify for which ones our system is designed. next we describe the data measurement and acquisition unit which measures flight data and transmits them to a ground database in real time. we compare the available technologies and provide reasoning for the selected solution where we specify the disadvantages of the selected technology and how we overcome those. the article provides description of material and data flow, which is related to our business model and what services we can provide to customers. finally, the results of the system 's initial testing are provided.
computer_graphics	let x = {f(1), ..., f(n)} be a set of scalar functions of the form f(i) : (2) which satisfy some natural properties. we describe a subdivision algorithm for computing a clustered epsilon-isotopic approximation of the minimization diagram of x. by exploiting soft predicates and clustering of voronoi vertices, our algorithm is the first that can handle arbitrary degeneracies in x, and allow scalar functions which are piecewise smooth, and not necessarily semi-algebraic. we apply these ideas to the computation of anisotropic voronoi diagram of polygonal sets; this is a natural generalization of anisotropic voronoi diagrams of point sites, which extends multiplicatively weighted voronoi diagrams. we implement a prototype of our anisotropic algorithm and provide experimental results.
bioinformatics	recent research has proposed that git2 (g protein-coupled receptor kinase interacting protein 2) acts as an integrator of the aging process through regulation of 'neurometabolic' integrity. one of the commonly accepted hallmarks of the aging process is thymic involution. at a relatively young age, 12 months old, git2(-/-) mice present a prematurely distorted thymic structure and dysfunction compared to age-matched 12 month-old wild-type control (c57bl/6) mice. disruption of thymic structure in git2(-/-) (git2ko) mice was associated with a significant reduction in the expression of the cortical thymic marker, troma-i (cytokeratin 8). double positive (cd4(+) cd8(+)) and single positive cd4(+) t cells were also markedly reduced in 12 month-old git2ko mice compared to age-matched control wild-type mice. coincident with this premature thymic disruption in git2ko mice was the unique generation of a novel cervical 'organ', i.e. 'parathymic lobes'. these novel organs did not exhibit classical peripheral lymph node-like characteristics but expressed high levels of t cell progenitors that were reflexively reduced in git2ko thymi. using signaling pathway analysis of git2ko thymus and parathymic lobe transcriptomic data we found that the molecular signaling functions lost in the dysfunctional git2ko thymus were selectively reinstated in the novel parathymic lobe-suggestive of a compensatory effect for the premature thymic disruption. broader inspection of high-dimensionality transcriptomic data from git2ko lymph nodes, spleen, thymus and parathymic lobes revealed a systemic alteration of multiple proteins (dbp, tef, per1, per2, fbxl3, ddit4, sin3a) involved in the multidimensional control of cell cycle clock regulation, cell senescence, cellular metabolism and dna damage. altered cell clock regulation across both immune and nonimmune tissues therefore may be responsible for the premature 'aging' phenotype of git2ko mice.
image_processing	the k-svd algorithm has been successfully utilized for adaptively learning the sparse dictionary in 2-d seismic denoising. because of the high computational cost of many singular value decompositions (svds) in the k-svd algorithm, it is not applicable in practical situations, especially in 3-d or 5-d problems. in this paper, i extend the dictionary learning based denoising approach from 2-d to 3-d. to address the computational efficiency problem in k-svd, i propose a fast dictionary learning approach based on the sequential generalized k-means (sgk) algorithm for denoising multidimensional seismic data. the sgk algorithm updates each dictionary atom by taking an arithmetic average of several training signals instead of calculating an svd as used in k-svd algorithm. i summarize the sparse dictionary learning algorithm using k-svd, and introduce sgk algorithm together with its detailed mathematical implications. 3-d synthetic, 2-d and 3-d field data examples are used to demonstrate the performance of both k-svd and sgk algorithms. it has been shown that sgk algorithm can significantly increase the computational efficiency while only slightly degrading the denoising performance.
data_structures	background: a current focus of biofilm research is the chemical interaction between microorganisms within the biofilms. prerequisites for this research are bioassay systems which integrate reliable tools for the planning of experiments with robot-assisted measurements and with rapid data processing. here, data structures that are both human-and machine readable may be particularly useful. results: in this report, we present several simplification and robotisation options for an assay of bacteria-induced biofilm formation by the freshwater diatom achnanthidiumminutissimum. we also tested several proof-of-concept robotisation methods for pipetting, as well as for measuring the biofilm absorbance directly in the multi-well plates. furthermore, we exemplify the implementation of an improved data processing workflow for this assay using the konstanz information miner (knime), a free and open source data analysis environment. the workflow integrates experiment planning files and absorbance read-out data, towards their automated processing for analysis. conclusions: our workflow lead to a substantial reduction of the measurement and data processing workload, while still reproducing previously obtained results in the a. minutissimum biofilm assay. the methods, scripts and files we designed are described here, offering adaptable options for other medium-throughput biofilm screenings.
electricity	bioremediation plays an important role in oil spill management and bio-electrochemical treatment systems are supposed to represent a new technology for both effective remediation and energy recovery. diesel removal rate increased by four times in microbial fuel cells (mfcs) since the electrode served as an electron acceptor, and high power density (29.05 w m(-3)) at current density 72.38 a m(-3) was achieved using diesel (v/v 1%) as the sole substrate. as revealed by scanning electron microscope images, carbon fibres in the anode electrode were covered with biofilm and the bacterial colloids which build the link between carbon fibres and enhance electron transmission. trace metabolites produced during the anaerobic biodegradation were identified by gas chromatography-mass spectrometry. these metabolites may act as emulsifying agents that benefit oil dispersion and play a vital role in bioremediation of oil spills in field applications. (c) 2017 elsevier ltd. all rights reserved.
digital_control	a system of generating tunable orbital angular momentum (oam) radio beams and a method of measuring the oam states are proposed and experimentally investigated. the oam beams, which are generated by a uniform circular array, can be dynamically configured by controlling the digital signals in the baseband. a 2-d near-field scanning platform is built to measure the oam states of the system. the platform can provide multiple feed ports for the transmitting array. iteration is used to calibrate the amplitude and phase of each feed port. the experimental results demonstrate the feasibility of the proposed methods on generating and measuring tunable oam beams.
relational_databases	nosql and especially graph databases are constantly gaining popularity among developers as they promise to deliver superior performance when handling highly interconnected data compared to relational databases. apache shindig is the reference implementation for opensocial with a highly interconnected data model. however, it had a relational database as back-end. in this paper we describe our experiences with the graph database neo4j as back-end and compare cypher, gremlin and java as alternatives for querying data with mysql. we consider performance as well as usability from a developer 's perspective. our results show that cypher is a good query language in terms of code readability and has a moderate overhead for most queries (20-200%). however, it has to be supplemented with ""stored procedures"" to make up for some performance deficits in pattern matching queries (>1000%). the restful api is unusable slow, whereas our websocket connection performs significantly better (>650%). (c) 2015 elsevier inc. all rights reserved.
parallel_computing	mode division multiplexing (mdm) is a promising technology for increasing the aggregate bandwidth of multimode fiber (mmf) in conjunction with wavelength division multiplexing (wdm) in face of the impending capacity crunch in optical fiber networks. this paper investigates the effect of radial and azimuthal mode spacings in a 25-channel mdm-wdm system in mmf using a spatial light modulator-controlled vcsel array for excitation of laguerre-gaussian (lg) modes. a data rate of 25gbps is achieved at a central wavelength of 1550.12 nm. the effects of different azimuthal and radial mode spacings of lg modes are analyzed in terms of the channel impulse response, eye diagram and bit-error rate.
operational_amplifier	the current feedback instrumentation amplifier (cfia) designed for eeg detection systems is presented. this cfia includes two digitally programmable operational transconductance amplifiers (dpotas) and a current feedback operational amplifier (cfoa) where the digital control of dpota is done using 4-bit current division network (cdn). pspice simulation results are carried out using 0.25 mu m ibm cmos process under +/- 0.8v supply voltage. the cfia reaches 126.6db common mode rejection ratio (cmrr), consumes 695 mu w, and has 9.4777 mu v/root hz input referred noise. the achieved gain is from 22.236db to 45.386db. these results make the cfia suitable for the eeg detection systems.
algorithm_design	as with other nature-inspired algorithms, the cuckoo optimization algorithm (coa) produces a population of candidate solutions to find the (near-) optimal solutions to a problem. in this paper, several modifications, including a dynamic mutation operator, are proposed for this algorithm. design of experiments is employed to determine factors controlling the value of parameters and the target levels of those values to achieve desirable output. the efficiency of the modified coa algorithm is substantiated with the help of several optimization test problems. the results are then compared to other well-known algorithms such as pso, de and harmony search using a non-parametric statistical procedure. in order to analyze its effectiveness, the proposed modified coa is applied to a feature selection problem and spacecraft attitude control problem.
symbolic_computation	quantum computing promises to improve the speed and scalability of computations over that of classical computing hardware. at this early stage of quantum computer hardware development, software frameworks which support rapid prototyping of quantum solutions on small-scale hardware or simulators are necessary to explore the application of quantum algorithms to hard computational problems. we present a software library, ""qxlib,"" which incorporates symbolic computation of optimization functions for quantum annealers as one means to enable rapid prototyping. we demonstrate its effectiveness on integer linear programming and integer factorization problems.
symbolic_computation	taking advantage of the hirota bilinear form, four classes of lump-type solutions to the (3+1)dimensional jimbo-miwa equation are presented through symbolic computation with maple. special choices of the involved parameters guaranteeing analyticity of the fourth solution are given, together with two particular lump-type solutions.
electrical_circuits	functional magnetic resonance imaging was used to identify the brain-based mechanisms of uncertainty and certainty associated with answers to multiple-choice questions involving common misconceptions about electric circuits. twenty-two scientifically novice participants (humanities and arts college students) were asked, in an fmr1 study, whether or not they thought the light bulbs in images presenting electric circuits were lighted up correctly, and if they were certain or uncertain of their answers. when participants reported that they were unsure of their responses, analyses revealed significant activations in brain areas typically involved in uncertainty (anterior cingulate cortex, anterior insula cortex, and superior/dorsomedial frontal cortex) and in the left middle/superior temporal lobe. certainty was associated with large bilateral activations in the occipital and parietal regions usually involved in visuospatial processing. correct-and-certain answers were associated with activations that suggest a stronger mobilization of visual attention resources when compared to incorrect-and-certain answers. these findings provide insights into brainbased mechanisms of uncertainty that are activated when common misconceptions, identified as such by science education research literature, interfere in decision making in a school-like task. we also discuss the implications of these results from an educational perspective.
network_security	network security with encryption and decryption technology to complete the application layer, but this technology will bring computing resources and a waste of energy, particularly in these two resources are limited wireless communication system for this problem, we use a large-scale multi-antenna technology, using beamforming algorithm in power and spectrum limited conditions, to maximize the mutual information system security, the simulation results demonstrate the ability to secure transmission algorithms can effectively improve the system.
electric_motor	the paper deals with the alternative of determination of state of the belt gear. to realize themeasurements a newly developed device was designed for measurement and diagnostics of the belt gears. the main task is to detect the v-belt slip expressed by the coefficient of elastic creep and of specific slip with a measuring device. the measurements regarding can be performed if input revolutions of the electric motor and torque of the belt gear are constant whereas the tensioning force of the belt gear changes. it is also possible to perform the measurement if the input revolutions of the electric motor and the tensioning forces are constant and the torque changes.
computer_vision	colour detection plays an important role for many computer vision-based applications. however, most existing colour detection methods tend to be environment dependent since slight changes of environmental factors such as illumination or shadowing effects could greatly reduce their performances. in this paper, a new colour model is introduced to allow enhanced colour detection from images, even with significantly different lighting conditions and image qualities. the proposed colour model is called the hpbr colour model. it is converted from the rgb colour model and it consists of three colour components, namely, hue (h), purity (p) and brightness (br). this colour model can be represented in three different geometric shapes: diamond, sphere and cylinder. to assess the effectiveness of the model, two different colour detection methods have been applied onto benchmark images. experimental results from both methods confirmed that the proposed colour model produced the best colour detection results among existing models.
electrical_network	the present paper proposes a model of fuzzy logic control of a doubly fed asynchronous machine (dfam). first, a mathematical model of dfam, written in an appropriate d-q reference frame, is established to investigate the results of simulations. in order to control the rotor currents of dfam, a torque tracking control law is synthesized using pi controllers; the stator side power factor is controlled at a unity level. then, artificial intelligent controls, such as fuzzy logic control, are applied. the simulated performances are then compared to those of a classical pi controller. results obtained, in matlab/simulink environment, show that the fuzzy control is more robust i.e. has a superior dynamic performance and, hence, is found to be a suitable replacement of the conventional pi controller for a high performance drive applications.
analog_signal_processing	this work combines photoplethysmographic and electrical impedance plethysmographic measurements. a lack of blood delivery and oxygenation during pregnancy may have fatal consequences for the fetus. photoplethysmographic measurements illuminate the tissue and measure the change of light absorption. in this contribution a photoplethysmographic measurement system is presented. the hardware concept includes an analog signal processing circuit for the photodiode and a special driver circuit to power two light sources (red and infrared led). for photoplethysmographic measurements only one led is required, but in view of future purposes, such as pulse oximetry, a second led is already implemented. furthermore this paper shows results of electrical impedance plethysmography. this designed photoplethysmographic measuring in combination with impedance cardiography might be promising in examine of fetus.
electric_motor	to produce reliable estimates of the size or vital rates of a given population, it is important that the boundaries of the population under study are clearly defined. this is particularly critical for large, migratory animals where levels of sustainable harvest are based on these estimates, and where small errors may have serious long-term consequences for the population. once populations are delineated, rates of exchange between adjacent populations can be determined and accounted/corrected for when calculating abundance (e.g., based on mark-recapture data). using satellite radio-collar locations for polar bears in the western canadian arctic, we illustrate one approach to delineating wildlife populations that integrates cluster analysis methods for determining group membership with home range plotting procedures to define spatial utilization. this approach is flexible with respect to the specific procedures used and provides an objective and quantitative basis for defining population boundaries.
pid_controller	in this paper, the transfer function model of heavy duty gas turbine has been developed for doing load frequency control studies. based on the large signal model of rowen, small signal model has been developed. this model is much suitable for doing automatic generation control. proportional integral and derivative secondary controller has been developed for both the small and large signal models to improve the system response. ziegler nichols' method, simulated annealing and fuzzy gain scheduling have been used for tuning the secondary controller. ziegler nichols' method is used as conventional tuning, whereas simulated annealing is a search based tuning and fuzzy gain scheduling is adaptive. it is found that simulated annealing tuned proportional integral derivative controller yields better response than other two controllers in both large signal and small signal model of heavy duty gas turbine plant. (c) 2016 elsevier ltd. all rights reserved.
analog_signal_processing	this work presents a procedure for the design and analysis of a linear tubular switched reluctance generator for wave energy conversion. the generator is meant to be applied to a direct drive wave energy converter, namely a point absorber. the device is modeled according to wave climate conditions at esposende site in the portuguese coast. the procedure starts with statistical analysis of the local random ocean behavior in order to determine most likely values of occurrence for the wave parameters in question. based on that, the generator is analytically designed. with the proper dimensions calculated, a numerical simulation is performed and the magnetic flux path and density values are determined.
electric_motor	[1] first results are reported on statistical tomography of kilometer-scale irregularities in the f layer high-latitude ionosphere from amplitude data of satellite radio probing. basic formulae for statistical tomography of three-dimensionally (3-d) anisotropic small-scale irregularities are presented. it is shown that 3-d anisotropy disguises spatial distribution of irregularities but is not an insuperable difficulty for tomographic reconstruction. an example is shown of imaging the spatial distribution of the variance of electron density fluctuations over the kola peninsula in february 1996. iterative procedure of tomographic inversion was used in the reconstruction. further steps of applying statistical tomographic approach are outlined.
analog_signal_processing	the power generation business unit of westinghouse electric corporation manufactures electric generators commonly used in power generation. these generators require an electrically insulative bracing structure to support the stator coil (armature) windings at each end of the machine. several large circular cross-ply composite rings are used to support the stator coil winding; adding stiffness to the structure to prevent excessive deflections in the stator coils resulting from peak electromagnetic loads which occur during electrical transients; there is concern regarding the achieved physical properties of the cross-ply wound composite rings due to limited processing capabilities and process variation. the support ring strength and modulus properties are critical to performance. westinghouse has performed testing of flexural strength, flexural modulus, shear strength, and shear modulus at various temperatures to determine the mechanical properties of manufactured composite support rings. discussions of measured properties, in relationship to composite material design theory and manufacturing parameters, are provided.
signal-flow_graph	the paper presents a graphical block-diagram based programming tool, which is a new software development system for digital signal processing (dsp). this system provides a block-diagram editor; therefore, the dsp system can be easily built by connecting functional blocks as described in the signal-flow graph. a block library is set up, which includes basic signal processing functions and some frequently used high level signal processing functions like fir, iir, fft, etc. a friendly graphic user interface (gui) based on the 'x-window' system is developed to support each design step. users can then improve their design easily according to the gui 's response. to guarantee the correctness of the circuits designed, the debugging and verifying capabilities are embedded in our system. the full system is combined with a structural silicon compiler, which we developed previously. several designs will be illustrated as examples. it has been shown that this tool will be suitable for dsp system design by using a silicon compiler.
network_security	internet technology today is not free from many problems or security holes. this security holes could be exploited by an unauthorized person to steal important data. the case of the attacks occurred because the party that was attacked also did not realize the importance of network security to be applied to the system. honeypot is a system that is designed to resemble the original production system and is made with the intention to be attacked or compromised. in this research, cubieboard implemented using low interaction honeypot as a decoy to attract attackers. the result of this research is a low interaction honeypot implemented on embedded system with the form of cubieboard that can emulates security vulnerabilities such as directory buster brute force, lfi, and rfi with 100% success rate, but still could not emulates sql injection vulnerability. one of the result of stress test with 773 samples, obtained average time of 5275 ms, deviation 2067 ms, sample throughput 367.012 per minute, and with median 5381 ms. the stress test is conducted with 50 threads and 10 ramp-ups per second.
analog_signal_processing	the principle of group delay swing enhancement in a transmission-line all-pass network using the combined coupling and dispersion boosting properties of a ferromagnetic substrate is proposed; full-wave verified and experimentally demonstrated using ferrite substrates as a proof of concept. the proposed group delay swing enhanced structures are compact in size, exhibiting a larger dispersion per unit area compared with other alternative techniques for dispersion enhancement, and a magnetically tunable group delay swing. the proposal to suppress the requirement of an external magnet is discussed based on self-biased ferromagnetic nanowire substrates and expected improvements are further pointed out. (c) 2012 wiley periodicals, inc. microwave opt technol lett 54:589-593, 2012; view this article online at wileyonlinelibrary.com. doi 10.1002/mop.26658
operational_amplifier	previous studies for measuring the high direct voltage focused on the resistive voltage divider or the hall voltage sensor. the cost of the hall voltage sensor is expensive and additional shielding method must be taken into account when using the voltage divider. in this paper, resistive voltage divider, integrated operational amplifiers and photocouplers are used cooperatively to design the 1kv dc voltage measurement circuit. two photocouplers are used together with each current transfer ratio (ctr) balance each other out to reduce the influences on the high input direct voltage and the low output direct voltage ratio. the experimental results, with carefully setting the offset and gain calibration values, show that measurement circuit can get a good measurement accuracy with low cost for solar energy system.
operational_amplifier	noise optimization is a challenging problem for nanoscale metal-oxide-silicon field-effect transistor circuits. this brief presents a technique that uses transconductance-to-drain current (g(m)/i-d)-dependent transistor-noise parameters to explore the design space and to evaluate tradeoff decisions. an expression for the corner frequency of the folded-cascode amplifier is derived. the design process demonstrated in this brief using the folded-cascode amplifier is applicable to a wide class of amplifier circuits.
software_engineering	with the explosion of 3d character animation across contemporary screen media, more people, disciplines and technologies are now engaging with its production. explicit representations of computer animation processes help facilitate engagement at a high level, however fail to convey the depth of specialised creative techniques, technical processes and discipline language that is prevalent during the act of animating. this paper introduces the mk i production model', a conceptual process which through its novel use of the software engineering methodology agent-oriented modelling', conveys such specialised attributes within an explicit process for producing 3d character animation. to gather insights into how this model is used and perceived by animators within a production environment, it was entrenched within a large undergraduate student animation project named gunter 's fables', where it was positioned as the principal device to inform animators of the production process and their expected activity. the project management team also used the model in weekly peer review sessions as a basis to evaluate animation, and to convey progress and achievement with a colour rating scale. upon completion of the production phase, the project 's 12 student animators successfully delivered 41 short, 10-15 second 3d character animation scenarios that were deemed to be of a consistent and fit for purpose quality. findings from regular sweatbox' review sessions and questionnaires suggest that further investigation and iterative development of the model may improve user engagement with the process. however, the model 's demonstrated ability to inform a depth of production process supports the notion that this novel production concept presents a way forward in the communication and production of 3d character animation, and allied animation activities.
operational_amplifier	this paper presents analog building blocks that find potential applications in display panels. a buffer (source-follower), subtractor, adder, and high-gain amplifier, employing only n-type enhancement amorphous gallium-indium-zinc-oxide thin-film transistors (a-gizo tfts), were designed, simulated, fabricated, and characterized. circuit simulations were carried out using a neural model developed in-house from the measured characteristics of the transistors. the adder-subtractor circuit presents a power consumption of 0.26 mw, and the amplifier presents a gain of 34 db and a power consumption of 0.576 mw, with a load of 10 m omega//16 pf. to the authors' knowledge, this is the highest gain reported so far for a single-stage amplifier with a-gizo tft technology.
machine_learning	global optimisation of unknown noisy functions is a daunting task that appears in domains ranging from games to control problems to meta-parameter optimisation for machine learning. we show how to incorporate heuristics to stochastic simultaneous optimistic optimization (stosoo), a global optimisation algorithm that has very weak requirements from the function. in our case, heuristics come in the form of covariance matrix adaptation evolution strategy (cma-es). the new algorithm, termed guided stosoo (stosoo-g), combines the ability of cma-es for fast local convergence (due to the algorithm following the ""natural"" gradient) and the global optimisation abilities of stosoo. we compare all three algorithms in the ""harder"" parts of the comparing continuous optimisers on black-box optimization benchmarking benchmark suite, which provides a default set of functions for testing. we show that our approach keeps the best of both worlds, i.e. the almost optimal exploration/exploitation of stosoo with the local optimisation strength of cma-es.
electric_motor	efficient liquid cooling systems in cutting and chipping processes are essential to remain below the temperature limits of the cutting tool and materials. impinging jet cooling near the processing location is a widely employed technique for this purpose. the cooling effect can be optimized using a pulsating cooling fluid to improve heat transfer, via a periodic renewal of the hydrodynamic and thermal boundary layer. this study focuses on a cooling nozzle which generates a passive jet excitation, without an electric motor or any valve system. four different nozzle design mechanisms for the jet excitation were developed and tested with respect to their passively generated pulsation. strouhal number, pressure fluctuation and pulsation amplitude were measured. a strouhal number close to 0.2 was achieved with one excitation mechanism. the strouhal number achieved by the other mechanisms was above 0.1. (c) 2016 the authors. published by elsevier ltd.
state_space_representation	in this paper, we propose a low complexity graph-based linear minimum mean-square-error (lmmse) equalizer in order to remove inter-symbol and inter-stream interference in a multiple input multiple output (mimo) communication. the proposed state space representation inflicted on the graph provides linearly increasing computational complexity with block length. in addition, owing to the gaussian assumption used in the presented cycle-free factor graph, the complexity of the suggested equalizer structure is not affected by the size of the signaling space. in addition, we introduce an efficient way of computing extrinsic bit log-likelihood ratio values for the lmmse estimation compatible with higher order alphabets, which is shown to perform better than the other methods in the literature. overall, we provide an efficient receiver structure reaching high data rates in frequency selective mimo systems, whose performance is shown to be very close to a genie-aided matched filter bound through extensive simulations.
signal-flow_graph	this paper presents signal flow graph nonlinear modeling of two-cell cascade buck converters. a systematic procedure for developing the unified flow graph model of the cascade converter is discussed. a simplified procedure is described that can be used to deduce large, small-signal and steady-state models from the unified signal flow graph of the converter. converter performance expressions, and small-signal and steady-state transfer functions are derived. the large-signal model is developed and programmed into a tutsim simulator. converter large-signal responses are obtained against supply and load disturbances. the validity of the proposed signal flow graph modeling of cascade converters is verified and comparisons are made via psim simulator results. a few experimental results are provided to verify the proposed method.
symbolic_computation	under investigation in this paper is a (2 + 1)-dimensional nonlinear schrodinger equation in the heisenberg ferromagnetic spin chain. via the symbolic computation and hirota method, the bilinear forms, dark one-, two- and three-soliton solutions are derived. propagation and interaction for the dark solitons are illustrated graphically: amplitude and shape of the dark one soliton keep invariant during the propagation, which imply the transport of the energy is stable in the (2 + 1)-dimensional heisenberg ferromagnetic spin chain. through the asymptotic analysis, elastic and inelastic interactions between the dark two solitons are discussed. for the elastic interaction, oblique, head-on and overtaking interactions between the dark two solitons are displayed, where the amplitudes and shapes remain unchanged after interaction except for certain phase shifts. however, in the area of the inelastic interaction, amplitudes of the dark two solitons vanish after interaction. for the elastic interaction among the dark three solitons, oblique, overtaking and interaction among the dark two parallel solitons and a single one are presented, whose characteristics are similar to those of the dark two solitons. inelastic-elastic interaction is investigated as well. linear stability analysis is used to analyze modulation instability and prove the dark solitons are stable. (c) 2016 elsevier ltd. all rights reserved.
cryptography	this work presents two implementation attacks against cryptographic algorithms. based on these two presented attacks, this thesis shows that the assessment of physical attack complexity is error-prone. hence, cryptography should not rely on it. cryptographic technologies have to be protected against all implementation attacks, have they already been realized or not. the development of countermeasures does not require the successful execution of an attack but can already be carried out as soon as the principle of a side channel or a fault attack is understood.
distributed_computing	distributed query processing is of paramount importance in next-generation distribution services, such as internet of things (iot) and cyber physical systems. even if several multi-attribute range queries supports have been proposed for peer-to-peer systems, these solutions must be rethought to fully meet the requirements of new computational paradigms for iot, like fog computing. this paper proposes dragon, an efficient support for distributed multi-dimensional range query processing targeting efficient query resolution on highly dynamic data. in dragon nodes at the edges of the network collect and publish multi-dimensional data. the nodes collectively manage an aggregation tree storing data digests which are then exploited, when resolving queries, to prune the sub-trees containing few or no relevant matches. multi-attribute queries are managed by linearizing the attribute space through space filling curves. we extensively analysed different aggregation and query resolution strategies in a wide spectrum of experimental set-ups. we show that dragon manages efficiently fast changing data values. further, we show that dragon resolves queries by contacting a lower number of nodes when compared to a similar approach in the state of the art. (c) 2015 elsevier b.v. all rights reserved.
computer_graphics	the traditional rubber hand illusion is a psychological experiment where participants are under the illusion that a rubber hand is part of their own body. this paper examines the use of real, virtual and augmented reality environments for identifying the elements that influence body ownership in healthy participants. compared to the classical experiment where a plastic rubber hand was used, a realistic 3d representation was chosen to create the same illusion this time in both immersive virtual reality and augmented reality. experiments were performed on 30 volunteers undergoing testing session composed of three stages. participants were asked to complete two different questionnaires, one measuring their cognitive workload and another one regarding their experience with the rubber hand illusion. in addition, eeg signals of the individuals were recorded, resulting in 90 electroencephalogram datasets. results indicate correlations between ownership statements with beta and gamma electroencephalogram bands in premotor cortex activity. link between higher gamma production in ventral premotor area during the illusion was established in previous studies.
image_processing	pointwise intensity-based algorithms are the most popular algorithms in dynamic laser speckle measurement of physical or biological activity. the output of this measurement is a two-dimensional map which qualitatively separates regions of higher or lower activity. in the paper, we have proposed filtering of activity maps to enhance visualization and to enable quantitative determination of activity time scales. as a first step, we have proved that the severe spatial fluctuations within the map resemble a signal-dependent noise. as a second step, we have illustrated implementation of the proposed idea by applying filters to non-normalized and normalized activity estimates derived from synthetic and experimental data. statistical behavior of the estimates has been analyzed to choose the filter parameters, and substantial narrowing of the probability density functions of the estimates has been achieved after the filtering. the filtered maps exhibit an improved contrast and allowed for quantitative description of activity.
electric_motor	with literally hundreds of electric motor manufacturers from which to choose, sorting through options to find the best value can be a daunting task. this paper draws on the author 's forty-plus years of experience to share practical methods for comparing motors before purchase. interwoven into the paper are suggestions and techniques for improving designs of motors already in service. areas of interest include electrical windings, bearings, rotor designs, ventilation and balancing.
control_engineering	controlling complex mechanical systems is often a difficult task, requiring a skilled developer with experience in control engineering. in practice however, the theoretical difficulties of designing a good controller is only a first step as the implementation itself on the various pieces of equipment is also often challenging. this paper investigates if iterative learning control (ilc) can be used as an alternative to tuning existing controllers for improving system performance. this is evaluated by a case study on a high speed xy-positioning system used for laser cutting. an ilc algorithm is implemented by using a server client structure from matlab. after tuning the parameters an implementation is found which is able to increase the tracking accuracy significantly for cutting speeds up to 0: 5 m/s. this is done only by implementing code on the master control unit and thus without changing subsystem controllers.
digital_control	the paper presents the design and some results for an experimental platform aimed to control the air pressure inside a small tank. the basic idea is to allow to the control algorithm to select an appropriate characteristic of the controller driving the air compressor, from an available set. in this first approach, the goal is to make functional the hardware circuits and to design the software support inside an integrated development environment with a very high level programming language. after some functional tests, future work is intended to implement artificial intelligent based algorithms in order to exploit the multicharacteristics features with a fuzzy decisions set for selecting an optimal control. the main parts of the controller are an industrial pressure sensor, a pic (tm) 16f877 microcontroller from microchip (tm) and the air pressure part consisting, mainly, from a car compressor and a small tank. additional elements make the operation safe. the solution with the microcontroller is put in operation in parallel with another one, using an industrial digital controller from honeywell (tm). the platform is intended both for research activities, dealing with all kind of control algorithms implemented in software, associated with pneumatic systems, and for academic purpose, joining in an unique structure sensors, microelectronics, interface techniques, industrial controllers, motors, pneumatic elements and software.
computer_programming	computer aided x-ray microtomography is an increasingly popular method to investigate the structure of materials. continuing improvements in the technique are resulting in increasingly larger data sets. the analysis of these data sets generally involves executing a static workflow for multiple samples and is generally performed manually by researchers. executing these processes requires a significant time investment. a workflow which is able to automate the activities of the user would be useful. in this work, we have developed an automated workflow for the analysis of microtomography scanned bread dough data sets averaging 5gb in size. comparing the automated workflow with the manual workflow indicates a significant amount of the time spent (33% in the case of bread dough) on user interactions in manual method. both workflows return similar results for porosity and pore frequency distribution. finally, by implementing an automated workflow, users save the time which would be required to manually execute the workflow. this time can be spent on more productive tasks. lay description technological advances in x-ray scanning techniques have resulted in larger, more complex microtomographic datasets. processing these datasets can be both a time consuming and oftentimes repetitive task as datasets of similar materials tend to have similar characteristics. what if there was a better way to analyze these datasets? our research has investigated using computer programming languages instead of researchers to automatically perform tasks involved in the analysis of microtomographic datasets of ten scanned bread dough samples. our results highlighted the benefits of using computers to automate the analysis process, demonstrating that nearly 33% of the time required is due to researchers interacting with the analysis programs and not from the analysis itself. the quantitative data provided by the automated workflow are nearly identical to results found by researchers. this research highlights the benefits of using automated computer processing for analysis of microtomographic datasets, which would allow researchers to spend their efforts elsewhere.
electric_motor	in previous studies on precise computation methods of iron loss, it has been shown that the 1-d dynamic magnetic field analysis with hysteresis in post-processing is effective. however, there is a problem in that the hysteresis makes the convergence of nonlinear iterations unstable. this paper proposes a stabilization method for the 1-d dynamic magnetic field analysis with hysteresis. the proposed method is characterized as an approach for improving the initial value and the step size in the newton-raphson method. the results of this paper showed that the convergence characteristic of the nonlinear 1-d magnetic field analysis for variety flux density waveforms of each part in an electric motor is improved using the proposed method.
system_identification	in this article a method for the measurement of the linear frequency response of weakly non-linear systems is described. a frequency domain estimator is developed by analyzing the output spectra for single- and multitone excitations of several types of system models with the most complex system one being a parallel-cascade wiener-hammerstein-type model which is able to represent a wide range of weakly non-linear systems. it is then shown that the output spectrum of such a weakly non-linear system can be expressed by a polynomial with constant coefficients for a given input signal at each frequency. this leads to the proposed polynomial estimator h-p that is capable of identifying the true linear, nonparametric frequency response of the system under test. special versions for either input or output noise only are developed and consistency is shown for all considered system models.
symbolic_computation	liquids with gas bubbles are commonly seen in medical science, natural science, daily life and engineering. nonlinear-wave symbolic computation on the (3 + 1)-dimensional variable-coefficient kudryashov-sinelshchikov model for a bubbly liquid is hereby performed. an auto-backlund transformation and with some solitonic solutions are obtained. with respect to the density fluctuation of the bubble-liquid mixture, both the auto-backlund transformation and solitonic solutions depend on the bubble liquid-viscosity, transverse-perturbation, bubble-liquid-nonlinearity and bubble-liquid dispersion coefficient functions. we note that some shock waves given by our solutions have been observed by the gas-bubble/liquid-mixture experiments. effects on a bubbly liquid with respect to the bubble-liquid-viscosity, transverse-perturbation, bubble-liquidnonlinearity and bubble-liquid-dispersion coefficient functions might be detected by the future gas-bubble/liquid-mixture experiments.
software_engineering	the ability to exploit emerging exascale computational systems will require a careful review and redesign of core numerical algorithms and their implementations to fully exploit multiple levels of concurrency, hierarchical memory structures and heterogeneous processing units that will become available in these computational platforms. this paper presents the ""unite and conquer"" approach to solve linear systems of equations and eigenvalue problems for extreme scale computing. indeed, there are two ways to optimize the execution of a restarted method on a large-scale distributed system. the first one is to optimize the number of floating point operations per restart cycle through maximizing the concurrency inside a restart cycle while minimizing latencies. the second-way is to accelerate/improve the rate of convergence for a given computational scheme. the unite and conquer restarted approach focuses on decreasing the number of restart cycles by coupling either synchronously or asynchronously several restarted methods called also co-methods. in the end of a restart cycle, each co-method locally gathers available results of all collaborating co-methods and selects the best one in order to create its restarting information. consequently this permits the global reduction of the number of cycles to convergence. the unite and conquer restarted methods are heterogeneous, fault tolerant, support asynchronous communications and present a big potential of load balancing. due to these properties, they are well adapted to large-scale multi-level parallel architectures. we show the relevant programming paradigms that allow multi-level parallel expression of these methods and how the software engineering technology can contribute significantly in achieving high scalability. we present some experiments validating the approach for unite and conquer restarted krylov methods on several parallel and distributed platforms. (c) 2016 elsevier b.v. all rights reserved.
electrical_network	distributed ac power systems using inverters connected in parallel are becoming increasingly widespread with the development of autonomous microgrids. inverters can be controlled to emulate the dynamics of nonlinear oscillators, such that multiple inverters coupled through an electrical network will synchronize and share load in proportion to their ratings. in this paper, a communication-less control method is developed for islanded parallel inverters based on the van der pol oscillator and a virtual impedance technique. the controller can be tuned to guarantee fast synchronization of inverters, as well as optimal load power sharing, regardless of differences in the physical parameters of the inverters and their respective filters. a methodology for parameter selection is presented to tune the controller so that the system voltage amplitude remains within prescribed bounds whilst ensuring optimal load sharing and minimizing synchronization time. simulation results demonstrate the performances which can be obtained with several parallel-connected inverters using this control method with correctly tuned parameters.
cryptography	the new styles and ways of life lead to greater use of wireless networks, the mobile device being a tool for data transmission, which are susceptible to threats in the transmission channels in the network. it security plays a very important role in guaranteeing the availability, privacy and integrity of information, one of the techniques that helps in this task is cryptography, whose foundation is to transform a message so that it is unintelligible except for those who have the key to decipher it. the research focuses on the use of the rsa algorithm between mobile devices, the encrypted data is sent through communication channels called threads that through formulas and processes executed on the server, will help to execute the encryption and decryption of the data. to carry it out, a prototype for the exchange of data between mobile devices wirelessly was designed and implemented, conducting performance tests with three nodes to improve the security. the results show the efficiency of the algorithm and additionally its functionality, the times of encryption and decryption are fast against the sending of information without any method or algorithm used.
pid_controller	vibration is a physical phenomenon involving repeated oscillatory movements or fluctuations at certain frequency and typically undesirable in many applications since it may cause undue failure or damage to the system. in this paper, the vibration of a three degree-of-freedom (dof) model representing a short length drive shaft has been effectively and robustly suppressed through the implementation of a novel active force control (afc) used in conjunction with a classic proportional-integral-derivative (pid) controller. the shaft vibration caused by its support and constraint during its operation was simulated using matlab and simulink considering a number of operating and loading conditions. the results proved that when a pure pid controller was implemented, the vibration is indeed reduced but at the expense of longer execution time and producing noticeable frequency oscillation with slight offset. on the other hand, when the afc loop was engaged by adding it directly in series with the pid controller (pid+afc) to produce a 2 dof controller without any need to further tune the pid controller gains, the vibration is significantly reduced with the amplitude hovering a zero datum without any offset and yielding an extremely low frequency trending. (c) 2016 penerbit utm press. all rights reserved
computer_graphics	in this paper, we present a simple and efficient method to represent terrains as elevation functions built from linear combinations of landform features (atoms). these features can be extracted either from real world data-sets or procedural primitives, or from any combination of multiple terrain models. our approach consists in representing the elevation function as a sparse combination of primitives, a concept which we call sparse construction tree, which blends the different landform features stored in a dictionary. the sparse representation allows us to represent complex terrains using combinations of atoms from a small dictionary, yielding a powerful and compact terrain representation and synthesis tool. moreover, we present a method for automatically learning the dictionary and generating the sparse construction tree model. we demonstrate the efficiency of our method in several applications: inverse procedural modeling of terrains, terrain amplification and synthesis from a coarse sketch.
analog_signal_processing	coherent techniques are expected to be used to meet the demand for higher data rates in short-reach optical links in the near future. digital coherent receivers used for long haul applications are not suitable for short-reach links because of excessive power dissipation, size, and cost. the power consumption, size, and cost of the receiver can be drastically reduced by processing signals in the analog domain itself. a 100 gb/s dual-polarization quadrature phase-shift keying receiver that uses analog domain signal processing is presented. the receiver, designed in 130-nm bicmos technology, consumes 3.5 w of power. simulations show bit error rates of less than 10-3 in the presence of dispersion up to 160 ps/nm, laser linewidths of up to 200 khz, and a frequency offset of 100 mhz between the transmitter and the receiver lasers.
electric_motor	the problem of improving the reliability and creation of fault tolerant systems is one of the most important in modern technology and engineering. actually, the complexity of technical systems is increasing, thus the requirements to reliability indices is constantly increasing. especially the correct assessment as in the design stage as well as in operating conditions is important in order to improve reliability. modern trends in the electrification of various types of vehicles set up similar tasks for developers and engineers of electric propulsion systems. considering that the electric propulsion systems are safety critical, very strict requirements are imposed on reliability and fault tolerance to each of their component units, such as traction motor, power electronics, electric power source, and control unit. this paper presents a systematic method of estimation the fault tolerance of a multi-phase permanent magnet synchronous motors based on a multi-level markov model of the lifecycles for the multi-state system. the impact on the fault tolerance degree regarding the number of phases of permanent magnet synchronous motors is investigated. the practical application of the proposed technique for the multi-phase traction motor and results are presented. finally, the results of the study allowing fault tolerance assessment and the choice of the most appropriate traction electric motor design considering reliability and fault tolerance are discussed.
electricity	the problem of inter-regional interchange scheduling in the presence of stochastic generation and load is considered. an interchange scheduling technique based on a two-stage stochastic minimization of expected operating cost is proposed. because directly solving the stochastic optimization is intractable, an equivalent problem that maximizes the expected social welfare is formulated. the proposed technique leverages the operator 's capability of forecasting locational marginal prices and obtains the optimal interchange schedule without iterations among operators. several extensions of the proposed technique are also discussed.
parallel_computing	we present a novel image-analysis based method for automatically distinguishing low, intermediate, and high grades of breast cancer in digitized histopathology. a multiple level feature set, including pixel-,object-,and semantic-level features derived from convolutional neural networks (cnn), is extracted from 106 hematoxylin and eosin stained breast biopsy tissue studies from 106 women patients. these multilevel features allow not only characterization of cancer morphology, but also extraction of structural and interpretable information within the histopathological images. in this study, an improved hybrid active contour model based segmentation method was used to segment nuclei from the images. the semantic level features were extracted by a cnn approach, which described the proportions of nuclei belonging to the different grades, in conjunction with pixel-level (texture) and object-level (architecture) features, to create an integrated set of image attributes that can potentially outperform either subtype of features individually. we utilized a cascaded approach to train multiple support vector machine (svm) classifiers using combinations of feature subtypes to enable the possibility of maximizing the performance by leveraging different feature sets extracted from multiple levels. final class (cancer grade) was detertnined by combining the scores produced by the individual svm classifiers. by employing a light (three-layer) cnn model and parallel computing, the presented approach is computationally efficient and applicable to large-scale datasets. the method achieved an accuracy of 0.92 for low versus high, 0.77 for low versus intermediate, and 0.76 for intermediate versus high, and an overall accuracy of 0.69 when discriminating low, intermediate, and high grades of histopathological breast cancer images. this suggested that our grading method could be useful in developing a computational diagnostic tool for differentiating breast cancer grades, which might enable objective and reproducible alternative for diagnosis. (c) 2016 elsevier b.v. all rights reserved.
pid_controller	open-loop unstable systems with time-delays are often encountered in process industry, which are often more difficult to control than stable processes. in this paper, the stabilization by pid controller of second order unstable processes, which can be represented as second-order deadtime with an unstable pole (sodup) and second-order deadtime with two unstable poles (sodtup), is performed via the necessary and sufficient criteria of routh-hurwitz stability analysis. the stability analysis provides improved understanding on the existence of a stabilizing range of each pid parameter. three simple pid tuning algorithms are proposed to provide desired closed-loop performance-robustness within the stable regions of controller parameters obtained via the stability analysis. the proposed pid controllers show improved performance over those derived via some existing methods. (c) 2017 published by elsevier ltd. on behalf of isa.
analog_signal_processing	optical receivers used in wdm networks are often preceeded by nn optical amplifier to ensure good receiver sensitivity. in this letter, we present an experimental investigation of homowavelength crosstalk in optically preamplified systems using an im/dd transmission scheme. as a light source, a dfb laser is modulated either directly or externally by an electrical generator. performance comparisons for both modulation schemes are given to show the influences of noise contribution of amplified spontaneous emission (ase) noise. (c) 1999 john wiley & sons, inc.
distributed_computing	background: mapping disease rates over a region provides a visual illustration of underlying geographical variation of the disease and can be useful to generate new hypotheses on the disease aetiology. however, methods to fit the popular and widely used conditional autoregressive (car) models for disease mapping are not feasible in many applications due to memory constraints, particularly when the sample size is large. we propose a new algorithm to fit a car model that can accommodate both individual and group level covariates while adjusting for spatial correlation in the disease rates, termed indicar. our method scales well and works in very large datasets where other methods fail. results: we evaluate the performance of the indicar method through simulation studies. our simulation results indicate that the indicar provides reliable estimates of all the regression and random effect parameters. we also apply indicar to the analysis of data on neutropenia admissions in new south wales (nsw), australia. our analyses reveal that lower rates of neutropenia admissions are significantly associated with individual level predictors including higher age, male gender, residence in an outer regional area and a group level predictor of social disadvantage, the socio-economic index for areas. a large value for the spatial dependence parameter is estimated after adjusting for individual and area level covariates. this suggests the presence of important variation in the management of cancer patients across nsw. conclusions: incorporating individual covariate data in disease mapping studies improves the estimation of fixed and random effect parameters by utilizing information from multiple sources. health registries routinely collect individual and area level information and thus could benefit by using indicar for mapping disease rates. moreover, the natural applicability of indicar in a distributed computing framework enhances its application in the big data domain with a large number of individual/group level covariates. ci nsw study reference number: 2012/07/410. dated: july 2012.
network_security	most complex tasks on the internet-both malicious and benign-are collectively carried out by clusters of ip addresses. we demonstrate that it is often possible to discover such clusters by processing data sets and logs collected at various vantage points in the network. obviously, not all clusters discovered in this way are malicious. nevertheless, we show that malicious clusters can accurately be distinguished from benign ones by simply using an ip blacklist and without requiring any complex analysis to verify malicious behavior. in this paper, we first propose a novel clustering framework which can be applied on data sets of network interactions to identify ip clusters carrying out a specific task collectively. then, given such a list of identified clusters of ip addresses, we present a simple procedure to spot the malicious ones using an ip blacklist. we show that by choosing the parameter of the proposed clustering process optimally using a blacklist, hence making it blacklist-aware, we significantly improve our overall ability to detect malicious clusters. furthermore, we mathematically show that even a blacklist with poor accuracy can be used to detect malicious clusters with high precision and recall. finally, we demonstrate the efficacy of the proposed scheme using real-world login events captured at the login servers of a large webmail provider with hundreds of millions of active users.
software_engineering	the objective of this study is to investigate the use of an alternative working pair in a solar absorption cooling system. licl-h2o is the new examined pair and it is compared energetically and exegetically with the conventional pair libr-h2o, which is the most usual in air-conditioning applications. the simplest solar cooling system is analyzed in order to focus in the comparison between these working fluids. specifically, flat plate collectors, coupled with a storage tank, feed the single effect absorption chiller which produces 250 kw cooling at 10 degrees c. the two pairs are examined parametrically for various heat source temperature levels and for three ambient temperature levels (25 degrees c, 30 degrees c and 35 degrees c). the minimization of the collecting area, which means maximum exergetic efficiency, is the optimization goal in every case. the final results show that licl-h2o pair performs better in all cases by giving greater exergetic efficiency. more specifically, about 8% lower collecting area is required to cover the demanded cooling load with this working pair. another interesting result is that the optimum heat source temperature for the licl-h2o is roughly lower than the respective for the libr-h2o. the system is analyzed in steady state with the commercial software engineering equator solver (ees). (c) 2016 elsevier ltd. all rights reserved.
cryptography	in this study, the authors propose a novel method to encrypt a colour image by use of logistic mapping and double random-phase encoding. firstly, use logistic mapping to diffuse the colour image, then the red, green and blue components of the result are scrambled by replacement matrices generated by logistic mapping. secondly, by utilising double random-phase encoding to encrypt the three scrambled images into one encrypted image. experiment results reveal the fact that the proposed method not only can achieve good encryption result, but also that the key space is large enough to resist against common attack.
image_processing	this paper presents preliminary results of the application of two-kinect cameras system on a two wheeled indoor mobile robot for off-line optimal path planning and execution. in our approach, the robot makes use of depth information delivered by the vision system to accurately model its surrounding environment through image processing techniques. in addition, a genetic algorithm is implemented to generate a collision-free optimal path linking an initial configuration of the mobile robot (source) to a final configuration (target). after that, piecewise cubic hermite interpolating polynomial is used to smooth the generated optimal path. finally, an adaptive fuzzy-logic controller is designed to keep track of a mobile robot on the desired smoothed path (by transmitting the appropriate right and left velocities using wireless communication). in parallel, sensor fusion (odometry sensors and kinect sensors) is used to estimate the current position and orientation of the robot using kalman filter. the validation of the proposed solution is carried out using the differentially-driven mobile robot, robuter, to successfully achieve safe motion (without colliding with obstacles) in an indoor environment. (c) 2016 elsevier b.v. all rights reserved.
image_processing	a four-dimensional visualization approach, featuring three dimensions in space and one dimension in time, is proposed to study local electrode degradation effects during voltage cycling in fuel cells. noninvasive in situ micro x-ray computed tomography (xct) with a custom fuel cell fixture is utilized to track the same cathode catalyst layer domain throughout various degradation times from beginning-of-life (bol) to end-of-life (eol). with this unique approach, new information regarding damage features and trends are revealed, including crack propagation and catalyst layer thinning being quantified by means of image processing and analysis methods. degradation heterogeneities as a result of local environmental variations under land and channel are also explored, with a higher structural degradation rate under channels being observed. density and compositional changes resulting from carbon corrosion and catalyst layer collapse and thinning are observed by changes in relative x-ray attenuation from bol to eol, which also indicate possible vulnerable regions where crack initiation and propagation may occur. electrochemical diagnostics and morphological features observed by micro-xct are correlated by additionally collecting effective catalyst surface area, double layer capacitance, and polarization curves prior to imaging at various stages of degradation. (c) 2017 elsevier b.v. all rights reserved.
microcontroller	nitrite (no2-) supplementation limits hypoxia-induced oxidative stress and activates the alternate no pathway which may partially account for the nitrite-mediated cardioprotection. so, sensitive and selective biosensors with point-of-care devices need to be explored to detect the physiological nitrite level due to its important role in human pathophysiology. in this work, cytochrome c reductase (ccr) biofunctionalized self assembled monolayer (sam) functionalized on gold nanoparticles (gnps) in polypyrrole (ppy) nanocomposite onto the screen printed carbon electrode (spce) was investigated as a biosensor for the detection of nitrite based on its electrochemical and catalytic properties. ccr was covalently coupled with sam layers on gnps by using edc and nhs. direct electrochemical response of cer biofunctionalized electrodes showed a couple of well-defined and nearly reversible cyclic voltammetric peaks at -0.34 and -0.45 vs. ag/agcl. under optimal conditions, the biosensor could be used for the determination of no2- with a linear range from 0.1-1600 mu m and a detection limit of 60 nm with a sensitivity of 0.172 mu a mu m-1 cm(-2). further, we have designed and developed a novel and cost effective portable electrochemical analyzer for the measurement of no2- in hypoxia induced h9c2 cardiac cells using arm microcontroller. the results obtained here using the developed portable electrochemical nitrite analyzer were also compared with the standard cyclic voltammetry instrument and found in agreement with each other.
machine_learning	multiple instance (mi) learning aims at identifying the underlying concept from collectively labeled data. a training sample consists of a set, known as a bag, of unlabelled instances. the bag as a whole is labeled positive if at least one instance in the bag is positive, or negative otherwise. given such training samples, the goal is to learn a description of the common instance(s) among the positive bags, i.e., the underlying concept that is responsible for the positive label. in this work, we introduce a learning scheme based on the notion of partial entropy for mi concept learning. partial entropy accentuates the intra-class information by focusing on the information reflected from the positive class in proportion to the total entropy, maximization of which is to equalize the likelihoods of intra-class outcomes among the positive class, essentially reflecting the intended concept. when coupled with a distance-based probabilistic model for mi learning, it is equivalent to seeking out a concept estimate that equalizes the intra-class distances while the distance to negative bags is restrained. it produces patterns that are similar to at least one instance from each of the positive bags while dissimilar from all instances in negative bags. the generated patterns from the optimization process correspond to prototypical concepts. maximum partial entropy is conceptually simple and experimental results on different mi datasets demonstrate its effectiveness in learning an explicit representation of the concept and its competitive performance when applied to classification tasks.
operational_amplifier	a design methodology for three-stage cmos otas operating in the subthreshold region is presented. the procedure is focused on the development of ultra-low-power amplifiers requiring low silicon area but being able to drive high capacitive loads. indeed, by following the presented methodology we designed a cmos ota in a 0.35-mu m technology that occupies only 4.4 . 10(-3) mm(2), is powered with a 1-v supply, exhibits 120-db dc gain and is able to drive a capacitive load up to 200 pf. thanks to proposed methodology, the ota is able to provide a 20-khz unity gain bandwidth while consuming 195 nw, even under the high load considered. moreover, the slew rate enhancer circuit in addition to the class ab output stage allows an average slew rate higher than 5 mv/mu s with the 200 pf load. comparison with prior art shows an improvement factor in the figures of merit higher than 5.
analog_signal_processing	this paper describes a novel analog circuit for extracting the tilt angle from the output of a linear micro-electromechanical-system accelerometer. the circuit uses the accelerometer signal, together with the gravitational acceleration vector, to generate the tilt signal. using a current-mode representation with metal-oxide semiconductor devices operating in weak inversion, the appropriate trigonometric function has been realized to compute tilt. furthermore, implementing a long-time constant filter to extract the mean tilt level provides adaptation to the static tilt level. specifically, this circuit has been designed as part of an implantable vestibular prosthesis to provide inclination signals for bypassing dysfunctional otolith end organs. the circuit has been fabricated in austriamicrosystems 0.35-mu m 2p4m complementary metal-oxide semiconductor technology, and this paper presents the theory, implementation, and measured results.
symbolic_computation	in this paper, stability and local bifurcation behaviors for the nonlinear aeroelastic model of an airfoil with external store are investigated using both analytical and numerical methods. three kinds of degenerated equilibrium points of bifurcation response equations are considered. they are characterized as (1) one pair of purely imaginary eigenvalues and two pairs of conjugate complex roots with negative real parts; (2) two pairs of purely imaginary eigenvalues in nonresonant case and one pair of conjugate complex roots with negative real parts; (3) three pairs of purely imaginary eigenvalues in nonresonant case. with the aid of maple software and normal form theory, the stability regions of the initial equilibrium point and the explicit expressions of the critical bifurcation curves are obtained, which can lead to static bifurcation and hopf bifurcation. under certain conditions, 2-d tori motion may occur. the complex dynamical motions are considered in this paper. finally, the numerical solutions achieved by the fourth-order runge-kutta method agree with the analytic results.
network_security	wireless sensor networks (wsns) have become increasingly popular in many applications across a broad range of fields. securing wsns poses unique challenges mainly due to their resource constraints. traditional public key cryptography (pkc) for instance is considered to be too computationally expensive for direct implementation in wsns. elliptic curve cryptography (ecc) allows one to reach the same level of security as traditional pkc using smaller key sizes. in this paper, a key distribution protocol was designed to securely provide authenticated motes with secret system keys using ecc based cryptographic functions. the designed scheme met the minimum requirements for a key distribution scheme to be considered secure and efficient in wsns.
analog_signal_processing	in this paper we present a quad-band single-chip gsm/gprs radio in 90nm digital cmos process based on the digital rf processor (drp (tm)) technology. this chip integrates all functions from physical layer to the protocol stack and peripheral support in a single chip rf soc. the transmitter uses a low-area small-signal digital polar architecture merging amplitude and phase information directly in an rf dac. the receiver is based on direct rf sampling and discrete-time analog signal processing. a dedicated internal microprocessor manages the digital rf controls to provide best achievable rf performances. the transceiver exceeds all 3gpp specifications demonstrating a receive nf of 1.8 db and a margin of 8db on tx spectral mask at 400 khz offset in gsm850/900 bands. the transceiver is best-in-class in area and occupies only 3.8 mm(2) of silicon area.
control_engineering	since industrial processes have a wide range of operating conditions, it is difficult to build a single global model that describes a process. one solution that is widely used in control engineering practice is to combine multiple models based on collected process data. for this approach to be successful, it is important to cluster the data before the modeling. in this study, pairwise constraints and an active-learning method were incorporated into the affinity propagation algorithm, resulting in a new method called active semi-supervised affinity propagation (assap) clustering. to apply assap to the modeling of industrial processes, an active-learning strategy is firstly used to obtain constraints on data based on the angle of change between two data points and the probability of their belonging to the same class, and then the constraints are used to adjust the clustering process so as to improve the clustering precision. finally, the least-squares-support-vector-machine (ls-svm) is used to build a submodel for each cluster of data points, and then all the sub-models are integrated into a model for the whole data set. verification of the assap method was carried out on data from the uci (university of california, irvine) machine learning repository and olivetti dataset. in addition, assap and ls-svm are combined to be applied to the data of the combustion process of a coke oven. the result shows the effectiveness of the method of modeling of complex industrial process based on assap. (c) 2016 published by elsevier ltd.
operational_amplifier	this paper presents a single-stage ultra-low-power fully differential operational transconductance amplifier (fd-ota) with rail-to-rail linear input range operating in weak inversion region. the input core of the ota is comprised of source degenerated, flipped voltage follower (fvf)-based bulk-driven class ab input pair, into which a regenerative feedback loop has been inserted to boost its bulk transconductance (gib). the proposed fd-ota has utilized selfcascode current mirror (sc-cm) loads, which increase its open loop gain from nominal intrinsic value of 42 db to 70.4 db. it has provided 9.24 khz gain bandwidth (gbw), consuming 64 nw of quiescent power from a 0.51 v single power supply at 15 pf load. the proposed ota in unity gain configuration has ensured reduced total harmonic distortion (thd) of 52.4 db at 200 hz frequency and 1 vp-p signal swing. its fully differential class ab input and output structures have ensured increased gain, gbw, slew rates and output swings with reduced nonlinearity and common mode substrate noise. the cadence virtuoso environment using gpdk 180 nm standard n-well cmos process technology has been used to simulate the proposed circuit.
computer_graphics	many vocational schools and universities offer lectures on non-stereoscopic 3d computer graphics (3dcg) animation production, as well as practical 3dcg software operation, modeling, and animation production. however, relatively few of these educational institutions provide lectures on stereoscopic 3d (s3d). to address this gap, we developed two 15-week syllabuses with educational materials, which focused on both knowledge based and skills-based education about 3dcg animation and s3d computer graphics (s3dcg) animation production, considering the potential employment of students in animation studios. our investigation confirmed that the knowledge and skills of the subjects improved in this study, so we presented a report on the effectiveness of the educational materials for s3dcg animation production education at the education symposium of siggraph asia 2015. by developing these educational materials, we reaffirmed the importance of camerawork skills education, which may be regarded as the cornerstone of 3dcg animation and s3dcg animation production. however, camerawork skills education in 3dcg animation classes remains limited in vocational schools and universities at present. we hypothesized that one of the reasons for the paucity of camerawork skills education is the lack of suitable educational materials for practical classes in the use of 3dcg software. indeed, educational materials that allow teachers to begin camerawork skills education for 3dcg and s3dcg animation production without preparation are greatly lacking. furthermore, modeling and character animation are regarded as essential before camerawork practice. camerawork practice can be started immediately if sufficient educational materials are provided. the educational materials that we developed are suitable for s3dcg but also for 3dcg camerawork practice. in this study, we present the camerawork skills education and evaluation methods involved in the educational materials developed for the s3d lectures and for camerawork practical classes in s3dcg animation. we then discuss the experimental classes in which we used the educational materials and we report the results of s3d knowledge tests and camerawork practical tests, which were conducted in order to measure the learning/education outcomes for the participating subjects, as well as the results of a survey that focused on their subjective experiences. the experimental results clearly demonstrated improvements in both the knowledge and skills of subjects, thereby confirming the effectiveness of the camerawork educational materials. we suggest that if students with knowledge of s3d and 3dcg animation are well-practiced in the use of these educational materials, their skills in s3dcg camerawork would improve markedly. 2016 elsevier ltd. all rights reserved.
parallel_computing	in the framework of further development of a unified computational tool for the needs of biomedical optics, we introduce an electric field monte carlo (mc) model for simulation of backscattering of coherent linearly polarized light from a turbid tissue-like scattering medium with a rough surface. we consider the laser speckle patterns formation and the role of surface roughness in the depolarization of linearly polarized light backscattered from the medium. the mutual phase shifts due to the photons' pathlength difference within the medium and due to reflection/refraction on the rough surface of the medium are taken into account. the validation of the model includes the creation of the phantoms of various roughness and optical properties, measurements of co- and cross-polarized components of the backscattered/reflected light, its analysis and extensive computer modeling accelerated by parallel computing on the nvidia graphics processing units using compute unified device architecture (cuda). the analysis of the spatial intensity distribution is based on second-order statistics that shows a strong correlation with the surface roughness, both with the results of modeling and experiment. the results of modeling show a good agreement with the results of experimental measurements on phantoms mimicking human skin. the developed mc approach can be used for the direct simulation of light scattered by the turbid scattering medium with various roughness of the surface. (c) 2016 society of photo-optical instrumentation engineers (spie)
data_structures	cultural heritage (ch) documentation tasks usually involve professionals from different knowledge areas, which implies not only a huge amount of information and requirements, but also a very heterogeneous set of sources, data structures, content and formats. geographic information systems (gis) have been used extensively by cultural heritage specialists, but this is just working around the real problem: there is no specialized software for ch professionals to document their work in 3d. in this paper, we present software named agata that allows specialists to interact in real time with high resolution polygonal models, and to annotate different raster and vectorial information directly onto them that might be useful for current or future research. moreover, these annotations can be exported in a standard format that allows researchers from other disciplines that might be interested in the dataset to access such information easily. the system is able to manage and annotate not only on buildings or archaeological sites, but also sculptures or paintings directly into the 3d dataset of any ch physical element. (c) 2016 elsevier masson sas. all rights reserved.
electric_motor	in this paper, a multi-mode parallel hybrid power-train so called clutchless geared smart transmission (cgst), is proposed and assessed in terms of the fuel economy. the use of a single motor/generator and a planetary gear enables the cgst to provide remarkable flexibility with four operational modes including the parallel hybrid mode. based on its novel configuration, a fuel consumption model is newly developed and simulated to analyze the fuel economy of the cgst. the performance of the cgst is compared with those of the power-split hybrid system and the conventional manual transmission in city and highway cycles. the cgst shows the best efficiency in highway driving by reducing the unnecessary energy loss from the electric motor. moreover, thanks to brake-regeneration and efficient engine operation with the specific operational modes, the fuel economy in the city cycle is comparable to that of the power-split hybrid system even though the cgst uses just a single electric motor.
data_structures	big data is growing remarkably with technological development. in the field of business, there is growing trend which try to find useful information to marketing activities from the enormous data. however, data analysis needs knowledge about data structures and programming skills. it is difficult for general employees to acquire these. in this study, we propose a system which visualizes the relation between the goods by using pos (point of sales) data with ids of a supermarket. we think that the analysts do not have the pre-requisite skills of programming, they can understand the relation between the goods by using our proposal system easily. then as the proposal system turns into a web application, they are able to share the result of analysis by using a web browser. it becomes clear that our proposal system is effective through a result of the interview evaluation.
analog_signal_processing	a nonuniform stub-loaded and coupling-free broadband phaser is proposed as an alternative to conventional coupled-line sections based phasers for enhanced design flexibility, reduced complexity and lower cost in radio analog signal processing (r-asp) systems. nonuniform open- and short-terminated stub-loaded sections are employed to achieve specified highly flexible group delays with flat transmission magnitude responses. the phaser does not require multilayer or wire-bonding technologies since it consists of couplingfree transmission lines. the principle and synthesis procedure of the phaser are presented and two design examples with diverse specifications are presented with theory and full-wave simulation results. the phaser can be realized using microstrip technology and integrate with different lumped components and planar structures.
computer_programming	since the shale gas production data predicted by traditional simulators is far below that of field test, reservoir volume parameters are often modified to meet the fitting demands. most pressure transient models of reservoir, merely based on darcy flow in the matrix and natural fractures, neglect the comprehensive influences of viscous flow, slip flow, transition flow and knudsen flow, etc. in this paper, two gas apparent permeability models considering multiple migration mechanisms are established through theoretical derivation and fitting. the models are applicable to various flow states and will help to simplify percolation models of matrix and fracture system. to achieve a better understanding of the migration mechanisms of shale matrix, the effects of compressed gas in the matrix pores, adsorbed gas on the pore wall and the diffused gas from kerogen on transient pressure should all be taken into account. based on the newly established gas apparent permeability models, a pseudo-triple-medium transient percolation mathematical model of multi-fractured horizontal well affected by multiple migration mechanisms is presented with the consideration of dissolved gas diffusion in kerogen and adsorbed gas desorption on matrix surface in the shale gas reservoir. source function idea combined with laplace transform, linear approximation and delta generalized function is used to get the point source solution of the mathematical model. by discretizing the artificial fractures, the pressure transient response of multi-fractured horizontal well in laplace space is obtained on the basis of point source solution. then pressure transient response type curves are plotted by computer programming, and pressure influence factors are also analyzed. besides, isothermal adsorption experiment data of shale cores indicates that the organic carbon content (toc) has obvious correlation with the adsorption coefficient defined in this paper, which gives a clue to link up the exploitation research with geological study, playing a guiding role in analyzing pressure response of the shale gas reservoir. (c) 2014 elsevier b.v. all rights reserved.
operational_amplifier	electrochemical biosensing is used to detect specific analytes in fluids, such as bacterial and chemical contaminants. a common implementation of an electrochemical readout is a potentiostat, which usually includes potentiometric, amperometric, and impedimetric detection. recently several researchers have developed small, low-cost, single-chip silicon-based potentiostats. with the advances in heterogeneous integration technology, low-power potentiostats can be implemented on paper and similar low cost substrates. this paper deals with the design of a low-power paper-based amperometric front-end for a low-cost and rapid detection environment. in amperometric detection a voltage signal is provided to a sensor system, while a small current value generated by an electrochemical redox reaction in the system is measured. in order to measure low current values, the noise of the circuit must be minimized, which is accomplished with a pre-amplification front-end stage, typically designed around an operational amplifier core. an appropriate circuit design for a low-power and low-cost amperometric front-end is identified, taking the heterogeneous integration of various components into account. the operational amplifier core is on a bare custom cmos chip, which will be integrated onto the paper substrate alongside commercial off-the-shelf electronic components. a general-purpose low-power two-stage cmos amplifier circuit is designed and simulated for the ams 350 nm 5 v process. after the layout design and verification, the ic was submitted for a multi-project wafer manufacturing run. the simulated results are a bandwidth of 2.4 mhz, a common-mode rejection ratio of 70.04 db, and power dissipation of 0.154 mw, which are comparable with the analytical values.
image_processing	the simultaneous three-dimensional (3d) visualization of intracranial tumors, brain structures, skull, and vessels is desired by neurosurgeons to create a clear mental picture of the anatomical orientation of the surgical field prior to the surgical intervention. different anatomical and pathological components are usually visualized separately on different magnetic resonance (mr) sequences; however, during surgery, they are tackled simultaneously. another problem is that most present day mr workstations enable review of two-dimensional (2d) slices only with limited postprocessing options. with recent software developments, a simultaneous 3d visualization simulating the real surgical field is possible using commercial or open source softwares. the authors have reviewed the important concepts and described a technique of interactive 3d visualization from routine 3d t1-weighted, mr angiography, and mr venography sequences using open source fsl ( pfunctional mri of the brain software library) and brainsuite softwares.
data_structures	we present a performance comparison of bounding volume hierarchies and kd-trees for ray tracing on many-core architectures (gpus). the comparison is focused on rendering times and traversal characteristics on the gpu using data structures that were optimized for very high performance of tracing rays. to achieve low rendering times, we extensively examine the constants used in termination criteria for the two data structures. we show that for a contemporary gpu architecture (nvidia kepler) bounding volume hierarchies have higher ray tracing performance than kd-trees for simple and moderately complex scenes. on the other hand, kd-trees have higher performance for complex scenes, in particular for those with high depth complexity. finally, we analyse the causes of the performance discrepancies using the profiling characteristics of the ray tracing kernels.
electrical_circuits	due to the rapid development of renewable energy and waste energy recovery, absorption energy storage is an important technology with promising future. however, because most researches focus on working fluid flow rather than energy flow used in electric power systems, it is hard to analyze the entire systems as a whole. this contribution introduces the electrical circuit analogy to analyze absorption energy storage systems from the perspective of energy flow. it turns the energy storage and release processes to their corresponding electrical circuits, which are described by kirchhoff 's laws in circuitous philosophy instead of complex component analysis. on this basis, optimization of an absorption energy storage system is converted to a conditional extremum problem, and applying the lagrange multiplier method offers the optimization equations to directly obtain the optimal structural and operating parameters with the best performance. in this contribution, the optimized results offer 13% and 25% higher power in the storage and release cases, respectively, compared to existing experimental results. besides, inspired from the batteries connected in parallel and series, the design of a multi-stage absorption energy storage system could store low-grade heat but provide high-grade heat, which further reveals the superior of the newly proposed approach. (c) 2016 elsevier ltd. all rights reserved.
microcontroller	in this paper, we have introduced how autonomous robots would benefit from improvements in haptic intelligence and overview of telerobotics systems. in the real world, we want robots to help to perform tasks in the remote environment. this paper also accentuates the synergy between the human operator and a robot and has various applications in healthcare, medicines, entertainment, education, graphic arts, the industry as well as space. our aim is to design and construct a robotic arm through in cooperation of haptic feedback. through the processes of conceptualization, design, assembly, and final coding, we were required to complete tasks ranging from needs assessment, static and dynamic load analyses, design for manufacturing, machining, troubleshooting, and finally microcontroller coding, to name but a few.
electrical_circuits	the paper is devoted to the problem of fault detection in analog electrical circuits described by linear or nonlinear polynomial models. so-called data-driven method for fault detection is considered. this method assumes that parameters of the circuit under consideration may be unknown. it does not use methods of identification and allows checking whether or not parameters of some elements deviate considerably from their nominal values.
computer_vision	a new image analysis algorithm based on mathematical morphology and pixel classification for grapevine berry counting is presented in this paper. first, a set of berry candidates represented by connected components was extracted. then, six descriptors were calculated using key features of these components, and were employed for false positive (fp) discrimination using a supervised approach. more specifically, the set of descriptors modelled the grapes' distinctive shape, light reflection pattern and colour. two classifiers were tested, a three-layer neural network and an optimised support vector machine. a dataset of 152 images was acquired with a low-cost smart phone camera. images came from seven grapevine varieties, 18 per variety, at the two phenological stages in the baggiolini scale between berry set (named stage k; 94 images) and cluster-closure (named stage l; 32 images). 126 of these images were kept for external validation and the remaining 26 were used for training (12 at stage l and 14 at k). from these training images, 5438 true/false positive samples were generated and labelled in terms of the six descriptors. the neural network performed better than the support vector machine, yielding consistent recall and precision average values of 0.9572 and 0.8705, respectively. the presented algorithm, implemented as a smartphone application, can constitute a useful diagnosis tool for the in-the-field and non-destructive yield prediction and berry set assessing for the grape and wine industry. (c) 2017 iagre. published by elsevier ltd. all rights reserved.
analog_signal_processing	commercial refrigeration systems applying r744 as the only refrigerant still have a large potential in development regarding energy efficiency, heat recovery and cost efficiency. special focus and emphasis has to be given to the system architecture with respect to increase the system efficiency when these units are operated at elevated ambient temperatures. the objective of this thorough theoretical study is to investigate the energy required for different r744 refrigeration systems at 25-50-75-100% cooling load conditions. all r744 system configurations are assumed to operate at high ambient temperatures (from 30 to 42 degrees c) which mean only transcritical operations are considered for the following system configurations. some alternatives are sustainable and viable competitors to conventional hfc supermarket refrigeration systems, up to now applied in warm climates: standard booster cycle (baseline) expander cycle (expander ->electrical generator) r744 booster cycle with a mechanical subcooler (ms) unit: working fluid ms: hydrocarbon economiser i cycle (with a flash tank, i.e. parallel compression) economiser ii cycle (without a flash tank; i.e. parallel compression) ejector supported parallel compression system these different cycles are evaluated with advanced spreadsheets assuming realistic component performances.
operating_systems	memory corruption vulnerability is prevalent in software that are written using languages that lack memory safety features, e.g., c and c++. this has become a serious problem because the number of the attacks that exploit this vulnerability has increased. more specifically, this vulnerability allows control-flow-hijacking, a memory corruption attack that involves a well-known dangerous program stack. several countermeasures have been proposed both in academia and the information technology industry to thwart such attacks. some of these countermeasures have been implemented and used in practice. however, memory corruption attacks continue to be a serious problem because even these countermeasures are simply bypassed by new attacks. in this paper, we survey and classify protection and mitigation technologies that are especially pervasive in operating systems and compilers. this study aims to organize the pervasive countermeasures against these attacks. we present the existing countermeasures to address the current serious problem and propose modifications to these countermeasures that can be implemented in the future.
network_security	due to lack of the ""source-network-ioad"" global perception and multiple time-scale situation awareness, the current distribution network cannot meet the requirements of the active distribution network (adn) such as active control and active management. an adn situation awareness system based on distributed monitoring and multi-source information fusion is proposed in this paper. by constructing a multi-level distributed monitoring system based on internet of things (lot) technology, monitoring objects of distribution network are expanded to achieve global awareness in spatial scale. in the light of the randomness and volatility risk of distribution network operation, it is necessary to enhance observability of situation awareness in time scale. thus, the situation awareness technology of distribution network based on multi-source information fusion is provided, which is constituted of the multi-source information fusion, source-load forecasting, fast simulation analysis, risk assessment and warning and visualization modules. finally, the operation cockpit visualization technology enables operators to efficiently capture accurate distribution network security situation trend. the adn situation awareness system demonstration project is currently being carried out by state grid jiangsu power company, the actual operation indicates that it can effectively enhance the operation situation awareness and risk early-warning capability.
computer_programming	this practical report analyzes a programming class using a micro robot (mr), the smallest soccer robot in the robocup world competition. this class examined the effect of using the mr as the actual equipment employed in programming. questionnaire results on this class revealed that these teaching materials evoked a heightened programming interest among students. moreover, the problems related to programming instruction using an mr were better understood; therefore, a strategy for improving the related problems is discussed here. (c) 2013 wiley periodicals, inc. comput appl eng educ 23:109-116, 2015; view this article online at ; doi
microcontroller	this paper presents a new automatic control system that can precisely and automatically analyze complex harmonics occurring from the power distribution transformers. the proposed system consists of pre-amplification block, digital signal processing block, and real-time monitoring block. it can be applied to a development board with a microcontroller connected to a pc to monitor harmonics in real time because it can be individually affixed to a transformer. the existing expensive harmonics measurement systems take a lot of time to analyze complex harmonics. unlike the conventional systems, since this system is accurate and automatic in measurement, it provides very low measurement errors and very small test overhead. the proposed system showed very low measurement errors of less than 0.8% as well as fast real-time measurements of approximately 23sec. for harmonics analysis as compared to external expensive equipment measurements. we hope that this new system will provide industry with a simple and inexpensive technique to control and analyze complex harmonics occurring from the distribution transformers.
pid_controller	goal: target-controlled infusion of anesthesia is a closed-loop automated drug delivery method with a computer-aided control. our goal is to design and test an automated drug infusion platform for propofol delivery in total intravenous anesthesia (tiva) administration. methods: in the proposed method, a dilution chamber with first-order exponential decay characteristics was used to model the pharmacodynamics decay of a drug. the dilution chamber was connected to a flow system through an electrochemical cell containing an organic film-coated glassy carbon electrode as working electrode. to set up the feedback-controlled delivery platform and optimize its parameters, ferrocenemethanol was used as a proxy of the propofol. the output signal of the sensor was connected to a pi controller, which prompted a syringe pump for feedback-controlled drug infusion. results: the result is a bench-top drug infusion platform to automate the delivery of a propofol based on the measurement of concentration with an organic film-coated voltammetric sensor. conclusion: to evaluate the performance characteristics of the infusion platform, the propofol concentration in the dilution chamber was monitored with the organic film-coated glassy carbon electrode and the difference between the set and measured concentrations was assessed. the feasibility of measurement-based feedback-controlled propofol delivery is demonstrated and confirmed. significance: this platform will contribute to high-performance tiva application of intravenous propofol anesthesia.
electrical_network	the issue of testability, intended as a measure of solvability of the parametric fault diagnosis problem in analog linear time-invariant electrical networks, is addressed in this paper. independently of the considered fault location method, such important metric provides information as to how many and which components can be diagnosed. for the reader 's convenience and to set up an appropriate framework for our main achievements, our first concern is to rederive fundamental results concerning analog linear time-invariant electrical network testability hinging on multifrequency measurements. then a novel algorithm for testability analysis is proposed, which is straightforward and able to circumvent the main drawbacks of formerly proposed methods, such as computational and conceptual complexities, proneness to roundoff errors, and vulnerability to particular cases. a computer program that implements such algorithm is also described. moreover, the possibility of employing further simplified versions of the latter and their links with a previously proposed approach are discussed on rigorous bases. finally, examples are provided, which show the effectiveness and robustness of the new algorithms, also by means of a comparison with the old ones. copyright (c) 2015 john wiley & sons, ltd.
signal-flow_graph	the discrete cosine transform (dct) and the discrete sine transform (dst) are members of the sinusoidal family of unitary transforms. a generalized signal flow graph for the dct/dst of type ii (dct-ii/dst-ii) computation and their inverses dct-iii/dst-iii is described. it is based on the fast, recursive and numerically stable hou 's algorithm. the generalized signal flow graph represents a unified approach to the fast dct-ii/dst-ii and dct-iii/dst-iii computation for any n = 2(m), m >0. it is suitable for the implementation on the universal vlsi chip.
operating_systems	hypervisors enable cloud computing model to provide scalable infrastructures and on-demand access to computing resources as they support multiple operating systems to run on one physical server concurrently. this mechanism enhances utilization of physical server thus reduces server count in the data center. hypervisors also drive the benefits of reduced it infrastructure setup and maintenance costs along with power savings. it is interesting to know different hypervisors' performance for the consolidated application workloads. three hypervisors esxi, xenserver, and kvm are carefully chosen to represent three categories full virtualized, para-virtualized, and hybrid virtualized respectively for the experiment. we have created a private cloud using cloudstack. hypervisors are deployed as hosts in the private cloud in the respective clusters. each hypervisor is deployed with three virtual machines. three applications web server, application server, and database servers are installed on three virtual machines. experiments are designed using design of experiments (doe) methodology. with concurrently running virtual machines, each hypervisor is stressed with the consolidated real-time workloads (web load, application load, and oltp) and important system information is gathered using sigar framework. the paper proposes a new scoring formula for hypervisors' performance in the private cloud for consolidated application workloads and the accuracy of the results are complemented with sound statistical analysis using doe. (c) 2016 elsevier b.v. all rights reserved.
cryptography	permutation polynomials over finite fields play important roles in finite fields theory. they also have wide applications in many areas of science and engineering such as coding theory, cryptography, combinatorial design, communication theory and so on. permutation binomials and permutation trinomials attract people 's interest due to their simple algebraic forms and additional extraordinary properties. in this paper, we find a new result about permutation binomials and construct several new classes of permutation trinomials. some of them are generalizations of known ones. (c) 2016 published by elsevier inc.
electrical_circuits	since thermal environment affects production, egg quality and laying hens' mortality rates, it is highly relevant to control the thermal environment within poultry houses so that the best financial profits could be obtained. three commercial poultry houses with different climatization systems are analyzed in current research: a poultry house with tunnel-like ventilation and pad cooling; a poultry house with natural ventilation and nebulization; a poultry house with simple natural ventilation. their thermal environment, production, egg quality and laying hens' mortality rates among different poultry houses and at different areas of the same poultry house are compared. economic profits based on difference in electric energy consumption by climatization systems and on the laying hens' productivity of each poultry house are calculated. electricity meters were installed within the electrical circuits of the climatization and light systems of the three poultry houses. data were registered between december 2011 and march 2012 and results showed that all the poultry houses featured heterogeneity in internal thermal environment with faults in the climatization systems. important differences were reported in egg production and quality caused by overheating. the poultry house with tunnel-like ventilation and pad cooling had the best thermal isolation from the external environment that resulted in a 12.04% improvement in production, decrease between 30 and 40% in laying hens' mortality rates and the best economic result.
electric_motor	ac motor-driven electric scooters are highly eco-efficient, high performance, more convenient, and air-pollution free. they offer a certain powerful solution to global environmental and energy problems. this paper presents a newly-developed super-rapid charging electric motor-driven scooter (electric scooter) incorporating edlc stack change-over power source. described are practical design criteria of the edlc stack-based electric scooter with a zcs-dc/dc high frequency link converter and experimental result of running operation performance. furthermore, a pulse power ultracapacitor (edlc) charger for home use is proposed from a practical point of view.
operating_systems	the mcs lock is one of the most prevalent queuing locks. it provides fair scheduling and high performance on massively parallel systems. however, the mcs lock mandates a bring-your-own-context policy: each lock user must provide an additional context (i.e., a queue node) to interact with the lock. this paper proposes mcsg, a variant of the mcs lock that relaxes this restriction. our key observation is that not all lock users are created equal. we analyzed how locks are used in massively-parallel modern systems, such as numa-aware operating systems and databases. we found that such systems often have a small number of ""regular"" code paths that enter the lock very frequently. such code paths are the primary beneficiary of the high scalability of mcs locks. however, there are also many ""guest"" code paths that infrequently enter the lock and do not need the same degree of fairness to access the lock (e.g., background tasks that only run periodically with lower priority). these guest users, which are typically spread out in various modules of the software, prefer context-free locks, such as ticket locks. mcsg provides these guests a context-free interface while regular users still enjoy the benefits provided by mcs. it can also be used as a drop-in replacement of mcs for more advanced locks, such as cohort locking. we also propose mcsg++, an extended version of mcsg, which avoids guest starvation and non-fifo behaviors that might happen with mcsg. our evaluation using microbenchmarks and the tpc-c database benchmark on a 16-socket, 240-core server shows that both mcsg and mcsg++ preserve the benefits of mcs for regular users while providing a context-free interface for guests.
bioinformatics	the serodiagnosis for tegumentary leishmaniasis (tl) presents problems related to the sensitivity and/or specificity of the tests. in the present study, an enzyme-linked immunosorbent assay (elisa) technique was used to evaluate the performance from a leishmania braziliensis hypothetical protein, lbhym, in an attempt to compare its serological reactivity with a soluble leishmania antigenic preparation (sla) for the serodiagnosis of cutaneous (cl) and mucosal (ml) leishmaniasis. lbhym was predicted to be a kinesin-like protein by bioinformatics tools. serum samples were collected from both cl and ml patients, as well as from those with chagas disease and from healthy subjects living in endemic or non-endemic areas of tl. also, sera were collected from patients before and after the treatments, seeking to evaluate their serological follow-up in relation to the anti-protein and anti-parasite antibody levels. when an elisa-rlbhym assay was performed, it proved to be significantly more sensitive than elisa-l. braziliensis sla in detecting both cl and ml patients. also, when using sera from chagas disease patients, the elisa-rlbhym proved to be more specific than elisa-sla. the anti-protein and anti-parasite antibody levels were also evaluated 6 months after the treatments, and treated patients showed significantly lower levels of specific-rlbhym antibodies, when compared to the anti-parasite antibody levels. in conclusion, the elisa-rlbhym assay can be considered a confirmatory serological technique for the serodiagnosis of l. braziliensis infection and can also be used in the serological follow-up of treated patients, aiming to correlate the low anti-protein antibody levels with the improvement of the healthy state of the patients.
computer_graphics	redirected walking techniques have been introduced to overcome physical space limitations for natural locomotion in virtual reality. these techniques decouple real and virtual user trajectories by subtly steering the user away from the boundaries of the physical space while maintaining the illusion that the user follows the intended virtual path. effectiveness of redirection algorithms can significantly improve when a reliable prediction of the users future virtual path is available. in current solutions, the future user trajectory is predicted based on non-standardized manual annotations of the environment structure, which is both tedious and inflexible. we propose a method for automatically generating environment annotation graphs and predicting the user trajectory using navigation meshes. we discuss the integration of this method with existing redirected walking algorithms such as force and mpcred. automated annotation of the virtual environments structure enables simplified deployment of these algorithms in any virtual environment.
state_space_representation	in this study, a new state space representation of the protein folding problem for the use of reinforcement learning methods is proposed. in the existing studies, the way of defining the state-action space prevents the agent to learn the state space for any amino-acid sequence, but rather, the defined state-action space is valid for only a particular amino-acid sequence. moreover, in the existing methods, the size of the state space is strictly depends on the amino-acid sequence length. the newly proposed state-action space reduces this dependency and allows the agent to find the optimal fold of any sequence of a certain length. additionally, by utilizing an ant based reinforcement learning algorithm, the ant-q algorithm, optimum fold of a protein is found rapidly when compared to the standard q-learning algorithm. experiments showed that, the new state-action space with the ant based reinforcement learning method is much more suited for the protein folding problem in two dimensional lattice model. (c) 2014 elsevier b.v. all rights reserved.
electricity	this study aims to conduct the nonlinearity analysis of the shading effect on the technical-economic performance of the building-integrated photovoltaic blind (bipb), which is designed as a preliminary study to evaluate the feasibility of the bipb before its implementation. first, in terms of the technical performance of the bipb, the shading effect due to the blind 's slat in the bipb can have a nonlinear effect on the amount of electricity generation per unit area (aegunit) from the bipb. particularly, as the width of the pv panel increases, the aeg(unit) from the bipb tends to decrease. second, in terms of the economic performance of the bipb, the feasibility of the bipb depends on the type of investment values. specifically, as' the width of the pv panel increases, the npv25 (net present value at year 25) tends to increase; however, the sir25 (saving-to-investment ratio at year 25) tends to decrease. that is, while the npv25 is determined to be highest at us$82,869 when the width of the pv panel is 50 mm, the sir25 is determined to be highest at 2.90 times when the width of the pv panel is 10 mm. the main findings of this study can be used to clearly define the design specifications of the bipb before its implementation, which ensure to meet the client expectations on various objectives, such as technical performance (e.g., the aeg(unit) from the bipb) and economic performance (e.g., npv25 and sir25). (c) 2016 elsevier ltd. all rights reserved.
electrical_network	microgrid is a low voltage electrical network with distributed generations, energy storage devices and controllable loads. this paper utilizes artificial neural network (ann) to predict the optimum voltages in order to extract the maximum power and increment the efficiency of photovoltaic system. in this regard, the optimum voltages are achieved by the genetic algorithm (ga). then these optimum values are used in ann method. the results of ann-ga is compared with the other methods that verified the proposed method with high accuracy which can track the maximum power point (mpp) under different insolation and temperature circumstances and also, meet the load demand with less fluctuation around the mpp.; also it can increase the convergence speed to achieve the mpp. as well as, the evaluation of fuzzy logic controller (flc) in comparison with the pi controller in pitch angle of wind turbine (wt) is carried out. in order to control the output power of wind turbine, by implementing the wind speed and active power as inputs of flc, it has faster responses, smoother power curves, less oscillation than aforementioned methods which lead to improve the dynamic responses of wt. the models are developed and applied in the matlab/simulink program.
symbolic_computation	based on generalized bilinear forms, lump solutions, rationally localized in all directions in the space, to dimensionally reduced p-gkp and p-gbkp equations in (2+1)-dimensions are computed through symbolic computation with maple. the sufficient and necessary conditions to guarantee analyticity and rational localization of the solutions are presented. the resulting lump solutions contain six parameters, two of which are totally free, due to the translation invariance, and the other four of which only need to satisfy the presented sufficient and necessary conditions. their three-dimensional plots with particular choices of the involved parameters are made to show energy distribution.
operating_systems	smartphones have become ubiquitous in our society. with a large number of users spending more time and sharing more personal data with these devices, it would be beneficial to gain some understanding of data security. this paper presents different security issues regarding applications of android systems which are one of the most popular mobile operating systems. the research also sheds a light on how the public feels about a number of privacy and security issues related to permissions and whether any additional factors play into an individual 's understanding of the application permission framework.
operating_systems	as automatic test systems continue to adopt architectures based on synthetic instrumentation and modular i/o platforms, software is eclipsing hardware as the primary input for determining technology insertion cadence and scope. while abstracting test programs sets from specific hardware is commonly referenced as a valuable tactic to reduce the risks of i/o obsolescence, it also requires significant up-front investment with a return that is later determined by the frequency of change. as systems become increasingly software-centric, a cost optimized development strategy requires bounding technology insertion options, evaluating the costs associated with developing driver and measurement layers across those options, and managing the costs of migrating across application software and operating systems as a function of time. this paper will discuss the evolving solution space for software dominated technology insertion strategies through an examination of the underlying compatibility of the cots components at play.
electricity	by proposing a three-hierarchy meta-frontier data envelopment analysis (dea), this paper first decomposes co2-emissions efficiency and the potential for emissions reduction into the following three components: structural, technical, and management. based on these components, we then conduct an empirical analysis of china 's total-factor co2-emissions efficiency, its potential for co2-emissions reduction, and its corresponding implementation path. the results show that co2-emissions efficiency in mainland china is relatively low because of structural inefficiency, technical inefficiency, and management inefficiency. the chinese government is expected to realize a large quantity of co2-emissions reduction potential (nearly 40% of the current total co2-emissions) through adjusting the industrial structure, narrowing the technology gap among regions, promoting the reform of marketization, and strengthening environmental regulation. the causes of co2-emissions inefficiency and the distribution of potential reductions in emissions show a distinct spatial difference characteristic. therefore, this paper also formulates emissions-reduction strategies for china 's 30 provinces according to their specific situations, noting the direction of the industrial structure adjustment and the path to improving co2-emissions efficiency.
algorithm_design	the security game is a basic model for resource allocation in adversarial environments. here there are two players, a defender and an attacker. the defender wants to allocate her limited resources to defend critical targets and the attacker seeks his most favorable target to attack. in the past decade, there has been a surge of research interest in analyzing and solving security games that are motivated by applications from various domains. remarkably, these models and their game-theoretic solutions have led to real-world deployments in use by major security agencies like the lax airport, the us coast guard and federal air marshal service, as well as non-governmental organizations. among all these research and applications, equilibrium computation serves as a foundation. this paper examines security games from a theoretical perspective and provides a unified view of various security game models. in particular, each security game can be characterized by a set system e which consists of the defender 's pure strategies; the defender 's best response problem can be viewed as a combinatorial optimization problem over e. our framework captures most of the basic security game models in the literature, including all the deployed systems; the set system e arising from various domains encodes standard combinatorial problems like bipartite matching, maximum coverage, min-cost flow, packing problems, etc. our main result shows that equilibrium computation in security games is essentially a combinatorial problem. in particular, we prove that, for any set system e, the following problems can be reduced to each other in polynomial time: (0) combinatorial optimization over e; (1) computing the minimax equilibrium for zero-sum security games over e; (2) computing the strong stackelberg equilibrium for security games over e; (3) computing the best or worst (for the defender) nash equilibrium for security games over e. therefore, the hardness [polynomial solvability] of any of these problems implies the hardness [polynomial solvability] of all the others. here, by ""games over e"" we mean the class of security games with arbitrary payoff structures, but a fixed set e of defender pure strategies. this shows that the complexity of a security game is essentially determined by the set system e. we view drawing these connections as an important conceptual contribution of this paper.
computer_graphics	in this paper, we first introduce the generalized alternated system. the definition of the julia set in the generalized alternated system is given, which is called a generalized alternated julia set. then, we achieve the control of generalized alternated julia sets by applying the classic control methods, which are gradient control and optimal control. in addition, the synchronization between two different generalized alternated julia sets is implemented using gradient control and optimal control. the simulations illustrate the effectiveness and correctness of these two control methods, and the results are displayed in 2d computer graphics.
pid_controller	the robust and precise control of piezoelectric stages is quite challenging due to the existence of strong hysteresis nonlinearity. in this paper, the dynamics of a piezoelectric stage is identified as a second-order linear system preceded by an input hysteresis characterized by the prandtl-ishlinskii (pi) model. then, a control strategy based on the uncertainty and disturbance estimator (ude) is developed to mitigate the effect of hysteresis nonlinearity and improve the performance of the positioning control of the piezoelectric stage, without the detailed model of the hysteresis except the slope information of the pi hysteresis asymptotes. moreover, the stability analysis of the closed-loop system with the ude-based controller is provided. extensive experimental studies are carried out on a physik instrumente p-753.31c piezoelectric stage to demonstrate that the ude-based controller can achieve excellent performance in trajectory tracking and disturbance rejection, compared to the proportional-integral-derivative (pid) controller and a disturbance-observer-based controller.
operating_systems	this article describes the approach of experts of the national research moscow state university of civil engineering (mgsu) to the construction of modern operating systems in buildings using bim-technology. this article was performed within the russian state task.
electricity	the jiuquan satellite launch center (jslc) is a relatively isolated special zone in the northwest region of china. the potential risk to the energy supply security and the pressure of national greenhouse gas emissions reduction clearly indicates the jslc 's need to lower its dependency on imported fossil fuels and electricity. this article presents a feasibility analysis on the available hybrid energy system based on the renewable energy availability and local electricity demand estimation in 2020 through homer model. the simulation results indicate that cost of energy (coe) of the three proposed options are 0.127, 0.033 and 0.123 $/kwh, respectively. it also shows that the proposed hybrid renewable energy systems can reduce carbon emissions by 40-70% compared to electricity from the existing power grid. a sensitivity analysis reveals that the coe has a significant positive relationship with carbon price and discount rate, whereas carbon price shows a significantly distinct impact on the coe for different options considered. the optimization results also show that a grid-connected renewable power system comprised of wind power and natural gas power plant is the most economic and environment-friendly energy supply option for jslc. however, a hybrid re system with a local energy storage facility can better guarantee the energy supply safety considering the special function and security needs of the jslc. this study verified that constructing new coal fired power plants is not a suitable choice from both the cost effectiveness and kenvironmental protection perspectives. (c) 2016 elsevier b.v. all rights reserved.
analog_signal_processing	we present a loss-gain equalized reconfigurable c-section analog signal processor (asp) for dynamic radio analog signal processing (r-asp). such an asp provides real-time tunable group delay response with all-pass transmission. we propose a lumped loss-gain implementation, where tuning and equalization are mostly easily achieved. a theoretical study derives the transfer function and the fundamental characteristics of the device. the asp is finally experimentally demonstrated, first using a single loss-gain pair and finally a three cascaded loss-gain pair structure with full reconfigurability, where up-chirp and down-chirp group delays are shown for illustration. it is expected that this asp will find wide applications in r-asp systems requiring dynamic adaptability.
control_engineering	soft computing, as opposed to traditional computing, deals with approximate models and gives solutions to complex real-life problems. unlike hard computing, soft computing is tolerant of imprecision, uncertainty, partial truth, and approximations. in effect, the role model for soft computing is the human mind. soft computing is based on techniques such as fuzzy logic, genetic algorithms, artificial neural networks, machine learning, and expert systems. although soft computing theory and techniques were first introduced in 1980s, it has now become a major research and study area in automatic control engineering. the techniques of soft computing are nowadays being used successfully in many domestic, commercial, and industrial applications. with the advent of the low-cost and very high performance digital processors and the reduction of the cost of memory chips it is clear that the techniques and application areas of soft computing will continue to expand. this paper gives an overview of the current state of soft computing techniques and describes the advantages and disadvantages of soft computing compared to traditional hard computing techniques. (c) 2016 the authors. published by elsevier b.v.
bioinformatics	dastarcus helophoroides, a predatory natural enemy of longhorned beetles, has a relatively longer lifespan compared to other insects. to determine the potential physiological roles of antioxidant enzymes superoxide dismutase (sod) in longevity and aging of d. helophoroides, analyses including molecular information, bioinformatics research, phylogenetic relationship and expression patterns were combined for investigation. four d.hsods were classified into three groups: one cytoplasmic cu/zn-sod, two extracellular cu/zn-sod and one mn-sod, were identified and characterized by multiple alignments. all d.hsods were highly homologous to sods of tribolium castaneum, and closely clustered together with sod genes from insects in phylogenetic analyses. comparison of the d.hsods expression in different tissues, stages and age groups showed that the sod transcripts could be detected in all examined specimens. the expression of d.hsods revealed tissue-specificity with relatively high levels in the male reproductive system and head and low levels in female reproductive systems and mid gut. expression analyses of d.hsods in different development stages demonstrated that d.hsod1 and d.hsod2 increased in 2nd and 5th instar larvae, whereas two extracellular cu/zn-sod genes (d.hsod3-a and d.hsod3-b) were much more expressed in newly emerged adults. the expression fluctuations of d.hsods during aging seemed to be less significant than during development, and exhibited relatively stable expression with an initial decline and then increased in older groups. the relatively stable and increased expression of d.hsods may indicate a strong ability of sods to eliminate oxidative damage products accumulated during aging and possibly retard aging. the research provides molecular biology and in vivo expression levels for future analysis of the sod family in d. helophoroides and other insects, and provides a basis for further study about the sod genes contribution on longevity of d. helophoroides. (c) 2017 elsevier b.v. all rights reserved.
computer_programming	background: flux analyses, including flux balance analysis (fba) and c-13-metabolic flux analysis (c-13-mfa), offer direct insights into cell metabolism, and have been widely used to characterize model and non-model microbial species. nonetheless, constructing the c-13-mfa model and performing flux calculation are demanding for new learners, because they require knowledge of metabolic networks, carbon transitions, and computer programming. to facilitate and standardize the c-13-mfa modeling work, we set out to publish a user-friendly and programming-free platform (wuflux) for flux calculations in matlab (r). results: we constructed an open-source platform for steady-state c-13-mfa. using guide (graphical user interface design environment) in matlab, we built a user interface that allows users to modify models based on their own experimental conditions. wuflux is capable of directly correcting mass spectrum data of tbdms (n-tertbutyldimethylsilyl-n-methyltrifluoroacetamide)-derivatized proteinogenic amino acids by removing background noise. to simplify c-13-mfa of different prokaryotic species, the software provides several metabolic network templates, including those for chemoheterotrophic bacteria and mixotrophic cyanobacteria. users can modify the network and constraints, and then analyze the microbial carbon and energy metabolisms of various carbon substrates (e.g., glucose, pyruvate/lactate, acetate, xylose, and glycerol). wuflux also offers several ways of visualizing the flux results with respect to the constructed network. to validate our model 's applicability, we have compared and discussed the flux results obtained from wuflux and other mfa software. we have also illustrated how model constraints of cofactor and atp balances influence fluxome results. conclusion: open-source software for c-13-mfa, wuflux, with a user-friendly interface and easy-to-modify templates, is now available at http://www.13cmfa.org/or (http://tang.eece.wustl.edu/tooldevelopment.htm). we will continue documenting curated models of non-model microbial species and improving wuflux performance.
bioinformatics	the wrky family, a large family of transcription factors (tfs) found in higher plants, plays central roles in many aspects of biological processes and adaption to environment. however, little information is available on this family in apple (malus domestica). in the present study, a total of 119 candidate wrky genes in apple genome were identified and classified into three main groups (group i-iii) based on the structure of the conserved domains. each group or subgroup showed similar exon-intron structures and motif compositions. the evolution analysis showed that 44 mdwrky genes clustered into 20 intensive regions (<100 kb) and 78 mdwrky formed 85 pairs of collinear relationships, suggesting that both tandem and segmental duplications played an important role in the evolution and diversification of the wrky gene family in apple. furthermore, the expression of the mdwrky genes in apple leaves in response to biotic stress (alternaria alternate) and hormone treatments [salicylic acid (sa), methyl jasmonate (meja) and ethephon] was examined by using rna-seq and qrt-pcr. the results showed that 63 mdwrky genes had differential expression in their transcript abundance in response to alternaria alternata apple pathotype infection. moreover, most pathogen responsive mdwrky genes were also changed significantly when apple leaves were treated by sa, meja or ethephon plant growth regulations, suggesting an interaction between sa, ja and ethylene (eth) hormone signaling under biotic stress. this work may provide the basis for future studies of the genetic modification of wrky genes for pathogen resistance in apple.
state_space_representation	we consider the parametric estimation of the driving levy process of a multivariate continuous-time autoregressive moving average (mcarma) process, which is observed on the discrete time grid (0, h, 2h, ... ). beginning with a new state space representation, we develop a method to recover the driving levy process exactly from a continuous record of the observed mcarma process. we use tools from numerical analysis and the theory of infinitely divisible distributions to extend this result to allow for the approximate recovery of unit increments of the driving levy process from discrete-time observations of the mcarma process. we show that, if the sampling interval h = h(n) is chosen dependent on n, the length of the observation horizon, such that nh(n) converges to zero as n tends to infinity, then any suitable generalized method of moments estimator based on this reconstructed sample of unit increments has the same asymptotic distribution as the one based on the true increments, and is, in particular, asymptotically normally distributed. (c) 2012 elsevier inc. all rights reserved.
analog_signal_processing	continuous valued number system is a novel number system which can be employed for developing analog signal processing units. it is a continuous number system which is represented by a set of continuous digits. one of the main features of this system is that digits share information, and have a digit-level redundancy. this redundancy is used to protect the digits against environment imperfections when implemented by analog circuits. in this paper, integrity of this number system in representing real values is explored. the study is required to show the effect of implementation imperfections which is an indicative of its feasibility. effects of possible errors and error threshold for implementing this system are studied in this paper. an error recovery method is proposed, which enhances this number system representation. an efficient error recovery method extends the application of this number system in high density memory and storage devices for hardware implementations of neural networks.
symbolic_computation	in this article, we investigate the lump solutions for the kadomtsev-petviashvili equation in (3 + 1) dimensions that describe the dynamics of plasmas or fluids. via the symbolic computation, lump solutions for the (3 + 1)-dimensional kadomtsev-petviashvili equation are derived based on the bilinear forms. the conditions to guarantee analyticity and rational localisation of the lump solutions are presented. the lump solutions contain eight parameters, two of which are totally free, and the other six of which need to satisfy the presented conditions. plots with particular choices of the involved parameters are made to show the lump solutions and their energy distributions.
computer_vision	introduction: use of computers is generally encouraged; this is to keep up with the fast-moving world of technology, research and science. extensive use of computers will result in computer vision syndrome (cvs), and the prevalence is increased dramatically. the main objective of the study was to assess the prevalence and associated factors of cvs among bank workers in gondar city, northwest ethiopia. methods: a cross-sectional institution-based study was conducted among computer-using bank workers in gondar city from april to june, 2015. data were collected through structured questionnaires and observations with checklists, entered with epi info (tm) 7 and analyzed by statistical package for the social sciences (spss) version 20. descriptive statistics and logistic regression were carried out to compute the different rates, proportion and relevant associations. results: among the total 304 computer-using bank workers, the prevalence of cvs was 73% (95% confidence interval [ci]= 68.04, 78.02). blurred vision (42.4%), headache (23.0%) and redness (23.0%) were the most experienced symptoms. inappropriate sitting position was 2.3 times (adjusted odds ratio [aor]= 2.33; 95% ci= 1.27, 4.28) more likely to be associated with cvs when compared with appropriate sitting position. those working on the computer for more than 20 minutes without break were nearly 2 times (aor= 1.93; 95% ci= 1.11, 3.35) more likely to have suffered from cvs when compared with those taking break within 20 minutes, and those wearing eye glasses were 3 times (aor= 3.19; 95% ci= 1.07, 9.51) more likely to suffer from cvs when compared with those not wearing glasses. conclusion: about three-fourths of computer-using bank workers suffered from cvs with the most experienced symptoms being blurred vision, headache and redness of eyes. in appropriate sitting position, working on the computer without a break for more than 20 minutes and wearing eye glasses were independently associated with cvs.
algorithm_design	generalized spatial modulation (gsm) is a spectral and energy efficient multiple-input-multiple-output transmission technique. the low-complexity detection algorithm design with near maximum likelihood (ml) performance at the receiver is very challenging, and is the focus of this letter. in specific, we exploit the fixed sparsity constraint in the transmitted gsm signals, and take advantage of bayesian compressive sensing (bcs) in sparse signal recovery. a new detection algorithm, referred to as enhanced bayesian compressive sensing (ebcs), is proposed. it features more than 75% complexity reduction at high signal-tonoise ratios compared with the ordered-blocked minimum-meansquared-error algorithm. furthermore, it is shown by simulation that its error performance is comparable to the ml algorithm, and the performance gap is negligible in many cases.
system_identification	for a dual-rate sampled hammerstein controlled autoregressive moving average (carma) system, this paper uses the polynomial transformation technology to obtain its dual-rate bilinear identification model which is suitable for the available dual-rate sampled-data, uses the maximum likelihood principle to construct a unified parameter vector of all parameters and an information vector formed by the derivative of the noise variable to the unified parameter vector, and directly identifies the parameters of the linear block and the nonlinear block for the dual-rate hammerstein carma system. the unified parameter vector contains the minimum number of the unknown parameters, and the proposed maximum likelihood estimation algorithm has higher computational efficiency than the over-parameterization model based least squares algorithm.
cryptography	this paper presents a new controlled quantum dialogue (cqd) protocol based on the cluster entangled states. the security analyses indicate that the proposed scheme is secure under not only various well-known attacks but also the collusive attack, where the participants may collude to communicate without the controller 's permission. compared to a previous cqd scheme, which is also robust against the conspiracy attack, the proposed protocol is more efficient in both the qubit efficiency and the hardware requirement.
electrical_circuits	printed carbon graphite materials are the primary common component in the majority of screen printed sensors. screen printing allows a scalable manufacturing solution, accelerating the means by which novel sensing materials can make the transition from laboratory material to commercial product. a common bottleneck in any thick film printing process is the controlled drying of the carbon paste material. a study has been undertaken which examines the interaction between material solvent, printed film conductivity and process consistency. the study illustrates that it is possible to reduce the solvent boiling point to significantly increase process productivity while maintaining process consistency. the lower boiling point solvent also has a beneficial effect on the conductivity of the film, reducing the sheet resistance. it is proposed that this is a result of greater film stressing increasing charge percolation through greater inter particle contact. simulations of material performance and drying illustrate that a multi layered printing provides a more time efficient manufacturing method. the findings have implications for the volume manufacturing of the carbon sensor electrodes but also have implications for other applications where conductive carbon is used, such as electrical circuits and photovoltaic devices.
analog_signal_processing	a pelton-wheel impulse turbine is a hydro mechanical energy conversion device which converts gravitational energy of elevated water into mechanical work. this mechanical work is converted into electrical energy by means of running an electrical generator the kinetic energy of the water-jet is directed tangentially at the buckets of a pelton-wheel. the water-jet strikes on each bucket 's convex profile splitter and get split into two halves. each half is turned backwards, almost through 180 degrees relative to the bucket on a horizontal plane. practically this angle may vary between 165 degrees to 170 degrees. normally all the jet energy is used in propelling the rim of the bucket wheel. invariably some jet water misses the bucket and posses onto the tail race without doing any useful work. this hydro, device is a good source of hydro-electrical energy conversion for a high water head. the present work in this research paper deals with some advanced modifications in the conventional pelton-wheel so that it can be used for low-head and heavy-discharge applications. both kinetic and potential energy of the water source is consumed by the runner wheel. considerable gravitational effect of the water jet is exploited by means of some modifications in a conventional pelton-wheel. a comparatively heavy generator can be run by this modified pelton-wheel turbine under low-head and heavy-discharge conditions. the modified features provide enough promising opportunities to use this turbine for mini and micro hydro power plants.
bioinformatics	predicting protein submitochondrial locations has been studied for about ten years. a dozen of methods were developed in this regard. although a mitochondrion has four submitochondrial compartments, all existing studies considered only three of them. the mitochondrial intermembrane space proteins were always excluded in these studies. however, there are over 50 mitochondrial intermembrane space proteins in the recent release of uniprot database. we think it is time to incorporate these proteins in predicting protein submitochondrial locations. we proposed the functional domain enrichment score, which can be used as an enhancement to our positional-specific physicochemical properties method. we constructed a high-quality working dataset from the uniprot database. this dataset contains proteins from all four submitochondrial locations. proteins with multiple submitochondrial locations are also included. our method achieved over 70% prediction accuracy for proteins with single location on this dataset. on the m3-317 benchmarking dataset, our method achieved comparable prediction performance to other state-of-the-art methods. our results indicate that the intermembrane space proteins can be incorporated in predicting protein submitochondrial locations. by evaluating our method with the proteins that have multiple submitochondrial locations, we conclude that our method is capable of predicting multiple submitochondrial locations. this is the first report of ab initio methods that can identify intermembrane space proteins. this is also the first attempt to incorporate proteins with multiple submitochondrial locations. the benchmarking dataset can be obtained by emails to the corresponding author.
parallel_computing	the construction of large software systems is always achieved through assembly of independently written components - program modules. for these software components to work together, they must share a common set of data types and principles for representing structured data such as arrays of values and files. this common set of tools for creating and operating on data objects is provided by the infrastructure of the computer system: the hardware, operating system and runtime code. because the nature and properties of these tools are crucial for correct operation of software components and their inter-operation, it is essential to have a precise specification that may be used for verifying correctness of application software on one hand, and to verify correctness of system behavior on the other. we call such a specification a program execution model (pxm). it is evident that the properties of the pxm implemented by a computer system can have serious impact on the ability of application programmers to practice modular software construction. this paper discusses the concept of program execution models and presents a set of principles that a pxm must satisfy to provide a sound basis for modular software construction. because parallel program execution on computer systems with many processing units is an essential part of contemporary computing environments, the expression of parallelism and modular software construction using components involving parallel operations is included in this treatment. the conclusion is that it is possible to build computer systems that implement a pxm within which any parallel program may be used, unmodified, as a component for building more substantial parallel programs.
network_security	the network systems of the world are fragile, and can come under attack from any source. the attack can be a denial-of-service (dos) state or another type of threat. what keep the networks safe are the intrusion detection and prevention systems (idps). they constantly monitor network traffic and if a malicious threat is detected, the threat is blocked and reported for further analysis. however, every defensive system must always have some type of weakness. false negatives and false positives are some examples of how idps can fail to protect the network. in another instance, a skilled attacker may employ direct kernel object modification (dkom) to trick the idps into detecting no malicious activities. the idps is strong, yet not strong enough. this paper presents a hybrid solution that incorporates both signature and anomaly based systems to detect and prevent more malicious attacks by intensifying what is cataloged to include common anomalies to the baselines used by the signature based systems. we also propose an improvement in the framework to current host idps/network using signature and anomaly based methodologies by implementing a hybrid vmm-based honeypot into a theorized self-healing hybrid idps to further boost their advantages in efficiency and accuracy. (c) 2016 the authors. published by elsevier b.v.
machine_learning	noise addition is a data distortion technique widely used in data intensive applications. for example, in machine learning tasks it helps to reduce overfitting, whereas in data privacy protection it adds uncertainty to personally identifiable information. yet, due to its mathematical operating principle, noise addition is a method mainly intended for continuous numerical data. in fact, despite the large amount of nominal data that are being currently compiled and used in data analysis, only a few alternative techniques have been proposed to distort nominal data in a similar way as standard noise addition does for numerical data. furthermore, all these alternative methods rely on the distribution of the data rather than on the semantics of nominal values, which negatively affects the utility of the distorted outcomes. to tackle this issue, in this paper we present a semantically-grounded alternative to numerical noise suitable for nominal data, which we name semantic noise. by means of semantic noise, and by exploiting structured knowledge sources such as ontologies, we are able to distort nominal data while preserving better their semantics and thus, their analytical utility. to that end, we provide semantically and mathematically coherent versions of the statistical operators required in the noise addition process, which include the difference, the mean, the variance and the covariance. then, we propose semantic noise addition algorithms that cope with the finite, discrete and non-ordinal nature of nominal data. the proposed algorithms cover both uncorrelated noise addition, which is suited to independent attributes, and correlated noise addition, which can cope with multivariate datasets with dependent attributes. empirical results show that our proposals offer general and configurable mechanisms to distort nominal data while preserving data semantics better than baseline methods based only on the distribution of the data. (c) 2017 elsevier b.v. all rights reserved.
data_structures	to ease the programming burden and to make parallel programs more maintainable, computational scientists and engineers currently have the options to use software libraries, templates, and general purpose language extensions to compose their application programs. these existing options, unfortunately, have considerable limitations with compatibility, expressive power and delivered performance. to address these issues, we design a domain specific language, gridfor, for computational problems defined over regular geometric grids. this language allows the programmer to first implement an algorithm on simple data structures, as commonly illustrated in textbooks or papers. the programmer then specifies transformations to extend the algorithm for complex data structures required by the target applications. we build a compiler to automatically translate a gridfor program to a parallel fortran version with message passing interface calls. several optimization techniques are implemented in our compiler to enhance the program speed.
machine_learning	the excellent features of bearing vibration signal are helpful to obtain accurate diagnosis results for the failure of bearing. in this study, the feature extraction method of bearing vibration signal based on wavelet packet transform-phase space reconstruction-singular value decomposition (wps) is presented to improve the traditional feature extraction method of bearing vibration signal based on wavelet packet transform-singular value decomposition (ws). in the proposed feature extraction method, singular value decomposition is performed for phase space reconstruction signal of each wavelet packet coefficient 's reconstructed signal of bearing vibration signal. the dynamic characteristics of a certain frequency range can be reflected by phase space reconstruction for wavelet packet coefficients' reconstructed signals of bearing vibration signal. support vector machine (svm) is a machine learning method based on structural risk minimization principle, and svm classifier can solve the classification problems with small training samples, high dimensions, and nonlinearity. thus, the svm model of bearing is established by the features of bearing vibration signal based on wavelet packet transform-phase space reconstruction-singular value decomposition in this study. the experimental results show that the feature extraction method of bearing vibration signal based on wavelet packet transform-phase space reconstruction-singular value decomposition is better than the feature extraction method of bearing vibration signal based on wavelet packet transform-singular value decomposition, and svm established by the features of bearing vibration signal based on wavelet packet transform-phase space reconstruction-singular value decomposition (wps-svm) has a stronger fault diagnosis ability of bearing than svm established by the features of bearing vibration signal based on wavelet packet transform-singular value decomposition (ws-svm).
microcontroller	this paper proposes an innovative method for power consumption measurement in microcontroller-based systems that provides high accuracy on a wide dynamic range of current values, which makes it particularly suitable for all those applications characterized by alternating low-/high-power modes and fast current variations. we demonstrate that using an op-amp-based voltage feedback configuration, it is possible to use shunt resistor values higher than usual to obtain increased voltage drops without affecting the microcontroller 's power supply voltage. consequently, it is possible to directly use a data acquisition board to acquire the shunt voltage, eliminating all those common errors, like offset and gain, due to the use of an additional intermediate amplification stage. the proposed scheme has been successfully used to accurately characterize the power consumption of a single sensor node of a wireless sensor network.
digital_control	a digital dead-beat current controller for voltage source converters is presented in this paper. the control structure is specified in a digital hardware description language, synthesized, and deployed on a field-programmable gate array chip. by updating, with negligible computation delay, the duty cycle twice in a switching period, the reference current error is nulled in half a modulation period, so that the controller 's small-signal bandwidth is maximized. in addition, due to a simple transient detection circuit, the large-signal response delay is reduced to a small fraction of the modulation period, which is determined by the chosen current signal oversampling rate. the controller can effectively support different voltage-source inverter applications, such as active filters, uninterruptible power supplies, microgrid distributed energy resource controllers, and dc-dc converter applications, including interface converters for renewable energy sources, laboratory battery chargers, and electronic welding machines.
computer_graphics	mesh saliency was introduced and joined the community of computer graphics ten years ago, which can benefit various applications, for instance, mesh reduction, mesh segmentation, self-similarity matching, scan integration, volume rendering, 3d printing, etc. before, saliency detection had been successfully applied to image processing and pattern recognition to study how the world is perceptually intelligible for robots. in contrast to color of images and coherence of videos, geometric signals are defined with two-dimensional manifolds whose discrete representation is irregular, leading differences to the nature and difficulties to the solution of mesh saliency. to tackle the challenge, the last decade has witnessed significant advances in mesh saliency detection. however, a survey of recent advances in mesh saliency detection as well as its applications does not yet exist to date. this paper provides a first and comprehensive reference source of shape context based mesh saliency for researchers from a wide range of domains, including but not limited to computer graphics and vision. it reviews main contributions, advantages, drawbacks, and applications of known mesh saliency detection methods and discusses current trends and outlook for future study. (c) 2016 elsevier ltd. all rights reserved.
operating_systems	to enable a prosperous internet of things (iot), devices and services must be extensible and adapt to changes in the environment or user interaction patterns. these requirements manifest as a set of design principles for each of the layers in an iot ecosystem, from hardware to cloud services. this paper gives concrete guidelines learned from implementing and deploying a full-stack synergistic iot platform. we address hardware design concerns and present a reference platform, firestorm. upon this platform, we demonstrate firmware and personal-area networking concerns and solutions. moving out towards larger scales we address local service discovery and syndication, and show how these principles carry through to global operation where security concerns dominate.
electrical_circuits	identifying the contents of a black-box electrical circuit is a challenging experiment. in this paper, we present an approach for identifying the topological structure of the circuit and estimating the values of the internal components, by applying input signals and measuring available signals. the black-box model is provided as a simulink model, whose contents are not accessible to the students. the overall procedure is performed in matlab/simulink environment and the results are obtained for a given circuit and compared with the actual values. the experiment is performed by a group of undergraduate students and the assessment results show its effectiveness in challenging their knowledge.
electrical_circuits	in this paper, the application of cots (commercial of-the-shelf) tegs (thermoelectric generator) of bi2te3 type for power supply of autonomous sensors has been investigated. architecture of a teg system has been established and the expected electrical power provision has been simulated and tested with agreement better than one order of magnitude between simulation and test. during the mission the heat flow of the teg may reverse, therefore this has to be taken into account in the design of the corresponding electrical circuits. teg sensitivity to low temperatures (below 0 degrees c) has been found and addressed via selection of different cots teg types which were tested without any problems down to -10 degrees c. a concept for central provision of electrical power with tegs has been discussed shortly that showed the need for new high temperature tegs which can operate on temperatures above 700 degrees c. (c) 2015 elsevier ltd. all rights reserved.
system_identification	the authors have previously shown that many traditional approaches to operational modal analysis (oma) struggle to properly identify the modal damping ratios for bridges under traffic loading due to the interference caused by the driving frequencies of the traffic loads. this paper presents a novel methodology for modal parameter estimation in oma that overcomes the problems presented by driving frequencies and significantly improves the damping estimates. this methodology is based on finding the power spectral density (psd) of a given modal coordinate, and then dividing the modal psd into separate regions, left- and right-side spectra. the modal coordinates were found using a blind source separation (bss) algorithm and a curve-fitting technique was developed that uses optimization to find the modal parameters that best fit each side spectra of the psd. specifically, a pattern-search optimization method was combined with a clustering analysis algorithm and together they were employed in a series of stages in order to improve the estimates of the modal damping ratios. this method was used to estimate the damping ratios from a simulated bridge model subjected to moving traffic loads. the results of this method were compared to other established oma methods, such as frequency domain decomposition (fdd) and bss methods, and they were found to be more accurate and more reliable, even for modes that had their psds distorted or altered by driving frequencies. (c) 2016 elsevier ltd. all rights reserved.
operational_amplifier	in order to obtain very precise measurements of the position of agents located at a considerable distance using a sensor system based on position sensitive detectors (psd), it is necessary to analyze and mitigate the factors that generate substantial errors in the system 's response. these sources of error can be divided into electronic and geometric factors. the former stem from the nature and construction of the psd as well as the performance, tolerances and electronic response of the system, while the latter are related to the sensor 's optical system. here, we focus solely on the electrical effects, since the study, analysis and correction of these are a prerequisite for subsequently addressing geometric errors. a simple calibration method is proposed, which considers psd response, component tolerances, temperature variations, signal frequency used, signal to noise ratio (snr), suboptimal operational amplifier parameters, and analog to digital converter (adc) quantitation snrq, etc. following an analysis of these effects and calibration of the sensor, it was possible to correct the errors, thus rendering the effects negligible, as reported in the results section.
cryptography	s-box plays an imperative role in designing a cryptographically strong block cipher. designing s-box based on chaos has attracted lots of attentions because of its distinct characteristics relevant to cryptography. in this paper, a 4d-4wing hyperchaotic system is investigated. its sophisticated nonlinear behaviors are used to generate two pseudorandom 8-bit integer sequences, which further drive iterative two-position swap on the identical map on gf(2(8)). according to the indicator of typical evaluation criteria including nonlinearity, differential uniformity, strict avalanche criterion, output bits independence criterion and bijective property, the preferred s-box is obtained from all those batch-generated ones. the comparison with the state-of-the-art chaos-based schemes shows that the obtained s-box achieves better cryptographical performance.
computer_programming	conventional taught learning practices often experience difficulties in keeping students motivated and engaged. video games, however, are very successful at sustaining high levels of motivation and engagement through a set of tasks for hours without apparent loss of focus. in addition, gamers solve complex problems within a gaming environment without feeling fatigue or frustration, as they would typically do with a comparable learning task. based on this notion, the academic community is keen on exploring methods that can deliver deep learner engagement and has shown increased interest in adopting gamification - the integration of gaming elements, mechanics, and frameworks into non-game situations and scenarios - as a means to increase student engagement and improve information retention. its effectiveness when applied to education has been debatable though, as attempts have generally been restricted to one-dimensional approaches such as transposing a trivial reward system onto existing teaching materials and/or assessments. nevertheless, a gamified, multi-dimensional, problem-based learning approach can yield improved results even when applied to a very complex and traditionally dry task like the teaching of computer programming, as shown in this paper. the presented quasi-experimental study used a combination of instructor feedback, real time sequence of scored quizzes, and live coding to deliver a fully interactive learning experience. more specifically, the ""kahoot!"" classroom response system (crs), the classroom version of the tv game show ""who wants to be a millionaire?"", and codecademy 's interactive platform formed the basis for a learning model which was applied to an entry-level python programming course. students were thus allowed to experience multiple interlocking methods similar to those commonly found in a top quality game experience. to assess gamification 's impact on learning, empirical data from the gamified group were compared to those from a control group who was taught through a traditional learning approach, similar to the one which had been used during previous cohorts. despite this being a relatively small-scale study, the results and findings for a number of key metrics, including attendance, downloading of course material, and final grades, were encouraging and proved that the gamified approach was motivating and enriching for both students and instructors.
operating_systems	programmable network like sdn allows administrators to program network infrastructure according to service demand and custom-defined policies. network policies are interpreted by the centralized controller to define actions and rules to process the network traffic on devices that belong to a single domain. however, actual networks are multi-domain where several domains are interconnected. then, because sdn controllers in a domain cannot define nor monitor policies in other domains, network administrators cannot ensure that their own policies, origin policies are being enforced by the domains not directly managed by them (i.e. foreign domains). we present audit, a multi-domain sdn policy verifier that identifies whether an origin policy is enforced by foreign domains. audit comprises (1) model for network topology, policies, and flows, (2) an audit protocol to gather information about the actions performed by network devices to carry the flows of interest, and (3) a validation engine that takes that information and detects security policy violations, and (4) an extension to the openflow protocol to enable external auditing. this paper presents our approach and illustrates its application using an example considering multiple sdn networks.
image_processing	in production processes that use surfacemount technology (smt) for the assembly of printed circuit boards, automated optical inspection is widely employed to diagnose component defects. however, commonly used inspection algorithms can hardly meet reliability and time efficiency requirements simultaneously, especially when applied to the components of high-density and large-scale integration, such as ball grid array (bga). in this paper, a novel approach is presented to inspect bga component defects. an adaptive thresholding combined with modified (e,d)-component segmentation is first performed to extract the grayscale image of solder balls. a line-based-clustering method is then proposed to recognize ball array. simultaneously, accurate position and orientation of bga are obtained based on the recognition results. finally, ball features are extracted to diagnose potential defects. the proposed algorithm is implemented on the host computer of samsung smt 482 machine. the results obtained show that the proposed approach is suitable for a vast majority of bgas with different ball arrays and also that it is robust to interferences caused by the image segmentation. furthermore, compared to samsung 's algorithm, it has significant advantages in time efficiency and high inspection accuracy under nonideal lighting conditions.
state_space_representation	we analyzed some singular distributed parameter system(sdps) with boundary conditions in high dimension bounded domain with sufficiently smooth boundary. with the spectrum theory in pde, the systems initially is formulated as an infinite-dimensional singular systems. the state space representation of the system is built according to matrices decomposition method. and the admissible property is discussed. by the singular system theory some novel uniform state feedback controller is designed.
cryptography	because the nodes in a wireless sensor network (wsn) are mobile and the network is highly dynamic, monitoring every node at all times is impractical. as a result, an intruder can attack the network easily, thus impairing the system. hence, detecting anomalies in the network is very essential for handling efficient and safe communication. to overcome these issues, in this paper, we propose a rule-based anomaly detection technique using roaming honeypots. initially, the honeypots are deployed in such a way that all nodes in the network are covered by at least one honeypot. honeypots check every new connection by letting the centralized administrator collect the information regarding the new connection by slowing down the communication with the new node. certain pre-defined rules are applied on the new node to make a decision regarding the anomality of the node. when the timer value of each honeypot expires, other sensor nodes are appointed as honeypots. owing to this honeypot rotation, the intruder will not be able to track a honeypot to impair the network. simulation results show that this technique can efficiently handle the anomaly detection in a wsn.
electric_motor	a large set of decimetric and microwave observations of solar millisecond radio spikes is compared and correlated with simultaneous hard x-ray observations in the 25-438 kev range, recorded by the hard x-ray burst spectrometer (hxrbs) on board the solar maximum mission satellite. radio spikes have time scales of 20-200 ms, while hard x-ray bursts rarely show fine structures shorter than 1 s. the main conclusions of a statistical analysis of a) the association rate, b) the correlation degree, and c) relative time delays between hard x-ray and radio spike emissions, are: 1) radio spike bursts reveal the highest hard x-ray association rate of any kind of coherent solar radio emission; approximately 95% of the observed events occur during (mostly impulsive) hard x-ray bursts. conversely, almost-equal-to 2% of all hxrbs flares produce radio millisecond spike bursts. 2) spike bursts are preferentially associated with the impulsive phase of the hard x-ray event; about half of all observations are closely associated with the main peak of a simultaneous x-ray event. 3) we find a significant temporal correlation between spike clusters and hard x-ray events. about 43% of the compared events show hard x-ray time profiles that mimic the concentration of simultaneous radio spikes. this also holds for small fluctuations with time scales of the order of a few seconds. 4) the durations of spike events and associated hard x-ray bursts closely correlate, the x-ray bursts being somewhat longer than the radio events. 5) the radio emission is usually delayed in respect to hard x-ray bursts, typically a few seconds. the relative delays seem to be restricted to the following rules: the radio event usually starts before the peak time of the hard x-ray event (73 out of 84 cases), and similarly, the x-ray burst almost always starts before the maximum of spike burst activity (83 out of 84 cases). this is shown to hold for a wide range of burst durations. we have not found any convincing relation concerning the relative time differences of the end times, however. 6) the observed delays of the order of several seconds put some constraints on the acceleration and propagation of particles. the delays are found to be incompatible with the build-up time of a loss-cone distribution (for maser emission) by an order of magnitude, if the, same population of electrons is responsible for radio and x-ray radiation. rather, considering the smallness of the radio spike sources, the proportionality of the x-ray flux with the spike rate, and the spatial 'spread of a propagating electron population, it is argued that both the time delays and the quantization into discrete radio events are caused by the operation of the accelerator.
computer_graphics	while display quality and rendering for head-mounted-displays (hmds) has increased in quality and performance, the interaction capabilities with these devices are still very limited or relying on expensive technology. current experiences offered for mobile hmds often stick to dome-like looking around, automatic or gaze-triggered movement, or flying techniques. we developed an easy to use walking-in-place technique that does not require additional hardware to enable basic navigation, such as walking, running, or jumping, in virtual environments. our approach is based on the analysis of data from the inertial unit embedded in mobile hmds. in a first prototype realized for the samsung galaxy gear vr we detect steps and jumps. a user study shows that users novice to virtual reality easily pick up the method. in comparison to a classic input device, using our walking-in-place technique study participants felt more present in the virtual environment and preferred our method for exploration of the virtual world.
electric_motor	this is the second of a two-part study that discusses multimode combustion in a mild hybrid electric vehicle. homogeneous charge compression ignition (hcci) combustion oxidizes the oxygen storage capacity (osc) of the three-way catalyst (twc), thereby removing the twc 's ability to convert nox under lean conditions. despite prolonged operation in hcci mode, enabled by the electric motor, the depletion of the osc causes significant penalties in fuel economy and the amounts of tailpipe nox are substantial. counter-intuitively, it is seen that decreasing the sizes of both hcci regime and osc results in reduced tailpipe nox while maintaining fuel economy benefits.
software_engineering	defect management is a central task in software maintenance. when a defect is reported, appropriate resources must be allocated to analyze and resolve the defect. an important issue in resource allocation is the estimation of defect resolution time (drt). prior research has considered different approaches for drt prediction exploiting information retrieval techniques and similarity in textual defect descriptions. in this article, we investigate the potential of text clustering for drt prediction. we build on a study published by raja (2013) which demonstrated that clusters of similar defect reports had statistically significant differences in drt. raja 's study also suggested that this difference between clusters could be used for drt prediction. our aims are twofold: first, to conceptually replicate raja 's study and to assess the repeatability of its results in different settings; second, to investigate the potential of textual clustering of issue reports for drt prediction with focus on accuracy. using different data sets and a different text mining tool and clustering technique, we first conduct an independent replication of the original study. then we design a fully automated prediction method based on clustering with a simulated test scenario to check the accuracy of our method. the results of our independent replication are comparable to those of the original study and we confirm the initial findings regarding significant differences in drt between clusters of defect reports. however, the simulated test scenario used to assess our prediction method yields poor results in terms of drt prediction accuracy. although our replication confirms the main finding from the original study, our attempt to use text clustering as the basis for drt prediction did not achieve practically useful levels of accuracy.
microcontroller	this work describes the design of two devices for measuring the blood volume changes, in the forearm with a portable device and in the thighs through clothes in seated position. when blood volume arrives to the measurement site from the left ventricle, the electrical properties of the body segment change. these changes, that mainly comprise the electrical impedance of the tissue, are measured through the injection of a safely ac current and the detection of the voltage changes due to blood flow. the signal recorded with such a method is the impedance plethysmogram (ipg). for the portable device, an analog processing converts the ipg waveform to square pulses and a microcontroller performs the on-line estimation of the heart rate. accuracy of the results accomplishes the standards of the association for the advancement of medical instrumentation for heart rate monitors. when measuring the ipg in the thighs through clothes, on the other hand, the main inconvenient are the stray capacitances that modify the waveform of the measured signal. however, with the proper cares, the waveform is good enough to extract the heart rate in the post processing.
relational_databases	this paper presents an analysis of the state of the art solutions for mapping a relational database and an ontology by adding reasoning capabilities and offering the possibility to query the inferred information. we analyzed four approaches: jena with d2rq, jena with r2rml, kaon2 and owl api. in order to highlight the differences between the four approaches, we used a nutrition diagnostics related ontology for the definition of the concepts and of the rules, and a relational database for the storage of the individuals. as performance evaluation, we focused on the time required to map the relational database to the ontology, and the time required to retrieve the information that is inferred about the diagnostics of a number of people. the obtained results show that the best performance in both cases is given by kaon2.
electricity	we study the energy dispatch of power distribution networks (pdns) coupled with urban transportation networks. the electricity demand at each charging/swapping facility is influenced by the arrival rates and charging requests of electric vehicles, which further depends on the spatial distribution of traffic flows over the entire transportation system. we consider the impact of the road congestion on route choices of vehicles from a system-level perspective. the traffic flow pattern in steady state is characterized by the wardrop user equilibrium. we consider the pdn load perturbation caused by the traffic demand uncertainty, and propose a robust dispatch method that maintains the feasibility of an alternating current power flow constraints. by applying the convex relaxation to nonlinear branch power flow equations, the proposed model yields a two-stage robust convex optimization problem with an implicit uncertainty set. moreover, a decomposition framework is proposed, in which the first phase determines the uncertainty set of electricity demand by solving two traffic assignment problems associated with the extreme scenarios, and the second phase solves a two-stage robust second-order cone program following a delayed constraint generation framework. several issues regarding the scalability and conservatism are elaborated. case studies corroborate the applicability and efficiency of the proposed method.
symbolic_computation	by using symbolic computation software(maple), a generalized dirac soliton hierarchy is derived from a new matrix spectral problem associated with the lie algebra sl(2,r). a bi-hamiltonian structure yielding liouville integrability is furnished by the trace identity. (c) 2016 elsevier ltd. all rights reserved.
distributed_computing	crowdsourcing is a new emerging distributed computing and business model on the backdrop of internet blossoming. with the development of crowdsourcing systems, the data size of crowdsourcers, contractors and tasks grows rapidly. the worker quality evaluation based on big data analysis technology has become a critical challenge. this paper first proposes a general worker quality evaluation algorithm that is applied to any critical tasks such as tagging, matching, filtering, categorization and many other emerging applications, without wasting resources. second, we realize the evaluation algorithm in the hadoop platform using the mapreduce parallel programming model. finally, to effectively verify the accuracy and the effectiveness of the algorithm in a wide variety of big data scenarios, we conduct a series of experiments. the experimental results demonstrate that the proposed algorithm is accurate and effective. it has high computing performance and horizontal scalability. and it is suitable for large-scale worker quality evaluations in a big data environment.
bioinformatics	hepatocellular carcinoma (hcca) is a primary malignancy of the liver. many different proteins are involved in hcca including insulin growth factor (igf) ii, signal transducers and activators of transcription (stat) 3, stat4, mothers against decapentaplegic homolog 4 (smad 4), fragile histidine triad (fhit) and selective internal radiation therapy (sirt) etc. the present study is based on the bioinformatics analysis of fhit protein in order to understand the proteomics aspect and improvement of the diagnosis of the disease based on the protein. different information related to protein were gathered from different databases, including national centre for biotechnology information (ncbi) gene, protein and online mendelian inheritance in man (omim) databases, uniprot database, string database and kyoto encyclopedia of genes and genomes (kegg) database. moreover, the structure of the protein and evaluation of the quality of the structure were included from easy modeler programme. hence, this analysis not only helped to gather information related to the protein at one place, but also analysed the structure and quality of the protein to conclude that the protein has a role in carcinoma.
cryptography	in this article, we present a compact implementation of the salsa20 stream cipher that is targeted towards lightweight cryptographic devices such as radio-frequency identification (rfid) tags. the salsa20 stream cipher, ann addition-rotation-xor (arx) cipher, is used for high-security cryptography in neon instruction sets embedded in arm cortex a8 cpu core-based tablets and smartphones. the existing literature shows that although classical cryptanalysis has been effective on reduced rounds of salsa20, the stream cipher is immune to software side-channel attacks such as branch timing and cache timing attacks. to the best of our knowledge, this work is the first to perform hardware power analysis attacks, where we evaluate the resistance of all eight keywords in the proposed compact implementation of salsa20. our technique targets the three subrounds of the first round of the implemented salsa20. the correlation power analysis (cpa) attack has an attack complexity of 2(19). based on extensive experiments on a compact implementation of salsa20, we demonstrate that all these keywords can be recovered within 20,000 queries on salsa20. the attacks show a varying resilience of the key words against cpa that has not yet been observed in any stream or block cipher in the present literature. this makes the architecture of this stream cipher interesting from the side-channel analysis perspective. also, we propose a lightweight countermeasure that mitigates the leakage in the power traces as shown in the results of welch 's t-test statistics. the hardware area overhead of the proposed countermeasure is only 14% and is designed with compact implementation in mind.
computer_programming	this paper addresses the continuing problem in the united states of a lack of female professionals in computer science. the research team conducted surveys of middle school students and working adults to examine their attitudes, motivations, and experience with computer science. based on the survey findings, the researchers are able to evaluate the effects of early, positive exposure to computer programming and give recommendations on how to improve the attitudes and confidence of young girls toward a possible career in computer science.
electrical_circuits	building physical computing projects can enable learners to integrate computing into a range of interests and disciplines. however, the electronic portion of these projects can be difficult. students are learning new concepts as well as how to work with new tools. this influx of information can be difficult for students to retain in their working memory as they construct their circuits. in this paper, we introduce bitblox, a set of modular, solderless breadboards for prototyping circuits. bitblox attempts to decrease the cognitive load on the user by reducing the complexity found in the standard breadboard by bringing visibility to the underlying connections within its modules. we present a comparative classroom study integrating the breadboard and bitblox into two different high school classes. our qualitative analysis focuses on student errors, strategies, and collaborative practices, highlighting important dynamics for designing hardware tools.
microcontroller	this paper presents a new single-phase asymmetrical cascaded multilevel dc-link inverter. the proposed inverter comprises two stages. the main stage of the inverter consists of multiple similar cells, each of which is a half-bridge inverter consisting of two switches and a single dc source. all cells are connected in a cascaded manner with a fixed neutral point. the dc source values are not made equal to increase the performance of the inverter. the second circuit is a folded cascaded h-bridge circuit operating at a line frequency. one of the main advantages of this proposed topology is that it is a modular type and can thus be extended to high stages without changing the configuration of the main stage circuit. two control schemes, namely, low switching with selective harmonic elimination and sinusoidal pulse width modulation, are employed to validate the proposed topology. the detailed approach of each control scheme and switching pulses are discussed in detail. a 150w prototype of the proposed system is implemented in the laboratory to verify the validity of the proposed topology.
pid_controller	this paper presents a flower pollination algorithm (fpa) tuned fuzzy logic controlled (flc) synchronous buck converter (sbc) for an integrated wave/ supercapacitor (sc) hybrid energy system. in order to compensate the irregular wave effects on electrical side of the wave energy converter (wec), a sc unit charged by solar panels is connected in parallel to the wec system and a sbc is controlled to provide more reliable and stable voltage to the dc load. in order to test the performance of the designed flc, a classical proportional-integral-derivative (pid) controller is also employed. both of the controllers are optimized by fpa which is a pretty new optimization algorithm and a well-known optimization algorithm of which particle swarm optimization (pso) to minimize the integral of time weighted absolute error (itae) performance index. also, the other error-based objective functions are considered. the entire energy system and controllers are developed in matlab/simulink and realized experimentally. real time applications are done through ds1104 controller board. the simulation and experimental results show that fpa tuned fuzzy logic controller provides lower value performance indices than conventional pid controller by reducing output voltage sags and swells of the wave/sc energy system. index terms-fuzzy
computer_graphics	objective visual quality assessment of 3d models is a fundamental issue in computer graphics. quality assessment metrics may allow a wide range of processes to be guided and evaluated, such as level of detail creation, compression, filtering, and so on. most computer graphics assets are composed of geometric surfaces on which several texture images can be mapped to make the rendering more realistic. while some quality assessment metrics exist for geometric surfaces, almost no research has been conducted on the evaluation of texture-mapped 3d models. in this context, we present a new subjective study to evaluate the perceptual quality of textured meshes, based on a paired comparison protocol. we introduce both texture and geometry distortions on a set of 5 reference models to produce a database of 136 distorted models, evaluated using two rendering protocols. based on analysis of the results, we propose two new metrics for visual quality assessment of textured mesh, as optimized linear combinations of accurate geometry and texture quality measurements. these proposed perceptual metrics outperform their counterparts in terms of correlation with human opinion. the database, along with the associated subjective scores, will be made publicly available online.
distributed_computing	most distributed computing applications require an effective scheduling algorithm to distribute and assign client 's tasks running on a set of processors. the existing algorithms assumed that the scheduled tasks can be simultaneously and ideally sent and received from the processors without any latent delay. however, this assumption is obviously impractical and unrealizable due to lack of consideration for constraints caused by the limited number of existing i/o ports at the client site. such an i/o port constraint confines the overall throughputs of the computing systems. this study investigates the theoretical scheduling patterns under the constraint of one i/o port which typically exists to achieve optimal makespan and latent delay. a heuristic algorithm to effectively schedule the given set of tasks is also proposed. two primary scheduling patterns leading to the optimal makespan and delay are discovered. performance of the proposed scheduling is better than other scheduling algorithms under the imposed constraints in terms of shorter makespan and less latent delay, in particular, the average time complexity is equal to o(n(2)). (c) 2016 elsevier b.v. all rights reserved.
relational_databases	many studies on reverse skyline query processing have been done for various services. the existing reverse skyline query processing methods are based on dynamic skylines. there are no reverse skyline query processing algorithms based on metric spaces for location-based services. the existing methods for processing a reverse skyline query have the limitation of service domains and require the high costs of computation to provide various location-based services. in this paper, we propose a new reverse skyline query processing method that efficiently processes a query over the moving objects. in addition, the proposed method processes a continuous reverse skyline query efficiently. in order to show the superiority of the proposed method, we compare it with the previous reverse skyline query processing method in various environments. as a result, the proposed method achieves better performance than the existing method. (c) 2015 elsevier b.v. all rights reserved.
operational_amplifier	hydrochloric acid doped thin film of poly-o-methyl aniline (pomani)-mn3o4 nanocomposites have been fabricated on glass substrate. the nanocomposite films showed rt-ntc characteristics in the temperature range of 35-185 degrees c with repeatability in the temperature range of 75-185 degrees c. the cut off temperature of the thermistor fabricated from the nanocomposite material was found to be between 165 and 170 degrees c. synthesised nanocomposite material has been characterized using ft-ir, xrd, tem for structure, morphology and tga/dtc for thermal stability. thermistor constant (beta) observed from rt characteristics are in the range of 7363 k-10,188 k and activation energy (delta e) was calculated which was in the range 0.634 ev-0.878 ev. further linearization of thin film based ntc thermistors was carried out using an low cost analog circuit by adding parallel (r-p), series resistance (r-s) and operational amplifier (op-amp). it has been observed that these thin film based temperature sensors have repeatable temperature sensing behavior on linearization with high sensitivity and low power dissipation (p-diss)2015 (c) elsevier b.v. all rights reserved.
bioinformatics	background: many plant pathogen secretory proteins are known to be elicitors or pathogenic factors, which play an important role in the host-pathogen interaction process. bioinformatics approaches make possible the large scale prediction and analysis of secretory proteins from the puccinia helianthi transcriptome. the internet-based software signalp v4.1, targetp v1.01, big-pi predictor, tmhmm v2.0 and protcomp v9.0 were utilized to predict the signal peptides and the signal peptide-dependent secreted proteins among the 35,286 orfs of the p. helianthi transcriptome. results: 908 orfs (accounting for 2.6% of the total proteins) were identified as putative secretory proteins containing signal peptides. the length of the majority of proteins ranged from 51 to 300 amino acids (aa), while the signal peptides were from 18 to 20 aa long. signal peptidase i (spi) cleavage sites were found in 463 of these putative secretory signal peptides. 55 proteins contained the lipoprotein signal peptide recognition site of signal peptidase ii (spii). out of 908 secretory proteins, 581 (63.8%) have functions related to signal recognition and transduction, metabolism, transport and catabolism. additionally, 143 putative secretory proteins were categorized into 27 functional groups based on gene ontology terms, including 14 groups in biological process, seven in cellular component, and six in molecular function. gene ontology analysis of the secretory proteins revealed an enrichment of hydrolase activity. pathway associations were established for 82 (9.0%) secretory proteins. a number of cell wall degrading enzymes and three homologous proteins specific to phytophthora sojae effectors were also identified, which may be involved in the pathogenicity of the sunflower rust pathogen. conclusions: this investigation proposes a new approach for identifying elicitors and pathogenic factors. the eventual identification and characterization of 908 extracellularly secreted proteins will advance our understanding of the molecular mechanisms of interactions between sunflower and rust pathogen and will enhance our ability to intervene in disease states.
electric_motor	this paper presents a design method of flux-switching permanent magnet machine to reduce acoustic noise and mechanical vibration. a main source of noise and vibration in electric motor is radial magnetic force. mechanical vibrations are generated by electromagnetic interference between harmonic components of radial magnetic force and mechanical resonance frequencies of structures of the motor. then, the motor design has to be considered to reduce the amplitude of radial magnetic force harmonic. the radial magnetic force is calculated by finite element method and maxwell stress tensor. the harmonic components of radial magnetic force are examined by fourier decomposition.
distributed_computing	allocating tasks to processors is a well-known np-hard problem in distributed computing systems. due to the lack of practicable exact solutions, it has been attracted by the researchers working on heuristic based suboptimal search algorithms. with the recent inclusion of multiple objectives such as minimizing the cost, maximizing, the throughput and maximizing the reliability, the problem gets even more complex and an efficient approximate method becomes more valuable. in this work, i propose a new solution for the multi-objective task allocation problem. my solution consists in designing a problem-specific neighboring function for an existing metaheuristic algorithm that is proven to be successful in quadratic assignment problems. the neighboring function, namely greedy reassignment with maximum release (gr-mr), provides a dynamic mechanism to switch the preference of the search between the exploration and exploitation. the experiments validate both that the quality of the solutions are close to the optimal and the proposed method performs significantly better comparing to three other metaheuristic algorithms. neighboring functions being the common reusable components of metaheuristic algorithms, gr-mr can also be utilized by other metaheuristic-based solutions in the future. (c) 2016 elsevier ltd. all rights reserved.
computer_programming	this article reports on the development of two courses designed for students in higher education game development programs during the period of 2006 to 2015. the students are from three different arts and design-related strands of the program, and had in common that very few had taken advanced science classes as part of their upper-secondary education. this meant that they were rather poorly equipped to learn programming, mathematics and physics, which they needed to master in order to understand the basics of game development. consequently, the courses was designed in a way that allowed the students to practically engage in creating a computer games alongside being taught the actual science they needed in order to efficiently utilize those skills. a working hypothesis for the project was that if the responsible teachers were able to run the course in a way that cohered with the principles of problem-based learning, this would create an environment which would enhance the students' motivation to learn basic science as well as the operative and innovation skills needed for fulfilling the course requirements. in addition, ideas developed within the field of situated and experiential learning constituted theoretical points of departure for developing the course. the article describes the practical and theoretical points of departure for developing the courses and reflects on the experiences made from running it. summing up, the authors conclude that the why and how of teaching needs to be in line with students' worlds in order for educational experiences to be considered as meaningful.
electric_motor	this paper presents a new design of an electronic fixed calliper-based wedge brake system. the movement of both sides of the brake piston is activated by a wedge block mechanism. the proposed fixed calliper-based electronic wedge brake system is a class of hydraulic-free device. the mechanism consists of two sets of wedge blocks, a ball screw drive shaft, a sliding beam and an electric motor. in this mechanism, the rotation of the shaft of the electric motor is converted into linear motion by using a ball screw drive shaft while the linear motion of the drive shaft will force the sliding beam to be displaced linearly. this will activate the wedge mechanism, which will cause the pad to be displaced tangentially to the disc brake. the movement of the pad in pressing the disc will generate clamping force and produce brake torque when the wheel rotates. in this study, the mathematical model of the system that generates the clamping force was identified. the model was based on a second order transfer function. the proposed mathematical model was then validated experimentally using a brake test rig installed with several sensors and input-output (10) device. the performance of the brake mechanism in term of rotational input of the drive shaft and clamping force produced by the brake were observed. accordingly, a torque tracking proportional-integral-derivative (pid) control of the system was proposed and studied through simulation and experiment. comparisons between experimental results and model responses were made. it is found that the trend between simulation results and experimental data are similar, with an acceptable level of error.
operational_amplifier	a receiver front-end supporting contiguous and non-contiguous intra-band carrier aggregation scenarios with a fully integrated spectrum sensor that can detect both in-gap and out-of-band blockers has been implemented in 65nm cmos technology. an nf of 2.5db is achieved using a noise canceling lnta, and linearized otas are used to achieve an iip3 improvement of up to 6.5db in-band and 11db at the filter band edge. the spectrum sensor can detect blocker levels in 22 steps of 9mhz between -100mhz and 100mhz if. the system consumes between 36.6ma and 57.6ma from a 1.2v supply.
electricity	large-scale deployment of renewable energy sources (res) plays a central role in reducing co2 emissions from energy supply systems, but intermittency from solar and wind technologies presents integration challenges. high temperature co-electrolysis of steam and co2 in power-to-gas (ptg) and power-to-liquid (ptl) configurations could utilize excess intermittent electricity by converting it into chemical fuels. these can then be directly consumed in other sectors, such as transportation and heating, or used as power storage. here, we investigate the impact of carbon policy and fossil fuel prices on the economic and engineering potential of ptg and ptl systems as storage for intermittent renewable electricity and as a source of low-carbon heating and transportation energy in the alpine region. we employ a spatially and temporally explicit optimization approach of res, ptg, ptl and fossil technologies in the electricity, heating, and transportation sectors, using the bewhere model. results indicate that large-scale deployment of ptg and ptl technologies for producing chemical fuels from excess intermittent electricity is feasible, particularly when incentivized by carbon prices. depending on carbon and fossil fuel price, 0.15-15 million tonnes/year of captured co2 can be used in the synthesis of the chemical fuels, displacing up to 11% of current fossil fuel use in transportation. by providing a physical link between the electricity, transportation, and heating sectors, ptg and ptl technologies can enable greater integration of res into the energy supply chain globally. (c) 2017 elsevier ltd. all rights reserved.
data_structures	in this paper we show how to construct a data structure for a string s of size n compressed into a context-free grammar of size n that supports efficient karp-rabin fingerprint queries to any substring of s. that is, given indices i and j, the answer to a query is the fingerprint of the substring s[i, j]. we present the first o(n) space data structures that answer fingerprint queries without decompressing any characters. for straight line programs (slp) we get o(log n) query time, and for linear slps (an slp derivative that captures lz78 compression and its variations) we get o(log log n) query time. we extend the result to solve the longest common extension problem in query time o(log n log l) and o(log l log log l + log log n) for slps and linear slps, respectively. here, l denotes the length of the lce. (c) 2017 elsevier inc. all rights reserved.
symbolic_computation	with the help of the symbolic computation system, maple and riccati equation (xi ' = a(0) + a(1)xi + a(2)xi(2)), expansion method, and a linear variable separation approach, a new family of exact solutions with q = lx + my + nt + gamma (x, y, t) for the (2+1)-dimensional generalized calogero-bogoyavlenskii-schiff system (gcbs) are derived. based on the derived solitary wave solution, some novel localized excitations such as fusion, fission, and annihilation of complex waves are investigated.
image_processing	we discuss two semi-independent calibration techniques used to determine the inflight radiometric calibration for the new horizons' multi-spectral visible imaging camera (mvic). the first calibration technique compares the measured number of counts (dn) observed from a number of well calibrated stars to those predicted using the component-level calibration. the ratio of these values provides a multiplicative factor that allows a conversation between the preflight calibration to the more accurate inflight one, for each detector. the second calibration technique is a channel-wise relative radiometric calibration for mvic 's blue, near-infrared and methane color channels using hubble and new horizons observations of charon and scaling from the red channel stellar calibration. both calibration techniques produce very similar results (better than 7% agreement), providing strong validation for the techniques used. since the stellar calibration described here can be performed without a color target in the field of view and covers all of mvic 's detectors, this calibration was used to provide the radiometric keyword values delivered by the new horizons project to the planetary data system (pds). these keyword values allow each observation to be converted from counts to physical units; a description of how these keyword values were generated is included. finally, mitigation techniques adopted for the gain drift observed in the near-infrared detector and one of the panchromatic framing cameras are also discussed. (c) 2016 elsevier inc. all rights reserved.
network_security	the fast retrieval in archival traffic data is essential for network security and forensic analysis. a bitmap index is a data structure enabling fast search over large data collections in a limited time, but the space consumption is always a problem. wah, plwah and compax are proposed for compressing bitmap indexes for less storage. in this paper, a new bitmap index encoding scheme, named masc, is proposed to further improve the compression ratio without impairing the query performance. instead of being limited to a fixed length (31 bits) in plwah and compax, the stride size can be as long as possible to encode consecutive zero bits and nonzero bits in a more compact way. instead of piggyback used in plwah, a new structure in masc called carrier is introduced as piggyback in plwah only carries an individual nonzero bit. we also generalize the traditional literal word concept in plwah and compax. the validity of masc encoding scheme is demonstrated with the application in internet traffic archival system. based on experiments with real internet traffic data set from caida, masc has a better compression ratio than plwah and compax2 without the penalty in query performance.
electric_motor	in the last decades, wearable powered orthoses have been introduced in the state of the art for lower-limb rehabilitation. most of these applications are driven by electric motors. comparing with electric motor actuators, pneumatic artificial muscle (pam) actuators are compliant because of the elasticity of pams. consequently, for more safety and comfort of lower-limb rehabilitation, a compliant robotic orthosis powered by pams is developed. based on safe control, a new control method, proxy-based sliding mode control (psmc), was introduced into rehabilitation robotics a few years ago. it combined safety and accuracy of tracking to make it suitable for the safe control of pam actuators. as the reason of low frequency response of pam actuators and variable loads caused by different human subjects, the fixed parameters of psmc makes the tracking performance vary from subject to subject, and lacks robustness. this paper presents a modification of psmc by using neural network to tune psmc gains online, and implements both psmc and modified psmc control schemes in the robotic orthosis. experimental results demonstrate that the improved psmc method performs better on tracking with little degradation on safety for different loads and human subjects.
operating_systems	we present bill2d, a modern and efficient c++ package for classical simulations of two-dimensional hamiltonian systems. bill2d can be used for various billiard and diffusion problems with one or more charged particles with interactions, different external potentials, an external magnetic field, periodic and open boundaries, etc. the software package can also calculate many key quantities in complex systems such as poincare sections, survival probabilities, and diffusion coefficients. while aiming at a large class of applicable systems, the code also strives for ease-of-use, efficiency, and modularity for the implementation of additional features. the package comes along with a user guide, a developer 's manual, and a documentation of the application program interface (api). program summary program title: bill2d catalogue identifier: aeylv1_0 program summary url: http://cpc.cs.qub.ac.uk/summaries/aeylv1_0.html program obtainable from: cpc program library, queen 's university, belfast, n. ireland licensing provisions: gnu general public license, version 3 no. of lines in distributed program, including test data, etc.: 37098 no. of bytes in distributed program, including test data, etc.: 1155037 distribution format: tar.gz programming language: c++(14). computer: tested on x86 and x86 64 architectures. operating systems: tested on linux, and os x versions 10.9-10.11. has the code been vectorized or parallelized?: shared memory parallelization when simulating ensembles of systems. vectorization of operations with r-2 vectors. ram: simulation dependent: kilobytes to gigabytes classification: 4.3, 7.8, 7.9, 7.10, 16.9. external routines: boost, cmake, gsl, hdf5; and optionally google-mock, googletest, and doxygen nature of problem: numerical propagation of classical two-dimensional single and many-body systems, possibly in a magnetic field, and calculation of relevant quantities such as poincare sections, survival probabilities, diffusion co-efficients, etc. solution method: symplectic numerical integration of hamilton 's equations of motion in cartesian coordinates, or solution of newton 's equations of motion if in a magnetic field. the program implements several well-established algorithms. restrictions: pointlike particles with equal masses and charges, although the latter restrictions are easy to lift. unusual features: program is efficient, extremely modular and easy to extend, and allows arbitrary particle-particle interactions. additional comments: the source code is also available at https://bitbucicet.orgisolanpaa/bill2d. see readme for locations of user guide, developer manual, and api docs. running time: from milliseconds to days, depends on type of simulation. (c) 2015 elsevier b.v. all rights reserved.
symbolic_computation	in this paper, with the aid of symbolic computation, we investigate the generalized nonlinear schrodinger maxwell-bloch equation, which describes the propagation of the optical soliton through an inhomogeneous two-level dielectric tapered fiber medium. by virtue of the darboux transformation method, two-soliton solutions are generated based on the constructed lax pair and figures are plotted to illustrate the properties of the obtained solutions. moreover, through manipulating the dispersion and nonlinearity profiles, various soliton control systems are investigated which is promising for potential applications in the design of soliton compressor, soliton amplification and highspeed optical devices in ultralarge capacity transmission systems. this means that we are able to control the soliton types with suitably selected values of the parameters. additionally more soliton control techniques are proposed and investigated. we expect that the above analysis could be observed in future experiments.
structured_storage	the aim of the chemotherapeutic regimens (chr) digitalization project is the proposal of a universal structure and creation of a publicly accessible database of contemporary chr as a universal utility for the communication and evaluation of contemporary and newly defined clinical schedules in anti-tumor chemotherapy. after analysis of contemporary anti tumor chr a standard xml structure was proposed, which enables the recording of simple chr from the field of chemotherapy in solid adult tumors, and also has the potential of recording the complex treatment protocols in the field of paediatric oncology. the resulting xml documents were saved on a web server. a publicly accessible chr database was constructed. there were a total of 130 xml documents with definitions of individual chr in the first phase. linked to this data store, three examples of web applications were added to demonstrate the potential uses of this newly created database.
pid_controller	in this paper, a decoupled proportional- integral- derivative (pid) control approach for seismic control of smart structures is presented. first, the state space equation of a structure is transformed into modal coordinates and parameters of the modal pid control are separately designed in a reduced modal space. then, the feedback gain matrix of the controller is obtained based on the contribution of modal responses to the structural responses. the performance of the controller is investigated to adjust control force of piezoelectric friction dampers (pfds) in a benchmark base isolated building. in order to tune the modal feedback gain of the controller, a suitable trade-off among the conflicting objectives, i.e., the reduction of maximum modal base displacement and the maximum modal floor acceleration of the smart base isolated structure, as well as the maximum modal control force, is created using a multi-objective cuckoo search (mocs) algorithm. in terms of reduction of maximum base displacement and story acceleration, numerical simulations show that the proposed method performs better than other reported controllers in the literature. moreover, simulation results show that the pfds are able to efficiently dissipate the input excitation energy and reduce the damage energy of the structure. overall, the proposed control strategy provides a simple strategy to tune the control forces and reduces the number of sensors of the control system to the number of controlled stories.
computer_graphics	given a graph g that admits a perfect matching, we investigate the parameter eta(g) (originally motivated by computer graphics applications) which is defined as follows. among all nonnegative edge weight assignments, eta(g) is the minimum ratio between (i) the maximum weight of a perfect matching and (ii) the maximum weight of a general matching. in this paper, we determine the exact value of eta for all rectangular grids, all bipartite cylindrical grids, and all bipartite toroidal grids. we introduce several new techniques to this endeavor. (c) 2016 elsevier b.v. all rights reserved.
computer_programming	braille-character recognition is one of the foundational skills required for teachers of braille. prior research has evaluated computer programming for teaching braille-to-print letter relations (e.g., scheithauer & tiger, 2012). in the current study, we developed a program (the visual braille trainer) to teach not only letters but also numerals, punctuation, symbols, and contractions; we evaluated this program with 4 sighted undergraduate participants. exposure to this program resulted in mastery of all braille-to-print relations for each participant.
data_structures	we present a language-independent verification framework that can be instantiated with an operational semantics to automatically generate a program verifier. the framework treats both the operational semantics and the program correctness specifications as reachability rules between matching logic patterns, and uses the sound and relatively complete reachability logic proof system to prove the specifications using the semantics. we instantiate the framework with the semantics of one academic language, kernelc, as well as with three recent semantics of real-world languages, c, java, and javascript, developed independently of our verification infrastructure. we evaluate our approach empirically and show that the generated program verifiers can check automatically the full functional correctness of challenging heap-manipulating programs implementing operations on list and tree data structures, like avl trees. this is the first approach that can turn the operational semantics of real-world languages into correct-by-construction automatic verifiers.
parallel_computing	the theory of three-way decisions is to consider a decision-making problem as a ternary classification one which is realized by the acceptance, rejection and non-commitment. recently, this theory has been integrated with formal concept analysis in two different ways: constructive and axiomatic methods. the constructive method is to define certain three-way concepts in a formal context to support three-way concept analysis, while the axiomatic one is to characterize general three-way concepts by axioms so as to perform three-way concept learning. nevertheless, there are similarities between the constructive and the axiomatic methods. in fact, both three-way concept analysis induced by the constructive method and three-way concept learning induced by the axiomatic one are realized by incorporating the idea of ternary classification into the design of extent or intent of a concept. however, their information fusion abilities need to be improved since neither of them is able to deal with large or multi-source data effectively. motivated by this problem, our paper is to reconsider three-way concept learning based on cognitive operators from the perspective of information fusion. that is, the parallel computing techniques of learning three-way concepts are developed for large and multi-source data. specifically, for large data, the relationship between the global granular concept and the local ones is first clarified, and then it is employed to design an information fusion algorithm. for multi-source data, the whole evaluation function used to induce three-way decisions is established by aggregating the results obtained in each single-source data, and three-way concept learning is made by constructing lower and upper approximation concepts. finally, we conduct some numerical experiments to evaluate the effectiveness of the proposed parallel computing algorithms. (c) 2017 elsevier inc. all rights reserved.
bioinformatics	objectives: the aim of this work was to construct inverpep, a database specialised in experimentally validated antimicrobial peptides (amps) from invertebrates. methods: amp data contained in inverpep were manually curated from other databases and the scientific literature. mysql was integrated with the development platform laravel; this framework allows to integrate programming in php with html and was used to design the inverpep web page 's interface. inverpep contains 18 separated fields, including inverpep code, phylum and species source, peptide name, sequence, peptide length, secondary structure, molar mass, charge, isoelectric point, hydrophobicity, boman index, aliphatic index and percentage of hydrophobic amino acids. calcampi, an algorithm to calculate the physicochemical properties of multiple peptides simultaneously, was programmed in perl language. results: to date, inverpep contains 702 experimentally validated amps from invertebrate species. all of the peptides contain information associated with their source, physicochemical properties, secondary structure, biological activity and links to external literature. most amps in inverpep have a length between 10 and 50 amino acids, a positive charge, a boman index between 0 and 2 kcal/mol, and 30-50% hydrophobic amino acids. inverpep includes 33 amps not reported in other databases. besides, calcampi and statistical analysis of inverpep data is presented. the inverpep database is available in english and spanish. conclusions: inverpep is a useful database to study invertebrate amps and its information could be used for the design of new peptides. the user-friendly interface of inverpep and its information can be freely accessed via a web-based browser at http://ciencias.medellin.unal.edu.co/gruposdeinvestigacion/prospeccionydisenobiomoleculas/inverpep/public/home_en. (c) 2016 international society for chemotherapy of infection and cancer. published by elsevier ltd. all rights reserved.
computer_graphics	terrain data can be processed from the double perspective of computer graphics and graph theory. we propose a hybrid method that uses geometrical and vertex attribute information to construct a weighted graph reflecting the variability of the vertex data. as a planar graph, a generic terrain data set is subjected to a geometry-sensitive vertex partitioning procedure. through the use of a combined, thin-plate energy and multi-dimensional quadric metric error, feature estimation heuristic, we construct even' and odd' node subsets. using an invertible lifting scheme, adapted from generic weighted graphs, detail vectors are extracted and used to recover or filter the node information. the design of the prediction and update filters improves the root mean squared error of the signal over general graph-based approaches. as a key property of this design, preserving the mean of the graph signal becomes essential for decreasing the error measure and conserving the salient shape features.
digital_control	the interleaved multilevel dc-dc converters have advantages of low voltage stress of the switches and diodes and reduction of filter size. particularly series input parallel output (isop) configuration is well suited for high output voltage and large output current application but input series output series (isos) configuration enable the utilization of low voltage rating switches in high voltage input and high voltage output applications that require galvanic isolation. the series connection of the isolated dc-dc converters at the input side also can be used for higher voltage application. while multilevel topology offers many new features, it also necessitates a balance control of the input capacitors. the paper describes the operating principles of the balancing circuit, analyzes the fundamental relationships, introduces principles of the operation of the circuit. the paper shows experimental results based on a few practical application examples. the paper discusses design of the transformer with balancing winding for isop, isos and parallel connection of the dc-dc converters to provide independent voltage balancing of input capacitors.
lorentz_force_law	when a strong on-board magnet is moved relative to a conducting sheet, a circulating eddy current will be induced in the conductor. the eddy current in turn produces a magnetic field, which by lorentz force law, produces repulsive forces between the two magnetic fields. an experimental study on the electrodynamic suspension system was carried with a 1.5 m diameter rotary type test wheel. two types of on board magnets are tested. one is a htsc magnet and the other one is a halbach-arrayed permanent magnet. the lorentz forces of the two eds systems are measured and compared with theoretical and numerical calculations.
computer_vision	the accurate location of eyes in a facial image is important to many human facial recognition-related applications, and has attracted considerable research interest in computer vision. however, most prevalent methods are based on the frontal pose of the face, where applying them to non-frontal poses can yield erroneous results. in this paper, we propose an eye detection method that can locate the eyes in facial images captured at various head poses. our proposed method consists of two stages: eye candidate detection and eye candidate verification. in eye candidate detection, eye candidates are obtained by using multi-scale iris shape features and integral image. the size of the iris in face images varies as the head pose changes, and the proposed multi-scale iris shape feature method can detect the eyes in such cases. since it utilizes the integral image, its computational cost is relatively low. the extracted eye candidates are then verified in the eye candidate verification stage using a support vector machine (svm) based on the feature-level fusion of a histogram of oriented gradients (hog) and cell mean intensity features. we tested the performance of the proposed method using the chinese academy of sciences' pose, expression, accessories, and lighting (cas-peal) database and the pointing'04 database. the results confirmed the superiority of our method over the conventional haar-like detector and two hybrid eye detectors under relatively extreme head pose variations. (c) 2016 elsevier b.v. all rights reserved.
structured_storage	successful, quality software projects need to be able to rely on a sufficient level of security in order to manage the technical, legal and business risks that arise from distributed development. the definition of a 'sufficient' level of security however, is typically only captured in implicit requirements that are rarely gathered in a methodological way. such an unstructured approach makes the work of quality managers incredibly difficult and often forces developers to unwillingly operate in an unclear/undefined security state throughout the project. ideally, security requirements are elicited in methodological manner enabling a structured storage. retrieval, or checking of requirements. in this paper we report on the experiences of applying a structured requirements elicitation method and list a set of gathered reference security requirements. the reported experiences were gathered in an industrial setting using the open source platform opencit in cooperation with industry partners. the output of this work enables security and quality conscious stakeholders in a software project to draw from our experiences and evaluate against a reference base line.
machine_learning	muts alpha is a key component in the mismatch repair (mmr) pathway. this protein is responsible for initiating the signaling pathways for dna repair or cell death. herein we investigate this heterodimer 's post-recognition, post-binding response to three types of dna damage involving cytotoxic, anti-cancer agents-carboplatin, cisplatin, and fdu. through a combination of supervised and unsupervised machine learning techniques along with more traditional structural and kinetic analysis applied to all-atom molecular dynamics (md) calculations, we predict that muts alpha has a distinct response to each of the three damage types. via a binary classification tree (a supervised machine learning technique), we identify key hydrogen bond motifs unique to each type of damage and suggest residues for experimental mutation studies. through a combination of a recently developed clustering (unsupervised learning) algorithm, rmsf calculations, pca, and correlated motions we predict that each type of damage causes mutsa to explore a specific region of conformation space. detailed analysis suggests a short range effect for carboplatin-primarily altering the structures and kinetics of residues within 10 angstroms of the damaged dna-and distinct longer-range effects for cisplatin and fdu. in our simulations, we also observe that a key phenylalanine residue-known to stack with a mismatched or unmatched bases in mmr-stacks with the base complementary to the damaged base in 88.61% of md frames containing carboplatinated dna. similarly, this phe71 stacks with the base complementary to damage in 91.73% of frames with cisplatinated dna. this residue, however, stacks with the damaged base itself in 62.18% of trajectory frames with fdu-substituted dna and has no stacking interaction at all in 30.72% of these frames. each drug investigated here induces a unique perturbation in the mutsa complex, indicating the possibility of a distinct signaling event and specific repair or death pathway (or set of pathways) for a given type of damage.
computer_vision	the study aimed to determine if computer vision techniques rooted in deep learning can use a small set of radiographs to perform clinically relevant image classification with high fidelity. one thousand eight hundred eighty-five chest radiographs on 909 patients obtained between january 2013 and july 2015 at our institution were retrieved and anonymized. the source images were manually annotated as frontal or lateral and randomly divided into training, validation, and test sets. training and validation sets were augmented to over 150,000 images using standard image manipulations. we then pre-trained a series of deep convolutional networks based on the open-source googlenet with various transformations of the open-source imagenet (non-radiology) images. these trained networks were then fine-tuned using the original and augmented radiology images. the model with highest validation accuracy was applied to our institutional test set and a publicly available set. accuracy was assessed by using the youden index to set a binary cutoff for frontal or lateral classification. this retrospective study was irb approved prior to initiation. a network pre-trained on 1.2 million greyscale imagenet images and fine-tuned on augmented radiographs was chosen. the binary classification method correctly classified 100 % (95 % ci 99.73-100 %) of both our test set and the publicly available images. classification was rapid, at 38 images per second. a deep convolutional neural network created using non-radiological images, and an augmented set of radiographs is effective in highly accurate classification of chest radiograph view type and is a feasible, rapid method for high-throughput annotation.
relational_databases	data-related businesses is an emerging trend in the recent decade. however, the availability and amount of information make it difficult to ensure quality in terms of data fusion and version control. completely automated data aggregation systems fail to provide reliable and consistent data. in this paper we summarise existing knowledge on relation databases and augment it with description of business requirements for data version control. we propose an architecture that addresses the requirements, and discuss possible future work to improve and evaluate the approach.
algorithm_design	data access delay has become the prominent performance bottleneck of high-end computing systems. the key to reducing data access delay in system design is to diminish data stall time. memory locality and concurrency are the two essential factors influencing the performance of modern memory systems. however, existing studies in reducing data stall time rarely focus on utilizing data access concurrency because the impact of memory concurrency on overall memory system performance is not well understood. in this study, a pair of novel data stall time models, the l-c model for the combined effort of locality and concurrency and the p-m model for the effect of pure miss on data stall time, are presented. the models provide a new understanding of data access delay and provide new directions for performance optimization. based on these new models, a summary table of advanced cache optimizations is presented. it has 38 entries contributed by data concurrency while only has 21 entries contributed by data locality, which shows the value of data concurrency. the l-c and p-m models and their associated results and opportunities introduced in this study are important and necessary for future data-centric architecture and algorithm design of modern computing systems.
parallel_computing	in the supervised classification, large training data are very common, and decision trees are widely used. however, as some bottlenecks such as memory restrictions, time complexity, or data complexity, many supervised classifiers including classical c4.5 tree cannot directly handle big data. one solution for this problem is to design a highly parallelized learning algorithm. motivated by this, we propose a parallelized c4.5 decision tree algorithm based on mapreduce (mr-c4.5-tree) with 2 parallelized methods to build the tree nodes. first, an information entropy-based parallelized attribute selection method (mr-a-s) on several subsets for mr-c4.5-tree is proposed to confirm the best splitting attribute and the cut points. then, a data splitting method (mr-d-s) in parallel is presented to partition the training data into subsets. at last, we introduce the mr-c4.5-tree learning algorithm that grows in a top-down recursive way. besides, the depth of the constructed decision tree, the number of samples and the maximal class probability in each tree node are used as the termination conditions to avoid the over-partitioning problem. experimental studies show the feasibility and the good performance of the proposed parallelized mr-c4.5-tree algorithm.
data_structures	path polymorphism is the ability to define functions that can operate uniformly over arbitrary recursively specified data structures. its essence is captured by patterns of the form xy which decompose a compound data structure into its parts. typing these kinds of patterns is challenging since the type of a compound should determine the type of its components. we propose a static type system (i.e. no run-time analysis) for a pattern calculus that captures this feature. our solution combines type application, constants as types, union types and recursive types. we address the fundamental properties of subject reduction and progress that guarantee a well-behaved dynamics. both these results rely crucially on a notion of pattern compatibility and also on a coinductive characterisation of subtyping.
state_space_representation	the daily return and the realized volatility are simultaneously modeled in the stochastic volatility model with leverage and long memory. the dependent variable in the stochastic volatility model is the logarithm of the squared return, and its error distribution is approximated by a mixture of normals. in addition, the logarithm of the realized volatility is incorporated into the measurement equation, assuming that the latent log volatility follows an autoregressive fractionally integrated moving average (arfima) process to describe its long memory property. the efficient bayesian estimation method using markov chain monte carlo method (mcmc) was proposed and implemented in the state space representation. model comparisons are performed based on the marginal likelihood, and the volatility forecasting performances are investigated using s&p500 stock index returns. (c) 2013 elsevier b.v. all rights reserved.
bioinformatics	this is the first report on a myophage that infects arthrobacter. a novel virus, vb_artm-arv1 (arv1), was isolated from soil using arthrobacter sp. strain 68b for phage propagation. transmission electron microscopy showed its resemblance to members of the family myoviridae: arv1 has an isometric head (similar to 74 nm in diameter) and a contractile, nonflexible tail (similar to 192 nm). phylogenetic and comparative sequence analyses, however, revealed that arv1 has more genes in common with phages from the family siphoviridae than it does with any myovirus characterized to date. the genome of arv1 is a linear, circularly permuted, double-stranded dna molecule (71,200 bp) with a gc content of 61.6%. the genome includes 101 open reading frames (orfs) yet contains no trna genes. more than 50% of arv1 genes encode unique proteins that either have no reliable identity to database entries or have homologues only in arthrobacter phages, both sipho- and myoviruses. using bioinformatics approaches, 13 arv1 structural genes were identified, including those coding for head, tail, tail fiber, and baseplate proteins. a further 6 arv1 orfs were annotated as encoding putative structural proteins based on the results of proteomic analysis. phylogenetic analysis based on the alignment of four conserved virion proteins revealed that arthrobacter myophages form a discrete clade that seems to occupy a position somewhat intermediate between myo-and siphoviruses. thus, the data presented here will help to advance our understanding of genetic diversity and evolution of phages that constitute the order caudovirales. importance bacteriophages, which likely originated in the early precambrian era, represent the most numerous population on the planet. approximately 95% of known phages are tailed viruses that comprise three families: podoviridae (with short tails), siphoviridae (with long noncontractile tails), and myoviridae (with contractile tails). based on the current hypothesis, myophages, which may have evolved from siphophages, are thought to have first emerged among gram-negative bacteria, whereas they emerged only later among gram-positive bacteria. the results of the molecular characterization of myophage vb_artm-arv1 presented here conform to the aforementioned hypothesis, since, at a glance, bacteriophage vb_artm-arv1 appears to be a siphovirus that possesses a seemingly functional contractile tail. our work demonstrates that such ""chimeric"" myophages are of cosmopolitan nature and are likely characteristic of the ecologically important soil bacterial genus arthrobacter.
signal-flow_graph	in this paper certain properties of algorithms used in symbolic manipulation on signal flow graphs are investigated. the rule-based approach and mason 's formula are compared with respect to preservation of minimal rational representation. it is shown by counter example that rule-based method does not possess this property if factor cancellations are allowed at elementary operation level only. a new efficient algorithm is proposed in which this problem is resolved.
control_engineering	one of the effect measures of improving water flow fluidity and solving city water pollution is water diversion from outside of an urban area. because of the different boundary condition, quantity of flow distribution and velocity is different for every river. the velocity of some river channels is even much smaller. in order to enhance the fluidity of those weak rivers with small velocity, to set up a series of sluice gates and to control gates by closing and opening in some need. thus water quantity is redistributed and the velocity is increased. for the need of investigating the effect of setting up and closing the gates, 2d unsteady river networks flow finite element model is established and verified. bases on the model, the velocity size and orientation of the every river and water levels are calculated at the condition of whether setting up gates. these numerical researches show that the water flow quantity and velocity of flow distribution are both increased significantly for the near of river. the maximum velocity increment 0.23 m/s, the maximum banked up water level is 0.014 m, the maximum water lowering is 0.05 m, this engineering effect is obvious and this provided quantity data for the projects plan and design.
control_engineering	the present paper considers a systematic approach within the framework of neural mathematics for constructing a computational procedure. this procedure aims to solve a class of problems arising from the control of the systems with distributed parameters; these systems are modeled by second-order one-dimensional hyperbolic partial differential equations (hpdes) with non-standard boundary conditions. the procedure reveals an explicit algorithmic parallelism and is mainly based on the combination of two powerful ""tools"": a convergent method of lines (mol) and the cellular neural network (cnn) paradigm. the role of the courant-isaacson-rees rule and of the riemann invariants for a correct application of the mol is emphasized. the procedure is illustrated on a control engineering application the overhead crane with flexible cable - within a more general context which includes modeling based on the generalized hamilton variational principle, synthesis of a stabilizing controller via the control lyapunov functional (clf), qualitative analysis, numerical solving using the proposed computational procedure, numerical simulations and the evaluation of the performances for the closed loop system. the procedure ensures the convergence of the approximation, preserves the basic properties and the lyapunov stability of the solution of the initial problem and reduces the systematic errors. (c) 2015 elsevier b.v. all rights reserved.
computer_vision	we explored how computer vision techniques can be used to detect engagement while students (n = 22) completed a structured writing activity (draft-feedback-review) similar to activities encountered in educational settings. students provided engagement annotations both concurrently during the writing activity and retrospectively from videos of their faces after the activity. we used computer vision techniques to extract three sets of features from videos, heart rate, animation units (from microsoft kinect face tracker), and local binary patterns in three orthogonal planes (lbp-top). these features were used in supervised learning for detection of concurrent and retrospective self-reported engagement. area under the roc curve (auc) was used to evaluate classifier accuracy using leave-several-students-out cross validation. we achieved an auc = .758 for concurrent annotations and auc = .733 for retrospective annotations. the kinect face tracker features produced the best results among the individual channels, but the overall best results were found using a fusion of channels.
computer_graphics	this paper proposes a novel method of semi-regular remeshing for triangulated surfaces to achieve superior triangles lead to advanced visualization of 3d model. it is based on mesh segmentation and subdivision surface fitting which uses curvature-adapted polygon patches. our contribution lies in building a sophisticated system with three stages, i.e., curvature-aware mesh segmentation, submesh surface fitting to generate a high-quality semi-regular mesh and finally, stitching the segments using an efficient algorithm. our method uses centroidal voronoi tessellation and lloyd 's relaxation to generate curvature-adapted site centers. geodesic distances from site centers are used for labeling segments and indexing corner vertices for each segment boundary. using information of site centers and corner vertices, feature-adapted polygonal patches are generated for each segment. these patches are then subdivided and optimized using squared distance metric to adjust position of the subdivision sampling with segment details and prevent oversampling. at last, an efficient stitching algorithm is introduced to connect regular submeshes together and build the final semi-regular mesh. we have demonstrated the results of our semi-regular remeshing algorithm on meshes with different topology and complexity and compared them with known methods. superior triangle quality with higher aspect ratio together with acceptable distortion error is achieved according to the experimental results.
computer_programming	this paper describes the development, validation, and uses of the collaborative computing observation instrument (c-coi), a web-based analysis instrument that classifies individual and/or collaborative behaviors of students during computing problem-solving (e.g. coding, programming). the c-coi analyzes data gathered through video and audio screen recording software that captures students' computer screens as they program, and their conversations with their peers or adults. the instrument allows researchers to organize and quantify these data to track behavioral patterns that could be further analyzed for deeper understanding of persistence and/or collaborative interactions. the article provides a rationale for the c-coi including the development of a theoretical framework for measuring collaborative interactions in computer-mediated environments. this theoretical framework relied on the computer-supported collaborative learning literature related to adaptive help seeking, the joint problem-solving space in which collaborative computing occurs, and conversations related to outcomes and products of computational activities. instrument development and validation also included ongoing advisory board feedback from experts in computer science, collaborative learning, and k-12 computing as well as classroom observations to test out the constructs in the c-coi. these processes resulted in an instrument with rigorous validation procedures and a high inter-rater reliability.
system_identification	the conventional normalized subband adaptive filter (nsaf) using a constant step-size generally faces an inherent trade-off between the steady-state misalignment and the convergence rate. we propose herein a variable step-size nsaf algorithm by minimizing the mean-square deviation (msd) between the optimal weight vector and the weight vector estimate with the utilization of the shrinkage denoising technique. with the estimation error involved, in the step-size adaptation for each subband individually, the proposed algorithm is capable of tracking non-stationary environments. without the explicit whitening assumption of the input signal in each subband, the proposed algorithm exhibits low steady-state msd even when the input signal of each subband is colored. simulation results validate the low misalignment and good tracking ability of the proposed algorithm in system identification application. (c) 2016 elsevier b.v. all rights reserved.
image_processing	modern cars are equipped with both active and passive sensor systems that can detect potential collisions. in contrast, locusts avoid collisions solely by responding to certain visual cues that are associated with object looming. in neurophysiological experiments, i investigated the possibility that the 'collision-detector neurons' of locusts respond to impending collisions in films recorded with dashboard cameras of fast driving cars. in a complementary modelling approach, i developed a simple algorithm to reproduce the neuronal response that was recorded during object approach. instead of applying elaborate algorithms that factored in object recognition and optic flow discrimination, i tested the hypothesis that motion detection restricted to a 'danger zone', in which frontal collisions on the motorways are most likely, is sufficient to estimate the risk of a collision. furthermore, i investigated whether local motion vectors, obtained from the differential excitation of simulated direction-selective networks, could be used to predict evasive steering maneuvers and prevent undesired responses to motion artifacts. the results of the study demonstrate that the risk of impending collisions in real traffic scenes is mirrored in the excitation of the collision-detecting neuron (dcmd) of locusts. the modelling approach was able to reproduce this neuronal response even when the vehicle was driving at high speeds and image resolution was low (about 200 x 100 pixels). furthermore, evasive maneuvers that involved changing the steering direction and steering force could be planned by comparing the differences in the overall excitation levels of the simulated right and left direction-selective networks. additionally, it was possible to suppress undesired responses of the algorithm to translatory movements, camera shake and ground shadows by evaluating local motion vectors. these estimated collision risk values and evasive steering vectors could be used as input for a driving assistant, converting the first into braking force and the latter into steering responses to avoid collisions. since many processing steps were computed on the level of pixels and involved elements of directionselective networks, this algorithm can be implemented in hardware so that parallel computations enhance the processing speed significantly.
state_space_representation	in this paper, we present a novel kernel adaptive recurrent filtering algorithm based on the autoregressive-moving-average (arma) model, which is trained with recurrent stochastic gradient descent in the reproducing kernel hilbert spaces. this kernelized recurrent system, the kernel adaptive arma (kaarma) algorithm, brings together the theories of adaptive signal processing and recurrent neural networks (rnns), extending the current theory of kernel adaptive filtering (kaf) using the representer theorem to include feedback. compared with classical feedforward kaf methods, the kaarma algorithm provides general nonlinear solutions for complex dynamical systems in a state-space representation, with a deferred teacher signal, by propagating forward the hidden states. we demonstrate its capabilities to provide exact solutions with compact structures by solving a set of benchmark nondeterministic polynomial-complete problems involving grammatical inference. simulation results show that the kaarma algorithm outperforms equivalent input-space recurrent architectures using first-and second-order rnns, demonstrating its potential as an effective learning solution for the identification and synthesis of deterministic finite automata.
operating_systems	traditionally, digital forensics focused on artifacts located on the storage devices of computer systems, mobile phones, digital cameras, and other electronic devices. in the past decade, however, researchers have created a number of powerful memory forensics tools that expand the scope of digital forensics to include the examination of volatile memory as well. while memory forensic techniques have evolved from simple string searches to deep, structured analysis of application and kernel data structures for a number of platforms and operating systems, much research remains to be done. this paper surveys the state-of-the-art in memory forensics, provide critical analysis of current-generation techniques, describe important changes in operating systems design that impact memory forensics, and sketches important areas for further research. (c) 2017 elsevier ltd. all rights reserved.
computer_programming	computer programming as a process that embodies the creation of an executable computer program for a given computational problem by analyzing the task and developing an algorithm that computes the desired result. due to its complex and diverse nature, programming requires a certain level of expertise in analysis of algorithms, data structures, mathematics, formal logic as well as related tasks such as testing and debugging. due to increasing awareness of need for programming, there exists numerous competitive programming websites where students can practice and solve problems. the aim of our work is to assess the performance of students on such platforms. this work shall not only help the learners to self-assess themselves, but it will also aid the educators to evaluate the progress of their students. to meet this objective, the data was collected from two different competitive programming environments, namely, hackerearth- a globally accessible competitive programming website and our university 's in-house programming portal, a university-based programming environment. we used supervised learning to predict the performance of students for both the datasets. the accuracy obtained for the hackerearth dataset is 80%, while the accuracy for the university dataset was computed to be 91%. apart from predicting the performance, rigorous analyses were done unearth hidden trends responsible for a learners programming acumen.
network_security	the multi objective genetic algorithms (mo-gas) are one of the most widely used techniques that have the capability to find the solution to the problem having multiple conflicting objectives like intrusion de- tection. it is a population based technique capable of producing a set of non-inferior solutions that exhibit the classification trade-offs for the user. this capabil- ity of moga can be exploited for generating optimal base classifiers and ensembles thereof for intrusion de- tection. this paper explores the various mogas proposed in the literature along with their pros and cons. the motivation for the use of moga and its issues are high- lighted. finally, the chapter highlights the concluding remarks.
operating_systems	operating system is essential to operate computers. normally, computers come with preloaded operating systems. however, often the preloaded operating systems are not able to fulfill all requirements of users. the users sometimes need to change the operating system based on their needs. although some comparative studies and tools are available on operating systems, there is still a lack of tools that provide independent and objective review and recommendation to help the users understand and select from all major operating systems. this paper propose a tool called fsos, which analyses well-known operating systems used at domestic, commercial and industrial level and suggest suitable operating systems to the users as per their requirements.
machine_learning	we present a new approach to lightweight intelligent transportation systems. our approach does not rely on traditional expensive infrastructures, but rather on advanced machine learning algorithms. it takes images from traffic cameras at a limited number of locations and estimates the traffic over the entire road network. our approach features two main algorithms. the first is a probabilistic vehicle counting algorithm fromlow-quality images that falls into the category of unsupervised learning. the other is a network inference algorithm based on an inverse markov chain formulation that infers the traffic at arbitrary links from a limited number of observations. we evaluated our approach on two different traffic data sets, one acquired in nairobi, kenya, and the other in kyoto, japan.
computer_graphics	in this paper, we first apply cosine radial basis function neural networks to solve the fractional differential equations with initial value problems or boundary value problems. in the examples, we successfully obtained the numerical solutions for the fractional riccati equations and fractional langevin equations. the computer graphics and numerical solutions show that this method is very effective.
image_processing	inadequate skid resistance of pavement surface is a substantial reason for traffic accidents. there is a close relationship between sliding resistance and characteristics of texture morphology, demanding high precision and comprehensive acquisition of both macrotexture and microtexture morphology. the traditional three light sources photometric stereo method is improved in this study fourfold. first, six light sources are adopted to enhance the illumination and eliminate incomplete information retrieval of pavement surface image. second, a low-rank approximation is proposed in the image processing stage to significantly reduce the interference of noise, highlights, and shadow, resulting in a higher precision of reconstructed pavement surface compared with the existing photometric stereo method using three light sources. third, unlike the control point-based weighting algorithm, a control point-based surface interpolation algorithm is established, which can further optimizes the precision of the reconstructed surface by combining the effect of global integration with the elevation of positions of relative points. under testing in indoor conditions, a surface interpolation photometric stereo method with 2,500 control points and using low-rank approximation can effectively measure both macrotexture and microtexture morphology. last, low-rank approximation and global integration with six light sources is used to relax the requirement of the surface interpolation photometric stereo method on control points. statistical analysis indicates that low-rank approximation and global integration with six light sources can be an effective method for reconstructing three-dimensional (3d) macrotexture and microtexture morphology. (c) 2016 american society of civil engineers.
computer_vision	this work aims to discriminate among different species of the genus cistus, using seed parameters and following the scientific plant names included as accepted in the plant list. also, the intraspecific phenotypic differentiation of c.creticus, through comparison with three subspecies (c.creticus subsp. creticus, c.c.subsp. eriocephalus and c.c. subsp. corsicus), as well as the interpopulation variability among five c.creticus subsp. eriocephalus populations was evaluated. seed mean weight and 137 morphocolorimetric quantitative variables, describing shape, size, colour and textural seed traits, were measured using image analysis techniques. measured data were analysed applying step-wise linear discriminant analysis. an overall cross-validated classification performance of 80.6% was recorded at species level. with regard to c. creticus, as case study, percentages of correct discrimination of 96.7% and 99.6% were achieved at intraspecific and interpopulation levels, respectively. in this classification model, the relevance of the colorimetric and textural descriptive features was highlighted, as well as the seed mean weight, which was the most discriminant feature at specific and intraspecific level. these achievements proved the ability of the image analysis system as highly diagnostic for systematic purposes and confirm that seeds in the genus cistus have important diagnostic value.
digital_control	the design of ""lab on a chip"" microfluidic devices is, typically, preceded by a long and costly period of prototyping stages in which the system is gradually refined by an iterative process, involving the manufacturing of a physical prototype and the making of a lot of laboratory experiments. in this scenario, a virtual prototyping framework which allows the emulation of the behavior of the complete system is greatly welcome. this paper presents such a framework and details a virtual prototyping methodology able to soundly handle microfluidic behavior based on systemc-ams extensions. the use of these extensions will permit the communication of the developed microfluidic models with external digital or mixed signal devices. this allows the emulation of the whole lab on a chip system as it usually includes a digital control and a mixed-signal reading environment. moreover, as systemc-ams is also being extended to cover other physical domains within the catrene ca701 project, interactions with these domains will be possible, for example, with electromechanical or optical parts, should they be part of the system. the presented extensions that can manage the modeling of a micro-fluidic system are detailed. two approaches have been selected: to model the fluid analytically based on the poiseuille flow theory and to model the fluid numerically following the sph (smoothed particle hydrodynamics) approach. both modeling techniques are, by now, encapsulated under the tdf (timed data flow) moc (model of computation) of systemc-ams. (c) 2015 elsevier b.v. all rights reserved.
software_engineering	generally, software re-engineering is economical and perfect way to provide much needed boost to a present software system. software re-engineering is like to obtain a fully completed software from existing software with additional features if needed. the overall process of software re-engineering is to analyze the needed requiements & its contents. it also changes the needed contents or transforms the existing software system for reconstructing a novel software system. the difficult part in re-engineering is to understand the traditional system. most of the software re-engineering mechanisms are aimed to achieve the common re-engineering objectives and the objectives are: improved software quality, reduced complexity, reduce maintenance cost and increased reliability. as a result, several traditional re-engineering mechanisms fail to verify the performance of individual functionality in existing software. this performance evaluation increases the complexity in re-engineering process. to minimizing the complexities in software re-engineering, this proposed system implements a novel approach named enhanced re-engineering mechanism. this enhanced mechanism introduces a new idea, before executing the re-build process the developer verifies the performance of particular function in existing system. after that, the function performance is compared with proposed algorithm. based on the comparison process only rebuild process should be carried out. finally this proposed mechanism reduces the complexities in software re-engineering.
signal-flow_graph	a topological method for obtaining the jacobian and hessian matrices of active networks is presented. it is based on the replacement of the investigated network by using a nullor equivalent circuit and on the representation of the circuit passive part by a chan-mai signal-flow graph (cmsfg). the jacobian and the hessian matrix elements of the nullor network can be obtained by means of the some dependent variables of two or four isomorphic cmsfgs, respectively. two examples illustrate the proposed method.
relational_databases	during the last decades, we assisted to what is called ""information explosion"". with the advent of the new technologies and new contexts, the volume, velocity and variety of data has increased exponentially, becoming what is known today as big data. among them, we emphasize telecommunications operators, which gather, using network monitoring equipment, millions of network event records, the call detail records (cdrs) and the event detail records (edrs), commonly known as xdrs. these records are stored and later processed to compute network performance and quality of service metrics. with the ever increasing number of collected xdrs, its generated volume needing to be stored has increased exponentially, making the current solutions based on relational databases not suited anymore. to tackle this problem, the relational data store can be replaced by hadoop file system (hdfs). however, hdfs is simply a distributed file system, this way not supporting any aspect of the relational paradigm. to overcome this difficulty, this paper presents a framework that enables the current systems inserting data into relational databases, to keep doing it transparently when migrating to hadoop. as proof of concept, the developed platform was integrated with the altaia - a performance and qos management of telecommunications networks and services.
electrical_network	external overvoltages constitute a typical cause of faults, damages and interruptions in the electrical networks' high-voltage transmission lines. in order to protect the lines and their equipment against lightning, overhead ground wires in combination with surge arresters are installed, improving the lightning performance of the system and reducing the annual failure rate. the achievement of low values of earth resistance is an essential requirement, since a good grounding system reduces considerably the corresponding insulation breakdowns. however, the behaviour of surge arresters in relation to the grounding resistance is different, as it depends on the position of the lightning hit. the current work is devoted to the sensitivity analysis of the failure probability of surge arresters with relation to the grounding resistance, investigating concurrently the effect of the arresters' installation interval and the energy absorption capability.
electricity	petrochemical plants require the addition and removal of energy to and from the process and the movement of material to, from, and within the process piping and vessels. these fundamental mass and energy transfer requirements are typically achieved through the use of process utilities, which include electricity, steam, fuel gas, cooling water and compressed air. utilities are responsible for a significant portion of the operating cost of a plant. therefore, reduction in the consumption of utilities is a common process optimisation area. the situation is different when it comes to the generation and transportation of these utilities, which are often overlooked with regard to optimisation. in this paper, the potential benefits of utility optimisation are illustrated with particular focus on the generation and transportation areas. the main objectives are reductions in electrical energy consumption and cost and are illustrated for a dual circuit cooling water system. this system is non-linear and also hybrid in the sense that it contains both continuous and discrete input variables, which significantly complicates the design and implementation of control and optimisation solutions. this paper illustrates how the cost and energy consumption of a hybrid system can be reduced through the implementation of hybrid non-linear model predictive control (hnmpc) and economic hnmpc (ehnmpc). the results are compared to that of a base case and an advanced regulatory control (arc) case, showing that significant additional benefit may be achieved through the implementation of these advanced control and optimisation techniques. the paper further illustrates that additional capital is not necessarily required for the implementation of these techniques. (c) 2017 elsevier ltd. all rights reserved.
bioinformatics	purpose. applying cnga3 gene augmentation therapy to cure a novel causative mutation underlying achromatopsia (achm) in sheep. methods. impaired vision that spontaneously appeared in newborn lambs was characterized by behavioral, electroretinographic (erg), and histologic techniques. deep-sequencing reads of an affected lamb and an unaffected lamb were compared within conserved genomic regions orthologous to human genes involved in similar visual impairment. observed nonsynonymous amino acid substitutions were classified by their deleteriousness score. the putative causative mutation was assessed by producing compound cnga3 heterozygotes and applying gene augmentation therapy using the orthologous human cdna. results. behavioral assessment revealed day blindness, and subsequent erg examination showed attenuated photopic responses. histologic and immunohistochemical examination of affected sheep eyes did not reveal degeneration, and cone photoreceptors expressing cnga3 were present. bioinformatics and sequencing analyses suggested a c. 1618g>a, p. gly540ser substitution in the gmp-binding domain of cnga3 as the causative mutation. this was confirmed by genetic concordance test and by genetic complementation experiment: all five compound cnga3 heterozygotes, carrying both p. arg236* and p. gly540ser mutations in cnga3, were day-blind. furthermore, subretinal delivery of the intact human cnga3 gene using an adeno-associated viral vector (aav) restored photopic vision in two affected p. gly540ser homozygous rams. conclusions. the c. 1618g>a, p. gly540ser substitution in cnga3 was identified as the causative mutation for a novel form of achm in awassi sheep. gene augmentation therapy restored vision in the affected sheep. this novel mutation provides a large-animal model that is valid for most human cnga3 achm patients; the majority of them carry missense rather than premature-termination mutations.
parallel_computing	this article presents recent efforts in improving the efficiency and scalability of the mixed cell computation step in the context of the polyhedral homotopy method. solving systems of polynomial equations is an important problem in applied mathematics. the polyhedral homotopy method is an important numerical method for this task. in this method, a necessary preprocessing step, known as the ""mixed cell computation"" problem has been the main bottleneck in the parallel efficiency and scalability. this article presents recent remarkable improvements in the parallel scalability of the algorithm that are applicable to a wide range of hardware architectures including multi-core systems, numa systems, computer clusters, and gpus devices. (c) 2016 elsevier ltd. all rights reserved.
operational_amplifier	four parts of opamp op1177arz manufactured by analog devices have been tested. the chips have been compared visually and with specialized software. forms of ionization response in three checkpoints have been registered, and maps of response amplitudes on the crystal surface have been constructed. it has been fixed, that crystals samples are various in spite of identical crystals marking. so tid behavior of various samples has been observed.
analog_signal_processing	a variable ratio gearbox (vrg) can be used in the drivetrain of a small to medium-size wind turbine to improve aerodynamic efficiency. currently, all commercially-available wind turbines operate using a fixed-gear ratio between the turbine rotor and electrical generator. a vrg allows wind turbines, with a constant-speed generator, to discretely vary rotor speed and to achieve greater aerodynamic efficiency. the authors' previous results demonstrate the viability of the vrg design. this research quantifies the gain in efficiency for a vrg-enabled wind turbine based on wind data from representing all seven wind classifications. a method is also presented to identify turbine sites that provide the vrg with the greatest opportunities to increase production. the overall findings suggest that the vrg can benefit all wind turbines, irrespective of wind class, with some wind profiles in the study experiencing gains greater than 10%. (c) 2012 elsevier ltd. all rights reserved.
digital_control	the nonideal effects of the comparator and dead time in a synchronous controlled dc-dc converter adversely affect the stability of a four-switch noninverting-buck-boost (nibb) converter. the pulse-skipping phenomenon occurs in the mode-transition region near the boundary between the step-down and step-up regions, and this phenomenon leads to an unstable output voltage and an unpredictable output voltage ripple. however, these two results may damage the entire power system and application system. this brief proposes an enhanced duty-cycle-overlap control technique for a digitally controlled nibb converter. the proposed technique offers two duty cycle limitations for various conditions in the mode-transition region and ensures the stability of the digital controller and output voltage. moreover, this technique involves combining the duty cycles of both step-down and step-upmodes for deriving an accurate value of the output voltage. the experimental results derived from a digital controller implemented through a field-programmable-gate-array-based platform revealed that the output voltage of the nibb converter was stable throughout the transition region. the observed input voltage of the converter, provided by a li-ion battery, was 2.5-4.5 v, and the output voltage was typically 3.3 v, which is suitable for communication systems, audio systems, and i/o pad power supplies. the switching frequency was 1 mhz, and the maximum load current was 500 ma.
image_processing	previous studies have demonstrated that matrix factorization techniques, such as nonnegative matrix factorization (nmf) and concept factorization (cf), have yielded impressive results in image processing and data representation. however, conventional cf and its variants with single layer factorization fail to capture the intrinsic structure of data. in this paper, we propose a novel sequential factorization method, namely graph regularized multilayer concept factorization (gmcf) for clustering. gmcf is a multi-stage procedure, which decomposes the observation matrix iteratively in a number of layers. in addition, gmcf further incorporates graph laplacian regularization in each layer to efficiently preserve the manifold structure of data. an efficient iterative updating scheme is developed for optimizing gmcf. the convergence of this algorithm is strictly proved; the computational complexity is detailedly analyzed. extensive experiments demonstrate that gmcf owns the superiorities in terms of data representation and clustering performance. (c) 2017 elsevier b.v. all rights reserved.
cryptography	in a digital multisignature scheme, two or more signers are allowed to produce a single signature on a common message, which can be verified by anyone. in the literature, many schemes are available based on the public key infrastructure or identity-based cryptosystem with bilinear pairing and map-to-point (mtp) hash function. the bilinear pairing and the mtp function are time-consuming operations and they need a large super-singular elliptic curve group. moreover, the cryptosystems based on them are difficult to implement and less efficient for practical use. to the best of our knowledge, certificateless digital multisignature scheme without pairing and mtp hash function has not yet been devised and the same objective has been fulfilled in this paper. furthermore, we formally prove the security of our scheme in the random oracle model under the assumption that ecdlp is hard.
cryptography	mds matrices are of great importance in the design of block ciphers and hash functions. mds matrices are not sparse and have a large description and thus induce costly implementation in software/hardware. to overcome this problem, in particular for applications in light-weight cryptography, it was proposed by guo et al. to use recursive mds matrices. a recursive mds matrix is an mds matrix which can be expressed as a power of some companion matrix. following the work of guo et al., some ad-hoc search techniques are proposed to find recursive mds matrices which are suitable for hardware/software implementation. in another direction, coding theoretic techniques are used to directly construct recursive mds matrices: berger technique uses gabidulin codes and augot et al. technique uses shortened bch codes. in this paper, we first characterize the polynomials that yield recursive mds matrices in a more general setting. based on this we provide three methods for obtaining such polynomials. moreover, the recursive mds matrices obtained using shortened bch codes can also be obtained with our first method. in fact we get a larger set of polynomials than the method which uses shortened bch codes. our other methods appear similar to the method which uses gabidulin codes. we get a new infinite class of recursive mds matrices from one of the proposed methods. although we propose three methods for the direct construction of recursive mds matrices, our characterization results pave the way for new direct constructions.
symbolic_computation	in this paper, the solution of limit problems, which is an important subject of high school and university mathematics is presented by using javacc code generation tool and symbolic computation methods. although javacc is generally used for generating programming language interpreters, in a similar way it can also be used in the evaluation of mathematical expressions. in this work, first the general grammar rules of limit expressions is extracted. then parser code for the limit expressions is generated with javacc according to the grammar rules. using the list of the tokens into which a limit expression is parsed with this code, an abstract syntax tree (ast) is constructed. finally, the solution is obtained by interpreting the ast with a class of visitor design pattern. the study can be regarded as a promising contribution to computer assisted education.
electrical_circuits	automata synchronization has many important applications, mostly in conformance testing of electrical circuits, self-correcting codes and protocol testing. finding a shortest synchronizing word cannot be done in polynomial time, assuming p not equal np. in some situations, especially for very large automata, finding such a word is almost impossible. therefore, we accept any synchronizing word that is reasonably short and can be calculated in short time. the existing algorithms are either polynomial (quick, but not optimal) or exponential (exact, but useless in case of large automata). in this paper we present a flexible algorithmic framework for synchronization. it allows the user to parameterize the algorithm to obtain a desired balance in terms of a trade-off between memory usage, runtime and optimality. we also discuss many practical issues that affect efficiency of an implementation. in particular, we design a new polynomial backward algorithm, which works significantly better than previously used heuristic algorithms. finally, we present detailed results of experiments involving automata up to 2000 states, which compare our algorithms in various settings and the other known algorithms, and check the impact of different parameters on the results. (c) 2015 elsevier ltd. all rights reserved.
electrical_circuits	colloidal behavior of a widely used non-ionic emulsifier, sorbitan monooleate (span80), was investigated in non-polar solvents (cyclohexane and xylene) using electrical impedance spectroscopy (eis). the electrical characteristics of the colloidal mixtures were measured with frequency scans ranging from 1 hz to 200 khz. the conductances at low frequencies were found to increase with an increase in span80 concentration. the source of conductivity for non-polar solvents using non-ionic emulsifiers is usually attributed to ionic impurities either in the span80 or in the non-polar solvents. the measured electrical characteristics for pure span80 and pure non-polar solvents revealed that the source of ionic conduction is impurities in span80. it was confirmed that the ionic impurities in the non-polar solvents are in form of aggregate of ions, ion-pairs, and triple ions which is unaffected with the emulsifier concentration. analyses using equivalent electrical circuits confirmed that the critical maxwell-wagner frequency is 0.6-1.8 hz for the mixtures. the conductance-concentration profiles for the mixtures at 1 hz showed transitions from a square root to a linear concentration dependence at the cmc. this indicated that the dissociation model holds below the cmc, while the fluctuation model applies above the cmc. the conductance profiles enabled estimates of the relative hydrophilic core radius and the fraction of charged micelles in both non-polar solvents.
data_structures	network intrusion detection systems (nids) are deployed to protect computer networks from malicious attacks. proper evaluation of nids requires more scrutiny than the evaluation for general network appliances. this evaluation is commonly performed by sending pregenerated traffic through the nids. unfortunately, this technique is often limited in diversity resulting in evaluations incapable of examining the complex data structures employed by nids. more sophisticated methods that generate workload directly from nids rules consume excessive resources and are incapable of running in real-time. this work proposes a novel approach to real-time workload generation for nids evaluation to improve evaluation diversity while maintaining much higher throughput. this work proposes a generative grammar which represents an optimized version of a context-free grammar derived from the set of strings matching to the given nids rule database. the grammar is memory-efficient and computationally light when generating workload. experiments demonstrate that grammar-generated workloads exert an order of magnitude more effort on the target nids. even better, this improved diversity comes at much smaller cost in memory and speeds four times faster than current approaches.
electric_motor	the additional design consideration of a plug-in hybrid electric vehicle (phev) caused by its recharging capability requires an optimal hybrid powertrain control strategy to fully exploit the vehicle 's capability. amongst many aspects of control algorithm development and design optimisation, the advantage of including a pure electric vehicle (ev) mode in the vehicle driving modes of a phev with a post-transmission electric motor was studied in this research. for this purpose, architecture of a series-parallel phev was determined and its simulation model was developed. then, various simulations were conducted to evaluate technical merits of the pure ev mode in terms of fuel economy and emissions. the simulation results favourably supports inclusion of the pure ev mode as one of the driving modes in the powertrain control strategy of the studied phev model with a post-transmission electric motor.
algorithm_design	opencl is a portable interface that can be used to program cluster nodes with heterogeneous compute devices. the opencl specification tightly binds its workflow abstraction, or ""command queue,"" to a specific device for the entire program. for best performance, the user has to find the ideal queue device mapping at command queue creation time, an effort that requires a thorough understanding of the match between the characteristics of all the underlying device architectures and the kernels in the program. in this paper, we propose to add scheduling attributes to the opencl context and command queue objects that can be leveraged by an intelligent runtime scheduler to automatically perform ideal queue device mapping. our proposed extensions enable the average opencl programmer to focus on the algorithm design rather than scheduling and automatically gain performance without sacrificing programmability. as an example, we design and implement an opencl runtime for task-parallel workloads, called multicl, which efficiently schedules command queues across devices. within multicl, we implement several key optimizations to reduce runtime overhead. our case studies include the snu-npb opencl benchmark suite and a real-world seismology simulation. we show that, on average, users have to apply our proposed scheduler extensions to only four source lines of code in existing opencl applications in order to automatically benefit from our runtime optimizations. we also show that multicl always maps command queues to the optimal device set with negligible runtime overhead.
structured_storage	the burgeoning volume of torrential data continues to grow exponentially in this very age of the internet of things. as this torrent of digital datasets continue to outgrow in datacenters, the focus needs to be shifted to stored data reduction methods and that too pertaining to nosql databases as traditional structured storage systems continuously tend to face challenges in providing the required storage, throughputs and computational power requirements necessary to capture, store, manage and analyze the deluge of data. deduplication systems, thus designed, retain a single copy of redundant data on disk to save disk space, but what if we want to keep certain copies intentionally and need wishful elimination. this paper leverages hadoop framework to design and develop a duplication detection system that detects multiple copies of the same data right at the file level itself and that too before transmission. thereafter, various datasets are tuned for better performance and analysed using mapreduce, hive and pig.
symbolic_computation	in this paper, we consider a variable coefficient calogero-degasperis equation, a variable coefficient potential kadomstev-petviashvili equation and the generalized (3+1)-dimensional variable coefficient kadomtsev-petviashvili equation with time-dependent coefficients. shock wave solutions for the considered models are obtained by using ansatz method in the form of tanhp function. the physical parameters in the soliton solutions are obtained as functions of the dependent coefficients. copyright (c) 2016 john wiley & sons, ltd.
distributed_computing	the local(a, b) randomized task scheduling algorithm is proposed for fully connected multiprocessors. it combines two given task scheduling algorithms (a, and b) using local neighborhood search to give a hybrid of the two given algorithms. objective is to show that such type of hybridization can give much better performance results in terms of parallel execution times. two task scheduling algorithms are selected: dsc (dominant sequence clustering as algorithms a), and cf'f's (cluster pair priority scheduling as algorithm b) and a hybrid is created (the local(dsc, cpps) or simply the local task scheduling algorithm). the local task scheduling algorithm has time complexity 0(broken vertical bar v broken vertical bar broken vertical bar 1e broken vertical bar(vertical bar v broken vertical bar + broken vertical bar e broken vertical bar)), where v is the set of vertices, and p is the set of edges in the task graph. the local task scheduling algorithm is compared with six other algorithms: cf'f's, dccl ((dynamic computation. communication load), dsc, ez (edge zeroing),. (linear clustering), and rdcc (randomized dynamic computation comm,unicalion). performance evaluation of the i oc al task scheduling algorithm shows that it gives up to 80.47 c improvement of nsl (normalized schedule length) over other algorithms.
control_engineering	the increasing pressures faced by manufacturers, the shortening of innovation cycles and the growing importance of high-efficiency manufacturing demand a higher versatility of factory automation. in order to achieve this target, engineering tasks currently performed manually need to be automated. in this case, ontologies emerge as a significant method for representing manufacturing knowledge in a machine-interpretable way. this knowledge can then be used by automated problem-solving methods to reconfigure the control software that coordinates and supervises manufacturing systems. besides, ontology can play a very important role in the process of creating as well as managing the knowledge. this paper addresses the important issues in developing domain-specific ontology for manufacturing used in industry 4.0 demonstration production line. a generic ontology is developed considering all the aspects about product from customized order to resulting production.
symbolic_computation	systems of polynomial equations arise throughout mathematics, engineering, and the sciences. it is therefore a fundamental problem both in mathematics and in application areas to find the solution sets of polynomial systems. the focus of this paper is to compare two fundamentally different approaches to computing and representing the solutions of polynomial systems: numerical homotopy continuation and symbolic computation. several illustrative examples are considered, using the software packages bertini and singular. (c) 2014 elsevier inc. all rights reserved.
